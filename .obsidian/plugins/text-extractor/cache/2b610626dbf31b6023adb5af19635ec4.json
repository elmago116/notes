{"path":"Clippings/PDF/Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing? A Structured Review.pdf","text":"arXiv:2202.12205v2 [cs.AI] 30 Jun 2022 Is Neuro-Symbolic AI Meeting its Promise in Natural Language Processing? A Structured Review Kyle Hamilton *, Aparna Nayak, Bojan Boži´c and Luca Longo SFI Centre for Research Training in Machine Learning, School of Computer Science, Technological University Dublin, Republic of Ireland E-mails: kyle.i.hamilton@mytudublin.ie, aparna.nayak@tudublin.ie, bojan.bozic@tudublin.ie, luca.longo@tudublin.ie Abstract. Advocates for Neuro-Symbolic Artiﬁcial Intelligence (NeSy) assert that combining deep learning with symbolic reasoning will lead to stronger AI than either paradigm on its own. As successful as deep learning has been, it is generally accepted that even our best deep learning systems are not very good at abstract reasoning. And since reasoning is inextricably linked to language, it makes intuitive sense that Natural Language Processing (NLP), would be a particularly well-suited candidate for NeSy. We conduct a structured review of studies implementing NeSy for NLP, with the aim of answering the question of whether NeSy is indeed meeting its promises: reasoning, out-of-distribution generalization, interpretability, learning and reasoning from small data, and transferability to new domains. We examine the impact of knowledge representation, such as rules and semantic networks, language structure and relational structure, and whether implicit or explicit reasoning contributes to higher promise scores. We ﬁnd that systems where logic is compiled into the neural network lead to the most NeSy goals being satisﬁed, while other factors such as knowledge representation, or type of neural architecture do not exhibit a clear correlation with goals being met. We ﬁnd many discrepancies in how reasoning is deﬁned, speciﬁcally in relation to human level reasoning, which impact decisions about model architectures and drive conclusions which are not always consistent across studies. Hence we advocate for a more methodical approach to the application of theories of human reasoning as well as the development of appropriate benchmarks, which we hope can lead to a better understanding of progress in the ﬁeld. We make our data and code available on github for further analysis.1 Keywords: Neuro-Symbolic Artiﬁcial Intelligence, Natural Language Processing, Deep Learning, Knowledge Representation & Reasoning, Structured Review 1. Introduction At its core, Neuro-Symbolic AI (NeSy) is “the combination of deep learning and symbolic reasoning” [1]. The goal of NeSy is to address the weaknesses of each of symbolic and sub-symbolic (neural, connectionist) approaches while preserving their strengths (see ﬁgure 1). Thus NeSy promises to deliver a best-of-both-worlds approach which embodies the “two most fundamental aspects of intelligent cognitive behavior: the ability to learn from experience, and the ability to reason from what has been learned” [1, 2]. Fig. 1. Symbolic vs Sub-Symbolic strengths and weaknesses. Based on the work of [8] Remarkable progress has been made on the learning side, especially in the area of Natural Language Processing (NLP) and in particular with deep learning architectures such as the Transformer [3, 4]. However, these systems display certain intrinsic weaknesses which some researchers [5, 6] argue cannot be addressed by deep learning alone and that in order to do even the most basic reasoning, we need rich representations which enable precise, human interpretable inference via mathematical logic.2 Recently, a discussion between Gary Marcus and Yoshua Bengio at the 2019 Montreal AI Debate prompted some passionate exchanges in AI circles, with Marcus arguing that “expecting a monolithic architecture to handle abstraction and reasoning is unrealistic”, while Bengio defended the stance that “sequential reasoning can be performed while staying in a deep learning framework” [9]. Spurred by this discussion, and almost ironically, by the success of deep learning (and ergo, the clarity into its limitations), research into hybrid solutions has seen a dramatic increase (see ﬁgure 2). At the same time, discussion in the AI community has culminated in “violent agreement” [10] that the next phase of AI research will be about “combining neural and symbolic approaches in the sense of NeSy AI [which] is at least a path forward to much stronger AI systems” [11]. Much of this discussion centers around the ability (or inability) of deep learning to reason, and in particular, to reason outside of the training distribution. Indeed, at IJCAI 2021, Yoshua Bengio afﬁrms that “we need a new learning theory to deal with Out-of-Distribution generalization” [12]. Bengio’s talk is titled “System 2 Deep Learning: Higher-Level Cognition, Agency, Out-of- Distribution Generalization and Causality.” Here, System 2 refers to the System 1/System 2 dual process theory of human reasoning explicated by psychologist and Nobel laureate Daniel Kahneman in his 2011 book “Thinking, Fast and Slow” [13]. AI researchers [1, 6, 14–18] have drawn many parallels between the characteristics of sub-symbolic and symbolic AI systems and human reasoning with System 1/System 2. Broadly speaking, sub-symbolic (neural, deep-learning) architectures are said to be akin to the fast, intuitive, often biased and/or logically ﬂawed System 1. And the more deliberative, slow, sequential System 2 can be thought of as symbolic or logical. But this is not the only theory of human reasoning as we will discuss later in this paper. It should also be noted that Kahneman himself has cautioned against the over reliance on the System 1/System 2 analogy in a followup discussion at the Montreal AI Debate 2 the following year, stating, “I think that this idea of two systems may have been adopted more than it should have been.”3 1.1. Reasoning & Language “Language understanding in the broadest sense of the term, including question answering that requires commonsense reasoning, offers probably the most complete application area of neurosymbolic AI” [1]. This makes a lot of intuitive sense from a linguistic perspective. If we accept that language is compositional, with rules and structure, then it should be possible to obtain its meaning via logical reasoning. Compositionality in language was formalized by Richard Montague in the 1970s, in what is now referred to as Montague grammar: “The key idea Fig. 2. Number of Neuro Symbolic articles published since 2010, normalized by the total number of all Computer Science articles published each year. The ﬁgure represents the unﬁltered results from Scopus given the search keywords described in section 5.2. is that compositionality requires the existence of a homomorphism between the expressions of a language and the meanings of those expressions.”4 In other words, there is a direct relationship between syntax and semantics (meaning). This is in line with Noam Chomsky’s Universal grammar5 which states that there is a structure to natural language which is innate and universal to all humans, and is governed by precise mathematical rules. While an analysis of the study of linguistics is beyond the scope of this paper, the key takeaway is this: what makes such theories so attractive to computational linguists is that meaning can be derived from syntactic structures which can be translated into computer programs. Today, industrial strength tools for extracting these structures (i.e., part-of- speech tagging, constituency parsing, dependency parsing) are readily available, such as for example NLTK6 or SpaCy7. The challenge lies in representing and utilizing these structures in a way that both captures the semantics and is computationally efﬁcient. On the one hand, distributed representations are desirable because they can be efﬁciently processed by gradient descent (the backbone of deep learning). The downside is that the meaning embedded in a distributed representation is difﬁcult if not impossible to decompose. So while a Large Language Model (LLM), a deep learning language model based on the principle of distributional semantics, may be very good at making certain types of predictions, it cannot be queried for answers not present in the training data by way of analogy or logic. We have also seen that even as these models get infeasibly large - the larger the model, the better the predictions [19] - they still fail on tasks requiring basic commonsense. The example in Figure 3, given by Marcus and Davis in [20] is a case in point. You are having a small dinner party. You want to serve dinner in the living room. The dining room table is wider than the doorway, so to get it into the living room, you will have to remove the door. You have a table saw, so you cut the door in half and remove the top half. Fig. 3. Third Generation Generative Pre-trained Transformer (GPT3) [21] text completion example. The prompt is rendered in regular font, while the GPT3 response is shown in bold. It is clear that GPT3 is incapable of commonsense. On the other hand, traditional symbolic approaches have also failed to capture the essence of human reasoning. While we may not yet understand exactly how people reason, it is generally accepted that human reasoning is nothing like the rigorous mathematical logic where the goal is validity. Though not for lack of ambition - Socrates got himself killed trying to get people to reason with logic [22]. In the Dictionary of Cognitive Science [23], Pascal Engel describes reasoning in a natural setting as “ridden with errors and paralogisms.” Engel refers to Daniel Kahneman, Amos Tversky, Philip Wason, among others, who have conducted numerous experiments and written extensively showing how logical fallacies and “noise” can lead to those errors [13, 24]. But even when the objective is not to emulate human thinking, but rather the execution of tasks which require precise, deterministic answers such as expert reasoning or planning, traditional symbolic reasoners are slow, cumbersome, and computationally intractable at scale, “typically subject to combinatorial explosions that limit both the number of axioms, the number of individuals and relations described by these axioms, and the depth of reasoning that is possible” [18]. For example, Description Logics (DLs) such as OWL8 are used to reason over ontologies and knowledge graphs (KGs). However, one must accept a harsh trade-off between expressivity and complexity when choosing a DL ﬂavor. Improving the performance of reasoning over ontologies and knowledge graphs that power search and information retrieval across the web is particularly relevant to the Semantic Web community. Hitzler et al. [25] report on recent research on neuro-symbolic integration in relation to the Semantic Web ﬁeld, with a focus on the promises and possible beneﬁts for both. The remainder of this manuscript is structured as follows. Section 2 offers a brief history of NLP in the context of reasoning. Several recent surveys and their contributions to NeSy are discussed in section 3, and are intended as an introduction to the ﬁeld. Our contribution is given in section 4, which also details the goals of NeSy selected for this survey. Section 5 describes the research methods employed for searching and analysing relevant studies. In Section 6 we analyze the results of the data extraction, how the studies reviewed ﬁt into Henry Kautz’s NeSy taxonomy [10], and we propose a simpliﬁed nomenclature for describing Kautz’s NeSy categories. Section 7 discusses the limitations and challenges of the reviewed implementations. Section 8 presents limitations of this work and future directions for NeSy in NLP, followed by the conclusion in Section 9. 2. A Brief History of NLP The study of language and reasoning goes back thousands of years, but it was not until the 1960’s that the ﬁrst computational models were realized. The Association for Computational Linguistics (ACL)9 was founded in 1962 for people working on computational problems involving human language, a ﬁeld often referred to as either computational linguistics or Natural Language Processing (NLP). Common NLP tasks are illustrated in Figure 4. Named Entity Recognition (NER) Part-of-Speech Tagging (POS) Text Categorization/ Classification Automatic Tpeech Recognition (ASR) Text-to-Speech (TTS) Syntactic Parsing Coreference Resolution Machine Translation Relation Extraction Question Answering (QA) Sentiment Analysis Semantic Parsing Paraphrase & Natural Dialog Agents Summarization NLP Fig. 4. Common Natural Language Processing tasks [26]. One of the ﬁrst NLP projects was a chat-bot named ELIZA [27], written by Joseph Weizenbaum around 1965. Given a small hand crafted set of rules, ELIZA was able to hold an, albeit superﬁcial, conversation, gaining tremendous popularity. Curiously, despite the program’s simplicity those who interacted with it, attributed to it human-like emotions. These early systems were based on pattern matching and small rule-sets, and were very limited for obvious reasons. In the 1970s and 80s linguistically rich, logic-driven, grounded systems, largely inﬂuenced by Noam Chomsky’s Universal Grammar10 were developed. The 1990s and early 2000s saw the ‘statistical revolution’ and the rise of machine learning, and work on NLP tasks focused on semantics, such as Natural Language Understanding (NLU), diminished for the next decade or so11. NLU returns to center stage, mixing techniques from previous years sometime around 2010. As a case in point, in 2011 IBM’s Watson DeepQA computer system won ﬁrst place on Jeopardy! for a prize of $1 million, competing against champions Brad Rutter and Ken Jennings.12 DeepQA is a large ensemble of techniques and models, the vast majority of which was focused on general Information Retrieval (IR), NLP/NLU, Knowledge Representation & Reasoning (KRR), and Machine Learning (ML) [28]. Broadly speaking, DeepQA is a large neuro-symbolic question answering software pipeline. In the last decade, and especially in the last few years, the emphasis on deep learning has somewhat overshadowed traditional NLP approaches. The Long Short Term Memory (LSTM) [29] architecture paved the way for the Transformer, which has generated a huge amount of optimism leading some people to believe that “deep learning is going to be able to do everything.”13 However, as already mentioned, the success of the Transformer and Large Language Models (LLMs) has also served to highlight their inherent shortcomings. This brings us to the present, or the “3rd Wave” [1], which seeks to overcome those shortcomings by combining deep learning with symbolic reasoning and knowledge, and by integrating and expanding on the work of previous decades. Areas of NLP which are said to beneﬁt from this approach are ones which require some form of reasoning or logic. In particular, Natural Language Understanding (NLU), Natural Language Inference (NLI), and Natural Language Generation (NLG). Natural Language Understanding (NLU) is a large subset of NLP containing topics particularly focused on semantics and meaning. The boundaries between NLP and NLU are not always clear and open to debate, and even when they are agreed upon, they’re somewhat arbitrary, as it’s a matter of convention and a reﬂection of history [26]. Natural Language Inference (NLI) enables tasks like semantic search, information retrieval, information extraction, machine translation, paraphrase acquisition, reading comprehension, and question answering. It is the problem of determining whether a natural language hypothesis h can reasonably be inferred from a given premise p [30]. For example, the premise “Hazel is an Australian Cattle Dog”, entails the hypothesis “Hazel is a dog”, and can be expressed in First Order Logic (FOL) by: p |= h. Natural Language Generation (NLG) is the task of generating text or speech from non-linguistic (structured) input [31]. It can be seen as orthogonal to NLU, where the input is natural language. An end-to-end system can be made up of both NLU and NLG components. When that is the case, what happens in the middle is not always that clear-cut. A neural language model such as GPT3 [21] has no structured component, however, whether it performs “understanding” is subject to debate - Figure 5. 3. Related Work Several recent surveys [1, 7, 8, 11, 15–18, 32] cover neuro-symbolic architectures in detail. Our aim is not to produce another NeSy survey, but rather to examine whether the promises of NeSy in NLP are materializing. However, for completeness, and by way of introduction to the subject, we brieﬂy summarize each of these surveys and provide references for the architectures under review. In response to recent discussions in the AI community and the resurgence of interest in NeSy AI, Garcez et al. [1] synthesize the last 20 years of research in the ﬁeld in the context of the aforementioned debate. The authors highlight the need for trustworthiness, interpretability, and accountability in AI systems, which ostensibly, NeSy is most Natural Language Natural Language (a) Symbolic view - reasoning is performed explicitly via rules and logic Natural Language Natural Language (b) Connectionist view - reasoning is performed implicitly inside the neural network Fig. 5. NLU takes as input unstructured text and produces output which can be reasoned over. NLG takes as input structured data and outputs a response in natural language. suited to, in particular when it comes to natural language understanding. The authors also emphasize the distinction between commonsense knowledge and expert knowledge, and suggest that these two goals may ultimately lead to two distinct research directions: “those who seek to understand and model the brain, and those who seek to achieve or improve AI.” Garcez at al. conclude that “Neurosymbolic AI is in need of standard benchmarks and associated comprehensibility tests which could in a principled way offer a fair comparative evaluation with other approaches” with a focus on the following goals: learning from fewer data, reasoning about extrapolation, reducing computational complexity, and reducing energy consumption14 - Figure 6. Reasoning about extrapolation Learning from fewer data Reducing computational complexity Reducing energy consumption Fig. 6. Neuro-Symbolic Artiﬁcial Intelligence promise areas [1] Sarker et al. [11] survey recent work in the proceedings of leading AI conferences. The authors review a total of 43 papers and classify them according to Henry Kautz’s categories 15, as well as an earlier categorisation scheme from 2005 [33]. Comparing the earlier research to the current trends, the authors conﬁrm advancements on both the neural side, as well as the logic side, with a tendency towards more expressive logics being explored today than was thought tractable in the past, and the inﬂuence of the success of neural networks on the rise in interest in NeSy in general. Sarker et al. identify four areas of AI that can beneﬁt from NeSy approaches: Learning from small data, Out of distribution handling, Intepretability, and Error recovery - Figure 7. Out of distribution handling Learning from small data Interpretability Error recovery ? Fig. 7. Neuro-Symbolic Artiﬁcial Intelligence promise areas [11] The authors conclude that “more emphasis is needed, in the immediate future, on deepening the logical aspects in NeSy research even further, and to work towards a systematic understanding and toolbox for utilizing complex logics in this context.” Based on the studies in our review, we come to a similar conclusion. Garcez et al. [8] survey recent accomplishments for integrated machine learning and reasoning motivated by the need for interpretability and accountability in AI systems. According to [8], there are three main important features of a NeSy system: Representation, Extraction, and Reasoning & Learning. Symbolic knowledge can also be categorized into three groups: rule-based, formula-based, and embedding-based. The authors categorize and describe the following neuro-symbolic architectures. Early systems such as KBANN [34] and CILP [35] embed propositional logic in a neural network by constraining the model parameters - Figure 8. Fig. 8. Knowledge representation of φ = {A ← B ∧ C, B ← C ∧ ¬D ∧ E, D ← E} using KBANN and CILP. [8] Tensorization is a process that embeds ﬁrst order logic (FOL) symbols into real-valued tensors. Reasoning is performed through matrix computation. Examples include Logic Tensor Networks (LTNs) [36] and Neural Tensor Networks (NTLs) [37] - Figure 9. Fig. 9. Logic Tensor Network (LTN) for P(x, y) → A(y) with G(x) = v and G(y) = u; G are grounding (vector representation) for symbols in ﬁrst-order language. [8] In Neural-Symbolic Learning the primary goal is learning, with the assistance of rules and logic. Different architectures are characterized by how the logic is incorporated into the network, and how it is translated into differentiable form. – Inductive Logic Programming (ILP) [38] is a set of techniques for learning logic programs from examples: * Neural Logic Programming (NLP) [39] * Differentiable Inductive Logic Programming (∂ILP) [40] * Neural Theorem Prover (NTP) [41] * Neural Logic Machines (NLMs) [42] – Horizontal Hybrid Learning combines expert knowledge in the form of rules/logic with data, thus are suitable to knowledge transfer learning (horizontally across domains). – Vertical Hybrid Learning combines symbolic and sub-symbolic modules which take inspiration from neuroscience in that certain areas of the brain are responsible for processing input signals, while other areas perform logical thinking and reasoning (vertically for a single domain). Neural-Symbolic Reasoning concerns itself with logical reasoning, as the name suggests, powered by neural computation. These consist of model-based, and theorem proving approaches. In early theorem proving systems such as SHRUTI [43] learning capability was limited. On the other hand, model-based approaches inside neural networks have been shown to demonstrate nonmonotonic, intuitionistic, abductive, and other forms of human reasoning capability. Hence, rather than attempting to perform both learning and reasoning in a single architecture, more recent designs tend to contain separate learning and reasoning modules which communicate with each other. The authors conclude that combining symbolic and sub-symbolic modules, in other words, the compositionality of neuro-symbolic systems, contributes to the development of explainable and accountable AI [44]. Yu et al. [32] divide neuro-symbolic systems into two types: heavy-reasoning light-learning and heavy-learning light-reasoning (Figure 10). These are similar to the Neural-Symbolic Reasoning and Neural-Symbolic Learning categorization in [8] above. Heavy-reasoning light-learning mainly adopts the methods of the symbolic system heavy reasoning light learning heavy learning light reasoning Fig. 10. Two types of neuro-symbolic systems: heavy reasoning light learning, and heavy learning light reasoning [32] to solve the problem in machine reasoning, and introduces neural networks to assist in solving those problems, while heavy-learning light-reasoning mainly applies methods of the neural system to solve the problem in machine learning, and introduces symbolic knowledge in the training process. – Heavy reasoning light learning (based on Statistical Relational Learning (SRL) [45]) * Probabilistic Logic Programming (ProbLog) [46] * Markov Logic Network (MLN) [47] * Inductive Logic Programming (ILP) [38] – Heavy learning light reasoning * Regularization models add symbols in the form of regular terms to the objective function as a kind of prior knowledge to guide training. * Knowledge transfer models integrate the knowledge graph that represents semantic information into the neural network model, making up for the lack of data by transferring semantic knowledge. Knowledge transfer models are mainly used to solve zero-shot learning and few-shot learning [48] tasks. Besold et al. [7] examine neuro-symbolic learning and reasoning through the lens of cognitive science, cognitive neuro-science, and human-level artiﬁcial intelligence. This is a much more theoretical approach. The authors ﬁrst describe some early systems such as CILP [35] and ﬁbring, introduced by Garcez & Gabby [49]. Fibred networks work on the principle of recursion, where multiple neural networks are connected together, such that a ﬁbring function in a network A, determines which neurons should be activated in a network B. A key characteristic of neuro-symbolic systems is modularity, where each network in the ensemble is responsible for a speciﬁc logic or task, increasing expressivity and allowing for non-classical logics to be represented such as connectionist modal, intuitionistic, temporal, nonmonotonic, epistemic and relational logic. Neuro-symbolic computation encompasses the integration of cognitive abilities - induction, deduction, abduction - and the study of mental models. The study of mental models has a long history, and the authors reference research from the ﬁeld of neuro science and cognitive science, including the “binding” problem, dual process theory (System 1/System 2), and theories of affect; with the goal of formulating these in a neuro-symbolic system. Of particular interest to our work are the two sections on Syntactic Structures, and Compositionality, as they both deal with modeling language. Psycho-linguists have different theories of language morphology (study of the internal construction of words 16), with some arguing for association based explanations (McClelland [50]), while others argue for a rule-based one (Pinker [51]) - the question being whether it is better to model language through a connectionist approach, per McClelland, or a symbolic one, as per Pinker. Whether to model language in a connectionist or symbolic manner hinges also on its inherent compositionality17. Von Rueden et al. [17] propose a taxonomy for integrating prior knowledge into learning systems. This is an extensive work covering types of knowledge and knowledge representations, neuro-symbolic integration approaches, motivations for each approach, challenges and future directions. The authors categorize knowledge into three types: scientiﬁc knowledge, world knowledge, and expert knowledge. Furthermore, knowledge representations are classiﬁed into eight types - Figure 11. Fig. 11. Types of knowledge representation [17]. Given that our work deals with natural language as input, we are only concerned with Logic Rules (which we subdivide into rules and logic) and Knowledge Graphs (which we subdivide into frames and semantic networks) - see section 6.2.2 Zhang et al. [15] survey the area of neuro-symbolic reasoning on Knowledge Graphs (KGs). The authors contribute a uniﬁed reasoning framework for Knowledge Graph Completion (KGC) and Knowledge Graph Question Answering (KGQA). Among future directions, the authors advocate for taking inspiration from human cognition for neural-symbolic reasoning in KGs, alluding to the dual model of human reasoning (System 1/System 2). Additional future directions include: – Few-shot Reasoning which addresses the issue of few labeled examples. – Reasoning upon Multi-sources which incorporates additional information from unstructured text. – Dynamic Reasoning which deals with inferring new facts evolving over time. – Analogical Reasoning (AR) which involves the use of past experiences to solve problems that are similar to problems solved before. Case Based Reasoning (CBR) is an example of AR [52]. – Knowledge Graph Pre-training which enables transfer learning for domain adaptation. Lamb et al. [16] review the state of the art on the use of Graph Neural Networks (GNNs) in NeSy (Figure 12). Similar to [1] and our work, this survey is motivated by the AI Debate in Montreal. Henry Kautz’s NeSy taxonomy (a) (b) Fig. 12. Graph Neural Network (GNN) intuition: generate node embeddings based on local neighborhoods, where nodes aggregate information from their neighbors using neural networks (a). The network neighborhood deﬁnes a computation graph such that every node corresponds to a unique computation graph (b). The key distinctions are in how different approaches aggregate information across the layers [53].18 is used as a foundation for describing NeSy systems. A high level overview of state of the art neural architectures (convolutional layers, recurrent layers, and attention) is given, followed by a discussion of each of the following: – Logic Tensor Networks (LTNs) [36] (Figure 9). – Pointer Networks [54]. Pointer networks are based on the encoder/decoder with attention (ie. transformer) architecture, with the modiﬁcation that the input length can vary. This architecture lends itself to combinatorial optimization problems such as the Traveling Salesperson Problem (TSP). – Graph Convolutional Networks (GCNs) [55] can be thought of as a generalization of Convolutional Neural Networks (CNNs) for non-grid topologies. – Graph Neural Network Model [56] - early GNN architecture similar to GCN. – Message-passing Neural Networks - similar to GNN with a slightly modiﬁed update function [16]. – Graph Attention Networks (GATs) [57] - implement an attention mechanism enabling vertices to weigh neighbor representations during their aggregation. GATs are known to outperform typical GCN architectures for graph classiﬁcation tasks. According to the authors, GNNs endowed with attention mechanisms “are a promising direction of research towards the provision of rich reasoning and learning in [Kautz’s] type 6 neuralsymbolic systems.” In NLP, GATs have enabled substantial improvements in several tasks through transfer learning over pretrained transformer language models, 19 while GCNs have been shown to improve upon the state-of-the-art for seq2seq models [58]. GNN models have also been successfully applied to relational tasks over knowledge bases, such as link prediction [59].20 The authors posit that the application of GNNs in NeSy will bring the following beneﬁts: – Extrapolation of a learned classiﬁcation of graphs as Hamiltonian, to graphs of arbitrary size. – Reasoning about a learned graph structure to generalise beyond the distribution of the training data. – Reasoning about the partO f (X; Y) relation (e.g., to make sense of handwritten MNIST digits and non-digits). – Using an adequate self-attention mechanism to make combinatorial reasoning computationally efﬁcient. Belle [18] aims to disabuse the reader of the “common misconception that logic is for discrete properties, whereas probability theory and machine learning, more generally, is for continuous properties.” The author advocates for tackling problems that symbolic logic and machine learning might struggle to address individually such as time, space, abstraction, causality, quantiﬁed generalizations, relational abstractions, unknown domains, and unforeseen examples. Harmelen & Teije [60] present a conceptual framework to categorize the techniques for combining learning and reasoning via a set of design patterns. “Broadly recognized advantages of such design patterns are they distill previous experience in a reusable form for future design activities, they encourage re-use of code, they allow composition of such patterns into more complex systems, and they provide a common language in a community.” A graphical notation is introduced where boxes with labels represent symbolic, and sub-symbolic modules, connected with arrows. Harmelen & Teije’s boxology representation of AlphaGo is given in ﬁgure 13. data ML sym KR sym Fig. 13. Schematic diagram using the boxology graphical notation of the AlphaGo system. Ovals denote algorithmic components (i.e. objects that perform some computation), and boxes denote their input and output (i.e. data structures) [60]. Earlier surveys [33, 61–64] tend to focus more on logic and logic programming, and less on learning, which is not surprising given that the ground breaking successes in deep learning are relatively recent. Several themes run through the above listed works, namely, the inherent strengths and weaknesses of symbolic and sub-symbolic techniques when taken in isolation, the types of problems which NeSy promises to solve, and the development of approaches over time. Two future directions of particular interest to our work emerge: building systems which take inspiration from human cognition and reasoning, and the integration of unstructured data. To our knowledge there is no survey speciﬁcally covering the application of NeSy computing for Natural Language Processing (NLP) where the input data is both unstructured and replete with the ambiguities and inconsistencies of human reasoning. 4. Contributions Our aim is to analyze recent work implementing NeSy in the language domain, to verify if the goals of NeSy are being realized, and to identify the challenges and future directions. We brieﬂy describe each of the goals illustrated in ﬁgure 14, which we have identiﬁed based on our synthesis of the related work outlined above. Out-of-distribution Generalization Interpretability Reduced DataTransferability Reasoning ? Fig. 14. Neuro-Symbolic Artiﬁcial Intelligence Goals 4.1. Out-of-distribution (OOD) Generalization OOD generalization [65] refers to the ability of a model to extrapolate to phenomena not previously seen in the training data. The lack of OOD generalization in LLMs is often demonstrated by their inability perform commonsense reasoning, as in the example in Figure 3. 4.2. Interpretability As Machine Learning (ML) and AI become increasingly embedded in daily life, the need to hold ML/AI accountable is also growing. This is particularly true in sensitive domains such as healthcare, legal, and some business applications such as lending, where bias mitigation and fairness are critical. “An interpretable model is constrained, following a domain-speciﬁc set of constraints that make reasoning processes understandable” [66]. 4.3. Reduced size of training data State-of-the-Art (SOTA) language models utilize massive amounts of data for training. This can cost in the thousands or even millions of dollars [19], take a very long time, and is neither environmentally friendly nor accessible to most researchers or businesses. The ability to learn from less data brings obvious beneﬁts. But apart from the practical implications, there is something innately disappointing in LLMs’ ‘bigger hammer’ approach. Science rewards parsimony and elegance, and NeSy promises to deliver results without the need for such massive scale. While this issue can be partially solved by ﬁne tuning a pre-trained LLM using only a small amount labeled data, these techniques come with their own limitations. For example, Jiang et al. [67] discuss issues such as over- ﬁtting the data of downstream tasks and forgetting the knowledge of the pre-trained model. 4.4. Transferability Transferability is the ability of a model which was trained on one domain, to perform similarly well in a different domain. This can be particularly valuable, when the new domain has very few examples available for training. In such cases we might rely on knowledge transfer similar to the way a person might rely on abstract reasoning when faced with an unfamiliar situation [68]. 4.5. Reasoning According to Encyclopedia Britannica, “To reason is to draw inferences appropriate to the situation” [69]. Reasoning is not only a goal in its own right, but also the means by which the other above mentioned goals can be achieved. Not only is it one of the most difﬁcult problems in AI21, it is one of the most contested. Also, a distinction must be made between human-level reasoning, or what is sometimes referred to as commonsense reasoning, and formal reasoning. While human-level reasoning can be ambiguous, error-prone, and difﬁcult to specify, formal reasoning, or logic, follows strict rules and aims to be as precise as possible. The challenge lies in determining when it is appropriate to deploy one or the other or both, and how. In section 7.1 we examine the uses of the term reasoning in more depth. 5. Methods Our review methodology is guided by the principles described in [70–72]. The data, queries, code, and additional details can be found in our github repository.22 5.1. Research Questions – Is Neuro-symbolic AI meeting its promises in NLP? 1. What are the existing studies on neurosymbolic AI (NeSy) in natural language processing (NLP)? 2. What are the current applications of NeSy in NLP? 3. How are symbolic and sub-symbolic techniques integrated and what are the advantages/disadvantages? 5.2. Search Process We chose Scopus to perform our initial search, as Scopus indexes most of the top journals and conferences we were interested in. In addition to Scopus, we searched the ACL Anthology database and the proceedings from conferences speciﬁc to Neuro-symbolic AI. It is possible we missed some relevant studies, but as our aim is to shed light on the ﬁeld generally, our assumption is that these journals and proceedings are a good representation of the area as a whole. The included sources are listed in Appendix C. Since we were looking for studies which combine neural and symbolic approaches, our query consists of combinations of neural and symbolic terms as well as variations thereof, listed in table 1. The keywords are deliberately broad, as it would be impossible to come up with a complete list of all possible keywords relevant to NeSy in NLP. More importantly, the focus of the work is not on speciﬁc subﬁelds, each of which may warrant a review of its own, but rather on the explicit use of neuro- symbolic approaches regardless of subﬁeld. Strictly speaking the only keywords that would cover this would be neuro-symbolic and its syntactic variants, but we relaxed this slightly on the basis that works which explore both symbolic reasoning and deep learning in combination (as per the deﬁnition in section 1) may not necessarily have used the term neuro-symbolic. Table 1 Search Keywords Table 2 Inclusion/Exclusion Criteria 32 12 5 7 3 Fig. 16. Study quality More than 85% of the studies satisfy the requirements listed from Q1 to Q6. However, over 80% of the studies fail to provide source code or details related to the computing environment which makes the system difﬁcult to reproduce. This leads to an overall reduction of the average quality score to 76.5% - Figure 16. Finally, a deep reading of each of the eligible studies led to 59 studies selected for inclusion. Data extraction was performed for each of the features outlined in Table 3. For acceptable values of individual features see Appendix B. The lists of neural and symbolic terms referenced in the table constitute the glossary items learned from conducting the selection process. Figure 17(a) shows the breakdown of conference papers vs journal articles, and Figure 17(b) shows the number of studies published each year. (a) Publication type 20 26 2 11 (b) Published year Fig. 17. Publications selected for inclusion 6. Results, Data Analysis, Taxonomies We perform quantitative data analysis based on the extracted features in Table 3. Each study was labeled with terms from the aforementioned glossary, and each term in the glossary was classiﬁed as either symbolic, or neural. A bi-product of this process are two taxonomies built bottom-up of concepts relevant to the set of studies under review. The two taxonomies are a reﬂection of the deﬁnition of NeSy provided earlier: “the combination of deep learning and symbolic reasoning.” To make this deﬁnition more precise, we limit the type of combination that qualiﬁes as neuro-symbolic. Speciﬁcally, the sub-symbolic and symbolic components must be integrated in a way such that one informs the other. By way of counter example, a system which is made up of two independent symbolic and sub-symbolic components would not be considered NeSy if there is no interaction between them. For example, while a system where one component is used to process one type of data, and the other is used to process another type of data may be an effective software pipeline design, we do not consider this type of solution neuro-symbolic as the two components do not interact in any way. Thus the deﬁnition becomes “the integration of deep learning and symbolic reasoning.” It should be noted, that these terms are not always consistently deﬁned in the literature. Table 3 Data extraction features a type of text classiﬁcation, but while one author’s stated objective is speciﬁc to sentiment, another author may be interested in solving for text classiﬁcation in general. As such there is no particular hierarchy or taxonomy associated with business applications. The relationship between all tasks, or business applications, and NeSy goals is shown in Figure 18. Emotion Recognition Sentiment Analysis Text Games Dialog System N2F Kg Completion / Link Prediction Entity Linking Relation Extraction Image Captioning Opnion Extraction Annotation Reading Comprehension Text Classification Causal Reasoning Question Answering Decision Support Argumentation Mining Language Modeling Information Extraction Entity Resolution Text Summarization Reasoning Interpretability Transferability None Fig. 18. Relationship between Business Applications and NeSy Goals. Question answering is the most frequently occurring task, and is associated mainly with reasoning, reduced data, and to a lesser degree, interpretability. The business application largely determines the type of model output, or what we term technical application. Most business applications are associated with a single (or at most two) technical applications. The exceptions being question answering and reading comprehension, which have been tackled as both inference and classiﬁcation problems, or with the goal of information extraction or text generation. Question answering is the most frequently occurring task, and is associated mainly with reasoning, reduced data, and to a lesser degree, interpretability. On a philosophical level this seems somewhat disappointing, as one would hope that in receiving an answer, one could expect to understand why such an answer was given. For completeness, the number of studies representing the technical applications and most frequently occurring business application is given in Figure 19, while Figure 20 illustrates the relationship between business applications, technical applications, and goals. Question answering Text classification Reading comprehension Sentiment analysis KG Completion / link prediction 10 7 5 5 5 (a) Top Business Applications (b) Technical Applications (model output) Fig. 19. Number of studies in each application category 6.1.2. Type of learning Machine learning algorithms are classiﬁed as supervised, unsupervised, semi-supervised, curriculum or reinforcement learning, depending on the amount and type of supervision required during training [73–75]. Figure 21 demonstrates that the supervised method outnumbers all other approaches. Emotion Recognition Sentiment Analysis Text Games Dialog System N2F Kg Completion / Link Prediction Entity Linking Relation Extraction Image Captioning Opnion Extraction Annotation Reading Comprehension Text Classification Causal Reasoning Question Answering Decision Support Argumentation Mining Language Modeling Information Extraction Entity Resolution Text Summarization Similarity Classification Inference Reasoning Interpretability Transferability Generative SimilaritySimilaritySimilarity None Fig. 20. Relationship between Business Applications, Technical Applications, and NeSy Goals Similarity Classification Type of Learning Technical Application (Model Output) NeSy Goals Generative Inference Information Semi-supervised Unsupervised Supervised Reinforcement Reasoning OOD Interpretability Reduced Data Transferability None Fig. 21. Relationship between Learning Type, Technical Application, and NeSy Goals. It is clear that supervised approaches dominate the ﬁeld, are applied across a variety of technical applications, and there is no clear winner when it comes to goals. 6.1.3. Implicit vs Explicit Reasoning The subset of tasks belonging to Natural Language Understanding (NLU) and Natural Language Generation (NLG) are often regarded as more difﬁcult, and presumed to require reasoning. Given that reasoning was one of the keywords used for search, it is not surprising that many studies report reasoning as a characteristic of their model(s). How reasoning is performed often depends on the underlying representation and what it facilitates. Sometimes the representations are obtained via explicit rules or logic, but are subsequently transformed into non-decomposable embeddings for learning. As such, we can say that any reasoning during the learning process is done implicitly. Studies utilizing Graph Neural Networks (GNNs) [76–82] would also be considered to be doing reasoning implicitly. The majority of the studies doing implicit reasoning leverage linguistic and/or relational structure to generate those internal representations. These studies meet 53 out of a possible 180 NeSy goals, where 180 = #goals * #studies, or 29.4%. For reasoning to be considered explicit, rules or logic must be applied during or after training. Studies which implement explicit reasoning perform slightly better, meeting 51 out of 135 goals, or 37.8% and generally require less training data. Additionally, 4 studies implement both implicit and explicit reasoning, at a NeSy promise rate of 40%. Of particular interest in this grouping is Bianchi et al. [83]’s implementation of Logic Tensor Networks (LTNs), originally proposed by Seraﬁni and Garcez in [84]. “LTNs can be be used to do after-training reasoning over combinations of axioms which it was not trained on. Since LTNs are based on Neural Networks, they reach similar results while also achieving high explainability due to the fact that they ground ﬁrst-order logic” [83]. Also in this grouping, Jiang et al. [85] propose a model where embeddings are learned by following the logic expressions encoded in huffman trees to represent deep ﬁrst-order logic knowledge. Each node of the tree is a logic expression, thus hidden layers are interpretable. Figure 22 shows the relationship between implicit & explicit reasoning and goals, while the relationship between knowledge representation, type of reasoning, and goals is shown in Figure 23. Both Implicit Explicit Reasoning OOD Interpretability Reduced Data Transferability None Fig. 22. Type of Reasoning and Goals. Around half, 48%, of studies where reasoning is performed explicitly mention interpretability as a feature. While nearly a third of studies performing reasoning implicitly do not meet any of the NeSy promises identiﬁed for this review. Semantic Network Frames Rules Logic Both Implicit Explicit Reasoning Reasoning NeSy GoalsKnowledge Representation OOD Interpretability Reduced Data Transferability None Fig. 23. Knowledge Representation, Type of Reasoning, and Goals. What is noteworthy, is that when Semantic Networks are utilized, reasoning is almost always done implicitly. The two exception are [83], and [77]. However, [83] utilizes FOL for explicit reasoning rather than its network component. On the other hand, [77] generate a novel interpretable reasoning graph as the output of their model. 6.1.4. Linguistic and Relational Structure In the previous section we described how linguistic and relational structures can be leveraged to generate internal representations for the purpose of implicit reasoning. Here we plot the relationships between these structures and other extracted features and their interactions - Figure 24. Perhaps the most telling chart is the mapping between structures and goals, where many the studies leveraging linguistic structure do not meet any of the goals. This runs counter to the intuition that language is a natural ﬁt for NeSy. Emotion Recognition Sentiment Analysis Text Games Dialog System N2F KG Completion / Link Prediction Relation Extraction Image Captioning Opnion Extraction Annotation Reading Comprehension Text Classiﬁcation Causal Reasoning Question Answering Decision Support Argumentation Mining Language Modeling Information Extraction Entity Resolution Text Summarization Reasoning OOD Interpretability Reduced Data Transferability None Semantic Network Frames Rules Logic Both Implicit Explicit Reasoning OOD Interpretability Reduced Data Transferability None Classiﬁcation Generative Inference Information Extraction Similarity Classiﬁcation Generative Inference Information Extraction Reasoning OOD Interpretability Reduced Data Transferability None Emotion recognition Sentiment analysis Text games Dialog system N2f Kg completion / link prediction Entity linking Relation extraction Image captioning Opnion extraction Annotation Reading comprehension Text classiﬁcation Causal reasoning Question answering Decision support Argumentation mining Language modeling Information extraction Entity resolution Text summarization Semi-supervised Unsupervised Supervised Reinforcement Compiled Cooperative Nested Sequential Linguistic Structure (LS) Relational Structure (RS) LS LS LS LS LS LS LS LS RS RS RS RS RS RS RS RS a) NeSy Goal b) NeSy Category c) Technical Application d) Knowledge Representation e) Reasoning Type -> NeSy Goal f) Technical Application -> NeSy Goal g) Business Use Case h) Business Use Case -> Learning Type Fig. 24. Relationships between leveraged structures and extracted features. As can be seen in a), e), and f), studies leveraging linguistic structures often do not meet any NeSy goals, which runs counter to our original hypothesis. Further investigation into this phenomenon may be warranted. Note: studies which do no leverage either structure are not shown 6.1.5. Datasets and Benchmarks Each study in our survey is based on a unique dataset, and a variety of metrics. Given that there are nearly as many business applications, or tasks, as there are studies, this is not surprising. As such it is not possible to compare the performance of the models reviewed. However, this brings up an interesting question, and that is how one might design a benchmark for NeSy in the ﬁrst place. A discussion about benchmarks at the IBM Neuro-Symbolic AI Workshop 202225 resulted in general agreement that the most important characteristic of a good benchmark for NeSy is in the diversity of tasks tackled. Gary Marcus pointed out that current benchmarks can be solved extensionally, meaning they can be “gamed”.26 In other words, with enough attempts, a model can become very good at a speciﬁc task without solving the fundamental reasoning challenge. In essence, this akin to over-ﬁtting on the test set. The phenomenon can be exposed when adversarial examples are introduced such as described in [86], or through the observation that spurious correlations can be introduced in the annotation process as per [87]. This leads to models which are not able to generalize out of the training distribution. In contrast, to solve a task intensionally is to demonstrate “understanding” which is transferable to different tasks. This view is controversial with advocates of purely connectionist approaches arguing that “understanding” is not only ill deﬁned, but also a moving target [1] - every time we solve for the current deﬁnition of understanding, the deﬁnition is revised to have to meet a higher bar. So instead of worrying about the semantics of “understanding”, the panelists agreed that to make the benchmarks robust to gaming is to build in enormous variance in the types of tasks they tackle. Taking this a step further, Luis Lamb27 proposed that instead of designing benchmarks for testing models, we should be designing challenges which encourage people to work on important real world problems. For a deeper dive, see the ACL-2021 Workshop on Benchmarking: Past, Present and Future (BPPF)28, where some of the same issues pertaining speciﬁcally to NLP and NLU were discussed, as well as the challenges in interpreting performances across datasets, models, and with the evolution of language and context over time. 6.2. Taxonomies: Neural, Symbolic, & Neuro-Symbolic 6.2.1. Neural In the main, the extracted neural terms refer to the neural architecture implemented in a given study. We group these into higher level categories such as Linear models, Early generation (which includes CNNs), Graphical models, Sequence-to-Sequence - Figure 25. We have included Transformers in the Sequence-to-Sequence category as the original architecture was an encoder/decoder with attention. It should be noted that not all Transformers since then employ both an encoder and decoder, or generate sequences. What they have in common is the attention mechanism described in the seminal paper Attention Is All You Need, by Vaswami et al. [3] which dramatically advanced NLP research. We also include here Neuro-Symbolic architectures such as Logic Tensor Networks (LTN), Recursive Neural Knowledge Networks (RNKN), Tensor Product Representations (TPRs), and Logical Neural Networks (LNN) because they are suitable to optimization via gradient descent - Figure 26. We include one study [88] which does not implement gradient descent, but rather Neuroevolution (NE). Neuroevolution involves genetic algorithms for learning neural network weights, topologies, or ensembles of networks by taking inspiration from biological nervous systems [89, 90]. Neuroevolution is often employed in the service of Reinforcement Learning (RL). Studies which do not specify a particular architecture are categorised as Multilayer Perceptron (MLP). 6.2.2. Symbolic The deﬁnition we adopted states that NeSy is the integration of deep learning and symbolic reasoning. Our neural taxonomy described above reﬂects the deep learning component. For the symbolic reasoning component we utilize four common Knowledge Representation (KR) categories: 1) production rules, 2) logical representation, 3) frames, and 4) semantic networks [91–96]. The following deﬁnitions are merely a glimpse at each of these topics, in order to provide a basic intuition. Convolutional Neural Network (CNN) input convolution pooling fully connected output Multilayer Perceptron (MLP) input outputhidden layers Neuroevolution (NE) evaluation selection crossovermutation Graph Neural Network (GNN) neural network input graph neighborhood aggregation Sequence-to-Sequence (Seq2Seq) encoder decoderinput output x 1 x 2 x n-1 x nencoder state RNN RNN RNN RNN RNN RNN RNN RNN Transformer (e.g. BERT) encoder decoder output y 1 y 2 y n-1 y n y 1 y 2 y n-1 input attention x 1 x 2 x n-1 x n h1 h0 h2 hn-1 hn s 1 s 2 s n-1 s n RNN RNN RNN RNN Z W RNN RNN RNN RNN WX+b WX+b WX+b WX+b Fig. 25. Neural architectures represented in Table 4 Logic Tensor Networks(LTN) Recursive Neural Knowledge Networks (RNKN) Tensor Product Representation (TPR) Logic Neural Networks (LNN) u = ⟨u 1, . . . .,un⟩ G(P(v,u) → A(u)) v = ⟨v 1, . . . .,vn⟩ 1-# uP th th ++ W 1 P W 2 P V 1 P V 2 P B 1 P B 2 P 1-# th th + + = + W 1 A W 2 A V 1 A V 2 A B 1 A B 2 A uA max p(3) 1 p (2) 2& p (2) 1 p (1) 3& p (3) 1 p (2) 1 p (1) 1 p(1) layer p(2) layer p(3) layer Root layer p (1) 2 p (1) 3 p (1) 4 p(1) 5 p (1) 1 p (1) 2& limb weakness nausea checst congestion palpitations ⇒ hyperthiroid ... chest congestion ⇒ hyperthiroid ... p (2) 2 p(1) 1 p (1) 2& limb weakness nausea heart failure chest congestion palitations heart failure Whiskers Tail Cat Dog Pet Laser pointer Chases → → → ⊗ ⊗ (Whiskers ⊗ Tail ⊗ (Laser pointer → Chases)) → Cat (Cat ⊗ Dog) → Pet Dog) LOVER John Mary John loves MaryBELOVED Fig. 26. Neuro-symbolic architectures represented in Table 4 1. Production rules - A production rule is a two-part structure comprising an antecedent set of conditions and a consequent set of actions [94]. We usually write a rule in this form: IF conditions T HEN actions ex) IF Bird T HEN f ly 2. Logical representation - Logic is the study of entailment relations—languages, truth conditions, and rules of inference. [94, 97]. A logic includes: – Syntax: speciﬁes the symbols in the language and how they can be combined to form sentences. Hence facts about the world are represented as sentences in logic. – Semantics: speciﬁes what facts in the world a sentence refers to. Hence, also speciﬁes how you assign a truth value to a sentence based on its meaning in the world. A fact is a claim about the world, and may be true or false. – Inference Procedure (reasoning): mechanical method for computing (deriving) new (true) sentences from existing sentences. The sentence \"Not all birds can ﬂy\" in First Order Logic (FOL) looks like: ¬(∀xBird(x) → Fly(x)) FOL is by no means the only choice, but as per [94] it is a simple and convenient one for the sake of illustration. Natural Logic (NL) for example, is a formal proof theory built on the syntax of human language, which can be traced to the syllogisms of Aristotle [98]. “For better or worse, most of the reasoning that is done in the world is done in natural language. And correspondingly, most uses of natural language involve reasoning of some sort. Thus it should not be too surprising to ﬁnd that the logical structure that is necessary for natural language to be used as a tool for reasoning should correspond in some deep way to the grammatical structure of natural language” [99]. Implementations and extensions include [30, 100–102]. Real-valued logics are often utilized in machine learning because they can be made differentiable and/or probabilistic [36] - ﬁrst introduced by Łukasiewicz at the turn of the 20th century [103, 104]). Other, logic-based cognitive modelling approaches such as non-monotonic logic, attempt to deal with the complexities of human reasoning, epistemology, and defeasible inference [105]. 3. Frames - Frames are objects which hold entities, their properties and methods. An individual frame schema looks like this: (Frame − name < slot − name1 f iller1 > < slot − name2 f iller2 > ...) (Penguin canFly : 0 isA : ′′Bird′′ ...) The frame and slot names are atomic symbols; the ﬁllers are either atomic values (like numbers or strings) or the names of other individual frames [94]. This is similar to Object Oriented Programming (OOP), where the frame is analogous to the object, and slots and ﬁllers are properties and values respectively. 4. Semantic networks - A semantic network is a structure for representing knowledge as a pattern of interconnected nodes and edges [96]. A Frame network is a kind of semantic network where nodes are frames, and edges are the relationships between nodes. An example of a semantic network often used in NLU systems is WordNet 29 - a lexical database of English - Figure 27. Today semantic networks are more often referred to as Knowledge Graphs (KGs).30 Table 4 shows which studies combine which of the above neural (6.2.1) and symbolic (6.2.2) categories as well as the number of NeSy goals satisﬁed. 6.2.3. Neuro-Symbolic NeSy systems can be categorized according to the nature of the combination of neural and symbolic techniques. At AAAI-20, Henry Kautz presented a taxonomy of 6 types of Neuro-Symbolic architectures with a brief example of each [10]. While Kautz has not provided any additional information beyond his talk at AAAI-20, several researchers hypernym attribute similar temperature antonym hot cold body temperature, blood heat coldness, cold, low temperature, frigidity, frigidness arctic, frigind, gelid, glacial, icy, polsr Fig. 27. English WordNet subgraph [106] have formed their own interpretations [1, 11, 16]. We have categorized all the reviewed studies according to Kautz’s taxonomy as well as our proposed nomenclature - Figure 28. Table 7 in Appendix A lists all the studies by category. Neuro-Symbolic Categories SequentialEnsemble Integrated Nested 1. symbolic Neuro symbolic 2. Symbolic[Neuro] 6. Neuro[Symbolic] 3. Neuro; Symbolic 4. Neuro: Symbolic → Neuro 5. Neuro_Symbolic Cooperative Fig. 28. Proposed Neuro-Symbolic Artiﬁcial Intelligence categories. Adapted from Henry Kautz. Type 1 symbolic Neuro symbolic is a special case where symbolic knowledge (such as words) is transformed into continuous vector space and thus encoded in the feature embeddings of an otherwise “standard” ML model. We opted to include these studies if the derived input features belong to the set of symbolic knowledge representations described in Section 6.2 - Figure 29. One could still argue that this is simply a case of good old fashioned feature engineering, and not particularly special, but we want to explore the idea that deep learning can perform reasoning, albeit implicitly, if provided with a rich knowledge representation in the pre-processing phase. We classify these studies as Sequential. Evaluating these studies as a group was particularly challenging as they have very little in common including different datasets, benchmarks and business applications. Half of the studies do not mention reasoning at all, and the ones that do are mainly executing rules on candidate solutions output by the neural models post hoc. In aggregate, only 26 out of a total of 115 (23 studies * 5 goals), or 22.6%, possible NeSy goals were met. Type 2 Symbolic[Neuro] is what we describe as a Nested architecture, where a symbolic reasoning system is the primary system with neural components driving certain internal decisions. AlphaGo is the example given by Kautz, Table 4 Neural & Symbolic Combinations where the symbolic system is a Monte Carlo Tree Search with neural state estimators nominating next states. We found four studies that ﬁt this architecture. We use [115] for the purposes of illustration - Figure 30. + NeSy Program Synthesizer DSL (Domain Specific Language) with internal neural components Transductive Learning module Unlabeled webpages OUTPUT: answers for each webpage Natural language query x x x x x x x x GetLeaves( GetDescendents( •, !\".matchKeyword(\", #))) Labeled webpages Fig. 30. Type 2 Nested. Given a natural language query and a set of web pages, the system outputs answers for each page. A symbolic reasoner, which uses a custom Domain Speciﬁc Language (DSL) to traverse the HTML, interacts with internal neural modules such as BERT which perform a number of Natural Language Processing tasks. What is learned is a DSL program, using only a few labeled examples, which can generalize to a large number of heterogeneous web pages. The authors report large improvements in precision and recall scores over state-of-the art, in some cases over 50 points [115]. Type 3 Neuro; Symbolic is what we call Cooperative. Here, a neural network focuses on one task (e.g. object detection) and interacts via input/output with a symbolic reasoner specializing in a complementary task (e.g. query answering). Unstructured input is converted into symbolic representations which can be solved by a symbolic reasoner, which in turn informs the neural component which learns from the errors of the symbolic component. This process is iterated until convergence or a satisfactory output is produced. There are nine studies in this category, all but one of which utilize rules and/or logic for knowledge representation. A common theme among the cooperative architectures is the business application of question answering. The Neuro-Symbolic Concept Learner (NS-CL) [137] - Figure 31 - is an example of Type 3, meeting 4 out of the 5 NeSy goals. Its ability to perform well with reduced data is particularly impressive: “Using only 10% of the training images, our model is able to achieve comparable results with the baselines trained on the full dataset.” Similarly, [116] report perfect performance on small datasets which they also attribute to the use of explicit and precise reasoning. Both studies display similar limitations, the use of synthetic datasets, and the need for handcrafted logic, a DSL (Domain Speciﬁc Language) in the case of [137], and Image Schemas in [116]. Six out of the nine studies leverage linguistic structures in some fashion, and in particular, [146] utilize natural logic, for a model which is both interpretable, and achieves state-of-the-art performance on two QA datasets. This work builds on [30, 101]. Types 4 and 5, Neuro: Symbolic → Neuro and Neuro_Symbolic respectively, were originally presented by Kautz under one heading. After his presentation, Kautz modiﬁed the slide deck31 separating these two types into systems where knowledge is compiled into the network weights, and where knowledge is compiled into the loss function. In Types 4 and 5, reasoning can be performed both implicitly and explicitly, in that it is calculated via gradient descent, but can also be performed post hoc. We have grouped studies belonging to these two categories under the moniker of Compiled systems, of which there are sixteen and seven respectively. Deep Learning For Mathematics [156] is the canonical example of Type 4, where the input and output to the model are mathematical expressions. The model performs symbolic differentiation or integration, for example, given x2 as input, the model outputs 2x. The model exploits the tree structure of mathematical expressions, which are fed into a sequence-to-sequence architecture. This seems like a particularly ﬁtting paradigm for natural language applications on the basis that structures such as parse trees can be similarly leveraged to output other meaningful structures such as for example: cause and effect relationships as exempliﬁed in [134] and [150], or the generation of argument schemes as per [76]. The downside of many of these types of systems is the need for hand-crafted Visual Representation Obj 1 Obj 2 Obj 3 Obj 4 Concept Embeddings Semantic Parsing (Candidate Interpretations) Back-propagation Symbolic Reasoning Answer: Cylinder REINFORCE Back-propagation Sphere Query(Shape, Filter(Red, Relate(Left, Filter(Sphere)))) Query(Shape, Filter(Sphere, Relate(Left, Filter(Red)))) Exist(AERelate(Shape, Filter(Red, Relate(Left, Filter(Sphere))))) Q: What is the shape of the red object left of the sphere? ✓ !v ! s Fig. 31. Type 3 Cooperative. The Neuro-Symbolic Concept Learner (NS-CL) jointly learns visual concepts, words, and semantic parsing of sentences without any explicit annotations. Given an input image, the visual perception module detects objects in the scene and extracts a deep, latent representation for each of them. The semantic parsing module translates an input question in natural language into an executable program given a domain speciﬁc language (DSL). The generated programs have a hierarchical structure of symbolic, functional modules, each fulﬁlling a speciﬁc operation over the scene representation. The explicit program semantics enjoys compositionality, interpretability, and generalizability [137]. rules and logic [125, 133, 150, 152]. In contrast, [155] learn rules from data (rule induction) by combining Logical Neural Networks (LNN) with text-based Reinforcement Learning (RL). One could argue that this is a combination of Type 4, compiled (logic embedded in the network), and Type 3, cooperative (symbolic and sub-symbolic modules learning from each other in an iterative fashion). [155] is the only work we found which meets all ﬁve promises, and, it outperforms previous SOTA approaches - Figure 32. Another example of a Type 4 system in our set of studies is Observation: You find yourself in a bedroom. An usual one. I guess you better just go and list everything you see here. There is an exit to the north. Don’t worry, it is unguarded. There is an exit to the south. Don’t worry, it is unblocked. You don’t like hasExit(bedroom, north), hasExit(bedroom, south), hasExit(dedroom, west), hasVisited(bedroom, south)go(x, west), go(x, north) Final sampled output action: go west go(x, y) ← hasExit(x, y)∧¬hasVisited(x, y)∧¬hasCoin(x) take(x) ← hasCoin(x) hasExit(x, y) ¬hasExit(x, y) hasVisited(x, y) ¬hasVisited(x, y) hasCoin(x, y) ¬hasCoin(x, y) ∧ ∧ ∧ ∧Logic: go(x,y) Logic: take(x) 0.5 0.5 0.83 0.17 0.99 0.99 Fig. 32. Type 4 Compiled. SymboLic Action policy for Textual Environments (SLATE) learns interpretable action policy for each action verb, go and take, from ﬁrst-order symbolic states. The goal is to learn symbolic rules as logical connectives for generating action commands by gradient-based training [155]. proposed by [85]. Here, knowledge is encoded in the form of huffman trees made of triples and logic expressions, in order to jointly learn embeddings and model weights - Figure 33. The model is intended for medical diagnosis decision support, where a requisite characteristic is interpretability, and this model meets that goal. Type 5 comprises Tensor Product Representations (TPRs) [157], Logic Tensor Networks (LTNs) [36], Neural Tensor Networks (NTN) [37] and more broadly is referred to as tensorization, where logic acts as a constraint. LT NEE [83] is an example of a compiled Type 5 system - Figure 34. Type 6 Neuro[Symbolic] is the most tightly integrated but perhaps the most elusive as there do not appear to be any recent implementations in existence. According to Kautz, this is the ultimate NeSy system which should be capable of efﬁcient combinatorial reasoning at the level of super-intelligence, if not human intelligence. p (3) 1 p(2) 2& p (2) 1 p (1) 3& p (3) 1 p (2) 1 p (1) 1 p (1) layer p (2) layer p (3) layer Root layer p(1) 2 p(1) 3 p (1) 4 p (1) 5 p (1) 1 p (1) 2& limb weakness nausea checst congestion palpitations ⇒ hyperthiroid ... chest congestion ⇒ hyperthiroid ... p(2) 2 p (1) 1 p(1) 2& limb weakness nausea heart failure chest congestion palitations heart failure Fig. 33. Type 4 Compiled. Huffman tree of the Recursive Neural Knowledge Network (RNKN), representing deep ﬁrst-order logic knowledge. The ﬁrst layer of the tree consists of entities, the second layer consists of relations (x → y). Higher layers compute logic rules. The root node is the ﬁnal embedding representing a document (in this case a single health record). Back propagation is used for optimization with softmax for calculating class probabilities [85]. Commonsense Knowledge Axiomatic Knowledge • Text annotated with entity linking • Entities dbr:cat and dbr:tiger appear in similar contexts.Entity Embeddings: • v(dbr:cat) ≈ v(dbr:tiger) species(dbr:cat) mammal(dbr:tiger) bird(dbr:penguin) [...] ∀x (mammal(x) → animal(x)) Instantiated atoms dbr:cat dbr:tiger dbr:penguin Universaly quantified formuls dbr:cat dbr:tiger dbr:penguin embedding Sub-symbolic commonsense knowledge Sub-symbolic commonsense knowledge with learned predicates LTN After Training Inferences: animal(dbr:cat) ? ∀x (species(x) → animal(x)) mammal animal species learning predicates with Fig. 34. Type 5 Compiled. LT NEE - Using Logic Tensor Networks (LTNs) it is possible to integrate axioms and facts (using ﬁrst-order fuzzy logic to represent terms, functions, and predicates in a vector space) with commonsense knowledge represented in a sub-symbolic form (based on the principle of distributional semantics and implemented with Word2Vec) in one single model performing well in reasoning tasks. The major contribution of this work is to show that combining commonsense knowledge under the form of text-based entity embeddings with LTNs is not only simple, but it is also promising. LTNs can also be used to do after-training reasoning over combinations of axioms on which it was not trained [83]. Figure 35 shows the number of studies per category, and Figure 36 illustrates the relationship between categories and goals. Table 5 shows the number of studies in each category per goal. 7. Discussion All studies report performance either on par or above benchmarks, but we cannot compare studies based on performance as nearly every study uses a different dataset and benchmark as discussed in Section 6.1.5. Our focus is instead on whether the goals of NeSy are being met. Our Promise Score metric is not necessarily what the studies’ authors were optimizing for or even reporting, especially studies which have not labeled themselves as NeSy per se. So we want to make it very clear that our analysis is not a judgement of the success of any particular study, but rather we seek to understand if the hypotheses about NeSy are materializing, namely that the combination of symbolic and sub-symbolic techniques will fulﬁll the goals described in Section 4: Out-of-distribution (OOD) Generalization, interpretability, tranferability, reduced data, and reasoning. And the short answer is we are not there yet, as can be seen in Figure 37. For a detailed breakdown of each goal and study see Table 6. In Section 4.5 we put forward the hypothesis that reasoning is the means by which the other goals can be achieved. This is not evidenced in the studies we reviewed. Some possible explanations for this ﬁnding are: 1) The kind of (a) NeSy category (b) Kautz category Fig. 35. Number of studies per category 4. neuro: symbolic → neuro 5. neuro_symbolic 3. neuro; symbolic 2. symbolic[neuro] 1. symbolic neuro symbolic Compiled Cooperative Nested Sequential Reasoning OOD Interpretability Reduced data Transferability None Fig. 36. NeSy categories to NeSy Goals. There is no obvious pattern with respect to what types of goals are met within each of the NeSy categories. Table 5 Number of studies meeting each goal. The Promise Ratio represents the percentage of goals reported to have been met out of the total number of possible goals (# of studies * 5 goals) in each category. (a) All studies (b) NeSy studies only Fig. 37. Proportion of studies which have met one or more of the 5 goals think”, accepting that how people think is ﬂawed, and subsequently attempting to build a model with a logical component, which by deﬁnition, is rooted in validity, seems counter productive to us. Although this does depend somewhat on the business application. For problems like MWP (Math Word Problems) [77, 123, 135], where answers are precise and unambiguous, less assumptions are needed. Additionally, the justiﬁcation of “because that’s how people think” is inconsistent. Some examples from the studies we reviewed include: – [83] describe human reasoning in terms of a dual process of “subsymbolic commonsense” (strongly correlated with associative learning), and “axiomatic” knowledge (predicates and logic formulas) for structured inference. – In [108] humans reason by way of analogy, and commonsense knowledge is represented in ConceptNet, a graphical representation of common concepts and their relationships. – For [116] human reasoning can be modeled by Image Schemas (IS). Schemas are made up of logical rules on (Entity1,Relation,Entity2) tuples, such as transitivity, or inversion. – [113] explain their choice of fuzzy logic for “its resemblance to human reasoning and natural language.” This is a probabilistic approach which attempts to deal with uncertainty. – [119] propose that human thought constructs can be modelled as cause-effect pairs. Commonsense is often described as the ability to draw causal conclusions from basic knowledge, for example: If I drop the glass, it will break. – And [123] state that “when people perform explicit reasoning, they can typically describe the way to the conclusion step by step via relational descriptions.” But the most plausible hypothesis in our view is that of Schon et al. [128]: in order to emulate human reasoning, systems need to be ﬂexible, be able to deal with contradicting evidence, evolving evidence, have access to enormous amounts of background knowledge, and include a combination of different techniques and logics. Most notably, no particular theory of reasoning is given. The argument put forward by Leslie Kaelbling at IBM Neuro-Symbolic AI Workshop 202232 is similarly appealing. Kaelbling points to the over-reliance on the System1/System2 analogy, and advocates for a much more diverse and dynamic approach. We posit that the type of reasoning employed should not be based solely on how we think people think, but on the attendant objective. This is in line with the “goal oriented” theory from neuroscience, in that reasoning involves many sub-systems: perception, information retrieval, decision making, planning, controlling, and executing, utilizing working memory, calculation, and pragmatics. But here the irony is not lost on us, and we acknowledge that by resorting to neuroscience for inspiration, we have just committed the same mischief for which we have been decrying our peers! But if we must resort to analogies with human reasoning then it is imperative to be as rigorous as possible. In their recent book, A Formal Theory of Commonsense Psychology, How People Think People Think [158], Gordon and Hobbs present a “large-scale logical formalization of commonsense psychology in support of humanlike artiﬁcial intelligence” to act as a baseline for researchers building intelligent AI systems. Santos et al. [159] take this a step in the direction we are advocating, Table 6 NeSy Promises reported as having been met ( One such system, proposed by Bianchi et al. [83] is the LT NEE - Figure 34 - an extention of Logic Tensor Networks (LTNs), in which pre-trained embeddings are fed into the LTN. They show promising results on small datasets which have the important characteristic of being capable of after-training logical inferences. However, LT NEE is limited by heavy computational requirements as the logic becomes more expressive, for example by the use of quantiﬁers. Other studies [116, 137] introduce logical inference within their solutions, but all require manually designed rules, and are limited by the domain expertise of the designer. Learning rules from data, or structure learning [164] is an ongoing research topic as pointed out by [17]. In [118] Chaturvedi et al. use fuzzy logic for emotion classiﬁcation where explicit membership functions are learned. However, as stated by the authors, the classiﬁer becomes very slow with the number of functions. Other (compiled) approaches involve translating logic into differentialble functions, which are either directly included as network nodes as in [85], or added as a constraint to the loss function, as in [165]. To achieve this, First Order Logic (FOL) can be operationalized using t-norms for example. To address the many types of reasoning as discussed in the previous section, we need to be able to incorporate other types of logic, such as temporal, modal, epistemic, non-monotonic, probabilistic, and more, which, presumably, are better able to model human reasoning. In summary, formulating logic, or more broadly reasoning, in a differentiable fashion remains challenging. 8. Limitations & Future Work We organized our analysis according to the characteristics extracted from the studies to test whether there were any patterns leading to NeSy goals. Another approach would be to reverse this perspective, and look at each goal separately to understand the characteristics leading to its fulﬁllment. However, each goal is really an entire ﬁeld of study in and of itself, and we do not think we could have done justice to any of them by taking this approach. We spent a lot of time looking for signal in a very noisy environment where the studies we reviewed had very little in common. More can be said about what we did not ﬁnd, than what we did. Another approach might be to narrow the criteria for the type of NLP task, while expanding the technical domain. In particular, a subset of tasks from the NLU domain could be a good starting point, as these tasks are often said to require reasoning. We tried to be comprehensive in respect to the selected studies which led to the trade-off of less space dedicated to technical details or additional context from the neuro-symbolic discussion. There are a lot of ideas and concepts which we did not cover, such as, and in no particular order, Relational Statistical Learning (RSL), Inductive Logic Programming (ILP), DeepProbLog [166], Connectionist Modal Logics (CML), Extreme Learning Machines (ELM), Genetic Programming, grounding and proposinalization, Case Based Reasoning (CBR), Abstract Meaning Representation (AMR), to name but a few, some of which are covered in detail in other surveys [7, 8]. Furthermore, we argued that we need differentiable forms of different types of logic, but we did not discuss how they might be implemented. A comprehensive point of reference such as this would be a very valuable contribution to the NeSy community, especially if the implementations were anchored in cognitive science and linguistics as discussed in 7.1. Finally, the need for common datasets and benchmarks cannot be overstated. 9. Conclusion We analyzed recent studies implementing NeSy for NLP in order to test whether the promises of NeSy are materializing in NLP. We attempted to ﬁnd a pattern in a small and widely variable set of studies, and ultimately we do not believe there are enough results to draw deﬁnitive conclusions. Only 59 studies met the criteria for our review, and many of them (in the Sequential category) we would not consider truly integrated NeSy systems. The one thing studies which meet the most goals [77, 88, 137, 143, 144, 152, 155] have in common is that they all belong to the tightly integrated set of NeSy categories, Cooperative and Compiled which is good news for NeSy. Two out of these seven report lower computational cost than baselines, and performance on par or slightly above baselines, though we must reiterate that performance comparisons are not possible as discussed in Section 6.1.5. On the down side, we have seen that some studies suffer from high computational cost, and that explicit reasoning still often requires hand crafted domain speciﬁc rules and logic which makes them difﬁcult to scale or generalize to other applications. Indeed, of the ﬁve goals, transferability to new domains was the least frequently satisﬁed. Our view is that the lack of consensus around theories of reasoning and appropriate benchmarks is hindering our ability to evaluate progress. Hence we advocate for the development of robust reasoning theories and formal logics as well as the development of challenging benchmarks which not only measure the performance of speciﬁc implementations, but have the potential to address real world problems. Systems capable of capturing the nuances of natural language (ie., ones that “understand” human reasoning) while returning sound conclusions (ie., perform logical reasoning) could help combat some of the most consequential issues of our times such as mis- and dis- information, corporate propaganda such as climate change denialism, divisive political speech, and other harmful rhetoric in the social discourse. Acknowledgements This publication has emanated from research supported in part by a grant from Science Foundation Ireland under Grant number 18/CRT/6183. For the purpose of Open Access, the author has applied a CC BY public copyright licence to any Author Accepted Manuscript version arising from this submission. References [1] A.d. Garcez and L.C. Lamb, Neurosymbolic AI: The 3rd Wave, arXiv, 2020. doi:10.48550/ARXIV.2012.05876. [2] L.G. Valiant, Three Problems in Computer Science, Journal of the ACM 50(1) (2003), 96–99. doi:10.1145/602382.602410. [3] A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A.N. Gomez, Ł. Kaiser and I. Polosukhin, Attention is all you need, in: Advances in neural information processing systems, Vol. 30, 2017, pp. 5998–6008. [4] J. Devlin, M.-W. Chang, K. Lee and K. Toutanova, BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding, in: Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), Association for Computational Linguistics, Minneapolis, Minnesota, 2019, pp. 4171–4186. doi:10.18653/v1/N19-1423. [5] J. Pearl, Theoretical Impediments to Machine Learning With Seven Sparks from the Causal Revolution, arXiv, 2018. doi:10.48550/ARXIV.1801.04016. [6] G. Marcus, Deep Learning: A Critical Appraisal, arXiv, 2018. doi:10.48550/ARXIV.1801.00631. [7] T.R. Besold, A.d. Garcez, S. Bader, H. Bowman, P. Domingos, P. Hitzler, K.-U. Kuehnberger, L.C. Lamb, D. Lowd, P.M.V. Lima, L. de Penning, G. Pinkas, H. Poon and G. Zaverucha, Neural-Symbolic Learning and Reasoning: A Survey and Interpretation, arXiv, 2017. doi:10.48550/ARXIV.1711.03902. [8] A.d. Garcez, M. Gori, L.C. Lamb, L. Seraﬁni, M. Spranger and S.N. Tran, Neural-Symbolic Computing: An Effective Methodology for Principled Integration of Machine Learning and Reasoning, arXiv, 2019. doi:10.48550/ARXIV.1905.06088. https://arxiv.org/abs/1905.06088. [9] Y. Bengio, G. Marcus and V. Boucher, AI DEBATE! Yoshua Bengio vs Gary Marcus, Montreal.AI. https://montrealartiﬁcialintelligence.com/aidebate/. [10] H. Kautz, The Third AI Summer, AAAI Robert S. Engelmore Memorial Lecture, Thirty-fourth AAAI Conference on Artiﬁcial Intelligence, New York, NY. https://henrykautz.com/talks/index.html. [11] M.K. Sarker, L. Zhou, A. Eberhart and P. Hitzler, Neuro-Symbolic Artiﬁcial Intelligence: Current Trends, arXiv, 2021. doi:10.48550/ARXIV.2105.05330. [12] Y. Bengio, System 2 Deep Learning: Higher-Level Cognition, Agency, Out-of-Distribution Generalization and Causality, 30th International Joint Conference on Artiﬁcial Intelligence. https://ijcai-21.org/invited-talks/. [13] D. Kahneman, Thinking, fast and slow, Farrar, Straus and Giroux, New York, 2011. ISBN 9780374275631 0374275637. [14] Z. Liu, Z. Wang, Y. Lin and H. Li, A Neural-Symbolic Approach to Natural Language Understanding (2022), arXiv:2203.10557 [cs]. [15] J. Zhang, B. Chen, L. Zhang, X. Ke and H. Ding, Neural, symbolic and neural-symbolic reasoning on knowledge graphs, AI Open 2 (2021), 14–35. doi:10.1016/j.aiopen.2021.03.001. [16] L.C. Lamb, A.d. Garcez, M. Gori, M.O.R. Prates, P.H.C. Avelar and M.Y. Vardi, Graph Neural Networks Meet Neural- Symbolic Computing: A Survey and Perspective, in: Proceedings of the Twenty-Ninth International Joint Conference on Artiﬁcial Intelligence, International Joint Conferences on Artiﬁcial Intelligence Organization, 2020, pp. 4877–4884. ISBN 978-0-9992411-6-5. doi:10.24963/ijcai.2020/679. [17] L. von Rueden, S. Mayer, K. Beckh, B. Georgiev, S. Giesselbach, R. Heese, B. Kirsch, M. Walczak, J. Pfrommer, A. Pick, R. Ramamurthy, J. Garcke, C. Bauckhage and J. Schuecker, Informed Machine Learning - A Taxonomy and Survey of Integrating Prior Knowledge into Learning Systems, IEEE Transactions on Knowledge and Data Engineering (2021), 1–1. doi:10.1109/TKDE.2021.3079836. [18] V. Belle, Symbolic Logic Meets Machine Learning: A Brief Survey in Inﬁnite Domains, in: Scalable Uncertainty Management, Springer International Publishing, 2020, pp. 3–16. ISBN 978-3-030-58449-8. [19] O. Sharir, B. Peleg and Y. Shoham, The Cost of Training NLP Models: A Concise Overview, ArXiv (2020). doi:10.48550/arXiv.2004.08900. [20] G. Marcus and E. Davis, GPT-3, Bloviator: OpenAI’s language generator has no idea what it’s talking about | MIT Technology Review. https://www.technologyreview.com/2020/08/22/1007539/gpt3-openai-language-generator-artiﬁcial-intelligence-ai-opinion/. [21] T.B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, S. Agarwal, A. Herbert-Voss, G. Krueger, T. Henighan, R. Child, A. Ramesh, D.M. Ziegler, J. Wu, C. Winter, C. Hesse, M. Chen, E. Sigler, M. Litwin, S. Gray, B. Chess, J. Clark, C. Berner, S. McCandlish, A. Radford, I. Sutskever and D. Amodei, Language Models are Few-Shot Learners (2020). doi:10.48550/ARXIV.2005.14165. [22] W. Farnsworth, The socratic method: A practitioner’s handbook, David R. Godine Publisher Inc, 2021. [23] P. Engel, Reasoning and Rationality, in: Dictionary of cognitive science neuroscience, psychology, Artiﬁcial Intelligence, linguistics, and philosophy, Taylor and Francis, 2003, pp. 315–316. doi:https://doi.org/10.4324/9780203486030. [24] D. Kahneman, O. Sibony and C.R. Sunstein, Noise: A Flaw in Human Judgment, HarperCollins Publishers Limited, 2021. ISBN 978-0- 00-830900-8. [25] P. Hitzler, F. Bianchi, M. Ebrahimi and M.K. Sarker, Neural-symbolic integration and the Semantic Web, Semantic Web 11(1) (2020), 3–11. doi:10.3233/SW-190368. [26] B. MacCartney, Understanding Natural Language Understanding, ACM SIGAI Bay Area Chapter Inaugural Meeting, San Mateo, CA. https://www.youtube.com/watch?v=vcPd0V4VSNU. [27] J. Weizenbaum, ELIZA—a computer program for the study of natural language communication between man and machine, Communications of the ACM 9(1) (1966), 36–45. [28] D.A. Ferrucci, Introduction to “This is Watson”, IBM Journal of Research and Development 56(3.4) (2012), 1:1–1:15. doi:10.1147/JRD.2012.2184356. [29] S. Hochreiter and J. Schmidhuber, Long Short-Term Memory, Neural Computation 9(8) (1997), 1735–1780. doi:10.1162/neco.1997.9.8.1735. [30] B. MacCartney and C.D. Manning, An extended model of natural logic, in: Proceedings of the Eight International Conference on Computational Semantics, Association for Computational Linguistics, Tilburg, The Netherlands, 2009, pp. 140–156. [31] A. Gatt and E. Krahmer, Survey of the State of the Art in Natural Language Generation: Core tasks, applications and evaluation, Journal of Artiﬁcial Intelligence Research 61 (2018), 65–170. doi:10.1613/jair.5477. [32] D. Yu, B. Yang, D. Liu and H. Wang, A Survey on Neural-symbolic Systems, arXiv, 2021. doi:10.48550/ARXIV.2111.08164. [33] S. Bader and P. Hitzler, Dimensions of Neural-symbolic Integration – A Structured Survey, in: We Will Show Them! Essays in Honour of Dov Gabbay, Volume One, S.N, College Publications, 2005. [34] G.G. Towell and J.W. Shavlik, Knowledge-based artiﬁcial neural networks, Artiﬁcial intelligence 70(1–2) (1994), 119–165. [35] A.S.d. Garcez, K. Broda, D.M. Gabbay et al., Neural-symbolic learning systems: foundations and applications, Springer Science & Business Media, 2002. [36] L. Seraﬁni and A.S. d’Avila Garcez, Learning and Reasoning with Logic Tensor Networks, in: AI*IA 2016 Advances in Artiﬁcial Intelligence, G. Adorni, S. Cagnoni, M. Gori and M. Maratea, eds, Lecture Notes in Computer Science, Springer International Publishing, 2016, pp. 334–348. ISBN 978-3-319-49130-1. doi:10.1007/978-3-319-49130-1_25. [37] R. Socher, D. Chen, C.D. Manning and A. Ng, Reasoning With Neural Tensor Networks for Knowledge Base Completion, in: Advances in Neural Information Processing Systems, Vol. 26, Curran Associates, Inc., 2013. [38] S. Muggleton, Inductive logic programming, New Generation Computing 8(4) (1991), 295–318. doi:10.1007/BF03037089. [39] F. Yang, Z. Yang and W.W. Cohen, Differentiable learning of logical rules for knowledge base reasoning, Advances in neural information processing systems 30 (2017). [40] R. Evans and E. Grefenstette, Learning explanatory rules from noisy data, Journal of Artiﬁcial Intelligence Research 61 (2018), 1–64. [41] T. Rocktäschel and S. Riedel, Learning knowledge base inference with neural theorem provers, in: Proceedings of the 5th workshop on automated knowledge base construction, 2016, pp. 45–50. [42] H. Dong, J. Mao, T. Lin, C. Wang, L. Li and D. Zhou, Neural Logic Machines, arXiv, 2019. doi:10.48550/ARXIV.1904.11694. [43] C. Wendelken and L. Shastri, Multiple instantiation and rule mediation in SHRUTI, Connection Science 16(3) (2004), 211–217. [44] G. Vilone and L. Longo, Notions of explainability and evaluation approaches for explainable artiﬁcial intelligence, Information Fusion 76 (2021), 89–106. [45] D. Koller, N. Friedman, S. Džeroski, C. Sutton, A. McCallum, A. Pfeffer, P. Abbeel, M.-F. Wong, C. Meek, J. Neville et al., Introduction to statistical relational learning, MIT press, 2007. [46] L. De Raedt, A. Kimmig and H. Toivonen, ProbLog: A Probabilistic Prolog and Its Application in Link Discovery., in: IJCAI, Vol. 7, Hyderabad, 2007, pp. 2462–2467. [47] M. Richardson and P. Domingos, Markov logic networks, Machine Learning 62(1) (2006), 107–136. doi:10.1007/s10994-006-5833-1. [48] Y. Wang, Q. Yao, J.T. Kwok and L.M. Ni, Generalizing from a few examples: A survey on few-shot learning, ACM computing surveys (csur) 53(3) (2020), 1–34. [49] A.S.d. Garcez and D.M. Gabbay, Fibring neural networks, in: Proceedings of 19th National Conference on Artiﬁcial Intelligence - AAAI- 2004, AAAI Press, 2004, pp. 342–347. [50] M.F. Joanisse and J.L. McClelland, Connectionist perspectives on language learning, representation and processing, Wiley Interdisciplinary Reviews: Cognitive Science 6(3) (2015), 235–247. [51] S. Pinker, Words and rules, Lingua 106(1–4) (1998), 219–242. [52] R.D. Sriram, Analogical and Case-Based Reasoning, in: Intelligent Systems for Engineering: A Knowledge-based Approach, Springer London, London, 1997, pp. 285–334. ISBN 978-1-4471-0631-9. doi:10.1007/978-1-4471-0631-9_6. [53] W.L. Hamilton, R. Ying and J. Leskovec, Representation Learning on Graphs: Methods and Applications (2017). doi:10.48550/ARXIV.1709.05584. [54] O. Vinyals, M. Fortunato and N. Jaitly, Pointer networks, Advances in neural information processing systems 28 (2015). [55] T.N. Kipf and M. Welling, Semi-supervised classiﬁcation with graph convolutional networks. 2017, ArXiv abs/1609.02907 (2017). [56] F. Scarselli, M. Gori, A.C. Tsoi, M. Hagenbuchner and G. Monfardini, The graph neural network model, IEEE transactions on neural networks 20(1) (2008), 61–80. [57] P. Velickovic, G. Cucurull, A. Casanova, A. Romero, P. Liò and Y. Bengio, Graph Attention Networks, CoRR abs/1710.10903 (2017). [58] L. Yao, C. Mao and Y. Luo, Graph convolutional networks for text classiﬁcation, in: Proceedings of the AAAI conference on artiﬁcial intelligence, Vol. 33, 2019, pp. 7370–7377. [59] M. Schlichtkrull, T.N. Kipf, P. Bloem, R.v.d. Berg, I. Titov and M. Welling, Modeling relational data with graph convolutional networks, in: European semantic web conference, Springer, 2018, pp. 593–607. [60] F. Van Harmelen and A.t. Teije, A boxology of design patterns for hybrid learning and reasoning systems, arXiv preprint arXiv:1905.12389 (2019). [61] B. Hammer and P. Hitzler (eds), Perspectives of Neural-Symbolic Integration, Vol. 77, Springer, 2007. ISBN 978-3-540-73953-1. [62] A.S. Garcez, L.C. Lamb and D.M. Gabbay, Neural-Symbolic Cognitive Reasoning, Cognitive Technologies, Springer, 2009. ISBN 978-3- 540-73245-7. doi:10.1007/978-3-540-73246-4.. [63] E. Gabrilovich, R. Guha, A. McCallum and K. Murphy, Knowledge Representation and Reasoning: Integrating Symbolic and Neural Approaches, The AAAI Press, Palo Alto, California., 2015. ISBN 978-1-57735-707-0. [64] T.R. Besold and K.-U. Kühnberger, Towards integrated neural–symbolic systems for human-level AI: Two research programs helping to bridge the gaps, Biologically Inspired Cognitive Architectures 14 (2015), 97–110. doi:10.1016/j.bica.2015.09.003. [65] Z. Shen, J. Liu, Y. He, X. Zhang, R. Xu, H. Yu and P. Cui, Towards Out-Of-Distribution Generalization: A Survey (2021). doi:10.48550/ARXIV.2108.13624. [66] C. Rudin, C. Chen, Z. Chen, H. Huang, L. Semenova and C. Zhong, Interpretable machine learning: Fundamental principles and 10 grand challenges, Statistics Surveys 16 (2022), 1–85. [67] H. Jiang, P. He, W. Chen, X. Liu, J. Gao and T. Zhao, SMART: Robust and Efﬁcient Fine-Tuning for Pre-trained Natural Language Models through Principled Regularized Optimization, in: Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, Online, 2020, pp. 2177–2190. doi:10.18653/v1/2020.acl-main.197. [68] F. Zhuang, Z. Qi, K. Duan, D. Xi, Y. Zhu, H. Zhu, H. Xiong and Q. He, A Comprehensive Survey on Transfer Learning, Proceedings of the IEEE 109(1) (2021), 43–76. doi:10.1109/JPROC.2020.3004555. [69] Reasoning, Encyclopædia Britannica, inc. https://www.britannica.com/technology/artiﬁcial-intelligence/Reasoning. [70] B. Kitchenham, Procedures for performing systematic reviews, Keele, UK, Keele University 33(2004) (2004), 1–26. [71] G. Paré, M.-C. Trudel, M. Jaana and S. Kitsiou, Synthesizing information systems knowledge: A typology of literature reviews, Information & Management 52(2) (2015), 183–199. doi:https://doi.org/10.1016/j.im.2014.08.008. [72] M.J. Page, J.E. McKenzie, P.M. Bossuyt, I. Boutron, T.C. Hoffmann, C.D. Mulrow, L. Shamseer, J.M. Tetzlaff, E.A. Akl, S.E. Brennan, R. Chou, J. Glanville, J.M. Grimshaw, A. Hróbjartsson, M.M. Lalu, T. Li, E.W. Loder, E. Mayo-Wilson, S. McDonald, L.A. McGuinness, L.A. Stewart, J. Thomas, A.C. Tricco, V.A. Welch, P. Whiting and D. Moher, The PRISMA 2020 statement: an updated guideline for reporting systematic reviews, Systematic Reviews 10(1) (2021), 89. doi:10.1186/s13643-021-01626-4. [73] M. Kang and N.J. Jameson, Machine Learning: Fundamentals, Prognostics and Health Management of Electronics: Fundamentals, Machine Learning, and the Internet of Things (2018), 85–109. [74] G. Bonaccorso, Machine learning algorithms, Packt Publishing Ltd, 2017. [75] Y. Bengio, J. Louradour, R. Collobert and J. Weston, Curriculum learning, in: Proceedings of the 26th annual international conference on machine learning, 2009, pp. 41–48. [76] E. Saveleva, V. Petukhova, M. Mosbach and D. Klakow, Graph-based Argument Quality Assessment, in: Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2021), INCOMA Ltd., Held Online, 2021, pp. 1268–1280. [77] Q. Zhang, L. Wang, S. Yu, S. Wang, Y. Wang, J. Jiang and E.-P. Lim, NOAHQA: Numerical Reasoning with Interpretable Graph Question Answering Dataset, in: Findings of the Association for Computational Linguistics: EMNLP 2021, Association for Computational Linguistics, Punta Cana, Dominican Republic, 2021, pp. 4147–4161. doi:10.18653/v1/2021.ﬁndings-emnlp.350. [78] K. Chen, W. Xu, X. Cheng, Z. Xiaochuan, Y. Zhang, L. Song, T. Wang, Y. Qi and W. Chu, Question Directed Graph Attention Network for Numerical Reasoning over Text, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, Online, 2020, pp. 6759–6768. doi:10.18653/v1/2020.emnlp-main.549. [79] Y. Gu, J.Z. Pan, G. Cheng, H. Paulheim and G. Stoilos, Local ABox consistency prediction with transparent TBoxes using gated graph neural networks, in: Proc. 14th International Workshop on Neural-Symbolic Learning and Reasoning (NeSy), 2019. [80] H. Lemos, P. Avelar, M. Prates, A. Garcez and L. Lamb, Neural-Symbolic Relational Reasoning on Graph Models: Effective Link Inference and Computation from Knowledge Bases, Lecture Notes in Computer Science 12396 LNCS (2020), 647–659. doi:10.1007/978- 3-030-61609-0_51. [81] M. Zhou, D. Ji and F. Li, Relation Extraction in Dialogues: A Deep Learning Model Based on the Generality and Specialty of Dialogue Text, IEEE/ACM Transactions on Audio Speech and Language Processing 29 (2021), 2015–2026. doi:10.1109/TASLP.2021.3082295. [82] S. Huo, T. Ma, J. Chen, M. Chang, L. Wu and M. Witbrock, Graph Enhanced Cross-Domain Text-to-SQL Generation, in: Proceedings of the Thirteenth Workshop on Graph-Based Methods for Natural Language Processing, TextGraphs@EMNLP 2019, Hong Kong, November 4, 2019, Association for Computational Linguistics, 2019, pp. 159–163. doi:10.18653/v1/D19-5319. [83] F. Bianchi, M. Palmonari, P. Hitzler and L. Seraﬁni, Complementing logical reasoning with sub-symbolic commonsense, Lecture Notes in Computer Science 11784 LNCS (2019), 161–170. doi:10.1007/978-3-030-31095-0_11. [84] L. Seraﬁni and A.d. Garcez, Logic Tensor Networks: Deep Learning and Logical Reasoning from Data and Knowledge, arXiv:1606.04422 [cs] (2016). [85] J. Jiang, H. Wang, J. Xie, X. Guo, Y. Guan and Q. Yu, Medical knowledge embedding based on recursive neural network for multi-disease diagnosis, Artiﬁcial Intelligence in Medicine 103 (2020). doi:10.1016/j.artmed.2019.101772. [86] R. Jia and P. Liang, Adversarial Examples for Evaluating Reading Comprehension Systems, in: Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Copenhagen, Denmark, 2017, pp. 2021– 2031. doi:10.18653/v1/D17-1215. [87] S. Gururangan, S. Swayamdipta, O. Levy, R. Schwartz, S. Bowman and N.A. Smith, Annotation Artifacts in Natural Language Inference Data, in: Proceedings of the 2018 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 2 (Short Papers), Association for Computational Linguistics, New Orleans, Louisiana, 2018, pp. 107–112. doi:10.18653/v1/N18-2017. [88] B. Škrlj, M. Martinc, N. Lavraˇc and S. Pollak, autoBOT: evolving neuro-symbolic representations for explainable low resource text classiﬁcation, Machine Learning 110(5) (2021), 989–1028. doi:10.1007/s10994-021-05968-x. [89] R. Miikkulainen, Neuroevolution, in: Encyclopedia of Machine Learning, Springer, New York, 2010. [90] J. Lehman and R. Miikkulainen, Neuroevolution, Scholarpedia 8(6) (2013), 30977. doi:10.4249/scholarpedia.30977. [91] R. Davis, H. Shrobe and P. Szolovits, What is a knowledge representation?, AI magazine 14(1) (1993), 17–17. [92] T.J. Bench-Capon, Knowledge representation: An approach to artiﬁcial intelligence, Vol. 32, Elsevier, 2014. [93] H.J. Levesque, Knowledge representation and reasoning, Annual review of computer science 1(1) (1986), 255–287. [94] R. Brachman and H. Levesque, Knowledge representation and reasoning, Elsevier, 2004. [95] I.L. Travis, Knowledge Representation in Artiﬁcial Intelligence, Clinic on Library Applications of Data Processing (27th: 1990) (1990). [96] J.F. Sowa, Principles of Semantic Networks, Morgan Kaufmann, 1991. ISBN 978-1-4832-0771-1. doi:10.1016/C2013-0-08297-7. [97] C.R. Dyer, CS 540 Lecture Notes: Logic, University of Wisconsin - Madison. https://pages.cs.wisc.edu/~dyer/cs540/notes/logic.html. [98] J. Byszuk, M. Wo´zniak, M. Kestemont, A. Le´sniak, W. Lukasik, A. Šel,a and M. Eder, Detecting Direct Speech in Multilingual Collection of 19th-century Novels, in: Proceedings of LT4HALA 2020 - 1st Workshop on Language Technologies for Historical and Ancient Languages, European Language Resources Association (ELRA), Marseille, France, 2020, pp. 100–104. ISBN 979-10-95546-53-5. [99] G. Lakoff, Linguistics and natural logic, Synthese 22(1) (1970), 151–271. doi:10.1007/BF00413602. [100] B. MacCartney and C.D. Manning, Natural logic for textual inference, in: Proceedings of the ACL-PASCAL Workshop on Textual Entailment and Paraphrasing, 2007, pp. 193–200. [101] G. Angeli and C.D. Manning, NaturalLI: Natural Logic Inference for Common Sense Reasoning, in: Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, Doha, Qatar, 2014, pp. 534–545. doi:10.3115/v1/D14-1059. [102] C. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. Bethard and D. McClosky, The Stanford CoreNLP Natural Language Processing Toolkit, in: Proceedings of 52nd Annual Meeting of the Association for Computational Linguistics: System Demonstrations, Association for Computational Linguistics, Baltimore, Maryland, 2014, pp. 55–60. doi:10.3115/v1/P14-5010. https://aclanthology.org/P14-5010. [103] S. McCall, Review of Selected Works, Synthese 26(1) (1973), 165–171. [104] F. Harder and T.R. Besold, Learning Łukasiewicz logic, Cognitive Systems Research 47 (2018), 42–67. doi:10.1016/j.cogsys.2017.07.004. [105] C. Strasser and G.A. Antonelli, Non-monotonic Logic, in: The Stanford Encyclopedia of Philosophy, Summer 2019 edn, Metaphysics Research Lab, Stanford University, 2019. [106] J.P. McCrae, E. Rudnicka and F. Bond, English WordNet: A new open-source wordnet for English, 2021. https://lexicala.com/review/2020/mccrae-rudnicka-bond-english-wordnet/. [107] J. D’Souza, I.O. Mulang’ and S. Auer, Team SVMrank: Leveraging Feature-rich Support Vector Machines for Ranking Explanations to Elementary Science Questions, in: Proceedings of the Thirteenth Workshop on Graph-Based Methods for Natural Language Processing, TextGraphs@EMNLP 2019, Hong Kong, November 4, 2019, Association for Computational Linguistics, 2019, pp. 90–100. doi:10.18653/v1/D19-5312. [108] A. Hussain and E. Cambria, Semi-supervised learning for big social data analysis, Neurocomputing 275 (2018), 1662–1673. doi:10.1016/j.neucom.2017.10.010. [109] Q. Cui, Y. Zhou and M. Zheng, Sememes-Based Framework for Knowledge Graph Embedding with Comprehensive-Information, Lecture Notes in Computer Science 12816 LNAI (2021), 419–426. doi:10.1007/978-3-030-82147-0_34. [110] C. Xu and R. Li, Relation Embedding with Dihedral Group in Knowledge Graph, in: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, Florence, Italy, 2019, pp. 263–272. doi:10.18653/v1/P19-1026. [111] A.I. Cowen-Rivers, P. Minervini, T. Rocktaschel, M. Bosnjak, S. Riedel and J. Wang, Neural Variational Inference For Estimating Uncertainty in Knowledge Graph Embeddings (2019). [112] M. Bounabi, K. Elmoutaouakil and K. Satori, A new neutrosophic TF-IDF term weighting for text mining tasks: text classiﬁcation use case, International Journal of Web Information Systems 17(3) (2021), 229–249. doi:10.1108/IJWIS-11-2020-0067. [113] F. Es-Sabery, A. Hair, J. Qadir, B. Sainz-De-Abajo, B. Garcia-Zapirain and I. Torre-DIez, Sentence-Level Classiﬁcation Using Parallel Fuzzy Deep Learning Classiﬁer, IEEE Access 9 (2021), 17943–17985. doi:10.1109/ACCESS.2021.3053917. [114] R. Lima, B. Espinasse and F. Freitas, The Impact of Semantic Linguistic Features in Relation Extraction: A Logical Relational Learning Approach, in: Proceedings of the International Conference on Recent Advances in Natural Language Processing (RANLP 2019), INCOMA Ltd., Varna, Bulgaria, 2019, pp. 648–654. doi:10.26615/978-954-452-056-4_076. [115] Q. Chen, A. Lamoreaux, X. Wang, G. Durrett, O. Bastani and I. Dillig, Web Question Answering with Neurosymbolic Program Synthesis, in: Proceedings of the 42nd ACM SIGPLAN International Conference on Programming Language Design and Implementation, Association for Computing Machinery, New York, NY, USA, 2021, pp. 328–343–. ISBN 9781450383912. https://doi.org/10.1145/3453483.3454047 . [116] Y. Yao, J. Xu, J. Shi and B. Xu, Learning to activate logic rules for textual reasoning, Neural Networks 106 (2018), 42–49. doi:10.1016/j.neunet.2018.06.012. [117] A.A.N. Tato, R. Nkambou and A. Dufresne, Hybrid Deep Neural Networks to Predict Socio-Moral Reasoning Skills, in: Proceedings of the 12th International Conference on Educational Data Mining, EDM 2019, Montréal, Canada, July 2-5, 2019, International Educational Data Mining Society (IEDMS), 2019. https://drive.google.com/ﬁle/d/1aCXyukLqVeuShQSGATRzEeDAk_Al7bVz. [118] I. Chaturvedi, R. Satapathy, S. Cavallari and E. Cambria, Fuzzy commonsense reasoning for multimodal sentiment analysis, Pattern Recognition Letters 125 (2019), 264–270. doi:10.1016/j.patrec.2019.04.024. [119] R. Ayyanar, G. Koomullil and H. Ramasangu, Causal relation classiﬁcation using convolutional neural networks and grammar tags, 2019. doi:10.1109/INDICON47234.2019.9028985. [120] J. Gong, H. Ma, Z. Teng, Q. Teng, H. Zhang, L. Du, S. Chen, M.Z.A. Bhuiyan, J. Li and M. Liu, Hierarchical Graph Transformer-Based Deep Learning Model for Large-Scale Multi-Label Text Classiﬁcation, IEEE Access 8 (2020), 30885–30896. doi:10.1109/ACCESS.2020.2972751. [121] A.M.P. Bra¸soveanu and R. Andonie, Semantic Fake News Detection: A Machine Learning Perspective, Lecture Notes in Computer Science 11506 LNCS (2019), 656–667. doi:10.1007/978-3-030-20521-8_54. [122] D. Hu, L. Wei and X. Huai, DialogueCRN: Contextual Reasoning Networks for Emotion Recognition in Conversations, in: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association for Computational Linguistics, Online, 2021, pp. 7042–7052. doi:10.18653/v1/2021.acl-long.547. [123] K. Chen, Q. Huang, H. Palangi, P. Smolensky, K.D. Forbus and J. Gao, Mapping Natural-Language Problems to Formal-Language Solutions Using Structured Neural Representations, in: Proceedings of the 37th International Conference on Machine Learning, JMLR.org, 2020. [124] L. Graziani, S. Melacci and M. Gori, Jointly Learning to Detect Emotions and Predict Facebook Reactions, Lecture Notes in Computer Science 11730 LNCS (2019), 185–197. doi:10.1007/978-3-030-30490-4_16. [125] K. Gupta, T. Ghosal and A. Ekbal, A Neuro-Symbolic Approach for Question Answering on Research Articles, in: Proceedings of the 35th Paciﬁc Asia Conference on Language, Information and Computation, Association for Computational Lingustics, Shanghai, China, 2021, pp. 40–49. [126] J. Langton and K. Srihasam, Applied Medical Code Mapping with Character-based Deep Learning Models and Word-based Logic, in: Proceedings of the 1st and 2nd Workshops on Natural Logic Meets Machine Learning (NALOMA), Association for Computational Linguistics, Groningen, the Netherlands (online), 2021, pp. 7–11. [127] L.B. Fazlic, A. Hallawa, A. Schmeink, A. Peine, L. Martin and G. Dartmann, A Novel NLP-FUZZY System Prototype for Information Extraction from Medical Guidelines, in: 2019 42nd International Convention on Information and Communication Technology, Electronics and Microelectronics (MIPRO), 2019, pp. 1025–1030. doi:10.23919/MIPRO.2019.8756929. [128] C. Schon, S. Siebert and F. Stolzenburg, The CoRg Project: Cognitive Reasoning, KI - Kunstliche Intelligenz 33(3) (2019), 293–299. doi:10.1007/s13218-019-00601-5. [129] M.L. Pacheco and D. Goldwasser, Modeling Content and Context with Deep Relational Learning, Transactions of the Association for Computational Linguistics 9 (2021), 100–119. doi:10.1162/tacl_a_00357. [130] K. Amin, Cases without Borders: Automating Knowledge Acquisition Approach using Deep Autoencoders and Siamese Networks in Case-Based Reasoning, in: 2019 IEEE 31st International Conference on Tools with Artiﬁcial Intelligence (ICTAI), 2019, pp. 133–140. doi:10.1109/ICTAI.2019.00027. [131] E. Altszyler, P. Brusco, N. Basiou, J. Byrnes and D. Vergyri, Zero-shot Multi-Domain Dialog State Tracking Using Prescriptive Rules, in: Proceedings of the 15th International Workshop on Neural-Symbolic Learning and Reasoning as part of the 1st International Joint Conference on Learning & Reasoning (IJCLR 2021), Virtual conference, October 25-27, 2021, CEUR Workshop Proceedings, Vol. 2986, CEUR-WS.org, 2021, pp. 57–66. [132] A. Sutherland, S. Magg and S. Wermter, Leveraging Recursive Processing for Neural-Symbolic Affect-Target Associations, in: 2019 International Joint Conference on Neural Networks (IJCNN), 2019, pp. 1–6. doi:10.1109/IJCNN.2019.8851875. [133] D. Demeter and D. Downey, Just Add Functions: A Neural-Symbolic Language Model, in: The Thirty-Fourth AAAI Conference on Artiﬁcial Intelligence, AAAI 2020, The Thirty-Second Innovative Applications of Artiﬁcial Intelligence Conference, IAAI 2020, The Tenth AAAI Symposium on Educational Advances in Artiﬁcial Intelligence, EAAI 2020, New York, NY, USA, February 7-12, 2020, AAAI Press, 2020, pp. 7634–7642. [134] B. Zhou, K. Richardson, Q. Ning, T. Khot, A. Sabharwal and D. Roth, Temporal Reasoning on Implicit Events from Distant Supervision, in: Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics, Online, 2021, pp. 1361–1371. doi:10.18653/v1/2021.naacl- main.107. [135] J. Qin, X. Liang, Y. Hong, J. Tang and L. Lin, Neural-Symbolic Solver for Math Word Problems with Auxiliary Tasks, in: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association for Computational Linguistics, Online, 2021, pp. 5870–5881. doi:10.18653/v1/2021.acl-long.456. [136] P. Sen, M. Danilevsky, Y. Li, S. Brahma, M. Boehm, L. Chiticariu and R. Krishnamurthy, Learning Explainable Linguistic Expressions with Neural Inductive Logic Programming for Sentence Classiﬁcation, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, Online, 2020, pp. 4211–4221. doi:10.18653/v1/2020.emnlp-main.345. [137] J. Mao, C. Gan, P. Kohli, J.B. Tenenbaum and J. Wu, The Neuro-Symbolic Concept Learner: Interpreting Scenes, Words, and Sentences From Natural Supervision, in: 7th International Conference on Learning Representations, ICLR 2019, New Orleans, LA, USA, May 6-9, 2019, OpenReview.net, 2019. [138] P. Kouris, G. Alexandridis and A. Stafylopatis, Abstractive Text Summarization: Enhancing Sequence-to-Sequence Models Using Word Sense Disambiguation and Semantic Content Generalization, Computational Linguistics 47(4) (2021), 813–859. doi:10.1162/coli_a_00417. [139] C.S. Pinhanez, P.R. Cavalin, V.H.A. Ribeiro, A.P. Appel, H. Candello, J. Nogima, M. Pichiliani, M.A. Guerra, M. de Bayser, G.L. Malfatti and H. Ferreira, Using Meta-Knowledge Mined from Identiﬁers to Improve Intent Recognition in Conversational Systems, in: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing, ACL/IJCNLP 2021, (Volume 1: Long Papers), Virtual Event, August 1-6, 2021, C. Zong, F. Xia, W. Li and R. Navigli, eds, Association for Computational Linguistics, 2021, pp. 7014–7027. doi:10.18653/v1/2021.acl-long.545. [140] W. Liu, J. Tang, X. Liang and Q. Cai, Heterogeneous graph reasoning for knowledge-grounded medical dialogue system, Neurocomputing 442 (2021), 260–268. doi:10.1016/j.neucom.2021.02.021. [141] P. Manda, S. SayedAhmed and S.D. Mohanty, Automated Ontology-Based Annotation of Scientiﬁc Literature Using Deep Learning, in: Proceedings of The International Workshop on Semantic Big Data, SBD ’20, Association for Computing Machinery, New York, NY, USA, 2020. ISBN 9781450379748. doi:10.1145/3391274.3393636. [142] Q. Huang, L. Deng, D. Wu, C. Liu and X. He, Attentive Tensor Product Learning, Proceedings of the AAAI Conference on Artiﬁcial Intelligence 33(01) (2019), 1344–1351. doi:10.1609/aaai.v33i01.33011344. [143] Z. Chen, Q. Gao and L.S. Moss, NeuralLog: Natural Language Inference with Joint Neural and Logical Reasoning, in: Proceedings of *SEM 2021: The Tenth Joint Conference on Lexical and Computational Semantics, Association for Computational Linguistics, Online, 2021, pp. 78–88. doi:10.18653/v1/2021.starsem-1.7. [144] K. Kogkalidis, M. Moortgat and R. Moot, Neural Proof Nets, in: Proceedings of the 24th Conference on Computational Natural Language Learning, Association for Computational Linguistics, Online, 2020, pp. 26–40. doi:10.18653/v1/2020.conll-1.3. [145] M. Wu, W. Wang and S.J. Pan, Deep Weighted MaxSAT for Aspect-based Opinion Extraction, in: Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP), Association for Computational Linguistics, Online, 2020, pp. 5618–5628. doi:10.18653/v1/2020.emnlp-main.453. [146] J. Shi, X. Ding, L. Du, T. Liu and B. Qin, Neural Natural Logic Inference for Interpretable Question Answering, in: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 2021, pp. 3673–3684. doi:10.18653/v1/2021.emnlp-main.298. [147] W. Wang and S.J. Pan, Variational Deep Logic Network for Joint Inference of Entities and Relations, Computational Linguistics 47(4) (2021), 775–812. doi:10.1162/coli_a_00415. [148] T. Li and V. Srikumar, Augmenting Neural Networks with First-order Logic, in: Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, Association for Computational Linguistics, Florence, Italy, 2019, pp. 292–302. doi:10.18653/v1/P19- 1028. [149] H. Honda and M. Hagiwara, Question Answering Systems with Deep Learning-Based Symbolic Processing, IEEE Access 7 (2019), 152368–152378. doi:10.1109/ACCESS.2019.2948081. [150] L. Yabloko, ETHAN at SemEval-2020 Task 5: Modelling Causal Reasoning in Language Using Neuro-symbolic Cloud Computing, in: Proceedings of the Fourteenth Workshop on Semantic Evaluation, International Committee for Computational Linguistics, Barcelona (online), 2020, pp. 645–652. doi:10.18653/v1/2020.semeval-1.83. [151] R. Das, M. Zaheer, D. Thai, A. Godbole, E. Perez, J.Y. Lee, L. Tan, L. Polymenakos and A. McCallum, Case-based Reasoning for Natural Language Queries over Knowledge Bases, in: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 2021, pp. 9594–9611. doi:10.18653/v1/2021.emnlp-main.755. [152] H. Jiang, S. Gurajada, Q. Lu, S. Neelam, L. Popa, P. Sen, Y. Li and A. Gray, LNN-EL: A Neuro-Symbolic Approach to Short-text Entity Linking, in: Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers), Association for Computational Linguistics, Online, 2021, pp. 775–787. doi:10.18653/v1/2021.acl-long.64. [153] C. Dehua, Z. Keting and H. Jianrong, BDCN: Semantic Embedding Self-explanatory Breast Diagnostic Capsules Network, in: Proceedings of the 20th Chinese National Conference on Computational Linguistics, Chinese Information Processing Society of China, Huhhot, China, 2021, pp. 1178–1189. [154] P. Verga, H. Sun, L. Baldini Soares and W. Cohen, Adaptable and Interpretable Neural MemoryOver Symbolic Knowledge, in: Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Association for Computational Linguistics, Online, 2021, pp. 3678–3691. doi:10.18653/v1/2021.naacl-main.288. [155] S. Chaudhury, P. Sen, M. Ono, D. Kimura, M. Tatsubori and A. Munawar, Neuro-Symbolic Approaches for Text-Based Policy Learning, in: Proceedings of the 2021 Conference on Empirical Methods in Natural Language Processing, Association for Computational Linguistics, Online and Punta Cana, Dominican Republic, 2021, pp. 3073–3078. doi:10.18653/v1/2021.emnlp-main.245. [156] G. Lample and F. Charton, Deep Learning for Symbolic Mathematics, arXiv preprint arXiv:1912.01412 (2019). doi:10.48550/ARXIV.1912.01412. [157] P. Smolensky, Tensor product variable binding and the representation of symbolic structures in connectionist systems, Artiﬁcial Intelligence 46(1) (1990), 159–216. doi:https://doi.org/10.1016/0004-3702(90)90007-M. [158] A.S. Gordon and J.R. Hobbs, A Formal Theory of Commonsense Psychology: How People Think People Think, Cambridge University Press, 2017. doi:10.1017/9781316584705. [159] H. Santos, M. Kejriwal, A.M. Mulvehill, G. Forbush and D.L. McGuinness, An experimental study measuring human annotator categorization agreement on commonsense sentences, Experimental Results 2 (2021), e19. doi:10.1017/exp.2021.9. [160] R. Cartuyvels, G. Spinks and M.-F. Moens, Discrete and continuous representations and processing in deep learning: Looking forward, AI Open 2 (2021), 143–159. doi:10.1016/j.aiopen.2021.07.002. [161] E. Tsamoura, T. Hospedales and L. Michael, Neural-Symbolic Integration: A Compositional Perspective, Proceedings of the AAAI Conference on Artiﬁcial Intelligence 35(66) (2021), 5051–5060. [162] G. Boleda, Distributional Semantics and Linguistic Theory, Annual Review of Linguistics 6(1) (2020), 213–234. doi:10.1146/annurev- linguistics-011619-030303. [163] X. Chen, C. Liang, A.W. Yu, D. Song and D. Zhou, Compositional Generalization via Neural-Symbolic Stack Machines, in: Proceedings of the 34th International Conference on Neural Information Processing Systems, NIPS’20, 2020. ISBN 9781713829546. [164] V. Embar, D. Sridhar, G. Farnadi and L. Getoor, Scalable Structure Learning for Probabilistic Soft Logic, arXiv:1807.00973 [cs, stat] (2018). [165] M. Diligenti, M. Gori and C. Saccà, Semantic-based regularization for learning and inference, Artiﬁcial Intelligence 244 (2017), 143–165. doi:10.1016/j.artint.2015.08.011. [166] R. Manhaeve, S. Dumancic, A. Kimmig, T. Demeester and L. De Raedt, DeepProbLog: Neural Probabilistic Logic Programming, Advances in Neural Information Processing Systems 31 (2018). Appendix A. NeSy and Kautz Categories Table 7 NeSy and Kautz Categories Appendix B. Allowed Values Table 8 Allowed values Appendix C. Venues Table 9 Venues referred in the study Appendix D. Acronyms Table 10 Acronyms and Abbreviations This figure \"iospress.png\" is available in \"png\"\u0000 format from: http://arxiv.org/ps/2202.12205v2","libVersion":"0.3.2","langs":""}