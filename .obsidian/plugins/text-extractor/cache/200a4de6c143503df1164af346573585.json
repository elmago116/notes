{"path":"Clippings/PDF/Literature reviews.pdf","text":"Ana Paula Cardoso Ermel · D. P. Lacerda · Maria Isabel W. M. Morandi · Leandro Gauss Literature Reviews Modern Methods for Investigating Scientific and Technological Knowledge Literature ReviewsAna Paula Cardoso Ermel · D. P. Lacerda · Maria Isabel W. M. Morandi · Leandro Gauss Literature Reviews Modern Methods for Investigating Scientiﬁc and Technological Knowledge Ana Paula Cardoso Ermel Production and Systems Engineering Universidade do Vale do Rio dos Sinos São Leopoldo, Rio Grande do Sul, Brazil Maria Isabel W. M. Morandi Production and Systems Engineering Universidade do Vale do Rio dos Sinos São Leopoldo, Rio Grande do Sul, Brazil D. P. Lacerda Production and Systems Engineering Universidade do Vale do Rio dos Sinos São Leopoldo, Rio Grande do Sul, Brazil Leandro Gauss Production and Systems Engineering Universidade do Vale do Rio dos Sinos São Leopoldo, Rio Grande do Sul, Brazil ISBN 978-3-030-75721-2 ISBN 978-3-030-75722-9 (eBook) https://doi.org/10.1007/978-3-030-75722-9 © The Editor(s) (if applicable) and The Author(s), under exclusive license to Springer Nature Switzerland AG 2021, corrected publication 2021 This work is subject to copyright. All rights are solely and exclusively licensed by the Publisher, whether the whole or part of the material is concerned, speciﬁcally the rights of reprinting, reuse of illustrations, recitation, broadcasting, reproduction on microﬁlms or in any other physical way, and transmission or information storage and retrieval, electronic adaptation, computer software, or by similar or dissimilar methodology now known or hereafter developed. The use of general descriptive names, registered names, trademarks, service marks, etc. in this publication does not imply, even in the absence of a speciﬁc statement, that such names are exempt from the relevant protective laws and regulations and therefore free for general use. The publisher, the authors and the editors are safe to assume that the advice and information in this book are believed to be true and accurate at the date of publication. Neither the publisher nor the authors or the editors give a warranty, expressed or implied, with respect to the material contained herein or for any errors or omissions that may have been made. The publisher remains neutral with regard to jurisdictional claims in published maps and institutional afﬁliations. This Springer imprint is published by the registered company Springer Nature Switzerland AG The registered company address is: Gewerbestrasse 11, 6330 Cham, Switzerland Foreword This book introduces the reader to the different facets of Literature Reviews (LR) as a research endeavor by its own merits and not only as a descriptive summary of previous work. Citing Sir Isaac Newton, after Vom Broke: “If I see further it is because I am standing on the shoulders of giants.” The quote summarizes well the leverage gained in scientiﬁc knowledge based on LRs. This book is welcomed for several reasons. First and foremost, because of its generic approach to literature reviews and its extension to the engineering and management ﬁelds. The deﬁnitions, methods, and tools of LR originate from psychology and education research and is nowadays the prominent method for evidence-based medicine and public policies, with fully devoted repositories in medicine and social sciences like the Cochrane, Joanna Briggs Institute and Camp- bell initiatives. It is gaining momentum in management and engineering, where it still suffers from misinformed conceptions and ongoing multidisciplinary method- ological adaptations. The extension of LR techniques and tools to management and engineering carries the inherent difﬁculties due to both ontological and epistemolog- ical differences among research ﬁelds and disciplines. One of the merits of this book is to boldly state yes, we can succeed in evidence-based management and engineering through the accumulation of knowledge gained with LRs. Second, the book directly addresses the ontological foundations of LR. It calls for inductive grounded theories in its title but opens the door to the hypothetical- deductive logic of Karl Popper in the second chapter. The contradiction is only apparent because the ontological nature of LR is largely in the eyes of the beholder. It can be used for theory development as well as to reﬁne or to falsify existing theories. It offers inferential and aggregative synthesis using the logic of induction, deduction, and abductive reasoning. It also resorts to both qualitative and quantitative methods. Third, the authors introduce a high-level demand for methodological rigor and here the words Systematic Literature Reviews (SLR) come into play. It is a brave new world. In SLRs, the focus shifts from LR to systematic LR, which are not only systematic but also transparent and reproducible, limiting systematic errors and bias. The reader is invited to relentlessly turn page after page of updated information on deﬁnitions, step-by-step methods, analysis, synthesis, computational tools, and v vi Foreword exemplar applications. A central chapter is devoted to a step-by-step guideline for practice. In summary, the book tells a simple story: deﬁne your subject, ask the appropriate research questions, search the literature, analyze, synthesize, and report. But be rigorous and transparent. Fourth, the method of SLR is introduced clearly and the explanation is didactic. The book chapters are well deﬁned and delineated. The reader might embark into an orderly and progressive journey after Chap. 1, from Chap. 2 (ontology) to Chap. 8 (applications), or rather take a direct jump to the chapter of interest, say to do step- by-step reviews (Chap. 3), analyze SLR data with the fundaments of scientomet- rics, bibliometrics, and content analysis (Chap. 4); synthesize and report (Chap. 5); systematize the review process (Chap. 6); explore software tools for qualitative and quantitative methods in SLRs (Chap. 7); or review exemplar cases (Chap. 8). Finally, and maybe most importantly, this book addresses an academic require- ment facing undergraduate and graduate students, their teachers and tutors, manage- ment and engineer practitioners, and policy-makers alike, in all phases of their careers: review the existing knowledge base of their discipline and subject matter. As repeatedly said after Mulrow, there are at least nine reasons to do SLRs. And I would add, there is at least one reason to recommend this book. SLRs (i) synthesize large amounts of information; (ii) direct the attention to key issues for research, practice, and policy-making; (iii) cost less than primary research; (iv) foster the generaliza- tion of ﬁndings; (v) assist in relating variables; (vi) address inconsistencies in ﬁnd- ings; (vii) increase statistical power by aggregating individual studies; (viii) improve the precision of statistical inference; and (ix) systematically report procedures and methods, allowing veriﬁcation. This book makes it possible to explore and apply SLR techniques, a mandatory requirement to answer the questions appearing in the day-to-day research in all undergraduate and graduate tasks, from simple assign- ments to dissertations and theses. And that is the reason why this book is a highly recommended reading for all students, researchers, and practitioners in engineering and management. Prof. Antônio Márcio T. Thomé, D.Sc. President, Global Manufacturing Research Group (GMRG) Industrial Engineering Department PUC-Rio - Pontiﬁcal Catholic University of Rio de Janeiro Rio de Janeiro, Brazil The original version of the book was revised: Belated corrections have been incorporated. The corrections to the book are available at https://doi.org/10.1007/978-3-030-75722-9_10 Acknowledgments I would like to thank everyone who somehow contributed to make this work come true. Initially, I highlight the encouragement of Prof. Dr. Cristiano Vitorino da Silva, who, since the beginning of my undergraduate studies, encouraged me to follow an academic career. I would also like to thank the specialists who dedicated their time to contribute with their knowledge to the construction of this research: Prof. Dr. Liane Kipper, Prof. Dr. Édison Renato Pereira da Silva, Prof. Dr. Amarolinda Zanela Klein, Prof. Dr. Flavio Sanson Fogliato, Prof. Dr. Mario Sergio Salerno, Prof. Dr. Osvaldo Gonçalves Quelhas, Prof. Dr. Antônio Márcio Thomé, Prof. Dr. Paulo Smith Schneider, Prof. Dr. Ricardo Cassel, Prof. Dr. Carlo Bellini, Prof. Dr. Junico Antunes, and Prof. Dr. Julio Cezar Siluk. I also thank my colleagues and friends from the Research Group on Modeling for Learning (GMAP | UNISINOS) for their partnership and incentive during the 2 years of the masters’ program: Jaqueline Abreu, Mariana Machado, Douglas Veit, Pedro do Nascimento, Jayme Peixoto, and Fábio Piran. Each one of you, in your way, contributed to this research. Special thanks to Lia Piovesan and Kymberli Borba, who, besides being colleagues, are friends that I will carry forever in my heart. I cannot fail to thank Aline Dresch, who started this project with me. Aline, you are an example of a person, a professional, and, without a doubt, an example to be followed. I take this opportunity to thank Leandro Gauss, whom I met in the master’s program. Leandro, I thank you for the honor of being able to share this project with you. Thank you for accepting this challenge, believing in our work, and, also, for all the teaching during this period. I thank Prof. Maria Isabel (Bel or Mabel to the intimate ones). My ﬁrst master’s reading was a chapter written by you: the famous Chap.6 on Systematic Literature Review. Bel, you are an amazing person, both professionally and personally. Thank you for all the technical teachings about the research topic, not forgetting the teachings about life. Finally, a special thanks to Prof. Daniel Pacheco Lacerda. Daniel, with no doubts, you are an extraordinary professional, with enviable knowledge. You are the great creator of this project and have spared no efforts until it became a reality. I admire your determination to always seek and defend the best for your students. I believe that this is the role of a teacher vii viii Acknowledgments and that you fulﬁll it with praise. Thank you for proposing this challenge to me and also for believing in my capacity to make it happen. Finally, I would like to thank my family, that even though physically distant, who have always been with me. Mom and Daddy, you never spared any effort to see me happy and you always supported me in all my decisions. What I am today I owe to you. To my brothers, Wilson, Anderson, and Cleiton, and my sisters-in-law, Raquel and Vanessa, thank you for not letting me give up despite all the difﬁculties encountered along the way. To my nephews, Arthur Vinícius, Maria Cristina, and Ana Luísa, thank you very much for being the light and illuminating my path. Without you, none of this would be possible. Thank you very much! I love you all! Ana Paula Cardoso Ermel This book has many origins that have converged to produce its outcome. During the discussions regarding my doctoral thesis, my orientator, Prof. Heitor M. Caulliraux (COPPE/UFRJ), stated that my research would face difﬁculties in demonstrating its originality. Due to this alert, I needed to tentatively develop an initial approach to demonstrate the feasibility of the research clearly. Intuitively, I was taking the ﬁrst steps of a systematic literature review (justiﬁcation of the thesis), which, although already known in other areas, was still incipient in Brazilian Production Engineering. In the course of the academic trajectory, in the ﬁrst contact with Prof. Márcio Thomé (PUC-Rio), we engaged in a heated discussion about the role of systematic literature reviews in our area. That debate marked the beginning of fruitful joint ventures. At one of many family dinners with Prof. Carlo Bellini (UFPB), discussing some research ideas, two references were recommended to me that would form the basis of this book. Finally, in a presentation by GPI/UFRJ (Integrated Production Group) led by Prof. Heitor M. Caulliraux (COPPE/UFRJ), I had my ﬁrst contact with bibliometric analysis software. As a result of these events, I had developed a clearer picture of the weaknesses and potential of systematic reviews. Prof. Édison Renato (COPPE/UFRJ) was also a great source of inspiration and ideas. “What to change” was clear in my mind, and GMAP | UNISINOS was the appro- priate environment for “Effecting Change,” although, I had no idea about “What to change” (the Theory of Constraints thinking process has always been one of the bases of my reasoning). So, from the outset, I would like to thank Prof. Heitor M. Caulli- raux (COPPE/UFRJ), Prof. Márcio Thomé (PUC-Rio), Prof. Carlo Bellini (UFPB), and Prof. Édison Renato (COPPE/UFRJ) for the exchanges, provocations, respect, and the critical acidity inherent to all great researchers. My respect and admiration for you! “For what to change” was built by many brains under the discipline Qual- itative Research Methods in Production Engineering in the postgraduate program, Production and Systems Engineering (PPGEPS/UNISINOS). My ﬁrst partner on this journey was Prof. Maria Isabel W. M. Morandi, Co- Founder of GMAP | UNISINOS with Prof. Luis Henrique Rodrigues (IESB). Since Mabel (as I affectionately call her), as always, had done a brilliant job, I invited her, together with Prof. Luis Felipe Riehs Camargo (IESB), to include a chapter in the books on Design Science and Design Science Research that we were Acknowledgments ix ﬁnishing with Prof. Aline Dresch (Dresch Consultoria) and Prof. Junico Antunes (PPGEPS/UNISINOS). I thank Mabel for her partnership as well as for her effort in making GMAP | UNISINOS resilient and great. I admire her a lot and consider her a friend with one of the biggest hearts I know. On this journey, another remarkable work in the discipline was carried out by Profs. Pedro Lima (RAND Corporation) and Andrey Schimidt (GERDAU), when they presented advances in bibliometric analysis software and quantitative techniques for quantitative analysis, respectively. Thousands of people in Brazil and around the world have seen Prof. Pedro Lima’s videos on search in scientiﬁc bases and via bibliometric software. Furthermore, I am very grateful to Prof. Pedro Lima for his intelligence, self-conﬁdence, and openness to new challenges! His dedication and qualities must inspire thousands of professionals and boost knowledge sharing, a value that we cultivate at GMAP | UNISINOS as one of the highest levels of human generosity. I thank him very much for his decisive contribution to our work. Finally, I would like to thank Prof. Ana Ermel (GMAP | UNISINOS) and Prof. Leandro Gauss (GMAP | UNISINOS), who ﬁnalized and materialized our vision of “What to change to” by building the Literature Grounded Theory. They believed, accepted the challenge, and were decisive regarding these ideas worked on for more than 10 years. I also thank Prof. Ana Ermel for her persistence, determination, open- ness to criticism, and unremitting work. Undoubtedly, it was her ﬁrst step toward a ﬁne scientiﬁc career. Moreover, I thank Prof. Leandro Gauss for his discipline, excellence in research, inventiveness, patience, and organization that were decisive for this work. God, in his wisdom, made us follow the same path after a great disap- pointment, when he asked me about the meaning of the work he was engaged in. We performed great research and works winning awards in the scientiﬁc community, I am sure that this constitutes the path of a promising research partnership. I am deeply grateful to Mabel and Ana, as without them, this book would not have been possible, and it is people like them who motivate us to seek ever greater achievements. Finally, I would like to thank other people who are also very important in my life. My gratitude goes to Prof. Ione Bentz (PPGDesign/UNISINOS), Prof. Luis Henrique Rodrigues (IESB), and Prof. Junico Antunes (PPGEPS/UNISINOS) for their high- level discussions that have always opened up new perspectives. I thank Prof. Jayme Peixoto (GMAP | UNISINOS and Prof. Douglas Veit (GMAP | UNISINOS) for the work we have been doing in UNISINOS Graduation. We are a strong team! I also extend my gratitude to Prof. Luiz Alberto Rocha (PPGEPS/UNISINOS) for his generosity, intellectual integrity, high level, and for being the most humane engineer I know! My congratulations for his leadership! I am grateful too to Prof. Fábio Sartori Piran (GMAP | UNISINOS) for his long-standing, successful partnership, for our shared moments of humor, and for the serious research work we have developed. I am grateful to Prof. Ricardo Cassel (UFRGS) for having been my professor, and, till today, someone so close in professional and family terms. Indeed, I admire him very much for his professional integrity, his humanity, and as a great father. I am indebted to him for all the lessons he gave me. My thanks also go to Prof. Priscila Ferraz (FIOCRUZ) for her friendship, as well as her intellectuality that brings us so close together, something that only increases exponentially! x Acknowledgments Naturally I thank my family, the ultimate reason for my life! My thanks are due to my wife, Carina Silveira Pereira (Xuxu) for her generosity, affection, strength, and balance to appreciate our achievements together, and, above all, for always believing in something better, and her determination to overcome every challenge. As always, I mean I would never have reached where I am now without the strength that emanates from her (my daring side)! I thank my children’s godmother, Tatiane Pereira for her decisive support for my family! I thank my mother-in-law, Eloir Pereira, and my father-in-law, Alvaci Pereira (Papipa), for their example that helped me have my warm heart. Nothing I say or write will ever express the love and admiration that I feel for them! I dedicate this book to my children Caio Lacerda and Serena Lacerda. In Caio I see dedication, intelligence, and the best heart that a Lacerda has ever had. In Serena I see the joy, creativity, spontaneity, and competitiveness that are inherent to our family. I love them so much, no matter what the qualities and faults they may have. I hope I have inspired all the people mentioned here. For me they have been inspiring and decisive! Lastly, I thank God for his immense generosity toward me! I graduated and work in a University of the Society of Jesus, which always inspires me with the motto “Search and ﬁnd God in all things and all things in God.” There is no doubt God has always been in everything I have done, and I am eternally grateful to Him. Some of his mysterious ways only time has made clear, but they have always been for my good. D. P. Lacerda I have been studying and working with Systems Thinking since 2006, when I had a class with Prof. Luis Henrique Rodrigues (IESB), undoubtedly one of the best professors I ever had in my life. As he states, Systems Thinking is the ability to assess the impact of our decisions on time and space. If I had known that, I might not have been so concerned when I decided to switch from an executive business career to an academic one. Undoubtedly, the trust of Professor Luis Henrique Rodrigues (IESB) and the opportunities he gave me were fundamental for this transition to be not only possible, but very successful. In this way, I would like to thank Prof. Luis Henrique Rodrigues (IESB) for being the ﬁrst pillar of my academic trajectory. It was also Prof. Luis Henrique Rodrigues (IESB) who introduced me to Prof. Daniel Pacheco Lacerda (PPGEPS/UNISINOS). In 2009, we founded together GMAP | UNISINOS. Since then, Daniel has been a mentor, a partner, and a great friend. I admire his ability to inspire and extract the best that each student has. I also admire his discipline and achievement capacity. But above all, I admire his character and generosity. Happy are those who have the opportunity to share a part of their lives with him. My gratitude to Prof. Daniel Pacheco Lacerda (PPGEPS/UNISINOS) for the whole partnership over these years—I hope that many more will come. It was in this trajectory together that the story of this book begins for me. My participation in this book goes back to the Easter holiday of 2013, when, visiting my parents on the beach, I prepared a seminar on Systematic Review of Literature to be presented in the Ph.D. class. My academic partner and Acknowledgments xi my professor of Qualitative Research Methods, Prof. Daniel Pacheco Lacerda (PPGEPS/UNISINOS), had another theme in mind for me. But I volunteered for this one: it was written! As a consequence of this seminar, came an invitation to write, along with Prof. Luis Felipe Rihes Camargo (IESB), a chapter of the book Design Science Research. Here are my thanks to the authors: Aline Dresch (Dresch Consultoria), Prof. Daniel Pacheco Lacerda (PPGEPS/UNISINOS), and Prof. Junico Antunes (PPGEPS/UNISINOS) for their trust and opportunity. Friendship with Prof. Aline Dresch (Dresch Consultoria) is one of the great gifts that life has given me. Prof. Junico Antunes (PPGEPS/UNISINOS) is one of the most brilliant minds I know; it is an honor and a pleasure to have been his student and today to be his colleague. I would also like to thank Prof. Luis Felipe Rihes Camargo (IESB), who accepted the challenge of sharing this mission. Felipe (as I got used to calling him) is a brilliant professional and a great friend that the academy gave me. Over the years, the content of this chapter has been helping students and researchers, what makes me very happy. However, in the search for continuous improvement, Prof. Daniel Pacheco Lacerda (PPGEPS/UNISINOS) continued to instigate and inspire his students to advance in this theme. Many advances have been achieved. Then came Prof. Ana Paula Cardoso Ermel (GMAP | UNISINOS) who accepted the great challenge of compiling and expanding the theme by proposing its integration with content analysis and synthesis methods. Some said it was too ambitious, but Ana went ahead and the result is materialized in her excellent master’s dissertation. My thanks and my acknowledgment to Prof. Ana Paula Cardoso Ermel (GMAP | UNISINOS). Her work was essential for the realization of this book. In parallel, Prof. Leandro Gauss (GMAP | UNISINOS) joined the team. With his exceptional intelligence and discipline, he is a fundamental part of our research group. In this project, he took on responsibilities far beyond a co-author. He was our project manager, taking care that the tasks were carried out according to the schedule. He also assumed responsibility for the interface with the publisher, taking care of the adjacent processes, which are fundamental to the publication. It should be noted, however, that his contribution is beyond this book! Prof. Leandro Gauss (GMAP | UNISINOS) is a partner for quality discussions; an exemplary professional and another friend in our “GMAP” family. My thanks to Prof. Leandro Gauss (GMAP | UNISINOS) for his fundamental participation in this project. External partners also contributed signiﬁcantly. Thanks to Prof. Édison Renato Silva (COPPE/UFRJ), Prof. Lia Kipper (UNISC), and Prof. Rosiane Serrano (IFRS)! Thanks to Prof. Raymond Opdenakker and Prof. Talmar Madis (Eindhoven Univer- sity of Technology—TU/e)! Their knowledge and contributions greatly enhance this work. I would like to thank those who, although did not contribute directly to this book, are somehow part of this trajectory. Former GMAP | UNISINOS partners: Prof. Secundino Luis Henrique Corcini Neto (JBS) and Prof. Dieter Brackman Goldmeyer (IFRS) who dreamed and built this excellent research group with us. To current GMAP | UNISINOS partners: Prof. Douglas Rafael Veit (GMAP | UNISINOS), xii Acknowledgments Prof. Fábio Sartori Piran (GMAP | UNISINOS), and Prof. Jayme Peixoto (GMAP | UNISINOS), thank you for allowing us to continue this dream, renewing and adding knowledge, but maintaining the spirit of brotherhood that has always characterized us.More broadly, I would like to extend my thanks to my family. I had the privilege of growing up in a home where study was encouraged and valued, but where play, coexistence, leisure, and especially love were always present. This was the foundation that made me what I am. My thanks to all of them, my grandparents—Trajano and Odete Motta, Hermano and Nilza Wolf, my parents—Augusto Fernando and Clarice Motta, my blood brother—Carlos Augusto, and my heart brother and sister—Ricardo and Joice. I also had the great blessing of having found a life partner who has complemented me for almost 30 years. Thank you very much, Renato Morandi, for all the love and complicity. Finally, I want to thank the God who gave me health to follow this path and allowed me to know and live with all these people. As part of a Jesuit University, I call upon the famous speech by Santo Inácio de Loyola (1491–1556): “Act as if everything depends on you, knowing that, in reality, everything depends on God.” As in a mosaic, the image is only complete when each piece is in place. Beauty can only be appreciated when the work is ﬁnished and the whole is inﬁnitely bigger and more beautiful than the sum of the parts. So is this book: a mosaic of knowledge and individual experiences. I hope that it contributes to the readers advance in their ﬁelds of knowledge! Maria Isabel W. M. Morandi Dear Ana, Prof. Maria Isabel, and Prof. Daniel thank you very much for inviting me to participate in this great project, certainly one of the greatest challenges I have ever faced, in this recent but intense academic career. To Prof. Daniel, my special thanks, your classes in the M.B.E. of Production and Systems Engineering changed the course of my life. Since then, everything good that has happened to me, professionally and academically, has your explicit or implicit participation. The invitation to co-author this book is just one more of the many generous opportunities that you have provided me with. As I have already told you a few times, I will be eternally grateful, and the way I have to repay you is through my unconditional effort to make the research from our group to be recognized as a reference in the areas in which we work. When you join a research group (in my case, another opportunity provided by Prof. Daniel), you come across very intelligent and productive people, and you start admiring them as if they were some kind of “gods.” As time goes by, you begin to perceive in them characteristics of normal people such as affection, generosity, and friendship, which gradually makes you feel part of the group. Prof. Maria Isabel, for me, is perhaps the best representation of this phenomenon. She welcomed me from the very ﬁrst moment and never refused any help that I asked her for. Prof. Maria Isabel, I would like to thank you for all your generosity, and I want you to know that you can count on me for anything you need. I am a soldier of your army! Acknowledgments xiii Ana and I have the same bachelor’s degree, we entered the masters in the same year, and, if I am not mistaken, we did all the classes and their respective assign- ments together. Perhaps the most remarkable one was the Meta-Analysis and Meta- Synthesis Seminar we prepared for Prof. Daniel’s class. I will never forget the last slide of this seminar, in which we formalized our perception about the lack of connec- tion between the activities of literature review, analysis, and synthesis. An initial insight, which later, very well worked out in Ana’s dissertation, resulted in the content of this book. Ana, I admire your willpower and resilience, characteristics that I have noticed since the ﬁrst work we did together. Once again, thank you very much for the opportunity to participate in this great project. This book only reinforces the power of a phrase that Prof. Daniel often says: “alone we go faster, but together we go further.” This idea extends not only to those who participated directly in this project but also to those who indirectly contributed to make this book come true. In this sense, I would like to thank the partnership and complicity of my wife Cíntia, and my two sons, Lucas and Miguel. I love you more than anything in this life. Be assured that the almost 400 hours that I have been absent to carry out this project will certainly make a difference, on a global scale, in the production of scientiﬁc and technological knowledge. Leandro Gauss Contents 1 Introduction ................................................... 1 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 7 2 Scientiﬁc Contributions of Systematic Literature Reviews: Fundamentals in Karl Popper ................................... 9 2.1 Objective Knowledge and the Karl Popper Worlds . . . . . . . . . . . . . . . 9 2.2 Meanings of Knowledge Production in the Light of Popper’s Three Worlds . ............................................. 15 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 18 3 Systematic Literature Review ................................... 19 3.1 Literature Review (LR) ...................................... 19 3.2 Systematic Literature Review (SLR) .......................... 20 3.3 Critical Assessment of SLR Methods . . . . . . . . . . . . . . . . . . . . . . . . . . 22 3.4 Closing Remarks ........................................... 28 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 29 4 Literature Analysis ............................................. 31 4.1 Literature Analysis ......................................... 31 4.2 Scientometric Analysis ...................................... 32 4.3 Bibliometric Analysis ....................................... 36 4.3.1 Research Performance . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 38 4.3.2 Scientiﬁc Mapping . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 40 4.4 Content Analysis ........................................... 50 4.5 Closing Remarks ........................................... 55 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 55 5 Literature Synthesis ............................................ 59 5.1 Literature Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 59 5.2 Conﬁgurative Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 60 5.2.1 Critical Interpretive Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . 67 5.2.2 Integrative Review .................................. 68 5.2.3 Narrative Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 68 5.2.4 Realist Review ..................................... 69 xv xvi Contents 5.2.5 Meta-interpretation .................................. 70 5.2.6 Meta-summary ..................................... 70 5.2.7 Meta-narrative Review ............................... 71 5.2.8 Ecological Triangulation . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 5.2.9 Grounded Theory . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 72 5.2.10 Meta-ethnography . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 74 5.2.11 Meta-synthesis ..................................... 75 5.2.12 Framework Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 76 5.3 Aggregative Synthesis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.3.1 Meta-analysis . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 79 5.4 Closing Remarks ........................................... 82 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 82 6 Literature Grounded Theory (LGT) ............................. 85 6.1 Conceptual Framework and Organization Structure . . . . . . . . . . . . . . 85 6.2 Stakeholders . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 88 6.3 Design (Stage 1) ........................................... 88 6.3.1 Research Question Formulation (Step 1.1) . . . . . . . . . . . . . . 89 6.3.2 Deﬁnition of Review Scope and Type (Step 1.2) . . . . . . . . . 91 6.3.3 Deﬁnition of the Research Team (Step 1.3) . . . . . . . . . . . . . 93 6.3.4 Deﬁnition of the Search Strategy (Step 1.4) . . . . . . . . . . . . . 93 6.3.5 Formulation of the Research Protocol (Step 1.5) . . . . . . . . . 102 6.3.6 Bias Assessment (Step 1.6) ........................... 104 6.4 Review (Stage 2) ........................................... 107 6.4.1 Search and Eligibility (Step 2.1) . . . . . . . . . . . . . . . . . . . . . . 108 6.4.2 Quality Assessment (Step 2.2) . . . . . . . . . . . . . . . . . . . . . . . . 108 6.4.3 Reliability Assessment (Step 2.3) . . . . . . . . . . . . . . . . . . . . . 111 6.4.4 Organization of the Corpus of Analysis (Step 2.4) . . . . . . . 112 6.5 Literature Analysis (Stage 3) ................................. 113 6.5.1 Scientometric Analysis (Step 3.1) . . . . . . . . . . . . . . . . . . . . . 113 6.5.2 Bibliometric Analysis (Step 3.2) ...................... 117 6.5.3 Content Analysis (Step 3.3) . ......................... 118 6.6 Literature Synthesis (Stage 4) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 133 6.6.1 Aggregative Synthesis (Step 4.1) . . . . . . . . . . . . . . . . . . . . . . 134 6.6.2 Conﬁgurative Synthesis (Step 4.2) . . . . . . . . . . . . . . . . . . . . . 137 6.7 Results (Stage 5) ........................................... 140 6.8 Update (Stage 6) . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 141 6.9 Closing Remarks ........................................... 141 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 142 7 Computational Tools for Literature Review, Analysis, and Synthesis .................................................. 147 7.1 Writing Review, Analysis, and Synthesis Protocols . . . . . . . . . . . . . . 150 7.2 Accessing and Exporting Metadata and Full Texts . . . . . . . . . . . . . . . 151 7.3 Reference Management Software . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 154 7.4 Software for Scientometric and Bibliometric Analysis . . . . . . . . . . . 159 Contents xvii 7.5 Software for Content Analysis ................................ 176 7.6 Writing the Report, Presenting Findings . . . . . . . . . . . . . . . . . . . . . . . 185 7.7 Final Remarks ............................................. 187 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 188 8 What to Consider in a Systematic Literature Review: Three Examples from Design Science Research ......................... 191 8.1 Justifying Systematic Literature Review ....................... 193 8.2 Developing and Presenting Synthesized Knowledge . . . . . . . . . . . . . 195 8.3 Tying It Together . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 196 8.4 Points of Further Attention in Executing SLR . . . . . . . . . . . . . . . . . . . 197 References . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . . 198 9 Future Perspectives ............................................. 201 Correction to: Literature Reviews ................................... C1 Chapter 1 Introduction In a very important sense, criticism is the main driver of any intellectual development. Without contradictions and without criticism there would be no rational reasons to alter our theories - as a result, there would be no further intellectual progress. (Popper 2008, p. 346). For Popper (1972, p. 61), “theories are networks launched to capture what we call ‘the world,’ to rationalize it, explain it, dominate it.” The process of generating theo- ries through scientiﬁc research has been intensifying each year. The constant growth in the volume of research is the result of the recognition that scientiﬁc and technical capacities are drivers of economic growth and, in this way, countries stimulate the production of scientiﬁc and technological research in different areas of knowledge (Board 2020). One of the consequences of the countries’ scientiﬁc and technological develop- ment is the constant growth in the number of scientiﬁc publications, as Fig. 1.1 shows. According to data provided by Scimago Journal Rank (SJR) in 2020, more than 4.8 million studies were published in the Scopus database. In engineering alone, in that same year, 874,946 studies were published (Scopus 2020). The volume of publications doubled in 14 years from 1,997,318 publications in 2005 to 4,875,829 in 2020. The increase in the speed and volume of research may contribute to the advance of science; however, it increases the difﬁculty in focusing and mastering the state of the art in a given area or even in a speciﬁc topic (Gough et al. 2012). As a result, the scientiﬁc literature has a certain degree of redundancy in searching for solutions to a common problem. This occurs, in general, because researchers have difﬁculties to obtain sufﬁcient knowledge about the set of research results that are carried out (Cooper et al. 2009). In this sense, conducting Systematic Literature Reviews (SLR) to investigate scientiﬁc and technological knowledge is a necessary condition for the production of original research. An SLR can be conceptualized as a study that aims to map, evaluate, and aggregate the results of studies produced on a speciﬁc topic or area of knowledge (Morandi and Camargo 2015). It is systematic because it uses explicit procedures to identify studies, deﬁne which studies will be included in the research, and how these studies will be analyzed (Gough et al. 2012). © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_1 1 2 1 Introduction11,42,05112,03,36912,25,85412,45,75413,19,02813,58,97314,40,65415,89,99917,46,83719,97,31821,33,14222,47,18723,84,97626,04,21127,71,76529,77,15931,86,03733,40,15934,60,74034,84,05036,38,76137,77,08039,46,93341,81,95548,75,829 1996 1997 1998 1999 2000 2001 2002 2003 2004 2005 2006 2007 2008 2009 2010 2011 2012 2013 2014 2015 2016 2017 2018 2019 2020Published Studies Year Fig. 1.1 Number of publications: 1996–2020. Source Scimago Journal Rank (SJR) (2019) When investigating scientiﬁc and technological knowledge, structuring research is a concern of the academic and business community. Medical science, for example, has made signiﬁcant progress in trying to increase the quality of the review process and synthesizing research systematically, transparently, and reproducibly (Tranﬁeld et al. 2003). In addition, it has structured data sources that support the systematic literature review in this ﬁeld of research. One of these sources is Medline ®,an online system for searching and analyzing medical literature, in which searches are organized using keywords, thus facilitating the mapping of a given topic. In addition, to increase the reliability of systematic reviews and promote the acces- sibility of the evidence on which they are based, the Cochrane Collaboration was instituted in 1993. It records research carried out and provides a manual with method- ological guidelines (Higgins and Green 2011). With the same objective, the PRISMA statement was found in 1996. It consists of a checklist containing 27 items and steps with the objective of helping researchers to improve the reports of systematic reviews (Moher et al., 2010). However, the interest in conducting systematic literature reviews, particularly in the area of operations management, did not adopt the same rigor as in the areas of health and public policies (Thomé et al. 2016). Despite the existence of guidelines for the implementation of systematic literature reviews, it is possible to show that in other areas, for example, engineering and social sciences, especially in production engineering, there are no data sources that allow indexing searches. The main tools for the operationalization of stages of an SLR are from the health area and need adaptations when applied to different areas. It is also worth mentioning that the mapping of scientiﬁc knowledge has become important outside the academic sphere. Competitive companies increasingly need to devote attention to innovation, which can derive from Research and Development (R&D) projects. With the mapping of scientiﬁc knowledge, coupled with techno- logical mapping, it is possible to identify emerging technologies and evaluate their technological differential, helping the company to mature its decisions in terms of research and development. Consequently, the literature review becomes an important instrument also in the business sphere. 1 Introduction 3 From the point of view of scientiﬁc research, to distinguish objective knowledge and position theories, concepts, and laws, Popper (1999, p. 152) proposed the concept of the three ontologically distinct worlds: The ﬁrst is the material world, or the world of material states; the second is the mental world, or the world of mental states; and the third is the world of intelligibles, or of ideas in the objective sense; it is the world of possible thought objects: the world of theories them- selves and their logical relationships, of arguments themselves, and of problem situations themselves. The logic of Popper’s Three Worlds promoted different possible interpretations for reality (Gaines 1984). World 1, called the physical world, encompasses the real world, that is, the world of material states. World 2 is the world of mental states, including states of consciousness, psychological dispositions, and states of unconsciousness. World 3 is the products of the human mind, which involve artifacts, true or false scientiﬁc theories, and scientiﬁc problems. In other words, the objects of World 3 are of human authorship, although they are not always the result of an action planned by humans (Popper 1999). Many objects in World 3 exist as material bodies. A book, which is a physical object and thus belongs to World 1, also has a content, which is a product of the human mind and, therefore, also belongs to World 3 (Popper et al. 1985). The worlds are related in such a way that the ﬁrst two interact with each other in the same way as the last two can also interact. Thus, the ﬁrst and the third World do not interact, except through the intervention of the second (Popper 1999). From the point of view of this book, the logic of Popper’s Three Worlds provides valuable contributions. In general, scientiﬁc and research methods are established in the generation, through the relation World 1 → World 3, or in the test of theories in the dyad World 3 → World 1. With the exponential expansion of knowledge, or World 3 in Popperian terms, there is a need for scientiﬁc methods and research that allow the generation and testing of theories and artifacts from the World 3 itself. World 3, of theories and scientiﬁc knowledge, directly affects World 1. Through the intervention of researchers, it is possible to make changes in World 1 by applying the theories belonging to World 3 (Popper 1999). In the same way, through the observation of real objects, which belong to World 1, it is possible to test or generate the theories belonging to World 3. In this perspective, the generation of knowledge may occur in the existing rela- tionship of World 1 to World 3 through the application of empirical methods (Popper 1972). However, the production of knowledge is also possible through a review of the published literature (Gough et al. 2012). A theory is generated from a problem that may originate in World 1 or in the World 3 itself. To solve this problem, a researcher critically analyzes the theories existing in World 3. If the researcher does not ﬁnd the solution, the researcher produces a new theory, which will be critically discussed by the scientiﬁc community and tested empirically in the World 1 (Popper and Eccles 1985). In empirical investigations, the construction of knowledge in the dyad World 1 and World 3 can be achieved using scientiﬁc methods. In addition to scientiﬁc methods, research methods assist in conducting the study and, consequently, in the relationship between these two worlds. 4 1 Introduction However, the construction of knowledge may also be carried out through research on the accumulated scientiﬁc and technological knowledge on the World 1, that is, through research in World 3. This process assists in the generation and testing of theories based on the knowledge available in World 3, which may subsequently ﬁnd support or application in World 1 (Popper and Eccles 1985). In addition, research on scientiﬁc and technological knowledge can identify gaps in a speciﬁc research ﬁeld or topic on which research is needed. After presenting this context, this book is an attempt to answer the need for a research method for the generation and testing of scientiﬁc knowledge that inte- grates review, analysis, and synthesis of scientiﬁc and technological knowledge. The techniques used for this purpose have deﬁciencies and need improvement. Mulrow (1987) analyzed 50 systematic literature reviews published in major health journals in 1985 and 1986 and concluded that research generally does not clearly specify the procedures for identifying, evaluating, and synthesizing the results of the primary studies included in those reviews. After 30 years, Moher et al. (2007) evaluated 300 systematic literature reviews and found that 66.8% of the studies reported information about quality assessment. In addition, only 23.1% of the studies reported conducting evaluation of publication bias. Moher et al. (2009) also performed an adequacy anal- ysis of systematic review reports. The authors concluded that the results are not adequately disclosed because they do not present explicit scientiﬁc criteria, such as the evaluation of the quality of studies included in the research or an adequate synthesis of results. Recently, 32 systematic reviews and meta-analyses in the ﬁeld of applied acupunc- ture were analyzed in patients who suffered a stroke aiming to assess the methodolog- ical quality of systematic reviews and primary studies included in the review (Xin- Lin et al. 2017). The results found showed methodological ﬂaws in both systematic reviews and primary studies. The lack of analysis of probability of bias in the selec- tion of studies was the most recurrent methodological ﬂaw among them. Sun et al. (2019) carried out another assessment of the methodological soundness of system- atic reviews. 26 systematic reviews published in the health area were analyzed, more speciﬁcally in the area of peripheral nerve reconstruction. The authors concluded that although the volume of systematic reviews increased, the quality of these works did not show the same behavior (Sun et al. 2019). The main deﬁciencies found were lack of determination of inclusion criteria, performed in 27% of the studies, and assessment of probability of bias, performed in 30% of the studies (Sun et al. 2019). In addition to ﬂaws in the evaluation of the quality of the studies included in the systematic reviews, it is possible to highlight problems associated with the analysis and synthesis of results. The researches carried out by Mulrow (1987) and Moher et al. (2007, 2009) show that the systematic reviews analyzed do not present a synthesis of results of studies included in the review. The synthesis process is the combination of results of primary studies aiming to generate new knowledge (Gough et al. 2012). In this way, the production of systematic reviews without syntheses of results contra- dicts the objective of conducting scientiﬁc research, which is to generate answers to problems and new knowledge. 1 Introduction 55738241,0441,3221,6454,3366,3538,2637,7686,3077,7398,18410,84913,41616,97520,43423,72727,04130,47232,66438,41450,0651999200020012002200320042005200620072008200920102011201220132014201520162017201820192020Published systematic reviews Year Fig. 1.2 Volume of systematic reviews published: 1999–2020. Source Scopus (2020) In addition, the existing techniques for reviewing, analyzing, and synthesizing the literature are used in isolation. Not all procedures applied to carry out system- atic literature reviews include steps and techniques for analyzing and synthesizing results. Likewise, the techniques used to synthesize results do not always under- stand SLR as one of its stages. Consequently, the techniques and tools to describe (bibliometric analysis) and analyze (content analysis) literature are used individu- ally and dispersedly. The difﬁculties increase according to the need to synthesize the literature, as techniques, although they may exist, are not widely controlled by the scientiﬁc community, which highlights the need to explore the concepts of existing techniques. In addition to the growth in the volume of publications, in general, it is possible to highlight the growth in published systematic reviews in particular. Figure 1.2 shows the volume of publications in the Scopus database between 1999 and 2020. In 20 years, the volume of published systematic reviews increased 87 times, from 573 publications in 1999 to 50,065 in 2020. Considering the methodological ﬂaws evidenced in systematic reviews, it is possible to infer that despite the growth in the volume of publications, and the results of these studies can be questionable from the scientiﬁc point of view. For research to be recognized as reliable, rigor, which is achieved through the use of methodological procedures, must be present at all stages of the research, from the establishment of objectives to the presentation of results (Hatchuel 2009). If, on the one hand, the advance of knowledge is evidenced through the intensive production of publications, on the other hand, concerns arise on how to effectively map the knowledge produced at a high scale. In addition, it is important to have systematics to identify the main knowledge-producing centers in order to increase interest in a particular research topic and identify gaps where research is necessary. Thus, this book presents the Literature Grounded Theory (LGT) method, which contributes to conducting more rigorous literature review studies and producing reli- able results. In addition, other important topics stand out, such as the structuring of a set of decisions to be taken while conducting an SLR, such as in choosing the best techniques and tools according to the objective of each research. In addition, the 6 1 Introduction LGT allows identifying sedimented knowledge, its results, and the location of unre- solved issues to accelerate the absorption and introduction of scientiﬁc knowledge in business. Since the main topics about the relevance of this book have been described, this section presents the structure of the book. This chapter presents the context of the topic addressed in the book. This chapter sets out the relevance and purpose of the LGT method. Chapter 2 outlines the epistemological bases that guide the conduction of research based on systematic literature reviews. The concepts associated with objective knowl- edge and the logic of the three worlds are established following Popper (1972,1999). In addition, the logic of development and evaluation of objective knowledge is detailed and, ﬁnally, the existing relationships between Popper’s Worlds and scientiﬁc and research methods are explored. Chapter 3 presents the concept of Systematic Literature Review (SLR) and how it differs from traditional ways of describing literature. In addition, it critically analyzes the common structure among SLR methods developed in recent years and highlights the main improvements needed. In Chapter 4, the concepts of literature analysis are discussed and their impor- tance for the systematic literature review is highlighted. In addition, it presents the most relevant techniques adopted to carry it out (scientometry, bibliometry, and content analysis) and presents the main analyses that can be performed using these techniques. Chapter 5 addresses the concept of literature synthesis and techniques for synthe- sizing the results of primary studies. Subsequently, qualitative and quantitative synthesis techniques, their applications, and the main existing methods are presented. Chapter 6 presents the Literature Grounded Theory (LGT), and a research method for reviewing, analyzing, and synthesizing literature. First, the conceptual framework and organizational structure of the LGT is presented. Then, dividing the structure into stages, the techniques and tools for its implementation are described. Finally, the main guidelines for conducting research with the application of the LGT are provided. Chapter 7 discusses software that may assist in reviewing and synthesizing litera- ture using the LGT. The chapter’s emphasis is on functionality, not the software tools themselves. The prescribed workﬂow of computational tools for LGT is exempliﬁed using computational tools. Chapter 8 focuses on introducing and commenting on examples of Systematic Literature Reviews (SLR) published in the area of Design Science Research (DSR). First, a comparison is made with SLR protocols and, subsequently, a critical analysis is carried out on three topics: justiﬁcation for the conduction of the SLR, coding, and synthesis. Chapter 9 presents the ﬁnal considerations and perspectives for future research, which arise from the development of the LGT. References 7 References Board. National Science. Science & Engineering Indicators 2020. National Center for Science and Engineering Statistics (NCSES) Alexandria: [s.n.] (2020) Cooper, H., Hedges, L.V., Valentine, J.C.: Handbook of Research Synthesis and Meta-Analysis, 2nd edn, 610 pp. Russel Sage Foundation, New York (2009). 9780871541635 Gaines, B.R.: Methodology in the large: modeling all there is. Syst. Res. 1(2), 91–103 (1984) Gough, D., Oliver, S., Thomas, J.: An Introduction to Systematic Reviews, 1st edn, 288 pp. SAGE Publications, Los Angeles (2012). 9781849201803 Hatchuel, A.: A foundationalist perspective for management research: a European trend and experience. Manag. Decis. 47(9), 1458–1475 (2009) Higgins, J., Green, S.: Cochrane Handbook for Systematic Reviews of Interventions (2011). www. handbook.cochrane.org. Accessed 14 Feb 2019 Moher, D., et al.: Epidemiology and reporting characteristics of systematic reviews. PLoS Med. 4(3), 447–455 (2007).1549-1277 Moher, D., et al.: Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement. Int. J. Surg. 8(5), 336–341(2010). 0031-9023 Moher, D., et al.: Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement. PLoS Med. 6(7) (2009). 0031-9023 Morandi, M.I.W.M., Camargo, L.F.R.: Systematic literature review. Des. Sci. Res. [S.l.] 161. Springer (2015) Mulrow, C.: Literature of the nedical review article : state of the science. Ann. Intern. Med. 106(3), 485–488 (1987) Popper, K.: Conhecimento Objetivo, 1st edn, 394 pp. Itatiaia, Belo Horizonte (1999) Popper, K.: Objective Knowledge, 1st edn, 394 pp. Clarendon Press, Oxford (1972) Popper, K., Eccles, J.C.: The self and Its Brain, 2nd edn, 597 pp. Springer, Berlin (1985). 13:978- 3-642-61893-2 Popper, K.R.: A lógica da pesquisa cientíﬁca, 3rd edn, 567 pp. Cultrix, São Paulo (1972) Popper, K.R.: Conjecturas e refutações, 5th edn, 449 pp. Universidade de Brasília, Brasília (2008) Scopus: Scimago J. Country Rank. https://www.scimagojr.com/. Accessed 9 July 2019 Scopus. Scopus Database. https://www.scopus.com. Accessed 10 Sept 2020 Sun, B.J., et al.: The quality of systematic reviews addressing peripheral nerve repair and reconstruction. J. Plast. Reconstr. Aesthetic Surg. 72(3), 447–456 (2019) Thomé, A.M.T., Scavarda, L.F., Scavarda, A.J.: Conducting systematic literature review in operations management. Prod. Plan. Control. 27(5), 408–420 (2016) Tranﬁeld, D., Denyer, D., Smart, P.: Towards a methodology for developing evidence-informed management knowledge by means of systematic review* introduction: the need for an evidence- informed approach. Br. J. Manag. 14, 207–222 (2003) Xin-Lin, C., et al.: Methodological quality of systematic reviewa and meta-analysis on acupunture for stroke: a review of review. Chin. J. Integr. Med. 23(11), 871–877 (2017) Chapter 2 Scientiﬁc Contributions of Systematic Literature Reviews: Fundamentals in Karl Popper This chapter outlines the epistemological bases that guide the conduct of research based on systematic literature reviews. Initially, the concepts associated with objec- tive knowledge and the logic of the Three Worlds, established by Popper (1972, 1999), are established. Next, the development logic and evaluation of objective knowledge are detailed. Finally, the relationships among Popper’s Worlds, and the scientiﬁc and research methods are explored. 2.1 Objective Knowledge and the Karl Popper Worlds In the book, Objective Knowledge (1999, p. 75), Popper states that “at each stage of the evolution of life and the development of an organism, we have to admit the existence of some knowledge in the form of dispositions and expectations.” In the search for knowledge, people can acquire information empirically, whether understanding or not the causes of the phenomenon (Werneck 2006). The term, knowledge, is broad and is increasingly assuming a central role in the development of modern societies. Among the diverse typologies of knowledge, Popper (1999, p. 110) presents the distinctions between objective and subjective knowledge: (i) knowledge or thought in the subjective sense, constituted of a state of mind or conscious- ness or a willingness to react and (ii) knowledge or thought in an objective sense, consisting of problems, theories, and argument as such. Subjective knowledge presupposes the existence of a knowledgeable person, who is the subjective being who knows and is constituted of a state of mind or conscience. Subjective knowledge is subject to the mental (physical) processes, interests, and expectations of the thinking being. In this sense, it consists of an idiosyncratic knowledge based on the capacity and effort of logical organization of the empir- ical experiences, of the information obtained. Therefore, they constitute knowledge related to the subject and his/her intellectual constitution. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_2 9 10 2 Scientiﬁc Contributions of Systematic Literature Reviews … “Objective knowledge consists of the logical knowledge of our theories, conjectures and assumptions” (Popper 1999, p. 78). Objective knowledge is independent of any individual and, as a consequence, of his/her perceptions about reality, his/her expe- riences and interests. In other words, objective knowledge exists independently of the mind of the bearers of this knowledge. For Popper (1999, p. 111): “knowledge in the objective sense is totally independent of any claim to know someone who does; it is also independent of anyone’s belief or willingness to agree; or to afﬁrm, or to act. Knowledge in the objective sense is knowledge without a knowledge bearer; it is knowledge without a person who knows.” Whereas subjective knowledge consists of thought processes and objective knowl- edge constitutes the content of thought. Thus, regarding objective knowledge (content of thought), researchers work through their subjective thought processes (Popper 1978). Thus, knowledge is objective when it does not depend on the person, can be justiﬁed, and is testable and understood by the community (Carr 1977). Besides distinguishing subjective knowledge from objective knowledge, Karl Popper advances in terms of positioning and ontological distinction of physical objects, states/processes of consciousness and objective knowledge. The position proposed in the logic of the Three Worlds defends the existence of three distinct, interrelated planes of reality. Therefore, World 1, World 2, and World 3 are outlined as follows: “In the material world or the world of material states [World 1]; the second is the mental world, or the world of mental states [World 2]; and the third is the world of the intelligi- bles, or of ideas in the objective sense; the world of possible thought objects: the world of theories themselves and their logical relationships, of arguments themselves, and of problem situations themselves. [World 3]” Popper (1999, p. 152). From these initial deﬁnitions by Popper, other research sought to clarify the under- standing of the Three Worlds in conceptual terms. For illustrative purposes, Table 2.1 presents some concepts of World 1, World 2, and World 3 (Table 2.1). In Popper’s logic, World 1 consists of the material, concrete plane, the reality being palpable, external to the mind and dissociated from the person. In fact, over the years, mankind has undertaken a search for understanding and prediction of it. In general terms, it is the world of physical, chemical, and biological phenomena. World 2 encompasses the subjective, formed by individual interests and experiences, emotions and the path of knowledge existing in the minds of individuals from their personal and professional trajectory; in other words, the individual and idiosyncratic mental processes contained in the minds of human beings. Finally, World 3 gathers scientiﬁc knowledge, theories, arts, concepts, and other objects that, despite being constructed by human beings, are independent of them (Peluso 1995). Although ontologically distinct, it is possible to evidence the interaction among the Three Worlds. For Popper (1999), one of the fundamental problems of his theory refers to the relationships among the Three Worlds. In an attempt to solve this problem, Gaines (1984) proposed an interaction model, which uses the concepts presented by Popper and seeks to show the causal relationships among the Three Worlds, as shown in Fig. 2.1. 2.1 Objective Knowledge and the Karl Popper Worlds 11 Table 2.1 Concepts of Popper’s three worlds World Eccles (1975) Popper and Eccles (1985) Iivari (2006) Gadenne (2016) 1 Comprises all objects or artifacts built by man, such as tools, machines, books, works of art and music Physical world—the universe of physical entities It is the natural world It is the physical world. It contains material objects, such as rocks and trees, but also atoms, subatomic particles, electrical ﬁelds, and gravitational force 2 Covers states of consciousness or mental states It is the world of mental states, including states of consciousness and psychological dispositions and unconscious states It is the world of consciousness and mental states It is the world of mental states, including conscious states and behavioral dispositions 3 It is the world of knowledge in the objective sense, including intellectual records, such as philosophical, theological, scientiﬁc, and historical ones. In addition, it comprises all theoretical systems, such as scientiﬁc problems and critical arguments The world of thought content and, in fact, of the products of the human mind It is the world of institutions, theories, and artifacts constructed by man It is the world of objects that are neither physical nor mental, of objective content of thought and products of the human mind Source Devised by the authors The relationships among the Worlds proposed by Popper give rise to reﬂection on their interactions. World 3 objects exist physically and thus belong to both World 3 and World 1. For example, a book constitutes a physical object and thus belongs to World 1, but its content is a product of the human mind, which means it belongs to World 3 (Popper and Eccles 1985). The possibilities of relationship among the Worlds are varied and each relationship could be exempliﬁed in some way. The interaction model among the Three Worlds removes a linear view and expands the possibilities for understanding the relationships. The central region, where the Three Worlds intersect, should be the objective of the researchers. In this region are located the laws, theories, and models belonging 12 2 Scientiﬁc Contributions of Systematic Literature Reviews … World 1 Physical World 2 Thought Processes World 3 Thought Content — Unrecognizable — Not modelable — Aspects of the physical world Known phenomenon that cannot be modeled Models well established in the physical world Mental phenomena not necessarily corresponding to the physical world or some logical content Concepts, structures and relationships not corresponding to the physical world or incomprehensible to the human mind at a certain moment Models of the physical world that are correct, but incomprehensible or not derivable Mathematical structures not corresponding to the physical world and incomprehensible Fig. 2.1 Model of interaction among Popper’s Three Worlds. Source Adapted from Gaines (1984) to World 3, which are developed and known from the thought processes of World 2, and broaden understanding of the reality of World 1. The intersection of World 1 and World 2 refers to phenomena that can be perceived, although their representation has a high degree of imprecision, or cannot even be formalized. This region encompasses paranormal phenomena, as well as feelings such as luck and intuition. In the region where World 2 intersects World 3 lies the world of structures that can be understood, as they are part of the human mind and possess objective knowledge, however they are not part of World 1. In this region, pure mathematics is found, as well as art forms, myths, and religions. The intersection of World 3 with World 1 can be considered as the region of reality models that are beyond our comprehension, at a given moment. It comprises the theory of the uniﬁed ﬁeld and complete global representations (Gaines 1984). The areas of the Three Worlds that do not intersect any other world correspond to phenomena that cannot be experienced or represented. In World 2, they are consistent with mental events and processes without correspondence with reality (World 1) and without objective knowledge (World 3). The World 3 region corresponds to formal structures that exceed the limit of our understanding, that is, they are not products of the human mind and cannot be transformed into an aspect of the physical world. In this context, the researchers are located at the intersections of two worlds, aiming, 2.1 Objective Knowledge and the Karl Popper Worlds 13 in three different ways, to reach the intersection of the Three Worlds, a place called “paradise” by the researchers (Gaines 1984). The interaction logic proposed by Gaines contradicts Popper’s theory. For Popper (1999), World 2 involving subjective experiences (mental processes) interacts as much with World 1 as with World 3. However, World 1 and World 3 cannot interact except through World 2, the mind being responsible for establishing an indi- rect connection, through mental processes, between the ﬁrst and the third Worlds. The theory of a systemic model of Three Worlds proposed by Popper introduced alternative perceptions of reality (Gaines 1984). As can be observed in Table 2.1, there is consensus regarding the interpretation of the concept of World 2. However, the interpretation of the concepts of Worlds 1 and 3 has generated contradictions over the years. For Eccles (1975), man-made artifacts are part of World 1, the world of material objects, such as machines, books, works of art, ﬁlms, and computers. Contrary to this interpretation, Iivari (2006) describes how the artifacts belong to World 3, which is also the world of institutions and theories. The interpretation of World 3, carried out by Gadenne (2016), suggests that World 3 is made up of objects that are neither physical nor mental, listing as constituents of this world the propositions, theories, critical arguments, tools, works of art, and musical compositions, these being real objects. Popper (1999, p. 109) describes the content of his Third World: “Among the inhabitants of my third world, there are more, especially, theoretical systems; but equally important inhabitants are problems and problem situations. And I will argue that the most important residents are the critical arguments and what can be called – in analogy with a material state or a state of consciousness – the state of a discussion or the state of a critical argument; and, naturally, the contents of magazines, books and libraries.” Due to these divergences of interpretation regarding the constitution of World 3, Popper’s conception has been criticized as imprecise and incoherent. For Popper, World 3 is a product of the human mind, constituted by objective knowledge. However, he lists as belonging to this world the tools and sculptures, which are material and which seem to belong to World 1 (Gadenne 2016). In the book, “The philosophy of Karl Popper” (1974), the author seeks to elucidate the concept of his Third World. To this end, Popper has broken World 3 into three parts and explains that it transcends the part of World 1 in which it is, so to speak, materialized. This materialized part, Popper calls “World 3.1,” describing the libraries as belonging to this world. In “World 3.2,” the contents that were interpreted by a human mind are displayed. Furthermore, “World 3.3,” called “Dark World,” which comprises theories, problems, and solutions that have not been materialized and, until then, unknown, or those that were not discovered. There are two fundamental characteristics of objective knowledge: objectivity and autonomy, arguing that scientiﬁc knowledge is something objective and, in this way, constitutes something, even without the existence of a researcher or a person who knows it (Popper 1999). The set of theories, problems, and arguments, although they are products of the human being, does not depend on human understanding (Peluso 1995). 14 2 Scientiﬁc Contributions of Systematic Literature Reviews … In this sense, the Third World is an autonomous world and, in this way, it is possible to discover new problems in World 3, which existed even before they were discovered. Therefore, in no sense are the problems manufactured by us, but rather discovered (Popper 1999). In this way, the possibility of developing new ideas, problems, and scientiﬁc knowledge opens up despite the empirical reality. In fact, the empirical reality serves to refute the proposed hypotheses and theoretical statements. In an attempt to solve problems (empirical or theoretical), it is possible to create new theories. These theories can be considered as a product of critical and creative thinking, based on the theories that exist in World 3. However, when producing new theories, they create new, unintended problems (Popper 1999). In this way, these new problems are autonomous and need to be discovered. This explains why World 3, despite being a human product, is also autonomous. It also explains the action on this world, aiding its development and growth, even though there is no man who can dominate it (Popper 1999). It is important to stress that, when Popper refers to the autonomy of World 3, it is possible to distinguish between two aspects. The ﬁrst of these is the autonomous existence of the objects in World 3, which, after being produced, can exist independently of human thought or actions. The second aspect states that new theories are active in a certain sense, that is, a theory can generate problem situations, which are also part of World 3 and will have to be discovered (Gadenne 2016). For understanding scientiﬁc knowledge, it is important to understand the problems of science and its scientiﬁc conjectures. It is essential to understand the importance of searching for alternative solutions and the effectiveness of the test methods imple- mented. Thus, it is possible to afﬁrm that understanding a theory of knowledge, in the sense that it is attributed to World 3, can lead to achievements in terms of under- standing the phenomena of consciousness and subjective knowledge (Peluso 1995). Thus, the growth of all knowledge consists of the modiﬁcation of previous knowl- edge, which until then has been taken for granted, allied with problems. The problems arise, generally, by the contradiction of the expectations intrinsic to the basic knowl- edge through the new discoveries, such as observations or some hypothesis suggested by them (Popper 1999). Even if a hypothesis is not successful in the falsiﬁability tests, it will continue to be useful, through the creation of better hypotheses (Popper 1999). Thus, it is possible to identify that, according to Popper’s concepts, the growth of knowledge cannot be considered a cumulative process, but as the elimination of error. In other words, the expansion of knowledge is carried out by replacing refuted theories with better, more satisfactory theories (Bettin 2014). Philosophers, such as Descartes, Hobbes, Locke, and David Hume, claim that the theory of human knowledge is largely subjectivist, as a type of human belief (Popper 1999). The theory proposed by Popper aimed to break this philosophical tradition, seeking to replace the subjectivist view with an objective theory of knowledge. In the next section, the relationships between scientiﬁc and research methods with Popper’s Three Worlds are explained. 2.2 Meanings of Knowledge Production in the Light of Popper’s Three Worlds 15 2.2 Meanings of Knowledge Production in the Light of Popper’s Three Worlds Historically, scientiﬁc knowledge has been developed in the direction, World 1 → World 3 of this dyad. Scientiﬁc methods support the construction and rational justi- ﬁcation of the knowledge produced. The main scientiﬁc methods are: (i) inductive, (ii) deductive, (iii) hypothetical-deductive, (iv) dialectic, and (v) abductive. (Dresch et al. 2015; Marconi and Lakatos 2003). The main scientiﬁc method used in the dyad, World 1 → World 3, is inductive. The inductive method starts from the search for laws, theories, theorems, and models from broad systematic observation and under different circumstances of reality. In this perspective, the patterns and regularities found from continuous observation reﬁne the descriptive and explanatory models, generating theoretical knowledge from the concrete reality of World 1. In turn, the scientiﬁc methods used in the dyad, World 1 ← World 3, are deduc- tive and hypothetical-deductive. In this perspective, from the accumulated scientiﬁc knowledge (World 3) problems and explanatory hypotheses are rationally formulated where empirical observation and the principle of falsiﬁability are used as criteria for the demarcation of scientiﬁc knowledge. Put in other terms, the observation of World 1 contributes toward evaluation of the adequacy of the formulated hypotheses, their need for reformulation, or even substitution for better scientiﬁc explanations of the phenomena. The abductive scientiﬁc method is also in line with this relationship in the World 1 ← World 3 dyad. However, the abductive logic is constituted of the World 2 ← World 3 relationship, through creative processes guided by the collection of available scientiﬁc knowledge. Therefore, World 1 contributes to the evaluation of feasibility in the real world it has not yet become. In other words, abductive reasoning seeks to prove that the phenomenon that does not exist can actually occur. Finally, the dialectical scientiﬁc method can confront both ideas per se (purely World 3), ideas and historical reality, or not (World 1 vs. World 3). Moreover, the deductive method allows, based on critical questioning, the formulation of problems from the objects of World 3 to create theories, explanatory models, and new theories without necessarily having an empirical basis. In such cases, they are subsequently subjected to observation or experimentation supporting the theoretical explanations on a corresponding empirical basis. In Fig. 2.2, the relationship between knowledge generation and the Three Worlds illustrates the possibilities of knowledge generation in the relationship of Worlds 1, 2, and 3. In addition to scientiﬁc methods, research methods support the conduct of study research and, consequently, operationalize the relationship between World 1 and World 3. The deﬁnition of the scientiﬁc method directs the choice of the research method according to the research objectives (describe, explore, explain, prescribe) (Dresch et al. 2015). The main research methods used are (i) survey, (ii) case study, (iii) modeling, (iv) simulation, (v) ﬁeld study, (vi) experiment, and (vii) theoret- ical/conceptual (Miguel et al. 2012). Besides these, it is important to highlight the use of the Design Science Research method, which is an approach to conduct research 16 2 Scientiﬁc Contributions of Systematic Literature Reviews … World 1 Physical World 2 Thought Processes World 3 Thought Content Generation of Knowledge from Observation of Reality Generation of Knowledge from Reasoning assessed in relation to reality Generation of Knowledge from Criticism and Formulation of New Problems Fig. 2.2 Relationship between knowledge generation and the Three Worlds. Source Prepared by the authors that aims to design or develop artifacts acting in World 1, based on problems observed in World 1 or possibilities arising from World 3 that provide satisfactory solutions (Dresch et al. 2015). The research methods relate the World 3 theories with the reality of World 1. The use of structured research methods for this interaction makes it possible to conduct studies that aim to understand reality or forward solutions to problems observed in the real world. The existing research methods are dedicated to the World 1 ↔ World 3 rela- tionship. We argue about the need for a research method, in this case, the Litera- ture Grounded Theory (LGT) that will be described in detail later, necessary for conducting research and generating scientiﬁc knowledge from objects existing in World 3. For the mapping of the existing theories in World 3, the same scientiﬁc methods described above also apply. In this perspective, the deﬁnition of the scientiﬁc method to be applied will depend, as in the empirical sciences, on the research question to be answered. The research question will determine the scope of the review, and also the deﬁnition of the implementation strategies (Morandi and Camargo 2015). Researches that aim to aggregate the results of similar studies are called aggregative reviews (Gough et al. 2012). These have strict research questions aimed at testing a theory based on the collection of empirical observations. Thus, it seems more appropriate to use the deductive scientiﬁc or hypothetical-deductive method (Morandi and Camargo 2015). In contrast, researches who aim to conﬁgure or “organize” the results of studies are called conﬁgurative reviews (Gough et al. 2012). Conﬁgurative reviews generally have broad research questions and aim to explore a research theme in a comprehensive manner (Morandi and Camargo 2015). Thus, the inductive scientiﬁc method is used in order to generate or explore the theory (Gough et al. 2012). The construction of knowledge can occur through the investigation of scientiﬁc and technological knowledge belonging to World 3. It can also arise from an existing problem in World 3 and be solved by its theories. It can be tested and criticized, and a researcher can later discover an application in World 1 (Popper and Eccles 1985). However, in order to carry out investigations of scientiﬁc and technological 2.2 Meanings of Knowledge Production in the Light of Popper’s Three Worlds 17 knowledge belonging to World 3, it is not possible to ﬁnd a research method for this purpose in the literature. There are techniques such as Systematic Literature Review (SLR), Narrative Review, and Integrative Review, which allow mapping of theories. In this sense, the research method we propose can contribute to the mapping and cartography of World 3. From this mapping of the existing scientiﬁc literature, it is possible to identify the main articles, authors, groups, countries, and research themes. Through an analytical, synthetic process it is possible to formulate new research possibilities based on World 3. The domain of World 3 is complementary to the existing approaches in the World 1 → World 3 relationship. Our argument lies in the need to expand the methodological possibilities based on World 3 → World 1 relationship. Additionally, the observed exponential development and scientiﬁc production can compromise a holistic view, or even hinder mastering the body of scientiﬁc knowl- edge necessary for the development of research. In this context, the survey, analysis, and synthesis of the empirical results observed in the research can contribute to gener- ation of aggregate scientiﬁc knowledge of the different studies. In this same context, there is also a contribution arising from the World 3 → World 1 relationship. This contribution can also occur by refuting, or not, hypotheses based on the aggregation of empirical studies on a given theme and research problem. In summary, there is a need for a research method that makes it possible to conduct investigations in World 3 complementing the existing methods in World 1. It should be noted that this is an initial discussion about the relationship among scientiﬁc methods, research methods recognized by the scientiﬁc community, and the Worlds proposed by Popper. We present a daring proposal for a research method that integrates the intellectual operations of review, analysis, and synthesis of the literature. We understand that a research method that expands our domain of World 3 can allow advancement of science from a holistic perspective and increase the synergy of the several studies conducted individually. Finally, in this section, we have sought to demonstrate some of the ontological and epistemological foundations aligned with the research method we are proposing. Box 2.1 What have we learnt in this chapter? • What Objective Knowledge is? • Karl Popper’s Three Worlds; • The potential relationships between scientiﬁc and research methods with Karl Popper’s Three Worlds; • The argument that supports LGT as a research method for conducting investigations in World 3. 18 2 Scientiﬁc Contributions of Systematic Literature Reviews … References Bettin, R.: Pluralidade de Mundos do Conhecimento em Karl Popper. Pontifícia Universidade Católica de São Paulo - PUC (2014) Carr, B.: Popper’s Third World. Philos. q. 27(108), 214–226 (1977) Dresch, A., Lacerda, D.P., Antunes, J.A.V.: Design Science Research: A Method for Science and Technology Advancement, 1st edn., p. 161. Springer International Publishing, New York (2015) Eccles, J.C.: Facing Reality, 2nd edn., p. 210. Springer, New York - Verlag, Heidelberg, Berlin (1975). 9780387900148 Gadenne, V.: Is Popper’s Third World autonomous? Philos. Soc. Sci. 46(3), 1–16 (2016) Gaines, B.R.: Methodology in the large: modeling all there is. Syst. Res. 1(2), 91–103 (1984) Gough, D., Oliver, S., Thomas, J.: An Introduction to Systematic Reviews, 1st edn., p. 288. SAGE Publications, Los Angeles (2012). 9781849201803 Iivari, J.: Information systems as a design science. Inf. Syst. Dev. 19(2), 15–27 (2006) Marconi, M.D.A., Lakatos, E.M.: Fundamentos de metodologia cientíﬁca, 5th edn., p. 310. Atlas S.A., São Paulo (2003) Miguel, P.A.C., et al.: Metodologia de pesquisa em engenharia de produção e gestão de operações, 2nd edn., p. 260. Elsevier Editora Ltda, Rio de Janeiro (2012). 9788535248500 Morandi, M.I.W.M., Camargo, L.F.R.: Systematic Literature Review. Design Science Research: A Method for Science and Technology Advancement, 1st edn., pp. 141–172. Springer International Publishing, New York (2015) Peluso, L.A.: A ﬁlosoﬁa de Karl Popper, 1st edn., p. 224. Papirus, Campinas (1995) Popper, K.: Objective Knowledge, 1st edn., p. 394. Clarendon Press, Oxford (1972) Popper, K.: The Philosophy of Karl Popper - Book II, pp. 671–1323. s.n., [S.l] (1974) Popper, K.: Three Worlds - The Tanner Lecture on Human Values. The University of Michigan, Ann Arbor (1978) Popper, K.: Conhecimento Objetivo, 1st edn., p. 394. Itatiaia, Belo Horizonte (1999) Popper, K., Eccles, J.C.: The Self and Its Brain, 2nd edn., p. 597. Springer, Berlin (1985). 13:978- 3-642-61893-2 Werneck, V.R.: Sobre o processo de construção do conhecimento: o papel do ensino e da pesquisa. Ensaio: Avaliação e Políticas Públicas em Educação 14(51), 173–196 (2006) Chapter 3 Systematic Literature Review This chapter presents the concept of Systematic Literature Review (SLR) and how it differs from the traditional ways of describing and portraying the literature. Moreover, it critically analyzes the common underlying structure among the SLR methods developed over the past years as well as highlights the improvements required. 3.1 Literature Review (LR) Science can be considered as a cooperative and cumulative practice, wherein individ- uals cooperate to produce and accumulate scientiﬁc knowledge by means of research (Cooper et al. 2009). This work of systematically building and organizing knowl- edge can be performed either through original research or literature review (Gough et al. 2012). The Literature Review (LR) is an essential element of any academic research activity. It can broadly be described as a more or less systematic way of collecting and synthesizing previous research (Baumeister and Leary 1997). The LR not only provides a comprehensive understanding of preceding studies on a topic but also produces an integrative interpretation of ﬁndings that is more substantive than those resulting from individual investigations (Webster and Watson 2002). However, traditional approaches of reviewing literature often lack thoroughness and are not undertaken systematically (Tranﬁeld et al. 2003). This implies a lack of knowledge of what the collection of studies is saying or pointing at, which might result in research built on ﬂawed assumptions (Snyder 2019). It is under these circumstances that SLR arises, a concept that will be described next. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_3 19 20 3 Systematic Literature Review 3.2 Systematic Literature Review (SLR) To guarantee the rigor in knowledge generation through LR, it is fundamental that the research is performed systematically. In the light of that emerges the SLR, a method for synthesizing the research ﬁndings in a systematic, transparent, and reproducible way (Littell et al. 2008). In general, SLR aims to identify all empirical evidence that ﬁts the pre-speciﬁed inclusion criteria to answer a particular research question or hypothesis. By using explicit and systematic procedures when reviewing the litera- ture, bias can be minimized, thus providing reliable ﬁndings from which conclusions can be drawn and decisions made (Snyder 2019). Box 3.1 Curiosities on SLR • The SLR originated from the education and psychology ﬁelds (Littell et al. 2008). • In the 1970s, SLR started being used in the areas of social sciences and behavior (Morandi and Camargo 2015). • Since then, the utilization of SLR has spread to several areas of knowledge, such as health, computer science, management, and engineering. The SLR differs from traditional LR in many aspects (Khan et al. 2003). The main difference between them lies in the fact that SLR aims at answering a speciﬁc question or hypothesis, while traditional LR focuses on summarizing what has been published on a given topic (Petticrew and Roberts 2006). To make that possible, SLR uses explicit and systematic procedures instead of the random process adopted by traditional approaches (Robinson and Lowe 2015). As a result, the ﬁnal product of SLR consists of new and integrative knowledge serving as a basis for building new models or theories, rather than a mere narrative description of current research (Snyder 2019). These differences are summarized in Table 3.1. Despite the advantages when compared to the traditional LR, there are some challenges to be overcome by SLR (Gough et al. 2012). Palomino et al. (2019) analyzed 59 SLR and pointed out that the main shortcomings found related to the early stages of review, more speciﬁcally during the problem deﬁnition and the searching of primary studies. Activities that require an iterative process that usually take a long time to be performed. Besides, another step that deserves attention is the selection of primary studies, since it directly inﬂuences the research results, independently of the other steps of SLR being performed properly (Palomino et al. 2019). 3.2 Systematic Literature Review (SLR) 21 Box 3.2 Key concepts Literature Review: Consists of a method for collecting and synthesizing previous research. Traditional Literature Review: Uses explicit, systematic, and reproducible procedures for searching, analyzing, and synthesizing the literature. Systematic Literature Review: Uses explicit, systematic, and reproducible procedures for searching, analyzing, and synthesizing the literature. To overcome these limitations, different methods for conducting SLR have been proposed over the past years. They emerged from different knowledge areas, with engineering and health science being noted as the most frequent ones. Figure 3.1 presents a timeline with the 12 main methods found in the literature. Table 3.1 Differences between traditional literature review and SLR Traditional literature review Systematic literature review The review question/topic Topics may be broad in scope; the goal of the review may be to place one’s research within the existing body of knowledge or to gather the information that supports a particular viewpoint Starts with a well-deﬁned research question to be answered by the review. Reviews are conducted to ﬁnd all existing evidence in an unbiased, transparent, and reproducible way Arching for studies Searches may be ad hoc and based on what the researcher is already familiar with. Searches are not exhaustive or fully comprehensive Attempts are made to ﬁnd all existing published and unpublished literature on the research question. The process is well documented and reported Study selection Often lack clear reasons for why studies were included or excluded from the review Reasons for including or excluding studies are explicit and informed by the research question Assessing the quality of included studies Often do not consider study quality or potential biases in study design Systematically assesses the risk of bias of individual studies and overall quality of the evidence, including sources of heterogeneity between study results Synthesis of existing research Conclusions are more qualitative and may not be based on study quality Base conclusion on the quality of the study and provide recommendations for practice or to address knowledge gaps Source (Cornell University Library Evidence Synthesis Service - A Guide to Evidence Synthesis - LibGuides at Cornell University 2021). 22 3 Systematic Literature Review 3 4 1 Cooper, Hedges, and Valentine (2009) Littel, Corcoran, and Pillai (2008) Khan, Kunz, and Kleijnen (2003) Denyer and Tranfield (2009) Smith et al. (2011) 6 Higgins and Green (2011) 8 9 11 Colicchia and Strozzi (2012) Gough, Oliver, and Thomas (2012) Borrego, Foster, and Froyd (2014) Morandi and Camargo (2015) 12 Thomé, Scavarda, and Scavarda (2016) 10 2 Kitchenham and Charters (2007) 5 7 Fig. 3.1 Methods for conducting SLR. Source Created by authors Although these methods have been developed independently of one another, they share a common underlying pattern, whereby it is possible to compare them. This pattern is depicted in Table 3.2, wherein the non-blank entries indicate the stages, steps, and techniques composing each method. This book refers to a method as a group of steps, organized into stages, which intend to solve SLR problems, while a technique consists of a set of related procedures required to execute each method step (Gauss et al. 2021). The meaning of each method step is given in Table 3.3, while the function of each technique is provided in Table 3.4. From the underlying pattern presented in Table 3.2, it was possible to identify the similarities and dissimilarities among the existing SLR methods, which will be critically assessed next. 3.3 Critical Assessment of SLR Methods As mentioned before, the 12 SLR methods developed over the past years emerged from different knowledge areas. The ﬁrst group, composed of six methods, is derived from the Engineering (Borrego et al. 2014; Colicchia and Strozzi 2012; Denyer and Tranﬁeld 2009; Kitchenham and Charters 2007; Morandi and Camargo 2015; Thomé et al. 2016). The second group of four methods came from the Health Sciences (Higgins and Green 2011; Khan et al. 2003; Littell et al. 2008; Smith et al. 2011). 3.3 Critical Assessment of SLR Methods 23Table3.2UnderlyingpatternamongexistingSLRmethodsStagesStepsTechniquesMethodsKhanetal.(2003)KitchenhamandCharters(2007)Littleetal.(2008)Cooperetal.(2009)DenyerandTranﬁeld(2009)Smithetal.(2011)HigginsandGreen(2011)ColicchiaandStrozzi(2012)Goughetal.(2012)Borregoetal.(2014)MorandiandCamargo(2015)Thoméetal.(2016)ReviewStakeholdersdeﬁnitionN/A••RequirementsspeciﬁcationGuidelines•Reviewquestion(s)formulationCIMO•••PICOC•PICOE•PICOS•PICO•Guidelines•••••ScopedeﬁnitionGuidelines••••••WorkteamselectionGuidelines••••SearchstrategydeﬁnitionGuidelines••••••••••••ProtocolformulationProtocol•Guidelines••••BiasminimizationGuidelines••SearchandeligibilityGuidelines••••••••••••QualityassessmentChecklist••••Guidelines•••••••CodingGuidelines•••••(continued) 24 3 Systematic Literature ReviewTable3.2(continued)StagesStepsTechniquesMethodsKhanetal.(2003)KitchenhamandCharters(2007)Littleetal.(2008)Cooperetal.(2009)DenyerandTranﬁeld(2009)Smithetal.(2011)HigginsandGreen(2011)ColicchiaandStrozzi(2012)Goughetal.(2012)Borregoetal.(2014)MorandiandCamargo(2015)Thoméetal.(2016)ReliabilityassessmentKrippendorff’salpha•Guidelines•AnalysisLiteratureanalysisScientometrics•Bibliometrics••Contentanalysis•SynthesisLiteraturesynthesisGuidelines••••••Meta-analysis•••••Meta-synthesis••Narrative••ResultspresentationGuidelines••••••••••UpdatingGuidelines••SourceCreatedbyauthors 3.3 Critical Assessment of SLR Methods 25 Table 3.3 Meaning of method steps Step Meaning Stakeholders deﬁnition Deﬁnition of the group of individuals that either impact or are impacted by the outcomes of SLR Requirements speciﬁcation Speciﬁcation of SLR requirements, whenever it is requested by an organization other than the one that will conduct the RSL Review question(s) formulation Formulation of the question(s)/hypothesis(es) to be answered/tested by the SLR Scope deﬁnition Deﬁnition of the extent and dimension of the SLR Work team selection Selection of the work team which will undertake the SLR Search strategy deﬁnition Deﬁnition of the search terms, search sources, and selecting criteria Protocol formulation Formalization of rules and procedures to be used during the SLR Bias minimization Deﬁnition of ways for minimizing bias Search and eligibility Searching and selecting the research in compliance with pre-speciﬁed search strategy Quality assessment Evaluation of rigor and relevance of the selected studies Coding Deﬁnition of the coding system to be assigned to the content of each selected study Reliability assessment Evaluation of the level of agreement among the researchers on the decisions made during the SLR Literature analysis Decomposition of the content into parts along with the description of how these parts relate Literature synthesis Association of independent results into new and integrative knowledge Results presentation Communication of SLR outcomes Updating Deﬁnition of when and how to update the SLR Source Created by authors Finally, the third group, composed of two methods, emerged from Social Science (Cooper et al. 2009; Gough et al. 2012). From a methodological perspective, except for the work of Gough et al. (2012), the 11 methods remaining tend to produce outcomes oriented to their respective ﬁelds. This tendency prevents the methods from being used in other areas without any changes in its steps and techniques. Changes that, when not performed properly, might compromise the research results and replicability. Concerning the stages of SLR, three were found: (i) review, (ii) analysis, and (iii) synthesis. The Review consists of identifying existing studies that ﬁt the pre-speciﬁed inclusion criteria to answer a particular research question or hypothesis (Snyder 2019). Although this stage is accomplished by all methods, it is undertaken through different steps and techniques. This situation can be highlighted by the step Review question(s) formulation which is executed by six different techniques. Another step 26 3 Systematic Literature Review Table 3.4 Function of techniques Technique Function Guidelines Orientates how to execute the method steps CIMO Articulates the concepts of Context (C), Intervention (I), Mechanism (M), and Outcomes (O) to aid the review question formulation (Denyer et al. 2008) PICOC Articulates the concepts of Population (P), Intervention (I), Comparison (C), Outcomes (O), and Context (C) to aid the review question formulation (Kitchenham and Charters 2007) PICOE Articulates the concepts of Population (P), Intervention (I), Context (C), Outcomes (O), and Effects (E) to aid the review question formulation (Khan et al. 2003) PICOS Articulates the concepts of Participants (P), Intervention (I), Comparison (C), Outcomes (O), and Study Design (S) to aid the review question formulation (Smith et al. 2011) PICO Articulates the concepts of Population (P), Intervention (I), Comparison (C), and Outcomes (O) to aid the review question formulation (Higgins and Green 2011) Protocol Compiles the rules or procedures for conducting the SLR into a single source (Morandi and Camargo 2015) Checklist Structures the list of items to be assessed (Littell et al. 2008) Krippendorff’s alpha Measures the level of agreement achieved when coding multiple units of analysis (Krippendorff, 2019) Scientometrics Measures the science’s growth, structure, interrelationships, and productivity (Siluo and Qingli, 2017) Bibliometrics Analyzes the publishing patterns (Zupic and ˇCater 2015) Content analysis Analyzes the presence, meanings, and relationships of words, themes, or concepts within qualitative data (Bardin, 1993) Meta-analysis Synthesizes data across quantitative studies (Glass 1976) Meta-synthesis Synthesizes data across qualitative studies (Finfgeld 2003) Source Created by authors of this stage, encompassed by half of the methods analyzed, is the Scope deﬁnition. In this step, the review boundaries are deﬁned, and one fundamental issue here is to formulate the conceptual framework (Morandi and Camargo 2015). The problem is, the existing methods do not provide enough information on how to perform it, leaving it up to the researcher to choose the most appropriate procedures, which can be particularly difﬁcult for the beginners. In terms of Bias minimization, although this step directly inﬂuences the reliability of the results (Whiting et al. 2016), only two methods addressing it were found. The Quality assessment, in turn, is tackled by 11 methods. However, the techniques adopted for that purpose often require adaptations since they are entirely derived from Health Sciences. As well as the Scope deﬁnition, the step of Coding also lacks practical guidance on how to be performed. This absence of procedures might result in inadequate analysis and synthesis, by which wrong 3.3 Critical Assessment of SLR Methods 27 conclusions can be drawn. Concerning the Reliability analysis, it is presented by solely two methods. This issue is particularly important because divergences on the research decisions may occur whenever the RSL is undertaken by two or more researchers. Divergences that, if not addressed properly, might result in errors being led to the next research stages (Higgins and Green 2011). The second stage identiﬁed was Analysis, which consists of decomposing the content into parts and describing how these parts interact (Hart 1998). In contrast to Review, this class is only addressed by two methods. However, they simply suggest the analysis as an activity preceding the synthesis and do not sufﬁciently tackle its purposes and procedures. The problem of approaching the analysis at this granu- larity level is that the researchers might be unaware of which technique to use for an intended objective, and when or how these techniques might interlink. As a conse- quence, meaningless outcomes retrieved from inadequate procedures might emerge from this stage (Hart 1998). Synthesis, the third stage found, consists of connecting the independent outcomes retrieved from the analysis (Hart 1998). Although the ﬁrst step of this stage, Litera- ture synthesis, is approached by most of the methods analyzed, some of them focus on the quantitative synthesis through the use of meta-analysis, which is unsuitable for heterogeneous data. The qualitative synthesis, usually undertaken through meta- synthesis, is accomplished by two methods at the most, being neglected by the remaining ones. The fact of not doing so may imply a limited capacity of articu- lating constructs, variables, propositions, and hypotheses retrieved from empirical and theoretical research (Bhattacherjee 2012), as well as restricting the assessment and integration of artifacts retrieved from research performed under Design Science paradigm (Dresch et al. 2015). The rest of the methods merely describe the impor- tance of synthesizing the literature without providing practical guidance on how to perform it. Independent of the nature of data, either quantitative or qualitative, the extant techniques for handling both lacks a synthesis framework, making the transformation of independent results into new and integrative knowledge difﬁcult. Another important issue is that scientiﬁc knowledge is transitory, therefore, so are the results of an SLR. In this sense, it is necessary to deﬁne when and how to update the SLR (Higgins and Green 2011). This activity is performed in step updating and is slightly tackled by 2 out of 11 methods analyzed. Finally, the iterations among the method steps are important to guide researchers on the feedback loops that might occur in the research process. Nevertheless, only the method proposed by Thomé et al. (2016) considers it. The problem of not doing so is that the research conduction becomes more difﬁcult and may ultimately result in an unfair application. Based on the aforementioned, it was possible to identify the common under- lying structure among the existing methods. Moreover, it could be found as the improvements required to enhance the thoroughness of the entire SLR process. In this sense, complementing the steps presented in Tables 3.2 and 3.3, Table 3.5 points out connected to its respective stages. 28 3 Systematic Literature Review Table 3.5 Improvements required in SLR methods Stages Improvements Meaning General Applicability Allow the SLR to be implemented by any area of knowledge without signiﬁcant methodological changes Theory testing and building Allow theory testing and building through the SLR Iterations Make the information and feedback ﬂows among the SLR steps more explicit Review Conceptual framework Provide templates and practical guidance on how to build conceptual frameworks Bias assessment Provide techniques or guidelines for minimizing the risk of bias Quality assessment Allow the quality assessment of primary studies retrieved from different ﬁelds to be performed by the same technique Coding Provide techniques or guidelines on how to build coding systems Analysis Literature analysis Provide techniques for analyzing the literature along with clear directives on how and when to use it Synthesis Qualitative synthesis Provide techniques for synthesizing qualitatively the literature along with clear directives on how and when to use it Artifacts assessment Provide techniques or guidelines for assessing artifacts Synthesis framework Provide templates and practical guidance on how to build synthesis frameworks Updating Reinforce the importance of deﬁning periods for updating the SLR Source Created by authors The requirements for improvement presented in Table 3.5 along with other advancements were implemented in the method entitled Literature Grounded Theory (LGT) which will be presented in Chap 6. 3.4 Closing Remarks The LR has become essential in scientiﬁc research, due to the advancement of knowl- edge generation. However, traditional approaches to reviewing literature often lack thoroughness and are not undertaken systematically. To overcome these limitations several SLR methods for synthesizing the research ﬁndings in a systematic, trans- parent, and reproducible way have been developed over the past years. Despite the 3.4 Closing Remarks 29 advantages of these SLR methods when compared to the traditional LR ones, they also need improvements for producing more reliable and reproducible outcomes. Box 3.3 What did we learn in this chapter? • The importance of SLR in academic research activities; • The differences between the traditional LR and SLR; • The common underlying structure among the SLR methods; • The limitations of the existing methods; • The methodological requirements for improvement. References Bardin, L.: L’analyse de contenu [Content Analysis], p. 223. Presses Universitaires de France Le Psychologue, Paris (1993) Baumeister, R.F., Leary, M.R.: Writing narrative literature reviews. Rev. Gen. Psychol. 1(3), 311– 320 (1997) Bhattacherjee, A.: Social Science Research: Principles, Methods, and Practices, 3rd edn. Textbooks Collection, [S.l.] (2012). 9781475146127 Borrego, M., Foster, M.J., Froyd, J.E.: Systematic literature reviews in engineering education and other developing interdisciplinary ﬁelds. J. Eng. Educ. 103(1), 45–76 (2014). 1069-4730 Colicchia, C., Strozzi F.: Supply chain risk management: A new methodology for a systematic literature review. Supply Chain Manag. 17(4), 403–418 (2012). 1359-8546 Cooper, H., Hedges, L.V., Valentine, J.C.: Handbook of Research Synthesis and Meta-Analysis, 2nd edn., p. 610. Russel Sage Foundation, New York (2009). 9780871541635 Cornell University Library Evidence Synthesis Service—A Guide to Evidence Synthesis— LibGuides at Cornell University. Disponível em: https://guides.library.cornell.edu/evidence-syn thesis/service. Acesso em: 15 abr. 2021 Denyer, D., Tranﬁeld, D.: Producing a Systematic Review. The Sage Handbook of Organizational Research Methods, 1st edn., pp. 671–689. SAGE Publications, London (2009) Denyer, D., Tranﬁeld, D., Vanaken, J.E.: Developing design propositions through research synthesis. Organ. Stud. 29(3), 393–413 (2008). 0170-8406 Dresch, A., Lacerda, D.P., Antunes, J.A.V.: Design Science Research: A Method for Scientiﬁc and Technology Advancement, p. 161. Springer, [S.l.] (2015). 978-3-319-07373-6 Finfgeld, D.L.: Metasynthesis: The state of the art—so far. Qual. Health Res. 13(7), 893–904 (2003). 1049-7323 (Print)r1049-7323 (Linking) Gauss, L., Lacerda, D.P., Cauchick, M.P.A.: Module-based product family design: systematic literature review and meta-synthesis. J. Intell. Manuf. 32(1), 265–312 (2021) Glass, G.V.: Primary, secondary, and meta-analysis of research. Educ. Res. 5(10), 3–8 (1976) Gough, D., Oliver, S., Thomas, J.: An Introduction to Systematic Reviews, 1st edn., p. 288. SAGE Publications, Los Angeles (2012). 9781849201803 Hart, C.: Doing a Literature Review: Realising the Social Science Research Imagination, 1st edn., p. 230. SAGE Publications, London (1988) Higgins, J., Green, S.: Cochrane Handbook for Systematic Reviews of Interventions Khan, K.S., et al.: Five steps for a sistematic review. J. r. Soc. Med. 96(1), 118–121 (2003) 30 3 Systematic Literature Review Kitchenham, B., Charters, S.: Guidelines for performing systematic literature reviews in software engineering. Engineering 45(4ve), 1051 (2007). 1595933751 Krippendorff, K.: Content Analysis: An Introduction to its Methodology, 4th edn., p. 356. Sage Publications Inc, Thousand Oaks (2019) Littell, J.H. Corcoran, J., Pillai, V.: Systematic Review and Meta-Analysis, pp. 1–211. s.n., [S.l] (2008). 978-0-19-532654-3 Morandi, M.I.W.M., Camargo, L.F.R.: Systematic Literature Review. Design Science Research, P. 161. Springer, [S.l.] (2015) Palomino, M., Abraham, D., Melendez, K.: Methodologies, methods, techniques and tools used on SLR elaboration: A mapping Studs. Trends and Applications in Software Engineering, pp.14–30. Springer, Cham (2019). 978-3-319-69340-8 Petticrew, M., Roberts, H.: Systematic Reviews in the Social Sciences: A Practical Guide. Malden, 1st edn., p. 336. Blackwell Publishing, MA (2006). 1473314060098 Robinson, P., Lowe, J.: Literature reviews vs systematic reviews. Aust. n. z. J. Public Health 39(2), 103–103 (2015) Siluo, Y., Qingli, Y.: Are Scientometrics, Informetrics, and Bibliometrics Different? 2017, pp. 1–12. [s.n.], Wuhan (2017) Smith, V., et al.: Methodology in conducting a systematic review of systematic reviews of healthcare interventions. BMC Med. Res. Methodol. 11(15), 1–6 (2011) Snyder, H.: Literature review as a research methodology: an overview and guidelines. J. Bus. Res. 104, 333–339 (2019). Disponível em: <https://doi.org/10.1016/j.jbusres.2019.07.039> Systematic vs Literature reviews—Systematic and Literature Reviews—LibGuides at Brown University. Disponível em: https://libguides.brown.edu/Reviews/types. Acesso em: 22 July 2020 Thomé, A.M.T., Scavarda, L.F., Scavarda, A.J.: Conducting systematic literature review in operations management. Prod. Plan. Control 27(5), 408–420 (2016) Tranﬁeld, D., Denyer, D., Smart, P.: Towards a methodology for developing evidence-informed management knowledge by means of systematic review. Br. J. Manag. 14, 207–222 (2003) Webster, J., Watson, R.T.: Analyzing the past to prepare for the future: writing a literature review. MIS Quarterly 26(2), 133–151 (2002) 0959-5309 Whiting, P., et al.: ROBIS: A new tool to assess risk of bias in systematic reviews was developed. J. Clin. Epidemiol. 69, 225–234 (2016) Zupic, I., ˇCater, T.: Bibliometric methods in management and organization. Organ. Res. Methods 18(3), 429–472 (2015) Chapter 4 Literature Analysis This chapter addresses the concept of the Literature Analysis and highlights its impor- tance for a Systematic Literature Review (SLR). Moreover, it presents the promi- nent techniques adopted to perform it—Scientometrics, Bibliometrics, and Content Analysis—as well as depicts the main analysis that can be carried out by them. 4.1 Literature Analysis Analyzing and synthesizing previous research is important for advancing knowledge on a given research topic (Zupic and ˇCater 2015). In this context, the Literature Analysis (LA) can be deﬁned as the process of systematically decomposing the content of a study into parts and describing how these parts are related (Hart 1998). Moreover, this reasoning can be broadened from the content to the metadata of studies comprising a research ﬁeld, wherein the volume of publications on a subject, the main authors, and journals can be identiﬁed among other factors. The LA also allows to position the research in the ﬁeld and show the interest of the scientiﬁc community. Although there is no standardization, the LA is usually undertaken from broad to narrow scope (i.e., from metadata to content), and the techniques employed in this context depend on the objective of the SLR being conducted. Regarding the meta- data, contextual data on years of publication, journals, authors, and characteristics of studies relevant to the synthesis, can be used (Thomé et al. 2016). For that purpose, it is recommended to use Scientometric and Bibliometric Analysis. Scientometric Analysis or Scientometrics aims at exploring existing relationships in scientiﬁc development and, consequently, promote the advancement of science and technology (Qiu et al. 2017). However, in some ﬁelds, Scientometrics is confused The original version of this chapter was revised: Figure 4.12 was updated. The correction to this chapter can be found at https://doi.org/10.1007/978-3-030-75722-9_10 © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_4 31 32 4 Literature Analysis with Bibliometrics or Informetrics. This confusion is justiﬁed because, despite being distinct, these techniques are strictly related (Osareh 1996), therefore it is impor- tant to distinguish the purpose of each of them. The main objective of Bibliomet- rics is to improve scientiﬁc documentation, information, and communication activ- ities through quantitative analysis of document collections, while Scientometrics contributes to understanding the mechanism of scientiﬁc research, through quanti- tative analysis of generation, propagation, and use of scientiﬁc information (Osareh 1996). Informetrics, in turn, deals with the measurement of information phenomena and the application of mathematical procedures to the problems of the discipline (Hood and Wilson 2001). Box 4.1 Key concepts Metadata: consists of data that describes and gives information about other data—in particular, data about the publication (title, year published, abstract, keywords, e.g.), the authors (names, afﬁliations, titles, e.g.), and the publication sources (names, type, ISSN/ISBN, etc.). To establish a common understanding of concepts and objectives of Sciento- metrics, Bibliometrics, and Informetrics, McGrath (1989) proposed a typology for deﬁning and classifying these three techniques, as shown in Table 4.1. Although Scientometrics, Bibliometrics, and Informetrics consist of three different techniques (Siluo and Qingli 2017), they are directly related to the measure- ment of knowledge, which makes them complementary in many aspects (Sengupta 1992). As mentioned before, besides the metadata concerning the research ﬁeld, the analysis can be employed at the document level. The reasoning here is to evaluate the content of primary studies to understand the underlying patterns of a speciﬁc subject (Hart 1998). For that purpose, the Content Analysis is one of the main techniques to be considered, which together with Scientometric and Bibliometric, will be detailed in the following sections. 4.2 Scientometric Analysis Scientometric Analysis or simply Scientometrics consists of a set of quantitative procedures used to analyze the scientiﬁc development process over time (Osareh 1996; Qiu et al. 2017). The term Scientometrics—Naukometriya in Russian—was ﬁrst used in 1978 by Vassily V. Nalimov and Z. M. Mulchenko, and gained recogni- tion after the creation of the journal named Scientometrics (Hood and Wilson 2001). 4.2 Scientometric Analysis 33 Table 4.1 Typology and deﬁnition of Scientometrics, Bibliometrics, and Informetrics Typology Scientometrics Bibliometrics Informetrics Object of analysis Disciplines, themes, areas, and ﬁelds Books, documents, magazines, articles, authors, and users Words, documents, and databases Variables Number of publications Number of citations, frequency of words, etc. Number of publications, citations, references, etc. Indicators Annual scientiﬁc production, researchers’ production, publications by country, publications by source, and publications by afﬁliation Co-word, co-citation, citation, bibliography coupling, co-authorship, and main path Quality, importance, and impact Objectives Describe the quantitative aspects of science Understand the scientiﬁc development along with the main subjects and contributors in a research ﬁeld Improve recovery efﬁciency Source Adapted from McGrath (1989) Since then, it has been employed for describing science in terms of growth, struc- ture, interrelationships, and productivity (Hood and Wilson 2001). In this context, the prominent indicators used are the (i) annual scientiﬁc production, (ii) researchers’ production, (iii) publications by country, (iv) publications by source, and (v) publica- tions by afﬁliation (Hood and Wilson 2001). Indicators that share the same reasoning of being “quick” and “understandable” measures (Vinkler 2010). Regarding the annual scientiﬁc production, the objective is to analyze the devel- opment of a theme or research ﬁeld over time. Moreover, it can be used to attest to the relevance of the research topic, in case the increased volume of publications is evidenced. Figure 4.1 gives an example of the annual scientiﬁc production of the subject Theory of Constraints. The researchers’ production, in turn, aims at identifying the most productive researchers on either a subject or a research ﬁeld, whose, therefore, must have its production incorporated into the SLR (Hood and Wilson 2001). Figure 4.2 shows an example of researchers’ production concerning the subject of Theory of Constraints. In terms of publications by country, it can be used when the objective is to identify the most relevant countries on a subject or in a research ﬁeld (Hood and Wilson 2001). This indicator is particularly important because government agencies promoting scientiﬁc and technological research use this measure to allocate resources related to public policies (FAPESP 2010). Figure 4.3 depicts an example of publications by country concerning the subject of Theory of Constraints. Concerning the publications by source, it aims at identifying the main journals on a subject or in a research ﬁeld. This indicator not only contributes to identifying 34 4 Literature Analysis Fig. 4.1 Annual scientiﬁc production of the subject Theory of Constraints. Source Scopus Database (2020) Fig. 4.2 Researchers’ production of the subject Theory of Constraints. Source Scopus Database (Scopus 2020) the existing knowledge to base the research but also to share the obtained results with a qualiﬁed audience. Figure 4.4 shows an example of publications by source, considering its publication sources. Finally, the publications by afﬁliation stand for identifying the institutions and/or research groups that most publish on either a subject or a research ﬁeld (Hood and Wilson 2001). This indicator assists both researchers and funding agencies in identi- fying institutions for strategic partnerships. Figure 4.5 shows an example of analyzing publications by afﬁliation. Figure 4.5 gives an example of publications by afﬁliation. 4.2 Scientometric Analysis 35 Fig. 4.3 Production by country concerning the subject of Theory of Constraints. Source Created by authors, based on the Scopus data (Scopus 2020) Fig. 4.4 Publications by source on the Theory of Constraints. Source Scopus Database (Scopus 2020) To improve the reliability of the results of a Scientometric Analysis, the following guidelines can be adopted. First, document all criteria used for gathering and analyzing the data (Glänzel and Schoepﬂin 1994). Second, consider competing keywords that express the same object and/or subject of study. Third, properly treat the database to ensure a reliable analysis. Finally, relativize the volume of research on a given theme compared to the growth of the discipline in which the theme belongs to. 36 4 Literature Analysis Fig. 4.5 Publications by afﬁliation on the Theory of Constraints. Source Scopus Database (Scopus 2020) Given the systematic nature of Scientometric Analysis, it contributes to enhancing the methodological thoroughness of the SLR process, allowing in this way the repro- ducibility and reliability of the results. Moreover, it allows a more in-depth analysis of scientiﬁc research in terms of time (years to be investigated) and space (journals and countries). To operationalize the Scientometric Analysis, it is possible to use the R program- ming language, with the Bibliometrix package, developed by Aria and Cuccurullo (2017). Besides, the Scopus database provides Scientometric indicators for the results of each search performed within the database. The next section presents the Bibliometric Analysis. 4.3 Bibliometric Analysis Bibliometric Analysis or Bibliometrics consists of a statistical technique to either map the state of the art or to identify research opportunities in a given ﬁeld of study (Oliveira et al. 2019). The use of Bibliometrics dates back to 1896, but it was only in 1969 that the term was recognized in replacement of the one used so far, “statistical bibliography” (Broadus 1987a; Pritchard 1969; Sengupta 1992). An overview of the Bibliometrics history was described by Broadus (1987b) in the research called “Toward a deﬁnition of Bibliometrics.” This study is synthesized and complemented by more recent deﬁnitions in Fig. 4.6. Another important milestone in Bibliometrics history is the establishment of its Fundamental Laws. These laws gave rise to the main indicators used to measure the productivity and efﬁciency of scientiﬁc production (Haddow 2018; Sengupta 1992). Table 4.2 presents the Lotka, Zipf, and Bradford’s laws along with their respective 4.3 Bibliometric Analysis 3719601969Pritchard \"the application of mathematics and statistical methods to books and other media of communication\" 021969Fairthorne \"quantitative treatment of the properties of the recorded discourse and behavior appertaining to it\" 0319701978Nicholas e Ritchie \"Bibliometrics is the statistical or quantitative description of a literature take here to mean, simply, a group of related documents\" 0419801981Schrader “the scientific study of recorded discourse”051981Potter \"Bibliometrics is, simply put, the study and measurement of publication patterns for all forms of written communication and their authors\" 061986Glas \"generally speaking bibliometrics could be defined as the search for systematic patterns in comprehensive bodies of literature\" 1987Broadus “The measurement the units of publications, bibliographic citations, and surrogates for them”1999Van Raan “Bibliometric cinematography: you can make maps in a time series, and thus create a 'movie' of the development of a research field\" T1T2T3T4T1T2T3T4T1T2T3T4T1T2T3T41984Harrod’s Librarians’ Glossary “the study of the use made of books and other media within and between library systems\" 071985Boyce e Kraft \"Bibliometrics is the quantitative study of written communication through its physical realization\" 080910T519901922Hulme “Statistical Bibliography”01192211122013The OECD \"Bibliometrics is a statistical analysis of books, articles, or other publications\" Fig.4.6HistoricaldeﬁnitionsofthetermBibliometrics.SourceCreatedbyauthorsbasedonBroadus(1987a),VanRaan(1999)andTheOECD—GlossaryofStatisticalTerms(2013) 38 4 Literature Analysis Table 4.2 The fundamental Laws of Bibliometrics Law Statement Lotka’s Law (1926) It states that the number of authors making x contributions in a given period is a fraction of the number making a single contribution, following the formula 1/x a where a is nearly equal to 2 Zipf’s Law (1949) It states that the most frequent word will occur approximately twice as often as the second most frequent word, three times as often as the third most frequent word, and so on, with this pattern being able to be modeled by Zipf distribution Bradford’ Laws (1934) It states that if scientiﬁc journals are arranged in order of their decreasing productivity of articles on a given subject, they may be divided into a nucleus of periodicals more particularly devoted to the subject, and several “groups” or “zones” containing the same number of articles as the nucleus, where the number of periodicals in the nucleus and succeeding zones will be 1 : n : n2,where n is a multiplier Source Haddow (2018), Hood and Wilson (2001) statements. Although the Lotka, Zipf, and Bradford’s laws had set the foundations, the Biblio- metric indicators evolved and have not limited itself to the original propositions (Thelwall 2008). In general terms, these indicators can be classiﬁed into two main streams, which include (i) research performance and (ii) scientiﬁc mapping (Cobo et al. 2011b). Both will be detailed in the next sections. 4.3.1 Research Performance The Research Performance aims at evaluating the performance of research, researchers, and institutions (Zupic and ˇCater 2015). Moreover, it is intended to build the conceptual, social, or intellectual structure of scientiﬁc research as well as to evidence its evolution (Gutiérrez-Salcedo et al. 2017). The availability of information sources on academic communication enabled the development of this performance stream. The publication of the Science Cita- tion Index (SCI) by Garﬁeld in 1969, allowed the emergence of two bibliometric applications regarding the Research Performance: the (i) Relational and (ii) Evalua- tive Bibliometrics. Relational Bibliometrics seeks to identify relationships within research, such as the emergence of new research fronts or co-authorship (Thel- wall 2008). The Evaluative Bibliometrics, in turn, analyzes the impact of academic research, based on the citation-based indicators, allowing the comparison of scientiﬁc contributions of articles, journals, individuals, or research groups (Thelwall 2008). However, other factors, besides scientiﬁc contribution, can inﬂuence the citation count. For example, the so-called cumulative advantage process postulates that arti- cles, which are initially well-cited, tend to continue being cited in part because they were cited, and not because of their intrinsic value (Thelwall 2008). Other causes 4.3 Bibliometric Analysis 39 that can inﬂuence the number of citations are the area to which the article belongs and its availability in the databases. Articles that have open access in the databases, tend to be more cited than those that have not (Bornmann and Marx 2015). Although there is an ongoing debate on the validity of citation-based indicators to evaluate the Research Performance, they remain in force but complemented by other metrics (Thelwall 2008). In this sense, the main indicators include the (i) impact factor, (ii) CiteScore, (iii) Eigenfactor, (iv) SCImago Journal Rank, and (v) h-index (Deb et al. 2019; Haddow 2018). The productivity of journals can be measured by the impact factor, which is an indicator conceived by the Journal Citation Report (JCR), belonging to Clarivate Analytics (Deb et al. 2019). The impact factor was created in the 1960s by Eugene Garﬁeld, director of the Institute of Scientiﬁc Information (ISI) at the time, and creator of the bibliographic database Science Citation Index (SCI). The impact factor consists of the ratio between the total citation counts of journals belonging to the ISI database during the previous two or ﬁve years, by the total number of publications made by the journals during the same period (Bensman 2007). Annually, JCR prepares bibliometric indicators on the journals’ productivity, with the impact factor being one of the metrics considered. Another indicator for measuring the impact of journals was developed by Elsevier in 2016, called CiteScore (Haddow 2018). CiteScore itself is an average of the sum of the citations received in a given year to publications published in the previous three years divided by the sum of publications in the same previous three years (Deb et al. 2019). When compared to the impact factor, CiteScore is considered more robust, since it uses a three-year period instead of two or ﬁve years, which on one hand might be particular short for areas of slower development rates, and on the other hand too long for areas of faster development rates (Zijlstra and Mccullough 2016). Concerning the Eigenfactor, it is an indicator created by researchers from the University of Washington, which consists of a rating of the total importance of a scientiﬁc journal (Bergstrom and West 2017; Haddow 2018). The Eigenfactor calculation is based on the number of times articles from the journal published in the past ﬁve years have been cited, but it also considers which journals have contributed these citations so that highly cited journals have more inﬂuence than lesser cited journals. References from one article in a journal to another article from the same journal are removed so that Eigenfactor is not inﬂuenced by journal self-citation (Haddow 2018). One of the most known indicators to evaluate the performance of journals is the SCImago Journal Rank (SJR), developed after the launch of the Scopus database (Haddow 2018). The SJR ranks academic journals based on citation weighting schemes and centrality of eigenvectors (González-Pereira et al. 2010). In general terms, the JCR can be calculated by the ratio of the number of citations received in the given year and the number of documents published in the journal in the three previous years (Mering 2017). The JCR can be obtained on a free website, which includes journals and bibliometric indicators from Scopus’ database. Classiﬁcations of journals are carried out annually for 27 areas and 313 categories of themes (Tode- schini and Baccini 2016). Although JCR uses similar calculations of impact factor, 40 4 Literature Analysis it is considered more appropriate to assess the citation relationships among scientiﬁc journals since it excludes self-citations (Haddow 2018). When the need for evaluating the individual performance of researchers comes to place, the h-index is used (Karanatsiou et al. 2017). This indicator was proposed by Hirsch (2005) and is calculated by counting the number of publications for which an author has been cited at least that same number of times (Thelwall 2008). For instance, an h-index of 15 means that the scientist has published at least 15 papers that have each been cited at least 15 times. One of the disadvantages of the h-index is that it considers the self-citation. This can be particularly worrying since the researchers themselves can increase their rates through this mechanism (Karanatsiou et al. 2017). 4.3.2 Scientiﬁc Mapping Scientiﬁc knowledge can be considered as a complex system. Therefore, it requires a network structure to outline the interaction among its main elements (Gutiérrez- Salcedo et al. 2017). In Bibliometrics, this network is composed of nodes, which stands for publications, journals, researchers, or keywords, and edges that depict the relationship between pairs of nodes (Van Eck and Waltman 2014). Regarding Scientiﬁc Mapping, the objective is to build bibliometric networks by which it is possible to identify how scientiﬁc knowledge is conceptually structured (Cobo et al. 2011b). In this sense, three categories of bibliometric networks can be found in the literature: (i) collaboration networks, (ii) conceptual networks, and (iii) citation networks. Collaboration Networks are used to understand how authors, institutions, or coun- tries cooperate in terms of scientiﬁc research (Gutiérrez-Salcedo et al. 2017). This cooperation can be expressed through co-authorship networks, which consist of an association in which two or more researchers, institutions, or countries jointly report their research results on some topic. Therefore, it can be viewed as social networks encompassing actors that reﬂect collaboration among them, as illustrated in Fig. 4.7 (Acedo et al. 2006; Lu and Wolfram 2012; Zupic and ˇCater 2015). The co-authorship networks can be used as a ﬁrst means of identifying research groups on a given subject (Peters and Van Raan 1991). Moreover, it can be employed to understand the prevalent factors deﬁning the collaboration, as well as to investigate the impacts of collaboration on the research results (Acedo et al. 2006). Box 4.2 highlights three works that employed the co-authorship networks for data analysis. 4.3 Bibliometric Analysis 41 Fig. 4.7 Countries co-authorship network the subject of Theory of Constraints. Source Created by authors using the software VosViewer Box 4.2 Examples of studies that used the co-authorship networks for data analysis • De Solla Price and Beaver (1966) used the co-authorship network to analyze social structures in a given research ﬁeld. The study manually classiﬁed a group of authors to identify the Invisible College collaboration network. They concluded that this ﬁeld of research is dominated by a small nucleus of active researchers and a signiﬁcant number of transient researchers. • Peters and Van Raan (1991), employed the co-authorship network to identify the collaboration among the researchers in the ﬁeld of chemical engineering. They concluded that the co-authorship networks are effective means for identifying the research groups, the relationships within and across groups, as well as their changes over time. • Acedo et al. (2006) carried out an exploratory analysis of co-authorship in the ﬁeld of management. The obtained results indicated a progressive growth in the number of co-authored publications in the area. This trend is explained by the fact that the articles published in co-authorship have a greater impact than those of single authorship. The second category, called the Conceptual Network, maps the relationships among the concepts present in a set of documents (Gutiérrez-Salcedo et al. 2017). This relationship can be expressed through co-word networks, which use the principle of co-occurrence to identify the relationships between words within the corpus of texts (Callon et al. 1983). In this kind of network, the object of analysis is the concepts itself and not the documents, authors, or journals (Aria and Cuccurullo 2017). These 42 4 Literature Analysis Fig. 4.8 Co-word network on the Theory of Constraints. Source Created by authors using the software VosViewer concepts are derived from the words comprising the articles’ titles, abstracts, and keywords, and are commonly used to identify the similarities among the studies on the same subject (Zupic and ˇCater 2015). When the co-word network is applied for mapping science, clusters of keywords are obtained giving rise to themes, as shown in Fig. 4.8. The strength of these clusters, or themes, is given by their density and centrality (Cobo et al. 2011a). The process of building the co-word networks starts with the extraction of the keyword from the bibliographic databases. Then, based on the principle of co- occurrence, the network is built using commercial software. Finally, the network is analyzed to obtain knowledge from it (He 1999). One advantage of the co-word network is that the similarities among studies are retrieved from a fraction of the content and not only from the metadata as other networks do (Lu and Wolfram 2012). Another beneﬁt lies in the ability to build networks for different periods, which is particularly important to identify the conceptual changes of a research ﬁeld over time (Zupic and ˇCater 2015). Regarding the disadvantages, the difﬁculty of extracting the data from databases is the most frequent one. It happens because bibliographic data of many journals miss the keywords. Another important aspect is that only considering keywords for building the network might be contestable since the network validity will depend on the ability of the keywords to capture the essential elements of the text. One way to overcome this limitation is to analyze the content of full-texts, however, the most common algorithms used for that purpose present problems in distinguishing the importance of words in high-volume texts (Zupic and ˇCater 2015). 4.3 Bibliometric Analysis 43 The third category, the Citation Network, maps the relationships among publi- cations through its cited references (Haddow 2018). In science, the citation can be deﬁned as a reference to the source of information used in research. Moreover, it consists of a measure of authors’ communication through literature (Osareh 1996). The citations form a visible and traceable path through the connection of scientiﬁc documents. Its importance motivated the development of many analytical techniques for investigating how the information about knowledge is generated and connected (Bellis 2009). Its ability to describe a body of literature and map the inﬂuence of authors, research, journals, organizations, and countries, resulted in a series of publications carrying out citation analyses from the 1970s on (Haddow 2018). Considered one of the most used categories in bibliometric analysis, citation networks play an important role in Research Performance and Scientiﬁc Mapping (Deb et al. 2019; Gutiérrez-Salcedo et al. 2017). When the objective is Scientiﬁc Mapping, the prominent topologies used are (i) citation, (ii) bibliographic coupling, and (iii) co-citation (Gutiérrez-Salcedo et al. 2017). Concerning the citation network, it is employed to map the path-dependence of scientiﬁc development or research streams as well as to measure the activity and interaction among researchers (Garﬁeld 1979). Based on the reasoning that researchers cite documents considered relevant for their research, the citations can also be seen as an appropriate measure of inﬂuence, i.e., the more cited the article, the more important it is (Zupic and ˇCater 2015). Figure 4.9 gives an example of a citation network concerning the subject of Theory of Constraints. The second network topology is the bibliographic coupling. Developed by Kessler in 1963, it considers that two documents are bibliographically coupled if they together cite a third document (Kessler 1963). It is based on the reasoning that the more the references overlap, the greater is their relationship (Zupic and ˇCater 2015). While the bibliographic coupling refers to the overlapping of references, its intensity depends Fig. 4.9 Citation network on the Theory of Constraints. Source Created by authors using the software VosViewer 44 4 Literature Analysis on the number of common references cited (Osareh 1996). The number of refer- ences shared across two documents (intensity) does not change over time. There- fore, to analyze the similarity between documents, the period in which the analysis is conducted is not relevant (Zupic and ˇCater 2015). However, given that citation patterns evolves over time, it is recommended the bibliographic coupling being performed in time intervals not greater than 5 years, considering the youngest and the oldest reference (Zupic and ˇCater 2015). This kind of bibliometric network is useful when the objective is to map the research streams, particularly the emerging ones that have not yet produced repre- sentative citation counts (Zupic and ˇCater 2015). Moreover, it has been frequently used for clustering publications by subject as shown by Fig. 4.10 (Aria and Cuccurullo 2017). The third network topology is the co-citation, which consists of a linkage between a pair of documents concurrently cited by a third document (Small 1973). It is grounded on the presuppose that the more two items are cited together, the greater the relationship between their content (Zupic and ˇCater 2015). Fig. 4.10 Bibliographic coupling network on the Theory of Constraints. Source Created by authors using the software VosViewer 4.3 Bibliometric Analysis 45 The co-citation network models the underlying pattern of communication among researchers sharing common objectives or interests (Üsdiken and Pasadeos 1995). Originally conceived by Small, in 1973, to analyze the association among documents, in 1981 its scope was expanded by White e Grifﬁth when analyzing the relationships among researchers. Finally, in 1991, McCain used the co-citation network to map the association among journals (Van Eck and Waltman 2014). Unlike the bibliographic coupling, depending on the evolution of the interests in a research ﬁeld, the pattern of the co-citation may vary over time (Small 1973). This variation can provide evidence on the development of the research ﬁeld as well as be used to detect changes in paradigms on it (Aria and Cuccurullo 2017). Besides that, from the co-citation networks it is possible to visualize the connections among different ﬁelds, trace the emergence and development of new research ﬁelds, and therefore, predict their changes (Bellis 2009; Vinkler 2010). The co-citation is the opposite of the bibliographic coupling. While the co-citation network accounts for the link between a pair of documents concurrently cited by a third document, the bibliographic coupling stands for the link between two documents that cite together a third document, as illustrated by Fig. 4.11 (Aria and Cuccurullo 2017). Thus, despite having related content, two articles strongly connected by a co-citation network might present a weak relationship in a bibliographic coupling network (Small 1973). Generally, co-citation networks are used for mapping the knowledge base and present better results when applied at longer time intervals. The bibliographic coupling networks, in turn, are used to map research fronts, therefore, its best results are taken whenever applied to shorter time intervals (Aria and Cuccurullo 2017). Despite the evidence proving the beneﬁts of Citation Networks, this category is not exempt from criticism (Van Raan 1996). One of the main criticisms attributed to it is that it might include excessive counts of negative citations, such as citations to refute determined research (Garﬁeld 1979). Moreover, undertaking the analysis of citations in isolation has the consequence of citation bias. For example, more recent publications have less time to be cited, therefore, the citation count as a measure of A Citing documents (research front) Cited documents (knowledge base) b a Co-citation B A a Bibliographic coupling Fig. 4.11 Differences between co-citation and bibliographic coupling. Source Zupic and ˇCater (2015) 46 4 Literature Analysis inﬂuence might be biased by older publications (Zupic and ˇCater 2015). Coupled with that arises the problem of self-citation, which many authors resort to increasing their rates (Zupic and ˇCater 2015). A summary of the network topologies for Scientiﬁc Mapping is given in Table 4.3. Different network topologies can be used to perform the Bibliometric Analysis. The choice of which one to use will depends on the unit of analysis as well as the objectives of the research being performed. In the context of SLR, the Bibliometric Analysis is particularly useful for reﬁning the search terms and identifying the current and emerging research streams. To operationalize this kind of analysis, there are different software available, as exhibited in Table 4.4. The expressive examples of Bibliometrics applications reveal its high potential to carry out scientiﬁc mapping. Its systematic nature allows reaching the quanti- tative rigor that traditional literature reviews do not present. With latent potential growth, Bibliometrics can become one of the main approaches to analyzing scien- tiﬁc literature (Zupic and ˇCater 2015). However, despite all its beneﬁts, there are still Table 4.3 Topology of Bibliometric networks Topology Node Unit of analysis Kind of relation Co-authorship – Author – Country – Institution – Author’s name – Country from afﬁliation – Institution from afﬁliation – Authors’ co-occurrence – Countries’ co-occurrence – Institutions’ co-occurrence Co-word –Keyword –Term –Keyword, or term extracted from title, abstract, or document’s body – Terms’ co-occurrence Citation – Author – Document – Journal – Organization – Country – Author’s name – Documents – Journal’s name – Organization’s name – Country’s name – Cited author – Cited documents – Cited journal – Cited organization – Cited country Bibliographic coupling – Author – Document – Journal – Author’s oeuvres – Documents – Journal’s oeuvres – Common references among author’s oeuvres – Common references among documents – Common references among journal’s oeuvres Co-citation – Author – Document – Journal – Author’s reference – Reference – Journal reference – Co-cited author – Co-cited documents – Co-cited journal Source Adapted from Cobo et al. (2011b) 4.3 Bibliometric Analysis 47 Table 4.4 Software for Bibliometric Analysis Software Function Topology/Analysis Bibexcel It converts bibliographic raw data into tabbed data records for further processing in Excel, Pajek, or NerDraw – Co-authorship – Bibliographic coupling –Co-word – Co-citation CiteSpace It analyzes and visualizes scientiﬁc literature, particularly the co-citation networks – Co-authorship – Bibliographic coupling –Co-word – Co-citation CoPalRed It performs co-word analysis from the keywords retrieved from scientiﬁc documents –Co-word IN-SPIRE It identiﬁes relationships, trends, and underlying themes from textual data –Co-word Leydesdorff’s Software It generates a word-occurrence matrix, a co-occurrence matrix, and a normalized co-occurrence matrix from a set of text ﬁles and a word list – Co-authorship – Bibliographic coupling –Co-word –Citation – Co-citation Network Workbench Tool It performs large-scale network analysis, modeling, and visualization for Biomedical, Social Science, and Physics Research – Co-authorship – Bibliographic coupling –Co-word –Citation – Co-citation Science of Science Tool It supports the temporal, geospatial, topical, and network analysis and visualization of datasets from micro to macro levels – Co-authorship – Bibliographic coupling –Co-word –Citation – Co-citation VantagePoint It obtains knowledge in search results from patent and literature databases – Co-authorship –Co-word –Citation – Co-citation VosViewer It constructs and visualizes bibliometric networks from a body of scientiﬁc literature – Co-authorship – Bibliographic coupling –Co-word – Co-citation Pajek It analyzes and visualizes large networks – Main path analysis –Citation (continued) 48 4 Literature Analysis Table 4.4 (continued) Software Function Topology/Analysis SciMat It performs a science mapping analysis under a longitudinal framework – Co-authorship –Co-word –Citation – Co-citation Source Adapted from Cobo et al. (2011b), Lucio-Arias and Leydesdorff (2008) challenges to overcome. Some of them, pointed out by Haddow (2018), are given in Table 4.5. For being an emerging ﬁeld, few methods for conducting Bibliometric Anal- ysis are available in the literature. One of them is that proposed by Oliveira et al. (2019), which systematically organizes the steps to be taken to identify the current and emerging research streams, as shown in Fig. 4.12. The method encompasses Table 4.5 Challenges on Bibliometric Analysis Challenge Description Deﬁning a sample This requires systematic and defendable criteria. While probability sampling is an option, content type, place of publications, and ﬁeld form parameters in many studies and can present demarcation difﬁculties Access to data The number of citations retrieved from different data sources may vary and there will be overlaps as well as unique citations in each. If the body of literature being sampled is not indexed adequately in a major source, then extensive manual effort may be required for data collection. Additional sources of data may be required for author and afﬁliation studies Deﬁning units of analysis A systematic and consistent approach to assigning categories, such as afﬁliation and content types, is critical. Careful planning and coding sheets should reduce the potential for bias and ill-deﬁned categories Counting citations Self-citations are usually included in citation data, but this presents problems because some ﬁelds have extremely high self-citation rates. Thus, self-citations should be considered when comparing ﬁelds. Does manual citation analysis require additional deﬁnitional decisions, such as whether references in footnotes are included in the citation count? Counting authors An author in multi-authored works can be counted as one or as a fraction of the total authors. This decision has implications for the results. Previous research can be used to justify the decision and to compare ﬁndings Comparison across ﬁelds Different scholarly communication patterns must be considered when making comparisons across ﬁelds to reach valid conclusions Source Haddow (2018) 4.3 Bibliometric Analysis 49 Mapping of the sate-of-the-art and identification, grouping, and analysis of gaps and trends Analysis of bibliometric data Mining of bibliometric data Define the field of study Define search platforms Conclusion Define and execute search criteria Review and save results Export saved results Import data to bibliometrics’ software Bibliometric parameters • Evolution of publications • Authors • Most searched areas • Institutions • Keywords •Journals • Articles • Countries Bibliometric networks • Citations (authors, articles, journals, and countries) • Co-citations (authors, journals, and articles) • Co-authorship (authors and countries) Network authors, institutions, and countries Overall ranking of the most cited articles Analysis and review of selected articles Keyword analysis Group analysis Timeline overview Interaction analysis Steps of the method Information flow Stages of the method Fig. 4.12 Method for conducting Bibliometric Analysis. Source Adapted from Oliveira et al. (2019) 50 4 Literature Analysis both bibliometric streams, the evaluation of Research Performance, and Scientiﬁc Mapping. From Fig. 4.12 it is possible to observe that up to the stage Mining of bibliometric data, the steps overlap with SLR. Therefore, the inclusion of Bibliometric Anal- ysis within the SLR process not only contributes to the SLR but also enhances the Bibliometrics itself as a ﬁeld of study. The next section presents Content Analysis. 4.4 Content Analysis Content Analysis is a technique for identifying communication patterns (Renz et al. 2018). It is undertaken in a systematic and replicable manner, from which it is possible to make valid inferences on a set of verbal, visual, or written data (Downe-Wamboldt 1992). Using Content Analysis, researchers can quantify and analyze the presence, meanings, and relationships of such certain words, themes, concepts, or constructs (Holdford 2008). The beginning of the use of Content Analysis is somewhat controversial. The research carried out by Bardin (1993) indicates the ﬁrst application dating back to mid-1915, while other studies, such as Stepchenkova et al. (2009) and Renz et al. (2018), point out the beginning in the 1920s and 1940s respectively. From the method- ological perspective, between the 1940s and 1950s, Content Analysis was simply resumed to a technique intended to systematically and quantitatively describe the content of communication (Berelson 1952). Later, between 1950 and 1960, its scope was broadened from the words counting (e.g., frequency) to the analysis of semantic relationships among them (De Sola Pool 1959). Regarding the nature of the analysis, there is an increasing tendency to classify Content Analysis in either quantitative or qualitative (Pashakhanlou 2017). The quan- titative analysis consists of statistical techniques for making inferences on the data (De Sola Pool 1959). The qualitative analysis, in turn, stands for non-statistical and exploratory techniques intended to obtain meaning from data (Stepchenkova et al. 2009). In Quantitative Content Analysis, the communication is decomposed into parts and then quantiﬁed through enumeration rules (Rourke and Anderson 2004). However, solely enumerating, or even establishing the correlation among the parts, might lead to meaningless results (Downe-Wamboldt 1992). That is because the correlation does not necessarily mean causality, and data without a context is not information (Yearworth and White 2013). To overcome these limitations, the Qualitative Content Analysis focuses on the meaning and relationship of the decomposed parts, emphasizing its similarities, dissimilarities, and complementarities (Graneheim and Lundman 2004). The object of analysis here is all types of recorded communication such as interviews, speeches, observation protocols, videos, and documents (Mayring 2000). The Qualitative Content Analysis requires an analytical process of deriving mean- ings (Hsieh and Shannon 2005). Since multiple meanings can be derived from the 4.4 Content Analysis 51 communication, the researcher needs to organize, compare, and validate the inter- pretation of data to ensure the research’s reliability (Defranco and Laplante 2017). Moreover, given the criticism on the understanding of the rationale underlying the qualitative research, it is quite important to explicit how and why the decisions were made as well as introducing reliability assessment in different stages of the research whenever possible (Graneheim et al. 2017). When comparing both, the qualitative approach presents better results with a reduced corpus of analysis, while the quantitative one performs better when applied in a larger corpus (Bardin 1993). Regardless of the approach used, either quantitative, qualitative, or mixed, the Content Analysis should be able to identify communica- tion patterns in a systematic and replicable manner. Moreover, by minimizing the reliability-related issues, it should allow theoretically useful generalizations, with minimal loss of information from the original data (Downe-Wamboldt 1992). Some methods for conducting Content Analysis have been developed over the years, however, the most established one is the three-stage method proposed by Bardin (1993) as presented in Fig. 4.13. The ﬁrst stage, Pre-analysis, consists of an organizing phase wherein the corpus of analysis (set of documents to be analyzed), the review of the study’s hypothesis and goals, and the deﬁnition of indicators are undertaken (Bardin 1993). Although executed in the opposite order, the ﬁrst two steps of Pre-analysis overlap the scope of SLR, as presented in Chap. 3. Concerning the indicators, they refer to dimensions of • Submitting data to statistical operations; • Inferring information from the data; • Interpreting the data according to the pre-defined hypotheses and goals; • Identifying new theoretical dimensions, if any. • Encoding the raw data; • Understanding the content. • Selecting documents to be analyzed; • Reviewing the study’s hypotheses and goals; • Defining indicators. Pre-analysis Exploration of the material Treatment and interpretation of the results obtained Fig. 4.13 Method for conducting Content Analysis. Source Created by authors based on Bardin (1993) 52 4 Literature Analysis performance against which the content will be analyzed. For example, if it is assumed that a concept is more important the more it appears, the corresponding indicator could be the frequency, whether absolute or relative or even weighted or not. The most common indicators used are the presence, frequency, intensity, distribution, and association, and their deﬁnition directly inﬂuences the enumeration rules to be employed in the analysis (Bardin 1993). The second stage refers to the Exploration of material, and it involves the process by which the raw data is systematically transformed into codes and then aggregated to categories, named encoding (Graneheim et al. 2017). Codes are the logical units that provide an accurate description of the relevant characteristics of the content (Hsieh and Shannon 2005). They are assigned to the material through the registration units, which consist of fractions of communication wherefrom it is possible to drive meaning (e.g., word or phrase). The meaning depends on the context, therefore, every registration unit must be associated with a comprehension boundary, i.e., context unit (Bardin 1993). The codes might be of two types, categorical and open. While the categorical codes are deﬁned a priori, the open codes emerge during the in-depth analysis of material (Dresch et al. 2015). Regarding the categories, they consist of group of codes sharing common characteristics. The criteria for grouping codes into categories might be semantic, synthetic, lexical, or expressive (Bardin 1993). As well as the codes, the categories might be deﬁned a priori or during the exploration of the material (a posteriori). In aggregative reviews, where the goal is to test hypotheses, the key concepts are already known, therefore the codes and/or categories might be deﬁned a priori. In conﬁgurative reviews, where the purpose is to generate or explore theories, most codes and/or categories emerge during the exploration (Gough et al. 2012). Figure 4.14 illustrates the relationship among the elements aforementioned. Document Context unit Category 2 Category 1 Context unit Code 1.2 Code 2.1 Theoretical Background Conceptual framework Registration unit Corpus of analysis Code 1.1 Registration unit Registration unit Code 2.n A priori categories A posteriori categoriesCategorical codes Open codes Fig. 4.14 Relationship among some encoding elements. Source Created by authors 4.4 Content Analysis 53 Table 4.6 Enumeration rules Rule Deﬁnition Occurrence (or absence) It has to do with the existence, or non-existence, of a code/category Absolut frequency It refers to the number of times a code/category appears Relative frequency It consists of the number of times a code/category appears divided by the total amount of appearances Absolute weighted frequency It refers to the number of times a code/category appears, moderated by its importance or weight Relative weighted frequency It consists of the number of times a code/category appears divided by the total amount of appearances, moderated its importance or weight Direction It has to do with the orientation of a code/category on a bipolar scale (e.g., negative, neutral, or positive) Order It refers to the order that a code appears Co-occurrence It consists of the simultaneous occurrence of two or more codes/categories Source Created by authors based on Bardin (1993) Another important constituent composing the encoding process are the enumer- ation rules, which consist of a set of mathematical procedures for quantifying the codes and categories. Table 4.6 presents the main enumeration rules proposed by Bardin (1993). Finally, the last stage consists of the Treatment and Interpretation of the Obtained Results. In this stage, simple statistical operations (e.g., percentages), or more complex procedures (e.g., factorial analysis), allow the establishment of results tables, diagrams, ﬁgures, and models, which condense and highlight the informa- tion provided by the analysis (Bardin 1993). With the advance of artiﬁcial intelli- gence, more recent applications have employed machine learning techniques for that purpose (e.g., association rules) (Gauss et al. 2021). Besides that, when the objec- tive is to depict the causal relationship among the codes and/or categories analyzed, more quantitative techniques such as nomological networks, functional models, and causal-loop diagrams are also used (Yearworth and White 2013). The Content Analysis can be performed manually, or computer-assisted. When assisted by a computer, more speciﬁcally by qualitative data analysis software (QDAS), the process becomes more objective, reliable, and replicable. The usage of QDAS does not substitute the researchers’ intelligence, on contrary, it should only be considered as an extension of their memory as well as means to enhance their organization capacity (Pashakhanlou 2017). Table 4.8 presents the most common QDAS. 54 4 Literature Analysis Table 4.8 QDAS for Content Analysis Software Description Observations NVivo It helps users organize and analyze non-numerical or unstructured data. The software allows users to classify, sort, and arrange information; examine relationships in the data; and combine analysis with linking, shaping, searching, and modeling – Commercial software – Website: www.qsrinternational.com/ nvivo ATLAS.ti It is a workbench for qualitative analysis of large bodies of textual, graphical, audio, and video data – Commercial software – Website: https://atlasti.com QDA Miner It is a qualitative data analysis software for organizing, coding, annotating, retrieving, and analyzing collections of documents, and images – Commercial software – Website: https://provalisresearch.com/ products/qualitative-data-analysis-sof tware Quirkos It is a software package for qualitative analysis of text data, commonly used in social science. It provides a graphical interface in which the nodes or themes of analysis are represented by bubbles – Commercial software – Website: https://www.quirkos.com MAXQDA It is a software package for qualitative and mixed methods research. Analyze all kinds of data—from texts to images and audio/video ﬁles, websites, tweets, focus group discussions, and survey responses – Commercial software – Website: https://www.maxqda.com/ Dedoose It consists of a cross-platform app for analyzing qualitative and mixed methods research with text, photos, audio, videos, and spreadsheet data – Commercial software – Website: https://www.dedoose.com webQDA It is a qualitative, web-based data analysis software intended for conducting qualitative research. It allows you to analyze text, image, video, audio, tables, PDF ﬁles, Youtube videos, etc. in a collaborative, synchronous, or asynchronous manner – Commercial software – Website: https://www.webqda.net QCAmap It consists of an open access web application for systematic text analysis in scientiﬁc projects based on the techniques of qualitative content analysis –Free software – Website: https://www.qcamap.org/ Iramuteq It consists of an R (programming language) interface for multidimensional text and questionnaire analysis –Free software – Website: http://www.iramuteq.org/ Source Created by authors 4.5 Closing Remarks 55 4.5 Closing Remarks This chapter presented the concept of the Literature Analysis as well as the prominent techniques adopted to perform it. For each technique (Scientometrics, Bibliomet- rics, and Content Analysis), its main procedures and constituents were discussed, in addition to highlighting the main tools used in its operation. References Acedo, F.J., et al.: Co-authorship in management and organizational studies: an empirical and network analysis. J. Manag. Stud. 43(50), 957–983 (2006) Aria, M., Cuccurullo, C.: Bibliometrix: an R-tool for comprehensive science mapping analysis. J. Inform. 11(4), 959–975 (2017) Bardin, L.: L’analyse de contenu [Content Analysis], p. 223. Presses Universitaires de France Le Psychologue, Paris (1993) Bellis, N.D.: Bibliometrics and Citation Analysis, 1st ed. The Scarecrow Press, Lanham (2009). ISBN 978-0-8108-6714-7 Bensman, S.J.: Garﬁeld and the impact factor. Annu. Rev. Inf. Sci. Technol. 41(1), 93–155 (2007) Berelson, B.: Content Analysis in Communication Research, vol. 1, no. 1, pp. 197–198. The Free Press, Glencoe III (1952) Bergstrom, C., West, J.: Eigenfactor® (2017) Bornmann, L., Marx, W.: Methods for the generation of normalized citation impact scores in bibliometrics: which method best reﬂects the judgements of experts? J. Inform. 9(2), 408–418 (2015) Bradford, S.C.: Sources of information on speciﬁc subjects. Eng. Illus. Wkl. J. 137(3550), 85–86 (1934) Broadus, R.N.: Early approaches to bibliometrics. J. Am. Soc. Inf. Sci. 38(2), 127–129 (1987a) Broadus, R.N.: Toward a deﬁnition of “bibliometrics.” Scientometrics 12(5–6), 373–379 (1987b) Callon, M., et al.: From translations to problematic networks: an introduction to co-word analysis. Soc. Sci. Inf. 22(2), 191–235 (1983) Cobo, M.J., et al.: An approach for detecting, quantifying, and visualizing the evolution of a research ﬁeld: a practical application to the fuzzy sets theory ﬁeld. J. Inform. 5(1), 146–166 (2011a) Cobo, M.J., et al.: Science mapping software tools: review, analysis, and cooperative study among tools. J. Am. Soc. Inf. Sci. 62(7), 1382–1402 (2011b) De Sola Pool, I.: Trends in Content Analysis, 1st edn., p. 244. University of Illinois Press, Champaign (1959) De Solla Price, D.J., Beaver, D.: Collaboration in an invisible college. Am. Psychol. 21(11), 1011– 1018 (1966) Deb, D., Dey, R., Balas, V.E.: Bibliometrics and research quality. In: Engineering Research Method- ology. Intelligent Systems Reference Library, 1st edn., vol. 153, pp. 95–105. Springer Nature, Singapore (2019). ISBN 978-981-13-2947-0 Defranco, J.F., Laplante, P.A.: A content analysis process for qualitative software engineering research. Innov. Syst. Softw. Eng. 13(2–3), 129–141 (2017) Downe-Wamboldt, B.: Content analysis: method, applications, and issues. Health Care Women Int. 13(3), 313–321 (1992) Dresch, A., Lacerda, D.P., Antunes Jr., J.A.V.: Design Science Research, 161 pp. Springer (2015). ISBN 978-3-319-07373-6 FAPESP: Science, Technology & Innovation Indicators in the State of São Paulo. Fundação de Amparo a Pesquisa do Estado de São Paulo, São Paulo (2010) 56 4 Literature Analysis Garﬁeld, E.: Is citation analysis a legitimate evaluation tool? Scientometrics 1(4), 359–375 (1979) Gauss, L., Lacerda, D.P., Cauchick Miguel, P.A.: Module-based product family design: systematic literature review and meta-synthesis. J. Intell. Manuf. 32(1), 265–312 (2021) Glänzel, W., Schoepﬂin, U.: Little scientometrics, big scientometrics … and beyond? Scientometrics 30(2–3), 375–384 (1994) González-Pereira, B., Guerrero-Bote, V.P., Moya-Anegón, F.: A new approach to the metric of journals scientiﬁc prestige: the SJR indicator. J. Inform. 4(3), 379–391 (2010) Gough, D., Oliver, S., Thomas, J.: An introduction to systematic reviews, 1st edn., 288 pp. SAGE Publications, Los Angeles (2012). ISBN 9781849201803 Graneheim, Lindgren, B.-M., Lundman, B.: Methodological challenges in qualitative content analysis: a discussion paper. Nurse Educ. Today 56(May), 29–34 (2017) Graneheim, U.H., Lundman, B.: Qualitative content analysis in nursing research: concepts, procedures and measures to achieve trustworthiness. Nurse Educ. Today 24(2), 105–112 (2004) Gutiérrez-Salcedo, M., et al.: Some bibliometric procedures for analyzing and evaluating research ﬁelds. Appl. Intell. 48(5), 1275–1287 (2017) Haddow, G.: Bibliometric research. In: Research Methods: Information, Systems, and Contexts, 2nd edn., pp. 241–266. Chandos Publishing, Cambridge (2018). ISBN 978-0-08-102220-7 Hart, C.: Doing a Literature Review: Realising the Social Science Research Imagination, 1st edn., p. 230. SAGE Publications, London (1998) He, Q.: Knowledge discovery through co-word analysis. Libr. Trends 48(1), 133–159 (1999) Hirsch, J.E.: An index to Quantify an Individual’s Scientiﬁc Research Output, pp.16569–16572. National Academy of Sciences, Saint Louis (2005) Holdford, D.: Content analysis methods for conducting research in social and administrative pharmacy. Res. Soc. Adm. Pharm. 4(2), 173–181 (2008) Hood, W.W., Wilson, C.S.: The literature of bibliometrics, scientometrics, and informetrics. Scientometrics 52(2), 291–314 (2001) Hsieh, H.F., Shannon, S.E.: Three approaches to qualitative content analysis. Qual. Health Res. 15(9), 1277–1288, (2005) Karanatsiou, D., Misirlis, N., Vlachopoulou, M.: Bibliometrics and altmetrics literature review: performance indicators and comparison analysis. Perform. Meas. Metr. 18(1), 16–27 (2017) Kessler, M.M.: Bibliographic coupling between scientiﬁc articles. Am. Doc. 24(1), 123–131 (1963) Lotka, A.J.: The frequency distribution of scientiﬁc productivity. J. Wash. Acad. Sci. 16(12), 317– 323 (1926) Lu, K., Wolfram, D.: Measuring author research relatedness: a comparison of word-based, topic- based, and author cocitation approaches. J. Am. Soc. Inf. Sci. Technol. 63(10), 1973–1986 (2012) Lucio-Arias, D., Leydesdorff, L.: Main-path analysis and path-dependent transitions in HistCiteTM- based historiograms. J. Am. Soc. Inf. Sci. Technol. 59(12), 1948–1962 (2008) Mayring, P.: The qualitative content analysis process. Forum: Qual. Soc. Res. (FQS) 1(2), Art. 20 (2000). ISBN 9789144001555 Mcgrath, W.: What Bibliometricians, Scientometricians and Informetricians Study; a Typology for Deﬁnition and Classiﬁcation; Topics for Discussion. The University of Western Ontario, London (1989) Mering, M.: Bibliometrics: understanding author, article and journal-level metrics. J. Ser. Rev. 43(1), 41–45 (2017) Oliveira, O.J.D., et al.: Bibliometric Method for Mapping the State-of-the-Art and Identifying Research Gaps and Trends in Literature: An Essential Instrument to Support the Development of Scientiﬁc Projects, p. 20. IntechOpen (2019) Osareh, F.: Bibliometrics, citation analysis and co-citation analysis: a review of literature I. Libri 46(1), 149–158 (1996) Pashakhanlou, A.H.: Fully integrated content analysis in international relations. Int. Relat. 31(4), 1–19 (2017) Peters, H.P.F., Van Raan, A.F.J.: Structuring scientiﬁc activities by co-author analysis. Scientomet- rics 20(1), 235–255 (1991) References 57 Pritchard, A.: Journal of documentation. J. Doc. 25(4), 348–349 (1969) Qiu, J., et al.: Informetrics: Theory, Methods and Applications, pp. 1–438 (2017). ISBN 9789811040320 Renz, S.M., Carrington, J.M., Badger, T.A.: Two strategies for qualitative content analysis: an intramethod approach to triangulation. Qual. Health Res. 28(5), 1–8 (2018) Rourke, L., Anderson, T.: Validity in quantitative content analysis. Educ. Technol. Res. Dev. 52(1), 5–18 (2004) Scopus: Scopus Database (2020) Sengupta, I.N.: Bibliometrics, informetrics, scientometrics and librametrics: an overview. Libri 42(2), 75–98 (1992) Siluo, Y., Qingli, Y.: Are Scientometrics, Informetrics, and Bibliometrics Different?, pp. 1–12 Wuhan (2017) Small, H.: Co-citation in the scientiﬁc literature: a new measure of the relationship between two documents. J. Am. Soc. Inf. Sci. 24(4), 265–269 (1973) Stepchenkova, S., Kirilenko, A.P., Morrison, A.M.: Facilitating content analysis in tourism research. J. Travel Res. 47(4), 454–469 (2009). ISBN 9781446246900 Terms, The OECD—Glossary of Statistical. The OECD—Glossary of Statistical Terms (2013) Thelwall, M.: Bibliometrics to webometrics. J. Inf. Sci. 34(4), 605–621 (2008) Thomé, A.M.T., Scavarda, L.F., Scavarda, A.J.: Conducting systematic literature review in operations management. Product. Plan. Control 27(5), 408–420 (2016) Todeschini, R., Baccini, A.: Handbook of Bibliometric Indicators, 1st edn., 405 pp. Wiley-VCH, Weinheim (2016) Üsdiken, B., Pasadeos, Y.: Organizational analysis in north America and Europe: a comparison of co-citation networks. Org. Stud. 16(3), 503–526 (1995) Van Eck, N.J., Waltman, L.: Visualizing bibliometric networks. In: Measuring Scholarly Impact: Methods and Practice, 1st edn., pp. 285–320. Springer International Publishing, Basel (2014). ISBN 9783319103778 Van Raan, A.F.J.: Advanced bibliometric methods as quantitative core of peer review based evaluation and foresight exercises. Scientometrics 36(3), 397–420 (1996) Van Raan, A.: Advanced bibliometric methods for the evaluation of universities. Scientometrics 45(3), 417–423 (1999) Vinkler, P.: The Evaluation of Research by Scientometric Indicators, 1st edn., 313 pp. Chandos Publishing, Oxford (2010). ISBN 978-1-84334-572-5 Yearworth, M., White, L.: The uses of qualitative data in multimethodology: developing causal loop diagrams during the coding process. Eur. J. Oper. Res. 231(1), 151–161 (2013). Disponível em: https://doi.org/10.1016/j.ejor.2013.05.002 Zijlstra, H., Mccullough, R.: CiteScore: A New Metric to Help You Track Journal Performance and Make Decisions (2016) Zipf, G.K.: Human Behavior and the Principle of Least Effort, 1st edn., p. 585. Addison-Wesley Press, Cambridge (1949) Zupic, I., ˇCater, T.: Bibliometric methods in management and organization. Org. Res. Methods 18(3), 429–472 (2015) Chapter 5 Literature Synthesis This chapter addresses the concept of Literature Synthesis and classiﬁes it as Conﬁg- urative and Aggregative based upon the research approach and objectives. For each type of synthesis, its main characteristics, techniques, and applications are pointed out. 5.1 Literature Synthesis As seen in Chap. 3, a common step in Systematic Literature Review (SLR) is the Literature Synthesis (Lau et al. 1997). It combines the effects of multiple primary studies to provide new knowledge on a subject, which is not possible to obtain by evaluating the studies independently (Morandi and Camargo 2015). In other words, the Synthesis is not a simple summary of results, on the opposite, it consists of an interpretation and reﬂection of research outcomes in the view of a theoretical framework (Thomas et al. 2012). When conducted rigorously, it is not only possible to identify the shortcomings of a particular theory, but also to enhance the articulation of its constructs and propositions as well as to broaden its boundaries (Straus et al. 2016). The Literature Synthesis can be carried out in either qualitative or quantitative research (Koricheva and Gurevitch 2013). Therefore, the dissimilarities between them are fundamental for selecting the most suitable synthesis technique (Morandi and Camargo 2015). In this sense, Table 5.1 provides a comparison between both qualitative and quantitative research approaches in ﬁve different dimensions (Saini and Shlonsky 2012). The original version of this chapter was revised: Figure 5.1 was moved to section 5.2.9. The correction to this chapter can be found at https://doi.org/10.1007/978-3-030-75722-9_10 © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_5 59 60 5 Literature Synthesis Table 5.1 Comparison between qualitative and quantitative research approaches Dimensions Qualitative research Quantitative research Assumptions – Reality is socially constructed – Variables are complex, interwoven, and difﬁcult to measure – Emic (insider’s point of view) – Ideographic (unique elements of the individual phenomenon) – Social facts have an objective reality – Variables can be identiﬁed, and relationships measured – Etic (outsider’s point of view) – Nomothetic (search for universal laws) Epistemological – Interpretivism – Post-positivism Purpose – Process-oriented – Contextualization (transferability) – Interpretation – Understanding perspectives – Outcome-oriented – Generalizability – Prediction – Causal explanation Process – Ends with hypothesis, theories (inductive) – Emergent design – Researcher as instrument – Naturalistic – Patterns, theories developed for understanding – Few cases, participants – Thematic, discourse analyses – Descriptive write-up – Begin with hypothesis, theories (deductive) – Manipulation and control – Use formal instruments – Experimentation – Generalization leading to prediction and explanation – Many cases, subjects – Statistical analyses – Abstract language in write-up Researcher’s role – Personal involvement and partiality – Subjective insider – Detachment and impartiality – Objective outsider Source Saini and Shlonsky (2012) As well as for the research approach, the Literature Synthesis can be classiﬁed into two types (Thomas et al. 2012): (i) Conﬁgurative; and (ii) Aggregative. This classiﬁcation not only relates to the research approach but also the objective of the work being conducted. For example, for qualitative research aiming at building or exploring theories, the Conﬁgurative Synthesis is the most appropriate, while for quantitative research seeking to test hypotheses or theories, the Aggregative Synthesis presents itself as the best option (Thomas et al. 2012). The following subsections provide further details on the main characteristics, techniques, and applications of each synthesis type. 5.2 Conﬁgurative Synthesis As previously mentioned, the Conﬁgurative Synthesis is normally employed in qual- itative research where the objective is to generate or explore theories. To this end, several techniques have been developed as presented in Table 5.2. This table, by 5.2 Conﬁgurative Synthesis 61Table5.2FrameworkforselectingthesynthesistechniqueObjectiveSynthesistechniqueOutputsApplicabilityTogenerateorreﬁneatheoryorhypothesis–CriticalInterpretiveSynthesis–Synthesizingargumentortheoreticalproposal–Comprehensivecriticalnarrativegroundedinthedata–Findingscaninformnewtypologiesconcepts,models,ortheorybutitmayrequireafurtherprocessofinterpretationbypolicymakersandpractitionerstoinformpractice–Integrativereview–Rich,contextualdata–Resultscapturethedepthandbreadthofthetopicandcontributetoanewunderstandingofthephenomenonunderinvestigation–Findingshavedirectapplicabilitytopracticeandpolicy–Narrativesynthesis–Amosaicormapderivedfromdescriptivedataandexemplarsfromstudies–Drawsoutcentraltheoriesorcasualmechanismsandbuildsanexplanationbytellingthestoryoftheﬁeldofinquiry–Canproduceoutputsthatmoreeasilytranslatemessagesandmoreapplicabletopolicymakersanddesignersofinterventions–Realistreview–Hypothesesandexplanationsaboutwhatworksforwhomdependingonthecontextandwhy–Theory-drivenevaluations/assessments–RelevantforevaluatingorassessingpublichealthinterventionsandprogramsToexploreexperiences,perceptions,preferences,beliefs,andvalues–Meta-ethnography–Newtheoryorlineofargument–Richcontextualdata–Findingscanbecomplexandconceptual,requiringafurtherprocessofinterpretationbypolicymakersandpractitionerstoinformpractice(continued) 62 5 Literature SynthesisTable5.2(continued)ObjectiveSynthesistechniqueOutputsApplicability–Meta-interpretation–Newinsightsthatarenotobservedinoriginalstudies–Broaderunderstandingoftheprocessanddynamicsofhumanbehaviorandexperienceinaparticularresearcharea–Thesynthesiswillcontain“atruth”ratherthan“theTruth,”andthuswillresultina“truthoftruths”–Caninformpublichealthdecisions–Thevalueofﬁndingscanbedeterminedbytheextenttowhichitprovidesatotaleffectthatisgreaterthanthesumofitsparts–Meta-summary–Quantitativelyorientedsummaryofqualitativeﬁndings—synthesizedstatementsthatarepracticalandusable–Findingscanbeusedtodevelopamapofqualitativestudies,whichcanserveasabasisforafurthersynthesis–Canhelpclinicianstoevaluatetheutilityofsynthesisresultsforpractice–Canhelpresearchersrecognizethetheoreticalandmethodologicaltrendsthathaveshapedthestudy–Usefulfortheposterioranalysesofreports–Meta-study–Anewinterpretation–Derivesquestionsfromeachofitscomponentsandinductivelygeneratesmanytheoreticalclaimsrelatedtoit–Revealssimilaritiesanddiscrepanciesamongaccountsofaphenomenon–Derivesamiddle-rangetheory–Themiddle-rangetheoryhasdirectapplicationsforparticulardeﬁnedareasofpractice–Canbecomplexandconceptual,requiringafurtherprocessofinterpretationbypolicymakersandpractitionerstoinformpractice(continued) 5.2 Conﬁgurative Synthesis 63Table5.2(continued)ObjectiveSynthesistechniqueOutputsApplicability–Meta-synthesis–Anexplanatorytheoryormodeltoexplainﬁndingsofsimilarqualitativestudies–Interpretativethemesandkeymetaphors–Richcontextualdata–Canbeusedtoinformpolicyorclinicaldecisions–Potentialtoenrichunderstandingofcomplex,multi-facetedhealthexperiencesandenvironments–Mixedstudiesreview–Rich,highlypracticalunderstandingofcomplexpublichealthinterventionsandprograms–Recommendsthattheconclusionsreﬂecttheexperiencesofthetargetgroupsforintervention–Relevantforpublichealth–Itcanprovidearichandhighlypracticalunderstandingofcomplexpublichealthinterventionsandprogramsandhighlycontext-sensitiveinterventionsToidentifygapsintheliteratureortheneedforfutureresearch–Integrativereview–Richcontextualdata–Resultscapturethedepthandbreadthofthetopicandcontributetoanewunderstandingofthephenomenonunderinvestigation–Findingshavedirectapplicabilitytopracticeandpolicy–Meta-ethnography–Newtheoryorlineofargument–Richcontextualdata–Findingscanbecomplexandconceptual,requiringafurtherprocessofinterpretationbypolicymakersandpractitionerstoinformpractice(continued) 64 5 Literature SynthesisTable5.2(continued)ObjectiveSynthesistechniqueOutputsApplicability–Meta-study–Anewinterpretation–Deriversquestionsfromeachofitscomponentsandinductivelygeneratesmanytheoreticalclaimsrelatedtoit–Revealssimilaritiesanddiscrepanciesamongaccountsofaphenomenon–Derivesamiddle-rangetheory(testabletheory)–Themiddle-rangetheoryhasdirectapplicationsforparticulardeﬁnedareasofpractice–Canbecomplexandconceptual,requiringafurtherprocessofinterpretationbypolicymakersandpractitionerstoinformpractice–Meta-synthesis–Anexplanatorytheoryormodeltoexplainﬁndingsofsimilarqualitativestudies–Interpretativethemesandkeymetaphors–Richcontextualdata–Canbeusedtoinformpolicyorclinicaldecisions–Potentialtoenrichunderstandingofcomplex,multi-facetedhealthexperiencesandenvironments–Realistreview–Hypothesesandexplanationsaboutwhatworksforwhomdependingonthecontextandwhy–Theory-drivenevaluations/assessments–RelevantforevaluatingorassessingpublichealthinterventionsandprogramsToexplorethemethodologicalaspectsofatopicorknowledgesynthesismethod–Meta-narrativereview–Unfoldingstorylinesresultinginmapsofmeta-narrativeswhichcanrevealdimensionsorthemes–Storylineoftheevolutionofconceptsovertime–Theoriestoexplainconﬂictingﬁndings–Caninformcomplexpolicy-makingquestions,butitmayrequireafurtherprocessofinterpretationbypolicymakersandpractitionerstoinformpractice(continued) 5.2 Conﬁgurative Synthesis 65Table5.2(continued)ObjectiveSynthesistechniqueOutputsApplicability–Meta-summary–Quantitativelyorientedsummaryofqualitativeﬁndings—synthesizedstatementsthatarepracticalandusable–Findingscanbeusedtodevelopamapofqualitativestudies,whichcanserveasabasisforafurthersynthesis–Canhelpclinicianstoevaluatetheutilityofsynthesisresultsforpractice–Canhelpresearchersrecognizethetheoreticalandmethodologicaltrendsthathaveshapedthestudy–Usefulfortheposterioranalysesofreports–Mixedstudiesreview–Rich,highlypracticalunderstandingofcomplexpublichealthinterventionsandprograms–Recommendsthattheconclusionsreﬂecttheexperiencesofthetargetgroupsforintervention–Relevantforpublichealth–Itcanprovidearichandhighlypracticalunderstandingofcomplexpublichealthinterventionsandprogramsandhighlycontext-sensitiveinterventions–Narrativesynthesis–Amosaicormapderivedfromdescriptivedataandexemplarsfromstudies–Drawsoutcentraltheoriesorcasualmechanismsandbuildsanexplanationbytellingthestoryoftheﬁeld,orinquiry–Canproduceoutputsthatmoreeasilytranslatemessagesandmoreapplicabletopolicymakersanddesignersofinterventions(continued) 66 5 Literature SynthesisTable5.2(continued)ObjectiveSynthesistechniqueOutputsApplicabilityTodevelopordescribeframeworks,guidelines,models,measures/scales,orprograms–Conceptsynthesis–Asynthesismodeldevelopedfromconceptsthatrepresentorderedinformationaboutattributesofoneormorethingsthatenablesdifferentiationamongthem–Usefulinareaswherethereislittleornoconceptdevelopment,wherethereisconceptdevelopmentbutnorealimpactonthetheoryofpractice–UsefulinareaswhereobservationsofphenomenaareavailablebutnotyetclassiﬁedSourceAdaptedfromKastneretal.(2016) 5.2 Conﬁgurative Synthesis 67 Kastner et al. (2016), consists of a framework that organizes the synthesis tech- niques according to the research objectives. To elaborate the framework, the author analyzed the objective, outputs, and applicability of 121 studies that implemented synthesis techniques in the areas of health, education, sociology, and philosophy. Besides the ﬁve main objectives, the work by Kastner et al. (2016) revealed the most frequently used techniques as being meta-synthesis (25%), meta-ethnography (19%), meta-study (11%), integrated synthesis (10%), and realistic synthesis (8%). The main synthesis techniques presented in Table 5.2, as well as others considered relevant in the context of this book, are presented next. It should be noted that, given their extension, the synthesis techniques may overlap with some SLR steps which have already been addressed in previous chapters. Therefore, the focus of the following subsections is on the product of these techniques, the synthesis itself. 5.2.1 Critical Interpretive Synthesis Critical Interpretive Synthesis aims at building a synthesizing argument that critically integrates the evidence of a large and complex body of literature (Saini and Shlonsky 2012). The synthesizing argument takes the form of a coherent theoretical framework comprising a network of constructs and the relationships between them. A key feature of this process that distinguishes it from other techniques is the aim of being critical. It questioning not only how the literature had constructed the problematics of access, but also the nature of the assumptions on which it drew as well as what has inﬂuenced its choice of proposed solutions (Dixon-Woods et al. 2006). In methodological terms, Critical Interpretive Synthesis does not offer pre-speciﬁed procedures for conducting the review. In this sense, some aspects of the evidence production are not visible or auditable, which ultimately may result in research not strictly reproducible (Dixon- Woods et al. 2006). Although it lacks some methodological procedures, Critical Interpretive Synthesis can be undertaken by four major steps recovered from Meta-Ethnography, as reasoned by Flemming (2009): (1) understanding the primary study itself; (2) trans- lating studies into one another; (3) synthesizing translations; and (4) expressing the synthesis. In the ﬁrst step, the primary study is read to develop an understanding of its position and context before comparing it to others. In the second step, the concepts, themes, and metaphors used by authors are identiﬁed and translated from one study into another to produce a reduced account of the content and context of all studies. The third step, in turn, compares the translations to determine if either the transla- tions and/or some of the concepts can encompass those of other accounts. Finlay, in the last step, the evidence from across studies is integrated into a comprehensible theoretical framework called a Synthesizing Argument. 68 5 Literature Synthesis 5.2.2 Integrative Review Integrative Review aims at mapping knowledge on a given subject and identifying opportunities for future research. It incorporates a wide range of purposes such as to deﬁne concepts, review theories and evidence, as well as to analyze method- ological issues on a particular subject (Hopia et al. 2016). This technique combines different research approaches and makes use of theoretical and empirical literature to conceive multiple perspectives on a given phenomenon (Whittemore and Knaﬂ 2005). Although this combination of approaches makes the technique more ﬂexible, it also raises questions about the rigor of its execution. In this sense, Whittemore and Knaﬂ (2005) improved the technique by including systematic procedures of a quantitative and qualitative nature, which can be summarized in ﬁve steps: (1) identiﬁcation of the problem; (2) bibliographic searching; (3) data evaluation; (4) data analysis; and (5) presentation of results. In the ﬁrst step, the research problem, the variables of interest, as well as the search strategy are deﬁned. In Step 2, the primary studies are searched and those in line with the research scope are selected for inclusion. In Step 3, the quality of the selected studies is assessed and the ones not reaching a predeﬁned threshold are discarded. In Step 4, in turn, the content of primary studies is reduced to codes and organized in categories. Then, the relation- ships between codes/categories are identiﬁed and depicted in the form of a conceptual map. Finally, the codes, categories, and relationships are synthesized and generalized for the set of studies included in the review. In the last step, the conclusions of the review are presented. 5.2.3 Narrative Synthesis Narrative Synthesis is an interpretative technique that aims to describe the similar- ities, dissimilarities, and complementarities among primary studies, as well as to organize them into homogenous groups (Barnett-Page and Thomas 2009). It is espe- cially useful for answering questions such as “why does something need to be done or must be stopped?” or “why does a particular practice have a given effect?”. Although it can manipulate data, the Narrative Synthesis is characterized by telling stories using texts (Popay et al. 2006). In other words, it consists of an orderly narrative summary of the results, which allows the inclusion of comments and interpretation (Cruzes et al. 2015; Saini and Shlonsky 2012). Besides that, Narrative Synthesis can be employed before other techniques, like Meta-Ethnography, to improve their results (Popay et al. 2006). In summary, it is a ﬂexible technique with the ability to handle large and varied evidence bases (Hopia et al. 2016). Regarding the limitations, transparency might be a problem in Narrative Synthesis, since it depends on the researchers’ interpretation and judgment (Lucas et al. 2007). Moreover, as well as other techniques, it does not provide a strict sequence of steps to be followed (Popay et al. 2006). To overcome these limitations, Popay et al. (2006) propose a four-stage process for conducting 5.2 Conﬁgurative Synthesis 69 Narrative Synthesis, as follows: (1) building a theoretical model on the subject; (2) developing a preliminary synthesis; (3) exploring relationships in the data; and (4) assessing the robustness of the synthesis. In the ﬁrst step, a theoretical model, repre- sented in the form of a diagram along with a complementary textual description, is developed. This theoretical model seeks to explain how actions are connected to effects. The authors do not specify whether this model is based on any under- lying theory already formalized or if it is a theoretical proposal by the researcher. However, the following steps of the synthesis make it possible to validate and identify under which conditions the model is valid. In Step 2, the similarities, dissimilarities, and complementarities among the content of primary studies are identiﬁed and then categorized into homogeneous groups (i.e., categories). In Step 3, in turn, the rela- tionships among these groups and the factors limiting or leveraging the success of a given intervention are explained. Finally, in Step 4, the results are critically assessed to enhance quality and minimize bias. 5.2.4 Realist Review Realist Review is an interpretive technique that includes evidence from qualitative and quantitative research, in speciﬁc contexts and settings (Saini and Shlonsky 2012). It seeks to explain why an intervention works, or not, for a speciﬁc case in a particular environment (Kastner et al. 2016). Putting it differently, it aims at answering “what works,” “for whom,” and “under what circumstances.” Realist Review is used to synthesize research with an explanatory and non-critical focus. It includes different formats of evidence and is oriented toward the evaluation of theories (Pawson et al. 2005). While providing reliable information about the theory being evaluated, guid- ance on how to deal with contradictory evidence is lacking, since all evidence is equally considered (Saini and Shlonsky 2012). In methodological terms, Realist Review follows a heterogeneous and iterative process, being less prescriptive than SLR. As posed by Pawson et al. (2005), it consists of a technique composed of ﬁve steps: (1) explain the scope; (2) search for evidence; (3) evaluate primary studies and extract data; (4) synthesize evidence and conclude; and (5) disseminate, implement and evaluate. In the ﬁrst step, the review question is deﬁned. It usually includes the nature, context, and objective of the intervention or policy being analyzed. In this step, the purpose of the review, which might be o three types, is deﬁned: (i) to identify which theories are most appropriate; (ii) to compare how the intervention works in different environments or for different groups; and (iii) to test how the intention of the policy translates into practice. The second step consists of the search and selection of primary studies that provide the necessary evidence to answer the review question. The third step refers to the critical evaluation of primary studies concerning their rigor and relevance. In this step, the extraction and organization of data are also carried out. In the fourth step, the data are synthesized to answer the review question, followed by the conclusions and recommendations made in Step 5. 70 5 Literature Synthesis 5.2.5 Meta-interpretation Meta-interpretation consists of a technique for synthesizing qualitative research, based on interpretation. It presents a synthesis of studies with different points of view, instead of seeking a deﬁnitive answer (Weed 2008). Meta-interpretation presupposes the existence of multiple perspectives and truths. Therefore, instead of providing a deﬁnitive answer, the Meta-interpretation presents several possible answers (Weed 2008). Weed (2008) presents an iterative procedure for performing Meta-Interpretation. Nevertheless, little detail is given for the synthesis stage itself. This procedure can be performed according to the following steps: (1) Identiﬁcation of the research area; (2) Preliminary selection of studies; (3) Thematic and context analysis; (4) Identiﬁcation and generalization of the exclusion criteria; (5) Identi- ﬁcation of emerging concepts; (6) Analysis of theory saturation; and (7) Summary of ﬁndings. The ﬁrst step in meta-interpretation is to identify the research area for the synthesis, rather than a research question. This is due to the iterative, induc- tive nature of the procedure. In the sequence, an initial selection of about four or ﬁve contrasting studies is made, seeking to cover the widest range of aspects. The procedure follows with a thematic and context analysis carried out simultaneously. As studies are analyzed, they can be excluded for several reasons, which should be recorded and generalized as exclusion criteria. Throughout the analysis, conceptual issues are identiﬁed and, as theoretical saturation cannot be achieved in the ﬁrst iteration, further studies should be searched. When analyzing the new studies, the exclusion criteria previously deﬁned must be revisited and revalidated. If it is consid- ered that any criteria are no longer valid, the studies excluded for this reason must be reintegrated into the dataset. New reasons for exclusion identiﬁed must be formal- ized and generalized. This iterative procedure continues as new concepts emerge, ending only when theoretical saturation is reached. At this point, the emerging theo- retical ﬁndings and insights are synthesized. In parallel, the limits of the discoveries are explained, based on a complete review of the exclusion criteria and excluded studies. 5.2.6 Meta-summary Meta-Summary aims at integrating results retrieved from topic/thematic summaries or surveys of data (Sandelowski et al. 2007). To this end, it not only extracts, groups, abstracts, and formats the results, but also calculates the frequency and intensity of effect (Sandelowski et al. 2007). Unlike other synthesis techniques that discard studies containing topics, summaries, or surveys of data, Meta-Summary considers them to generate its ﬁnal product. However, due to the lack of details these types of studies present, the Meta-Summary outcomes does not provide interpretations or explanation on the phenomenon under investigation (Sandelowski et al. 2007). 5.2 Conﬁgurative Synthesis 71 Concerning the methodological aspects, four steps are required to perform a Meta- Summary (Sandelowski and Barroso 2003): (1) extracting relevant statements from independent ﬁndings; (2) reducing the statements into abstract ﬁndings; (3) orga- nizing the abstract ﬁndings into interstudy and intrastudy matrices; and (4) calcu- lating the effect sizes. Step 1 consists of locating and separating the ﬁndings produced in each study report. Findings include the discoveries, conclusions, judgments, or pronouncements about the events, experiences, or cases under investigation, regard- less of the extent of the data transformation involved. Step 2 refers to the thematic grouping of different ﬁndings to avoid redundancies while ensuring that the ﬁndings’ content and meaning were considered. The abstract ﬁndings are then organized into interstudy and intrastudy matrices in Step 3. Interstudy matrices organize reports by the abstracted ﬁndings, while the intrastudy matrices organize the ﬁndings by the reports. Once the abstract ﬁndings are organized, effect sizes can be calculated in Step 4. 5.2.7 Meta-narrative Review Meta-Narrative Review is a technique of systematic review, which aims to address themes that are conceptualized and studied differently by different groups of researchers (Greenhalgh et al. 2004). It is based on the reasoning of “normal science” developed by (Thomas Kuhn 1962)in The Structure of Scientiﬁc Revolutions.This reasoning considers that science, in most cases, is conducted according to a paradigm that is accepted by a group of researchers but not by all. The Meta-Narrative proposes to synthesize primary studies conducted under different paradigms, providing a narra- tive of those that are homogeneous. It moves toward addressing the conﬂicting ﬁnd- ings and explaining them based on the contestation between the different paradigms from which the data were generated (Greenhalgh et al. 2004). Thus, it allows under- standing how knowledge was developed, that is, how previous knowledge impacted the construction of new knowledge (Thomas et al. 2012). From a methodological perspective, Meta-Narrative Review can be undertaken six steps, as pointed out by Greenhalgh et al. (2004): (1) planning; (2) search; (3) mapping; (4) appraisal; (5) synthesis; and (6) recommendations. The ﬁrst step comprises (i) the assembling of a multidisciplinary research team whose background encompasses the relevant research; (ii) the statement of a broad and open research question; and (iii) the contract with funder or client, if applicable. The second step begins with an initial search to map the diversity of perspectives and approaches. For each identiﬁed perspective/approach, the conceptual or empirical papers should be searched by using electronic databases and “snowballing” procedure—citation tracking. Step 3 accounts for the identiﬁcation of each research paradigm concerning (i) the key elements—conceptual, theoretical, methodological, and instrumental; (ii) the key actors and events; and (iii) the prevailing language. Step 4 seeks to evaluate the validity and relevance of each primary study for the review question as well as to extract and organize the key results. Step 5, in turn, (i) comprises the identiﬁcation 72 5 Literature Synthesis of all the key dimensions of the problem that have been researched (i.e., the different paradigms); (ii) provides a narrative with the contribution by each separate research paradigm; and (iii) treats conﬂicting ﬁndings as higher order data, and explain them in terms of contestation among the different paradigms from which the data were generated. According to the intended use of the review, recommendations should be made based on the critical analysis of the synthesis performed in Step 6. 5.2.8 Ecological Triangulation Ecological Triangulation is a synthesis technique that aims at answering questions such as what intervention works for what kinds of outcomes for what kind of persons under what kinds of conditions (Barnett-Page and Thomas 2009). To reach this goal, and based upon the assumption that the relationship between behavior, people, and environment are mutually interdependent, the Ecological Triangulation analyses the phenomenon of interest from different viewpoints (triangulation concept), which require cumulative and multi-faceted evidence (Barnett-Page and Thomas 2009). The use of triangulation is important to increase the reliability (validity) of qualitative research, since it considers multiple points of view. In methodological terms, Ecological Triangulation can be performed by four major steps, which include: (1) searching and selecting primary studies; (2) appraising the quality of primary studies; (3) extracting the data from primary studies; and (4) performing the triangulation analysis. The ﬁrst step comprises the search and selection of primary studies with the potential to answer the review question. The second step seeks to evaluate the quality, in terms of rigor and relevance, of the primary studies. The data extraction step aims to extract from each primary study included in the synthesis the data that answer the following questions: What theoretical framework was used in the study (metatheory)? What methods were used in the study (meta-method)? And what interventions with which people under what conditions produced what results (meta-analysis)? Finally, the last step focus on determining what evidence—theory, method, people, and conditions—supports interventions with positive results. 5.2.9 Grounded Theory Grounded Theory consists of a technique used to generate or discover theory “grounded” in the observed data (Strauss and Corbin 1990). To this end, constant comparative procedures are used throughout the analysis and interpretation processes to ﬁnd emerging concepts in the data and to consider the interconnections among them (Barnett-Page and Thomas 2009). Although Grounded Theory is recognized for its systematic process of abstraction, which transforms content into theory, proce- dures linked to data collection are often criticized for considering open research 5.2 Conﬁgurative Synthesis 73 questions as well as for neglecting the use of theoretical frameworks deﬁned a priori (Hull 2013). Nevertheless, when incorporated into SLR, the Grounded Theory no longer has such limitations. Concerning the methodological aspects, it can be undertaken by three major steps (Strauss and Corbin 1990): (1) data collection; (2) encoding raw data; and (3) theory building. The ﬁrst step consists of collecting data through interviews, direct observa- tions, documental analyzes, or from the combination of these sources (Stern 1980). In the context of this book, the focus is on documental analysis, more speciﬁcally asso- ciated with scientiﬁc literature. In the second step, the data is decomposed, clustered, and then associated to build the theory. In this step, three fundamental activities take place (Strauss and Corbin 1990): (i) open coding; (ii) axial coding; and (iii) selective coding. Open coding consists of extracting meaning from the text and encapsu- lating it into codes, as illustrated in Box 5.1. Axial coding, in turn, refers to aggre- gating codes into categories (also referred to as concepts or constructs) using simi- larity/dissimilarity criteria. Finally, selective coding accounts for the identiﬁcation and establishment of the relationship among the categories. Box 5.1 Example of open coding In the book Basics of Qualitative Research: Techniques and Procedures for Developing Grounded Theory, the authors Straus and Corbin (1990) illustrate the process of open coding through an interview conducted with a woman on drug use by adolescents: Interviewer Tell me about teens and drug use Respondent I think teens use drugs as a release from their parents [“rebel- lious act”]. Well, I don’t know. I can only talk for myself. For me, it was an experience [“experience”] [in vivo code]. You hear a lot about drugs [“drug talk”]. You hear they are bad for you [“negative connotation” to the “drug talk”]. There is a lot of them around [“available supply”]. You just get into them because they’re accessible [“easy access”] and because it’s kind of a new thing [“novel experience”]. It’s cool! You know, it’s something that is bad for you, taboo, a “no” [“negative connotation”]. Everyone is against it [“adult negative stance”]. If you are a teenager, the ﬁrst thing you are going to do is try them [“challenge the adult negative stance”] In Step 3, the categories and their relationships are articulated in abstract models that provide a new theoretical understanding of a particular phenomenon (Barry and Roux 2013). Figure 5.1 gives an example of an abstract model (causal-loop diagram) used to describe the role of equity-funded entrepreneurial start-up system in assessing technology development risk and deciding where to allocate capital (Yearworth and White 2013). 74 5 Literature Synthesis Fig. 5.1 Example of an abstract model (causal-loop diagram) for theory building. Source Yearworth and White (2013) 5.2.10 Meta-ethnography Meta-Ethnography aims at building a general interpretation grounded in the ﬁndings of the separate studies (Flemming 2009). To this end, the concepts comprising each primary study are identiﬁed and those that better represent the entire dataset are chosen by constant comparisons between individual accounts (Dixon-Woods et al. 2006). If compared to other synthesis techniques, Meta-Ethnography has a broader scope. However, it lacks clarity and comprehensiveness on the analysis and synthesis procedures, making it difﬁcult to judge their rigor and credibility (France et al. 2014). In methodological terms, Meta-Ethnography is a technique composed of seven steps (Noblit and Hare 1988): (1) getting started; (2) deciding what is relevant to the initial interest; (3) reading the studies; (4) determining how the studies are related; (5) translating the studies into one another; (6) synthesizing translation; and (7) expressing the synthesis. In the ﬁrst step, the core research subject is identiﬁed. Then, in Step 2, the studies are searched for inclusion, and the ones ﬁtting the research scope are read and re-read (Step 3) in order to draw up a list of key concepts. In Step 4, the relationships between the studies are determined, followed by the identiﬁcation of common and disparate concepts both within and across the studies, in Step 5. Finally, in Step 6, the relationships between concepts are established and then expressed, usually by conceptual frameworks, in Step 7. Figure 5.2 gives an 5.2 Conﬁgurative Synthesis 75 Fig. 5.2 Example of a conceptual framework for synthesizing interpretations. Source Monforte- Royo et al. (2012) example of a conceptual framework used to explain the wishing of hastening death in patients with chronic or advanced illness (Monforte-Royo et al. 2012). 5.2.11 Meta-synthesis Meta-Synthesis aims at building an abstract model, capable of explaining or exploring the underlying aspects of a set of independent and heterogeneous studies (Walsh and Downe 2005). To reach this goal, Meta-Synthesis brings together and breaks down ﬁndings, examines them, discovers the essential features, and combines phenomenon into a transformed whole (Saini and Shlonsky 2012). As well as Meta-Ethnography, it presents a comprehensive scope without detailed guidance on the analysis and synthesis procedures. From a methodological perspective, Meta-Synthesis can be undertaken by six steps, as reasoned by (Walsh and Downe 2005): (1) framing a meta-synthesis exer- cise; (2) locate relevant studies; (3) deciding what to include; (4) appraisal of studies; (5) analytic technique; and (6) synthesis of translations. In Step 1, an appropriate research question, purpose, or aim is framed. In Step 2, the location of relevant studies to compose the Meta-Synthesis is carried out. Among those potentially rele- vant studies, the ones in compliance with the research scope are selected for inclusion in Step 3. Then, in Step 4, the rigor of each study is assessed. In Step 5, it is determined how the studies are related, or dissonant, through a compare and contrast exercise. 76 5 Literature Synthesis Fig. 5.3 Example of a functional model for synthesizing translations. Source Gauss et al. (2021) In practical terms, this exercise starts by reading the studies and ﬁnishes with the creation of a grid of key concepts. These ﬁndings are then juxtaposed to both identify homogeneity of categories/codes/themes and note the discordance and dissonance among them (Walsh and Downe 2005). Afterward, the translation of one study’s ﬁndings into another is undertaking. Finally, in Step 6, the translations are synthe- sized to elucidate more reﬁned meanings, exploratory theories, and new concepts. In practical terms, the outcomes of a Meta-Synthesis are represented by network-based models or frameworks, along with their summary description, as shown in Fig. 5.3. This ﬁgure depicts a functional model used to connect 72 methods to design modular product families into a meta-method (Gauss et al. 2021). 5.2.12 Framework Synthesis Framework Synthesis is a technique for synthesizing qualitative data, which presup- poses the building of comprehensive conceptual models/frameworks on a given subject from the “best-ﬁt” models/frameworks available in the literature. In this sense, based on a model/framework that does not entirely match the subject under investigation, but which is the “best-ﬁt” model/framework available in the litera- ture so far, new evidence is collected and then analyzed to transform the “best-ﬁt” model/framework into a new and broader explanatory model/framework (Gough 5.2 Conﬁgurative Synthesis 77 Table 5.3 Example of a “best-ﬁt” model Stages Themes Perceived need Decision-making Access Use 1. Family factors affecting the perceived need 2. Personal factors affecting the perceived need 3. Media representations of perceived need 4. Spending capacity 5. Media input into decision-making 6. Physicians input into decision-making 7. Family members input into decision-making 8. Community input into decision-making 9. Pharmacy input into decision-making 10. Access: obtaining micro-nutrients 11. Perceived beneﬁts 12. Perceived risks (negative factors) 13. Habitual use 14. Intermittent use Source Carroll et al. (2011) et al. 2012). Unlike other techniques that strictly address inductive reasoning, Frame- work Synthesis starts with deductive rationale, by establishing search, eligibility, and analysis criteria based on an existing model/framework, and ends with inductive reasoning, by complementing the original model/framework with new concepts that emerge during the course of the research (Barnett-Page and Thomas 2009). Although the use of conceptual models/frameworks identiﬁed a priori can accelerate the initial stages of synthesis as well as better organize the course of the research, they are not always available in the literature, which can make the use of the technique unfeasible. Another point is that the search for existing conceptual models/frameworks is gener- ally conducted unsystematically, which can lead to the identiﬁcation of “best-ﬁt” models that are in fact not the best or most current ones. Although there is no standard procedure in the literature on how to implement the Framework Synthesis, Carroll et al. (2011) propose a sequence of four steps, which include: (1) identifying a pre-existing conceptual model or framework; (2) searching and selecting relevant studies to compose the synthesis; (3) extracting new concepts and relationships from the selected studies; and (4) building the ﬁnal conceptual model or framework. In Step 1, the search and identiﬁcation of existing models/frameworks in the literature are carried out. This search is usually done unsystematically and uses previous literature reviews or classic books/articles on the subject under investigation as a source. Table 5.3 gives an example of the “best-ﬁt” model used in the work by Carroll et al. (2011), which intended to examine people’s attitudes toward the taking of agents or supplements that may be used in the primary prevention of colorectal cancer. 78 5 Literature Synthesis In Step 2, studies in compliance with the research scope and aligned with the concepts recovered from the “best-ﬁt” model are identiﬁed and selected. This is a step that follows the search and eligibility procedures commonly found in the SLR methods. At the end of this stage, the research corpus is obtained. In Step 3, in turn, the studies are analyzed in-depth, and through the encoding approach used in the Grounded Theory, new concepts and their respective relationships are extracted from the full-texts (Thomas et al. 2012). Finally, the concepts and relationships identiﬁed a priori (Step 1), along with those obtained throughout the analysis process (Step 3), are articulated and synthesized in the form of a more comprehensive conceptual model than the one originally identiﬁed (“best-ﬁt” model). Besides the new conceptual model, an explanation describing it is usually employed as the ﬁnal result of the synthesis. Figure 5.4 gives an example of the ﬁnal conceptual model build in the work by Carroll et al. (2011). With the Framework Synthesis, we ﬁnished the presentation of the most used techniques in Conﬁgurative Synthesis. In the next section, the concept of Aggregative Synthesis will be presented, as well as its most used technique. Fig. 5.4 Example of a conceptual model resulting from the framework synthesis. Source Carroll et al. (2011) 5.3 Aggregative Synthesis 79 5.3 Aggregative Synthesis The purpose of Aggregative Synthesis is to test hypotheses or theories. Although it is not a rule, the researches following this objective are usually of a quantitative nature, since testing hypothesis require variables that can be measured empirically (Bacharach 1989). Unlike Conﬁgurative Synthesis, which can be undertaken by a multitude of techniques, Aggregative Syntheses are usually performed by the Meta- Analysis, a technique which will be detailed next (Morandi and Camargo 2015). 5.3.1 Meta-analysis Meta-Analysis combines the results of two or more separate studies to synthesize evidence on the effects of interventions (Koricheva and Gurevitch 2013). It is typi- cally a two-stage technique, wherein a summary statistic is calculated for each study, and then, a summary (combined) intervention effect estimate is calculated as a weighted average of the intervention effects estimated in the individual studies (Higgins et al. 2020a). Unlike conﬁgurative synthesis, where the researchers implic- itly assign some level of importance to each study, in Meta-Analysis the weights are assigned based on mathematical criteria speciﬁed in advance, thus resulting in a more objective and replicable framework (Borenstein et al. 2009). Besides that, Meta-Analyses provides an improvement in precision, the ability to answer questions not posed by individual studies, and the opportunity to settle controversies arising from conﬂicting claims. However, they also have the potential to mislead seriously, particularly if speciﬁc study designs, within-study biases, variation across studies, and reporting biases are not carefully considered (Higgins et al. 2020a). These issues might be mitigated whenever conducting Meta-Analysis in conjunction with SLR. In methodological terms, Meta-Analysis can be undertaken by ﬁve major steps, which include: (1) framing the research question; (2) locating and screening studies; (3) data extraction and tabulation; (4) calculating the summary effect estimate; and (5) synthesizing the results. In Step 1, an appropriate research question is framed. This task is usually assisted by PICO logic (Higgins and Green 2011), wherein the ﬁrst letter of the acronym (P) refers to the Population from which the Meta-Analysis is interested to draw conclusions. The second letter (I) has to do with an Intervention taken in an experiment group (sample of population which suffered the intervention) to change it from a current to a future state. The third letter (C), in turn, refers to the control group (sample of population which did not suffer the intervention) against which the experiment group will be Compared to evaluate the effects of the intervention. Finally, the last letter (O) consists of the intervention Outcomes. In Step 2, the location of relevant studies to compose the Meta-Analysis is carried out. Among those potentially relevant studies, the ones ﬁtting the Population, Inter- vention, Comparison, and Outcomes are selected for inclusion. Then, in Step 3, the outcomes extracted from each primary study are tabulated in such a way that they 80 5 Literature Synthesis Experiment Group (Tamiflu) Control Group (Placebo) Id. Study Name Tamiflu Mean Tamiflu Std-Dev Tamiflu Sample Size Placebo Mean Placebo Std-Dev Placebo Sample Size 1 Primary Study 1 140.600 125.200 933 165.500 156.500 473 2 Primary Study 2 129.000 114.600 240 144.500 118.000 235 3 Primary Study 3 102.400 89.900 204 125.300 98.900 200 4 Primary Study 4 154.000 166.500 17 93.600 134.400 9 5 Primary Study 5 107.600 104.600 31 171.000 177.100 27 6 Primary Study 6 193.700 152.300 199 203.900 146.300 202 7 Primary Study 7 185.000 145.600 358 192.400 145.200 375 8 Primary Study 8 138.700 138.400 226 143.700 125.400 225 Fig. 5.5 Effects of Tamiﬂu in the duration of ﬂu symptoms (h). Source Created by authors based on Borenstein (2021) can be compared. This organization is usually undertaken in the form of a table, in which the lines represent the primary studies, and the columns represent the groups and their respective descriptive statistics, as shown by Fig. 5.5. The next issue is to calculate the summary effect estimate in Step 4. This process starts by identifying the type of data associated with the studies composing the research. In Meta-Analysis, the data might be of ﬁve types (Higgins et al. 2020b): (i) dichotomous, or binary data, where each outcome is one of only two possible categorical responses; (ii) continuous data, where each outcome is a measurement of a numerical quantity; (iii) counts and rates calculated from counting the number of events occurred; (iv) time-to-event (typically survival) data that analyze the time until an event occurs, but where not all cases experienced the event (censored data); Finally, (v) ordinal data (including measurement scales), where each outcome is one of several ordered categories, or generated by scoring and summing categorical responses. With the data type identiﬁed, the next task is to deﬁne the measure from which the summary effect estimate will be calculated. Table 5.4 presents the most frequently used effect measures, their deﬁnition, as well as to which data type they are related to. Afterward, a summary intervention effect estimate is calculated as a weighted average of the intervention effects retrieved from individual studies, wherein more weight is assigned to the more precise studies (Borenstein et al. 2009). The combi- nation of intervention effect estimates across studies may optionally incorporate an assumption that the studies are estimating the same effect (ﬁxed-effect) or estimating intervention effects that follow a distribution across studies (random-effect) (Higgins et al. 2020a). 5.3 Aggregative Synthesis 81 Table 5.4 Effect measures Data type Effect measure Deﬁnition Dichotomous Risk ratio The ratio of the risk of an event in the two groups Odds ratio The ratio of the odds of an event Risk difference The difference between the observed risks (proportions of individuals with the outcome of interest) in the two groups Continuous Mean difference The absolute difference between the mean value in the two groups Standardized mean difference The absolute difference between the mean value, measured in different scales, in two groups Ratio of means The relative difference between the mean value in the two groups Counts and rates Count The number of times these events occur Rate The relation between counts to the amount of time during which they could have happened Time-to-event Hazard ratio It describes how many times more (or less) likely a participant is to suffer the event at a particular point in time if they receive the experimental rather than the comparator intervention Ordinal Measurement scale The intangible criteria characterized by categorical measures Source Created by authors based on Higgins et al. (2020b) Finally, in Step 5, the results of Meta-Analyses are usually synthesized using a forest plot, as shown in Fig. 5.6. A forest plot displays effect estimates and conﬁdence intervals for both individual studies and Meta-Analyses. Each study is represented by a block with a horizontal line, wherein the area of the block indicates the weight assigned to the study while the horizontal line depicts its conﬁdence interval (usually with a 95% level of conﬁdence) (Higgins et al. 2020a). The conﬁdence interval depicts the range of intervention effects compatible with the study’s result. If this horizontal line crosses the vertical line of no effect, the null hypothesis of difference in means being equals to zero is rejected. This can also be veriﬁed by the p-values higher than the signiﬁcance level of 5%. The size of the block draws the eye toward the studies with larger weight, which dominate the calculation of the summary result, presented as a diamond at the bottom. The effect measure illustrated in Fig. 5.6 consists of the means difference, however, the reasoning presented above also applies to the other effect measures given in Table 5.4. Although the forest plot provides a graphic representation of the Meta-Analysis, it is usually complemented by a summary description of results. 82 5 Literature Synthesis Id. Study Name Difference in means p-value Difference in means and 95% confidence interval 1 Primary Study 1 -24.900 0.003 2 Primary Study 2 -15.500 0.147 3 Primary Study 3 -22.900 0.015 4 Primary Study 4 60.400 0.317 5 Primary Study 5 -63.400 0.103 6 Primary Study 6 -10.200 0.494 7 Primary Study 7 -7.400 0.491 8 Primary Study 8 -5.000 0.688 Summary result -16.759 0.000 -100.00 -50.00 0.00 50.00 100.00 Favors Tamiflu Favors Placebo Weight Confidence interval Line of no effect Meta-analysis Effect measure Fig. 5.6 Impact of Tamiﬂu on ﬂu symptoms (hours to relief). Source Created by authors based on Borenstein (2021) 5.4 Closing Remarks In this chapter, two types of Literature Synthesis were presented. Conﬁgurative Synthesis, which aims at building and/or exploring theories, and Aggregative Synthesis, which intends to test hypotheses and/or theories. Regarding the ﬁrst, the 12 most used synthesis techniques were presented. Concerning the second, given the limited number of available techniques, only the most relevant one was addressed. In this chapter, the sequence of execution of these techniques was also minimally detailed, and from this, it was possible to identify overlaps and limitations when compared to the stages of Literature Review and Analysis, seen in Chaps. 3 and 4. To integrate these three stages—Literature Review, Analysis, and Synthesis—into a holistic approach for conducting SLR, the next Chap. 6 introduces the method entitled Literature Grounded Theory. References Bacharach, S.B.: Organizational theories: some criteria for evaluation. Acad. Manag. Rev. Manag. 14(4), 496–515. ISSN 1989.03637425 Barnett-Page, E., Thomas, J.: Methods for the synthesis of qualitative research: a critical review. BMC Med. Res. Methodol. 9(1), 1–11 (2009). ISSN 1471-2288 Barry, M., Roux, L.: The case study method in examining land registration usage. Geomatica 67(1), 9–20 (2013) Borenstein, M., et al.: Introduction to Meta-analysis, 421 p. Wiley, Padstow (2009). ISBN 978-0- 470-05724-7 References 83 Borenstein, M.: Impact of Tamiﬂu on ﬂu symptoms. (2021). Disponível em: www.Meta-Analysis. com. Acesso em: 3 fev 2021 Carroll, C., Booth, A., Cooper, K.: A worked example of “best ﬁt” framework synthesis: A systematic review of views concerning the taking of some potential chemopreventive agents. BMC Med. Res. Methodol. 11 (2011) Cruzes, D.S. et al.: Case studies synthesis: a thematic, cross-case, and narrative synthesis worked example. Empir. Softw. Eng. 20(6), 1634–1665 (2015) Dixon-Woods, M., et al.: Conducting a critical interpretive synthesis of the literature on access to healthcare by vulnerable groups. BMC Med. Res. Methodol. 6, 1–13 (2006) Flemming, K.: Synthesis of quantitative and qualitative research: an example using critical interpretive synthesis. J. Adv. Nurs. 66(1), 201–217 (2009) France, E.F. et al.: A methodological systematic review of what’s wrong with meta-ethnography reporting. BMC Med. Res. Methodol. 14(119), 1–16 (2014) Gauss, L., Lacerda, D.P., Cauchick Miguel, P.A.: Module-based product family design: systematic literature review and meta-synthesis. J. Intell. Manuf. 32(1), 265–312 (2021) Gough, D., Oliver, S., Thomas, J.: An Introduction to Systematic Reviews, 1st edn, 288 p. SAGE Publications, Los Angeles (2012). ISBN 9781849201803 Greenhalgh, T., Robert, G., Macfarlane, F., Bate, P., Kyriakidou, O. Diffusion of innovations in service organizations: systematic review and recommendations. The Milbank quarterly, 82(4), 581–629. (2004). https://doi.org/10.1111/j.0887-378X.2004.00325.x Higgins, J., Green, S.: Cochrane Handbook for Systematic Reviews of Interventions. Higgins, J., Li, T., Deeks, J.J.: Analysing Data and Undertaking Meta-analyses. Cochrane Handbook for Systematic Reviews of Interventions Version 6.1. (2020a). Disponível em: https://training. cochrane.org/handbook/current/chapter-10 Higgins, J., Li, T., Deeks, J.J.: Choosing Effect Measures and Computing Estimates of Effect. Cochrane Handbook for Systematic Reviews of Interventions Version 6.1. Cochrane (2020b). Disponível em: www.training.cochrane.org/handbook Hopia, H., Latvala, E., Liimatainen, L.: Reviewing the methodology of an integrative review. Scand. J. Caring Sci. 30(4), 662–669 (2016) Hull, S.: Doing Grounded Theory: Notes for the Aspiring Qualitative Analyst. Division of Geomatics, University of Cape Town (2013) Kastner, M., et al.: Conceptual recommendations for selecting the most appropriate knowledge synthesis method to answer research questions related to complex evidence. J. Clin. Epidemiol. 73(1), 1–21 (2016) Koricheva, J., Gurevitch, J.: Place of Meta-analysis Among Other Methods of Research Synthesis. Handbook of Meta-analysis in Ecology and Evolution, 1st edn, pp. 3–13. Princeton University Press, New Jersey (2013) Lau, J., Ioannidis, J.P.A., Schmid, C.H.: Quantitative synthesis in systematic reviews. Ann. Intern. Med. 127(9), 820–826 (1997) Lucas, P.J., et al.: Worked examples of alternative methods for the synthesis of qualitative and quantitative research in systematic reviews. BMC Medical Research Methodology v. 7 , 2007. Monforte-Royo, C., et al.: What lies behind the wish to hasten death? A systematic review and meta-ethnography from the perspective of patients. PLoS One 7(5) (2012). ISSN 1932-6203 Morandi, M.I.W.M., Camargo, L.F.R.: Systematic Literature Review. Design Science Research: A Method for Science and Technology Advancement, 1st edn, pp. 141–172. Springer International Publishing, New York (2015) Noblit, G.W., Hare, R.D.: Meta-ethnography: Synthesizing Qualitative Studies, 1st edn. SAGE Publications, Newbury Park (1988). ISBN 9780803930230 Pawson, R., et al.: Realist review—a new method of systematic review designed for complex policy interventions. J. Health Serv. Res. Policy 10(SUPPL. 1), 21–34 (2005) Popay, J., et al.: Guidance on the conduct of narrative synthesis in systematic reviews. In: ESRC Methods Programme, 92 p (2006). https://doi.org/10.13140/2.1.1018.4643 84 5 Literature Synthesis Saini, M., Shlonsky, A.: Systematic Synthesis of Qualitative Research, 1st edn, 223 p. Oxford University Press, New York (2012). ISBN 9780195387216 Sandelowski, M., Barroso, J.: Writing the proposal for a qualitative research methodology project. Qual. Health Res 13(6), 781–820 (2003). https://doi.org/10.1177/1049732303013006003 Sandelowski, M., Barroso, J., Voils, C.I.: Using qualitative metasummary to synthesize qualitative and quantitative descriptive ﬁndings. Res. Nurs. Health 30(1), 99–111 (2007) Stern, P.N.: Grounded Theory Methodology: Its Uses and Processes. XII(1), (1980) Straus, S.E., et al.: Introduction: engaging researchers on developing, using, and improving knowl- edge synthesis methods: a series of articles describing the results of a scoping review on emerging knowledge synthesis methods. J. Clin. Epidemiol. 73(1), 15–18 (2016) Strauss A, Corbin J.: Basics of Qualitative Research: Grounded Theory Procedures and Techniques, 2nd edn, 272 p. SAGE Publications, Newbury Park (1990). ISBN 978-1412906449 Thomas, J., Harden, A., Newman, M.: Synthesis: Combining Results Systematically and Appropri- ately. An introduction to Systematic Reviews, 1st edn, p. 288. SAGE Publications, Los Angeles (2012) Thomas, K.: The Structure of Scientiﬁc Revolutions, 264 p. University of Chicago Press, Chicago (1962). ISBN 9780226458113 Walsh, D., Downe, S.: Meta-synthesis method for qualitative research: a literature review. J. Adv. Nurs. 50(2), 204–211 (2005). ISSN 1365-2648 Weed, M.: A potential method for the interpretive synthesis of qualitative research: issues in the development of “meta-interpretation.” Int. J. Soc. Res. Methodol. 11(1), 13–28 (2008) Whittemore, R., Knaﬂ, K.: The integrative review: updated methodology. Methodol. Issues Nurs. Res. 52(5), 546–553 (2005) Yearworth, M., White, L.: The uses of qualitative data in multimethodology: developing causal loop diagrams during the coding process. Eur. J. Oper. Res. 231(1), 151–161 (2013). https://doi.org/ 10.1016/j.ejor.2013.05.002 Chapter 6 Literature Grounded Theory (LGT) This chapter introduces the Literature Grounded Theory (LGT), a research method for reviewing, analyzing, and synthesizing literature. The conceptual framework and organization structure of LGT are presented ﬁrst. Then, by breaking down the structure into steps, the techniques and tools for its implementation are described. Finally, the major guidelines for conducting research with LGT are given. 6.1 Conceptual Framework and Organization Structure The research consists of a systematic investigation intended for developing theories, establishing evidence, and solving problems (Dresch et al. 2015). Based on the presuppose that scientiﬁc and technological knowledge can be derived from the research available in Poppers’ World 3 (Popper 1972), the LGT is introduced as a research method for reviewing, analyzing, and synthesizing literature. This reasoning is illustrated by the four-chunk conceptual framework depicted in Fig. 6.1. The ﬁrst chunk consists of the Poppers’ World 3, wherein the scientiﬁc and technological knowledge exists in the form of artifacts, researches, and problems (Popper 1972). By reviewing all empirical evidence of World 3 in compliance with the research objectives, the knowledge starts being produced in the second chunk. Then, in the third chunk, the empirical evidence is systematically decomposed and analyzed to understand the relationship among the independent parts. Finally, in the last chunk, those parts are reorganized and the relationship among them is synthesized to generate The original version of this chapter was revised: Table 6.28 and Figures 6.2 and 6.5 are updated. The correction to this chapter can be found at https://doi.org/10.1007/978-3-030-75722-9_10 Electronic supplementary material The online version of this chapter (https://doi.org/10.1007/978-3-030-75722-9_6) contains supplementary material, which is available to authorized users. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_6 85 86 6 Literature Grounded Theory (LGT) Fig. 6.1 LGT conceptual framework. Source Created by authors World 3: Scientific and Technological Knowledge Literature Review Literature Analysis Literature Synthesis new and integrative knowledge. In this context, the main outcomes of the LGT include: (i) the identiﬁcation of knowledge evidence; (ii) the review, analysis, and synthesis of empirical and theoretical research, (iii) the theory testing and building; and (iv) the identiﬁcation of future research opportunities. Concerning the organization structure, the LGT is composed of six main stages, as shown in Fig. 6.2: (1) design, (2) review, (3) analysis, (4) syntheses, (5) results, and (6) update. The design consists of deﬁning the review scope and strategy. The review stands for selecting a reliable corpus of analysis following the review scope. The analysis accounts for decomposing the corpus into parts as well as understanding how these parts interact. The synthesis, in turn, has to do with the reorganization of these parts into a new and integrative perspective. The results consist of reporting the ﬁndings, followed by update, which relates to the time interval required for updating 6.1 Conceptual Framework and Organization Structure 87 1.1 Research question formulation 1.2 Definition of review scope and type 1.3 Definition of the research team Research question Review scope and type Conceptual framework Research team 1.5 Formulation of the research protocol Search string and sources Eligibility criteria Protocol Validated protocol 1 Design 2 Review Preliminary corpus of analysis 3.1 Scientometric analysis 3.3 Content analysis Corpus of analysis (full-texts) Corpus of analysis (meta-data) Preliminary corpus of analysis (w/ quartiles) 3 Analysis 4.1 Aggregative synthesis 4.2 Configurative synthesis Codes, categories, and relationships Scientific development indicators 4 Synthesis Performance indicators and networks Comparable outcomes 5.1 Research report formulation Synthesis of the results5 Results 6.1 Research update Research report6 Update Needs for improvement 1.6 Bias assessment Experts’ opinion Needs for improvement Available literature in world 3 (meta-data and full texts)Stakeholders LGT steps Information flow Feedback flow Research question Review scope and type Conceptual framework2.4 Organization of the corpus of analysisDiscarded studies 2.1 Search and eligibility 3.2 Bibliometric analysis Discarded studies 2.2 Quality assessment Discarded studies 2.3 Reliability assessment Table of documents Validated protocol (data analysis) Needs for updating 1.4 Definition of the search strategy Fig. 6.2 LGT organization structure. Source Created by authors the research. There is another element that does not conﬁgure a stage itself, but entities that will be affected by the research results, deﬁned here as stakeholders. Each stage along with its respective steps and technique will be detailed in the following subsections. 88 6 Literature Grounded Theory (LGT) 6.2 Stakeholders People or entities who are either affected or may affect the results of a Systematic Literature Review (SLR) are deﬁned in LGT as stakeholders (Gough et al. 2012). The presence of stakeholders during the SLRs process is extremely important since it increases the probability of the obtained results being useful and relevant (Saini and Shlonsky 2012). Ranging from the research question formulation up to the presenta- tion of the results (Gough et al. 2012), the participation of stakeholders can beneﬁt the working team through its previous knowledge on a given subject or by its experience in conducting SLR (Morandi and Camargo 2015). With that intention, the following questions should be explored (Grimshaw et al. 2004): (i) to whom should research knowledge be transferred? (ii) what should be transferred? (iii) with what effect should research knowledge be transferred? (iv) by whom should research knowl- edge be transferred? (v) how should research knowledge be transferred? Moreover, it is important to describe the involvement of stakeholders as well as they were trained to make decisions throughout the research (Saini and Shlonsky 2012). Box 6.1 gives examples of stakeholders and the type of knowledge that can be embodied within SLR. Box 6.1 Example of Stakeholders • Researchers. • Professors. • Organizations. Types of knowledge embodied by stakeholder within SLR • Organizational knowledge. • Technical or tacit knowledge on a given subject. • Methodological knowledge concerning the conduction of SLR. • Knowledge of laws and standards associated with a given subject. 6.3 Design (Stage 1) The design consists of the starting point of LGT. This is the stage where the planning and review scope are deﬁned. Moreover, it is here that the search strategy, as well as the working team which will lead it, is selected. A set of decisions and rules that, formalized in a review protocol, will guide the research process until the obtention of ﬁnal results. As illustrated in Fig. 6.2, the design stage consists of six steps, which include: (1.1) research question formulation, (1.2) delimitation of review scope and type, (1.3) deﬁnition of the research team, (1.4) deﬁnitions of the search strategy, (1.5) 6.3 Design (Stage 1) 89 formulation of the research protocol, and (1.6) bias assessment. These steps along with their respective techniques and tools will be detailed in the next subsections. 6.3.1 Research Question Formulation (Step 1.1) In most cases, and SLR is not different, the ﬁrst decision to be made concerns the research question formulation (Higgins and Green 2011). Considered as the most important element, the research question guides the decision-making along the entire research process. Nevertheless, its response requires time and resources that are not always available (Counsell 1997). Therefore, it is critical to make sure that the right question is being made (Kitchenham and Charters 2007). To help in that challenge, different techniques might be used. One of them is the Population, Intervention, Comparison, Outcomes, and Context (PICOC). A tech- nique ﬁrst used in health science (Petticrew and Roberts 2006), and then adapted to Software Engineering (Kitchenham and Charters 2007). The transition from a ﬁeld to another might require some adaptations, for that reason, Fig. 6.3,aswellasits following description, presents the PICOC in a more general fashion. The ﬁrst item of PICOC, the Population (P), refers to the population from which the SLR is interested to draw conclusions. It can be a ﬁeld of study, an area, an industry, a sector, a region, a group of individuals, or any other element delimitating the research boundaries. The Intervention (I) has to do with an action taken in the population to change it from a current to a future state. The intervention usually assumes the form of a technology, method, technique, and design proposition, among other entities capable of generating outcomes whenever applied to the population. The Control/Comparison (C), in turn, refers to the entity to which the intervention will be compared. Therefore, as indicated in Fig. 6.3, it usually assumes the same form of intervention to allow comparisons. The use of control is not mandatory, and it depends on the research objective. However, its adoption might increase the conﬁdence that P I C O C Population • Field of study • Area • Industry • Sector • Region • Group of individuals Intervention • Technology • Method • Technique • Design proposition Control/Comparison • Technology • Method • Technique • Design proposition Outcomes • Difference between the current and future state • Characteristics by which the Intervention and Control will be com- pared Context • The circumstances the Intervention was implemented Fig. 6.3 PICOC technique. Source Adapted from Petticrew and Roberts (2006) and Kitchenham and Charters (2007) 90 6 Literature Grounded Theory (LGT) the intervention produced the outcomes. The Outcomes (O) consists of the difference between the current and future state, after the intervention. In the case of comparisons, it can also refer to the speciﬁc characteristics by which the intervention and control will be compared. In more practical terms, it is what should be evaluated. Finally, the Context (C) has to do with the circumstances the Intervention was implemented. Box 6.2 provides an example of PICOC’s application. Box 6.2 PICOC • P: Brazilian bus manufactures; • I: Data Envelopment Analysis (DEA); • C: Stochastic Frontier Analysis (SFA); • O: Similarities and dissimilarities on the modeling approach; • C: Technical efﬁciency of a bus assembly line. Research question • What are the similarities and dissimilarities of the DEA and SFA modeling approach when measuring the technical efﬁciency of a bus assembly line in Brazil? Another technique that can assist the deﬁnition of the research question is Context, Intervention, Mechanism, and Outcomes (CIMO). Proposed by Denyer et al. (2008), the CIMO differs from PICOC by not considering the Population (P) and Control/Comparison (C), as well as by introducing the Mechanism (M), which consists of the mean by which the intervention produces the outcomes. Box 6.3 provides an example of CIMO’s application. Box 6.3 CIMO • C: Conceptual design; • I: Modularity; • M: Product family design methods; • O: Product family structures. Research question • Which methods can be used to conceptually design product family structures through the use of modularity? In both cases (PICOC and CIMO), after ﬁlling the elements of each technique, the research question can be formulated, preferably in one sentence, as follows: 6.3 Design (Stage 1) 91 “Evaluate the [Mechanism(s)] by which the [Intervention] produces the [Outcome(s)] for the problem-in-[Context] when compared with [Control].” The elements and their respective sequence in the sentence may vary from one research to another. Besides that, this structure might be used to formulate more than one question per research, when the objective is to investigate different samples of population or outcomes, for example (Higgins and Green 2011). 6.3.2 Deﬁnition of Review Scope and Type (Step 1.2) Besides the research question, it is important to explicit the reasons why the SLR is being undertaken. These reasons might affect the amplitude and deepness of the review scope as well as the type of review to be performed. The amplitude refers to the extent of the research question or to the number of questions posed in the same research. For example, one study may want to understand the impacts of electric vehicles in cross-industry competition (automotive, energy, mobility, etc.). Another study, in turn, may want to understand these impacts only within the automotive industry, which for sure has a narrow scope if compared to the former one (Gough et al. 2012). Concerning the deepness, it relates to how deep the scope will be explored. The deepness usually affects the stages of review and analysis, and it can take place in different forms. One of them is by restricting the search of primary studies to particular databases, journals, languages, and document types, among other factors. The other way is by limiting the analysis to the metadata instead of deepening into the corpus’ content, for example (Whittemore and Knaﬂ 2005). Ideally, research should be broad and deep; however, it would probably take a long time as well as consume many resources to be done (Morandi and Camargo 2015). Therefore, this decision not only depends on the research objective but is also limited to the time and resources available (Green et al. 2006). Conventionally, but not limited to it, there are two feasible paths as illustrated by the green-ﬁlled area in Fig. 6.4: (i) to obtain a thorough knowledge of a few things or (ii) to obtain a superﬁcial knowledge of many things. In the ﬁrst option, the amplitude and deepness should be narrow and deep, respectively, while in the second case, it should be broad and superﬁcial (Booth et al. 2018). After deﬁning the amplitude and deepness of the review scope, the next issue is to select which type of review will be undertaken. The review might be of two types: (i) aggregative and (ii) conﬁgurative. The aggregative reviews intend to aggregate the results of homogeneous and comparable studies. They follow deductive reasoning and use quantitative procedures to respond to closed questions or test hypotheses empirically (Gough et al. 2012). The conﬁgurative reviews, in turn, aim at conﬁguring or organizing the results of heterogeneous studies. Following inductive reasoning, they use a mix of qualitative and quantitative procedures to respond to open questions or explore and build theories (Sandelowski et al. 2011). It is important to mention that, although presented as different review types, some studies encompass characteristics of both (Morandi and Camargo 2015). 92 6 Literature Grounded Theory (LGT) Thorough knowledge of a few things Thorough knowledge of many things Superficial knowledge of a few things Superficial knowledge of many things Narrow Amplitude Deepness Broad Superficial Deep Fig. 6.4 Amplitude and deepness of review scope. Source Created by authors Another important activity of this step is the deﬁnition of the theoretical frame- work, which consists of a simple and parsimonious explanation of the constructs and propositions underlying research and its boundaries (Bacharach 1989). The constructs refer to generalizable properties associated with objects, events, or people, speciﬁcally chosen (or “created”) to explain a given phenomenon. The proposi- tion, in turn, stands for a tentative and conjectural relationship between constructs that are stated in a declarative form (Bhattacherjee 2012). Finally, the boundaries comprise the assumptions about values, time, and space that limit the research extent (Bacharach 1989). A theoretical framework can be represented either graphically or descriptively. Adapted from Bhattacherjee (2012), Fig. 6.5 gives an example of a theoretical frame- work of research that aims at investigating the earning potential of undergraduates in the UK. Based on the researchers’ domain knowledge as well as in literature consulted so far, they believe that the Earning Potential depends on Academic Achievements, Intelligence, and Effort. Therefore, these constructs, limited to the population of undergraduates in the UK, composed the theoretical framework. Besides that, the Academic Achievement Intelligence Construct Directly influences Boundary = Undergraduate students of the UK Proposition Effort Earning Potential Directly influences Moderates the influence Fig. 6.5 Example of a theoretical framework. Source Adapted from Bhattacherjee (2012) 6.3 Design (Stage 1) 93 deﬁnition of constructs and their relationships (propositions) were also considered, as depicted in the arrows of Fig. 6.5 and the following description: “The current knowledge suggests that the Intelligence (IQ), moderated by the Effort invested in the learning process (hours of study), directly affects the Academic Achievement (grade point average of the entire course), which ends up directly inﬂuencing the Earning Potential (salary after undergraduate).” In general terms, the theoretical framework consists of the background by which the research question is supported (Barnett-Page and Thomas 2009), which along with the review scope and type serves as input ﬂows for the subsequent steps of LGT. 6.3.3 Deﬁnition of the Research Team (Step 1.3) Although the SLR can be performed by a single researcher, it usually requires knowl- edge on the subject to be investigated as well as on the methodological procedures, characteristics not easily found in the same person (Gough et al. 2012). For that reason, Step 1.3 of LGT consists of deﬁning the team to conduct the SLR. The Deﬁnition of the Research Team depends on the research scope and the time/cost available to execute it. Moreover, the aspects concerning the quality and reliability of the study should also be considered. “The Cochrane Collaboration,” for example, argues that the SLR must be conducted by more than one researcher. According to them, this practice enhances the reliability of results, since the search, eligibility, and quality assessment being performed independently and then compared reduces the error likelihood (Higgins and Green 2011). The research team should be maintained together up to the obtention of the results, except those specialists or stakeholders who are only able to contribute to speciﬁc SLR steps (Morandi and Camargo 2015). Besides that, the team should guarantee information transparency and reliability from the search up to the synthesis of results (Thomé et al. 2016). Table 6.1 provides a comparison between SLR performed by a researcher and research team. It is important to highlight that both approaches have pros and cons. Therefore, the appropriate decision should consider the objective of the research as well as the stakeholders’ opinion on the dimensions presented in Table 6.1. 6.3.4 Deﬁnition of the Search Strategy (Step 1.4) In general, SLR aims to identify all empirical evidence that ﬁts the pre-speciﬁed inclusion criteria to answer a particular research question or hypothesis (Snyder 2019). To make that possible it is necessary to deﬁne a Search Strategy in accordance with the research question, scope, and type (Hammerstrøm et al. 2009). There are three main concerns involving the Search Strategy: (i) what to search? (ii) where to search? and (iii) which studies to consider? Questions that can be 94 6 Literature Grounded Theory (LGT) Table 6.1 Comparison between SLR performed by a researcher and research team Dimension Researcher Research team Knowledge Requires a more experienced researcher with knowledge on the subject to be investigated as well as on the methodological issues Requires a multidisciplinary team of researcher with complementary knowledge on the subject to be investigated as well as of the methodological issues Time Tends to be longer due to the serial activities Tends to be shorter due to the parallel activities Cost Tends to be lower due to the single resource Tends to be higher due to the multiple resources Quality More prone to bias due to the individual judgment Less prone to bias due to the comparison of multiple independent judgments Source Created by authors answered by the three following subsections: (i) the deﬁnition of search terms, (ii) the deﬁnition of the search string, and the (iii) deﬁnition of the selection criteria, respectively. 6.3.4.1 Deﬁnition of the Search String The search string consists of a sentence composed of terms and Boolean operators that are used for searching primary studies in a given source. The term, or simply keyword, stands for an individual word such as “customer,” or an expression like “customer experience,” that is deeply grounded on the research subject, question, and scope (Hammerstrøm et al. 2009). The terms can be deﬁned in different ways. One way is extracting the central elements comprising the research question and/or the theoretical framework. For example, in the question posed in Box 6.3 “Which methods can be used to conceptually design product family structures through the use of modularity?”, the central elements could be “design,” “product family,” and “mod- ularity.” Considering the framework presented in Fig. 6.5, the central elements could be “academic achievement,” “earning potential,” “graduate,” and “UK.” Another common way is to recur to classical works on the subject and ﬁnd out the most frequent terms (Cooper et al. 2009). Thebrainstormingfollowedbyanassessment with experts on the subject as well as with stakeholders is also an option (Colicchia and Strozzi 2012). Given the iterative nature of the research, the terms might evolve on the course of SLR. This is particularly concerning since it requires the researcher extra work. One way to reduce this risk is to perform some trial searches in databases, and then use the metadata in the bibliometric analysis of co-words, as seen in Chap. 4.The central elements identiﬁed in the co-word analysis can be used to reﬁne the search terms as indicated by the feedback from Steps 3.2 and 3.3 to Step 1.4 in Fig. 6.2. 6.3 Design (Stage 1) 95 The search must be broad enough to identify relevant studies, but strict enough to minimize the capture of irrelevant literature (Smith et al. 2011). For this reason, the search terms are not used independently but connected through Boolean operators (Littell et al. 2008). The Boolean operators can be of two types: logical and proximity operators. In the context of SLR, a logical operator consists of character used to connect two or more terms/expressions, while a proximity operator is a character used to narrow search engine results by limiting them to those that have terms/expressions placed within a speciﬁc number of words in the content (Gough et al. 2012). Table 6.2 synthesizes the use of search terms as well as of the main Boolean operators. It is important to mention that its use and format may vary depending on the search source used. After deﬁning “what to search” it is necessary to deﬁne “where to search,” an issue that will be detailed in the next section. 6.3.4.2 Deﬁnition of the Search Sources The LGT classiﬁes the literature into three types: (i) peer-reviewed literature, (ii) gray literature, and (iii) patent speciﬁcations. The peer-reviewed literature consists of scientiﬁc research written by experts and reviewed by several other experts in the ﬁeld before being published (Thomé et al. 2016). Examples of peer-reviewed literature include books and articles published in scientiﬁc journals (Littell et al. 2008). The gray literature, in turn, refers to research that is either unpublished or has been published in non-commercial forms, such as government reports, policy statements, pre-prints and post-prints of articles, conference proceedings, theses and dissertations, and research reports, among others (Chaabna et al. 2018). Finally, the patent speciﬁcation is a document describing the invention for which a patent is sought and setting out the scope of the protection of the patent (Abbas et al. 2014). There is a variety of sources whereby the literature can be found. In LGT, these sources are categorized into two types: (i) primary sources and (ii) databases. The primary source consists of a repository wherein the literature metadata and/or content can be found. For peer-reviewed literature, for example, the primary source can be the website of scientiﬁc journals such as the Journal of Operations Management, Journal of Intelligent Manufacturing, among others. While for the gray literature, the primary source can be the website of a particular government agency, university, conference, magazine, etc. Concerning the database (db), it can be deﬁned as an organized collection of primary sources (s), from which the literature (l) is retrieved, i.e., db = {s|∀l ∈ s}. There are databases for the three types of literature, and it is the responsibility of the researcher to identify the most suitable sources for its research. For the peer- reviewed literature, there is a broad range of databases delivering a comprehensive overview of the world’s research output in different ﬁelds of science (Cooper et al. 2009). Therefore, it is always a good strategy to select the databases linked to the ﬁeld in which the research is grounded. To assist in the identiﬁcation process, Table 6.3 96 6 Literature Grounded Theory (LGT) Table 6.2 Terms and Boolean operators Function Example Search terms Exact word Retrieves the studies containing the term within the search string Government: retrieves the studies containing the word “government” Truncated word Retrieves the studies containing variants of the term within the search string Govern*: retrieves the studies containing the variants “government,” “governor,” and “to govern,” among others Exact expression Retrieves the studies containing the expression in the quotation marks within the search string “Federal government”: retrieves the studies containing the exact expression, but not studies containing only the word “federal” or only the word “government” Logical operators AND Retrieves the studies containing all terms within the search string, regardless of the order Federal AND government: retrieves the studies containing both terms, regardless of proximity OR Retrieves the studies containing at least one of the terms within the search string FederalORgovernment: retrieves the studies containing one of both terms NOT Retrieves the studies containing the ﬁrst term but not the second within the search string Government NOT federal: retrieves the studies containing the term “government” but excludes any that also contain the term “federal” Proximity operators NEAR Retrieves the studies containing the terms located closely together in the text, regardless of the order Federal NEAR/6 government: retrieves the studies containing the term “federal” and the term “government” within a distance of six words, regardless of the order WITHIN Retrieves the studies containing the terms located closely together in the text and the order the terms are deﬁned Federal WITHIN/6 government: retrieves the studies containing the term “federal” and the term “government” within a distance of six words, in this exact order (continued) 6.3 Design (Stage 1) 97 Table 6.2 (continued) Function Example ADJ Retrieves the studies containing adjacent terms in the text Federal ADJ/6 government: retrieves the studies containing the terms “federal” and “government” adjacently in the text Source Morandi and Camargo (2015) exhibits the main databases organized by area of knowledge. Most of them feature smart tools to track, analyze, and visualize research, including access to the full texts. In terms of gray literature, the range of existing databases is extremely smaller. Some examples of searching databases for gray literature include the OpenGrey (http://www.opengrey.eu/), which covers literature on Science, Technology, Biomed- ical Science, Economics, Social Science, and Humanities; Cochrane Library (https:// www.cochranelibrary.com/), which entails a collection of evidence-based medicine studies; Agricola (https://agricola.nal.usda.gov/), which covers a wide variety of topics including physiology, nutrition, food science, and microbiology. As well as for peer-reviewed literature, the searching databases for patents allow the use of search strings. Besides that, the patent speciﬁcation can be found through keywords, requester, inventor, number, and date (CGCOM 2016). Each patent database has particular characteristics and information, which can be accessed publicly or privately. Table 6.4 provides some examples of patent databases. Besides the approach of directly searching the literature on primary sources or databases, there are two other useful ways by which the literature can be found. The ﬁrst one is through contact with experts, either individuals or organizations that own or have access to literature not published in the databases (Gough et al. 2012). The second one is through snowballing, which refers to using the reference list of a document or the citations to the document to identify additional literature (Wohlin 2014). Concerning snowballing, it involves two approaches, one that works back in time from the document, while the other approach works forward in time from that document (Webster and Watson 2002). In the snowballing backward, the refer- ence section of the documents already included in the review is scoured. In the snowballing forward, certain citation tracking databases (Google Scholar, Web of Science, Scopus, etc.) are used to identify documents that had subsequently cited the ones included in the review (Wohlin 2014). In both approaches, this process is undertaken iteratively until no new paper is found, as depicted in Fig. 6.6. After deﬁning “where to search” it is necessary to deﬁne “which studies to consider,” an issue that will be detailed in the next section. 98 6 Literature Grounded Theory (LGT) Table 6.3 Main databases per area of knowledge Area Database Engineering –arXiv – Analytical Abstracts – Chemical Abstracts (SciFinder Scholar) Compendex EV2 – Drug information full-text –ESDU –GeoRef – Inspec/Ovid – IEEE XPLORE – International tables for crystallography – Knovel library – KnowIt All U (Bio Rad) – LOCUS – MathSciNet—Mathematical Reviews – Reaxys –SCOPUS – Web of Science – Science Direct Biomedics – Biomed Central – BVS: Biblioteca virtual em saúde – Cochrane –EBM—Ovid – Embase – Free Medical Journal – Lilacs – Primal Picture – PubMed/Medline –SCOPUS –Up to date – Web of Science Social science – Applied Social Sciences Index and Abstracts—ASSIA (ProQuest) – ERIC (Education Resources Information Center) (ProQuest) – Èrudit – Europeana – Artemis Primary Sources (Gale) – Gallica Digital Library – Oxford Journals – Persée – REDALYC—Red de Revistas América Latina, Caribe, España y Portugal – SAGE Journals Online –SCOPUS – SLAVERY and Anti-Slavery Collection (Gale) – SocINDEX with Full Text (EBSCOhost) – SOCIAL Services Abstracts (ProQuest) – Sociological Abstracts (ProQuest) – Web of Science (continued) 6.3 Design (Stage 1) 99 Table 6.3 (continued) Area Database Multidisciplinary – Applied Social Sciences Index and Abstracts—ASSIA (ProQuest) – ERIC (Education Resources Information Center) (ProQuest) – Èrudit – Europeana – Artemis Primary Sources (Gale) – Gallica Digital Library – Oxford Journals – Persée – REDALYC—Red de Revistas América Latina, Caribe, España y Portugal – SAGE Journals Online –SCOPUS – SLAVERY and Anti-Slavery Collection (Gale) – SocINDEX with Full Text (EBSCOhost) – SOCIAL Services Abstracts (ProQuest) – Sociological Abstracts (ProQuest) – Web of Science Source Created by authors based on Universidade de São Paulo (2019) 6.3.4.3 Deﬁnition of Eligibility Criteria After deﬁning the search string and source, it is necessary to establish the eligibility criteria from which the primary studies will be selected to compose the review. These criteria can be of inclusion or exclusion, and their deﬁnition can occur, in part, before the search process and, in part, during the eligibility process (Morandi and Camargo 2015). The criteria deﬁned a priori are generally of the “inclusion” type. These are broader criteria that deﬁne minimum conditions, which, if met, justify the inclusion of the study in the review, some examples include time horizon, language, document type, and subject area, among others (Gough et al. 2012). These criteria, in most cases, compose the search string, when using the abstract and citation databases covering peer-reviewed literature, i.e., TITLE-ABS-KEY ((“Modularity” OR “Modular”) AND “design” AND (“Product family” OR “Product platform”)) AND (LIMIT-TO (SUBJAREA, “ENGI”) OR LIMIT-TO (SUBJAREA, “BUSI”)) AND (LIMIT-TO (DOCTYPE, “ar”)) AND (LIMIT-TO (LANGUAGE, “English”)) AND (PUBYEAR < 2020). Besides these more generic criteria, there are some more speciﬁc ones. For example, if the purpose of the research is to identify the common underlying structure among the extant methods for designing modular product families, those documents addressing modular product families, but which do not present a sequence of logical steps on how to design them, should not be considered. In this case, the inclusion criterion could be: studies presenting logical steps on how to design product families. Or, supposing that the objective of the study is to undertake a meta-analysis on the effects of a drug on the duration of ﬂu symptoms, if the studies under evaluation do not present results in the form of descriptive statistics, such as mean and standard deviation, these cannot be included. Therefore, the inclusion criterion should be: 100 6 Literature Grounded Theory (LGT) Table 6.4 Patent databases Database Description Type United States Patent and Trademark Ofﬁce (USPTO) The USPTO maintains a permanent, interdisciplinary historical record of all U.S. patent applications since 1976 (http://patft. uspto.gov/netahtml/PTO/index.html) Public European Patent Ofﬁce (EPO) The EPO provides a historical record of patent applications of 44 countries contracting to the European Patent Convention since 1973 (https://www.epo.org/ searching-for-patents.html) Public Instituto Nacional da Propriedade Industrial (INPI) The INPI supplies an interdisciplinary historical record of all Brazilian patent applications since 1970 (https://gru.inpi.gov. br/pePI/jsp/patentes/PatenteSearchBasic o.jsp) Public World Intellectual Property Organization (WIPO) The WIPO provides the world’s most comprehensive source of data on the intellectual property (IP) system, as well as of empirical studies, reports, and factual information on IP (https://patentscope.wipo. int/search/en/search.jsf) Public IBM Patents IBM maintains a historical record of U.S. patent applications since 1920 (https://www. research.ibm.com/patents/) Public Intellectual property India (IPI) The IPI supplies an interdisciplinary historical record of Indian patent applications (https://ipindiaservices.gov.in/publicsearch) Public National Center for Biotechnology Information (NCBI) The NCBI houses a series of databases relevant to biotechnology and biomedicine and is an important resource for bioinformatics tools and services (https:// www.ncbi.nlm.nih.gov/) Public Questel-Orbit Orbit is a web-based commercial searchable patent database made available by Questel, with full-text coverage of the PCT, Chinese, European (EP), Japanese, and US collections as well as several other, mainly European, collections (https://www.orbit.com/) Private STN The STN is an online database service, operated by the Chemical Abstracts Service (CAS) of the American Chemical Society and FIZ Karlsruhe, which provides full-text coverage of the European (EP), PCT, and US collections as well as the British, French, and German collections (http://www.stn-internati onal.de/) Private (continued) 6.3 Design (Stage 1) 101 Table 6.4 (continued) Database Description Type Dialog The Dialog is an online database service operated by ProQuest, which encompasses around 600 databases covering subject areas including “Agriculture & Nutrition, Chemistry, Energy& Environment, Medicine & Biosciences, Pharmaceuticals [and] Engineering & Technology” (https://dialog. com/) Private Source Adapted from Macedo et al. (2001) Snowballing Event Information flow Snowballing procedure Studies in compliance with the eligibility criteria Backward: Iterate: 1. Look at title in reference list 2. Look at the source of reference End iterate: 3. Look at the abstract 4. Look at the full-text Forward: 1. Look at title of the paper citing 2. Look at the abstract of the paper citing 3. Look at the source of the paper citing 4. Look at the full-text of the paper citing In each step of both, backward and forward snowballing, it is possible to decide to exclude or include a paper for further consideration Final inclusion of a paper should be based on the full-text, i.e. before the paper can be included in a new set of papers that goes into the snowballing procedure Iterate until no new papers are found If no new paper are found then the snowballing procedure is finished Fig. 6.6 Snowballing. Source Adapted from Wohlin (2014) studies presenting results in terms of mean and standard deviation (Borenstein et al. 2009). Still regarding the inclusion criteria, when the gray literature is considered an option, the questions proposed by Garousi et al. (2018), and exposed in Table 6.5, can also be considered as a set of inclusion criteria. In this context, if at least one of the answers is yes, the study should be included in the review. Regarding the exclusion criteria, they are usually deﬁned during the eligibility process. Since they can emerge at any time in the eligibility process, those studies analyzed before their creation must be re-analyzed in the light of the new criterion (Higgins and Green 2011). The rationale behind them is to remove, among the studies 102 6 Literature Grounded Theory (LGT) Table 6.5 Questions to decide whether to include gray literature # Question Answer 1 Is the subject “complex” and not solvable by considering only the formal literature? Yes/No 2 Is there a lack of volume or quality of evidence, or a lack of consensus of outcome measurement in the formal literature? Yes/No 3 Is the contextual information important to the subject under study? Yes/No 4 Is it the goal to validate or corroborate scientiﬁc outcomes with practical experiences? Yes/No 5 Is it the goal to challenge assumptions or falsify results from practice using academic research or vice versa? Yes/No 6 Would a synthesis of insights and evidence from the industrial and academic community be useful to one or even both communities? Yes/No 7 Is there a large volume of practitioner sources indicating high practitioner interest in a topic? Yes/No Source Adapted from Garousi et al. (2018) that passed the inclusion criteria, those that for one reason or another should not be included in the review. For example, suppose the objective of the research is to perform a meta-synthesis of the methods to design modular product families, and, after the ﬁrst inclusion ﬁlter, there are some studies addressing the design support systems. Nevertheless, if the focus of the study is on design methods, and not on the systems to support its operationalization, these studies should be excluded. Thus, the exclusion criteria would be: studies addressing design support systems. In summary, the eligibility criteria, either of inclusion or exclusion, should provide evidence on the decisions made during the selection of the corpus of anal- ysis. Moreover, they must allow the research replicability as well as support its transparency. 6.3.5 Formulation of the Research Protocol (Step 1.5) The research protocol comprises a tool that synthesizes the research design (Thomé et al. 2016). It is there that the deﬁnitions guiding the decision-making throughout the subsequent stages of LGT are formalized. Moreover, it is considered a mechanism whereby research transparency and replicability are promoted (Higgins and Green 2011). Concerning the Formulation of the Research Protocol, it consists of aggregating the deﬁnitions made in steps from 1.1 to 1.4, with other ones involving data collection, analysis, and synthesis, into a single source, as suggested in Table 6.6. Although it is performed before the Review stage, some needs for improvement might emerge along the course of the research, as indicated by the feedback ﬂows in Fig. 6.2. When 6.3 Design (Stage 1) 103 Table 6.6 Research protocol template Research Protocol Research Title: Insert the title of the research, e.g., Modern Methods for Systematic Literature Review. Research Team: Insert the researchers’ name, e.g., Ermel. A., Lacerda. D., Morandi. M., and Gauss. L. Stakeholders: Insert the name of stakeholders, e.g., U.S. Department of Agriculture (USDA). Revision: 00 Date: 00/00/0000 Revised by: Ermel. A. 1. Research Question(s): Insert the research question(s) retrieved from step 1.1, e.g., Which methods can be used to conceptually design product family structures through the use of modularity? 2. Research Objective(s) Insert the research objective(s) (Describe, Explore, or Explain), e.g., (i) Identify the existing methods to design modular product families, (ii) uncover the underlying structure interconnecting these methods, and (iii) organize these methods and their respective instances into structured classes of problems. 3. Review Scope: 3.1 Amplitude: Narrow Broad 3.2 Deepness: Superficial Deep 3.3 Review Type: Aggregative Configurative 4. Theoretical Framework: Insert the theoretical framework recovered from step 1.2, e.g. The current knowledge suggests that the In- telligence (IQ), moderated by the Effort invested in the learning process (hours of study), directly affects the Academic Achievement (grade point average of the entire course), which ends up directly influencing the Earning Potential (salary after undergraduate). Whenever possible, complement the description by the corresponding nomological network, e.g., Figure 5. 5. Time Horizon: Insert the time interval to be searched, e.g., Between 2000 and 2020. 6. Search String: Insert the search string retrieved from step 1.4, e.g., TITLE-ABS-KEY ( \"electric vehicle\" AND ( \"compe- tition\" OR \"competitiveness\" OR \"competitive\" ) AND \"strategy\" ) AND ( PUBYEAR < 2021 ) AND ( LIMIT-TO ( DOCTYPE , \"ar\" ) ) AND ( LIMIT-TO ( LANGUAGE , \"English\" ) ). 7. Search Sources: Insert the search sources recovered from step 1.4, e.g., Scopus, Web of Science, and Science Direct. 8. Searching Approach: Direct searching Experts contacting Snowballing Other: 9. Eligibility Criteria: 9.1 Inclusion criteria: Insert the criteria retrieved from step 1.4, such as language, document type, sub- ject area, etc. 9.2 Exclusion criteria: Insert the criteria retrieved from step 1.4. 10. Data Analysis: 10.1 Scientometric analysis: Scientific development 10.2 Bibliometric analysis: Research performance Scientific mapping 10.3 Content analysis: Aggregative Thematic analysis Structural analysis 11. Data Synthesis: 11.1 Aggregative synthesis: Quantitative meta-analysis Qualitative meta-analysis 11.2 Configurative synthesis: Meta-synthesis Other: Source Created by authors based on Moher et al. (2009), Higgins and Green (2011), and Morandi and Camargo (2015) it happens, every change in the protocol should be justiﬁed to guarantee they were implemented toward rigor and relevance, and not to bias (Gough et al. 2012). The research protocols can be made available on institutional websites of some areas of knowledge. In health science, for example, the protocols for SLR can be published on Cochrane (https://www.cochrane.org/) and should be available before publishing the research. PROSPERO (https://www.crd.york.ac.uk/prospero/), in like 104 6 Literature Grounded Theory (LGT) manner, records the protocols on the effects of interventions and strategies to prevent, diagnose, treat, and monitor health conditions (Gough et al. 2012). Besides the insti- tutional websites, it is possible to publish the protocols, in the form of academic articles, in journals like Systematic Reviews Journal (https://systematicreviewsjour nal.biomedcentral.com/) and BMJ Open (https://bmjopen.bmj.com/) (Higgins and Green 2011). 6.3.6 Bias Assessment (Step 1.6) One of the reasons why the results of SLR are more reliable, if compared to LR, is the adoption of strategies for minimizing bias (Morandi and Camargo 2015). Considered a systematic deviation from the truth, the bias can occur at any stage of SLR, and its presence may affect the reliability of the research results (Higgins and Green 2011) Therefore, it is fundamental to know the types of bias that exist and how they can be eliminated or minimized (Whiting et al. 2016). Table 6.7 provides the main types of bias as well as the strategies for combating them. In LGT, the risk of bias concerning the research protocol can be assessed through the questions presented in Table 6.8. Each question can be answered as “yes,” “prob- ably yes,” “probably no,” “no,” and “no information.” As a result, the overall level of bias concerning the protocol might be classiﬁed as “low,” “high,” or “unclear.” If the answers to all questions are “yes” or “probably yes,” the level of concern can be judged as “low.” If the sum of questions answered as “no” or “probably no” is greater Table 6.7 Types of bias and strategies for combating them Type of bias Deﬁnition How to minimize or eliminate Publication bias The tendency of positive evidence to be more likely to be published than negative evidence – Use gray literature to either complement or counterpoint the peer-reviewed publications – Contact experts to have access to non-published studies relevant to the research Time interval bias The ﬂaws caused by selecting studies that only cover a certain time interval – Use awidetimerange Location bias The publication of research ﬁndings in journals with different ease of access or levels of indexing in standard databases – Use different databases for searching Language bias The tendency of research being published in a particular language – Not limit the search to a speciﬁc language Selection bias The tendency of not identifying all available data on a subject – Elaborate the research protocol Source Created by authors 6.3 Design (Stage 1) 105 Table 6.8 Questions for bias assessment Questions Answers 1. Is the review scope (amplitude, deepness, and type) in compliance with the research question? – Yes: the review scope in compliance with the research question – No: the review scope not in compliance with the research question – No information: insufﬁcient data reported to permit the judgment 2. Is the theoretical framework appropriate to the research question? – Yes: theoretical framework presenting constructs and propositions in compliance with the research question – Probably yes/no: theoretical framework incomplete, with propositions missing or not clearly stated – No: the theoretical framework is missing, or its constructs and propositions are not adhered to the research question – No information: insufﬁcient data reported to permit the judgment 3. Are the eligibility criteria in compliance with the research question and scope? – Yes: the eligibility criteria properly delimitate the searching space as well as complies with the amplitude, deepness, and type of review – Probably yes/no: the eligibility criteria do not clearly delimitate the searching space or do not comply with one or more dimensions of review scope (amplitude, deepness, or type) – No: the eligibility criteria not properly delimitates the searching space nor comply with the review scope (amplitude, deepness, or type) – No information: insufﬁcient data reported to permit the judgment 4. Does the research include an appropriate range of search sources for peer-reviewed, gray, and patent literature? – Yes: range of search sources adequate to the research subject – Probably yes/no: incomplete range of search sources – range of search sources adequate to the research subject – No: range of search sources not adequate to the research subject – No information: insufﬁcient search sources reported to permit the judgment (continued) 106 6 Literature Grounded Theory (LGT) Table 6.8 (continued) Questions Answers 5. Are complementary approaches to database searching being used? – Yes: there is at least one additional approach used (experts contacting, snowballing, etc.) – Potentially yes/no: there is at least one additional approach used, but the beneﬁts of using are no clear – No: there is no additional approach used (experts contacting, snowballing, etc.) – No information: insufﬁcient data reported to permit the judgment 6. Is the search string likely to retrieve as many eligible studies as possible? – Yes: the search string is complete, showing an appropriate combination of search terms and Boolean operators – Potentially yes/no: appropriate search terms are provided, but with no indication on how they were combined – No: the search string is complete but has inappropriate terms or combinations – No information: insufﬁcient data reported to permit the judgment 7. Were the restrictions on time horizon, publication format, or language appropriate? – Yes: no restrictions applied – Probably yes: restrictions on time horizon supported by a plausible described rationale – No: restriction on language (e.g., restriction to English language articles) or publication format (e.g., restriction to full-text published studies) is rarely appropriate – No information: insufﬁcient data reported to permit the judgment 8. Are the type of data to be collected properly deﬁned? – Yes: the type of data deﬁned and in compliance with the techniques for data analysis and synthesis – Probably yes/no: the type of data deﬁned, but not totally in compliance with the techniques for data analysis and synthesis – No: type of data not deﬁned or not in compliance with the techniques for data analysis and synthesis – No information: insufﬁcient data reported to permit the judgment 9. Are the techniques for data analysis properly deﬁned? – Yes: data analysis technique(s) deﬁned and capable of generating outcomes to answer the research question – Probably yes/no: data analysis technique(s) deﬁned, but with doubtful ability to generate outcomes to answer the research question – No: data analysis technique(s) not deﬁned or not capable of generating outcomes to answer the research question – No information: insufﬁcient data reported to permit the judgment (continued) 6.3 Design (Stage 1) 107 Table 6.8 (continued) Questions Answers 10. Are the techniques for data synthesis properly deﬁned? – Yes: data synthesis technique(s) deﬁned and capable of synthesizing the outcomes retrieved from data analysis – Probably yes/no: data synthesis technique(s) deﬁned, but with doubtful ability to synthesize the outcomes retrieved from data analysis – Yes: data synthesis technique(s) not deﬁned or not capable of synthesizing the outcomes retrieved from data analysis – No information: insufﬁcient data reported to permit the judgment Source Created by authors based on Whiting et al. (2016) than those answered as “no information,” the level of concern should be judged as “high,” otherwise should be judged as “unclear.” In cases where the protocol presents the level of concern about bias different from “low,” the process should go back to the previous LGT steps, as indicated by the feedback ﬂow of Fig. 6.2. For more detailed bias assessments, and not limited to the research protocol, the ROBIS technique proposed by Whiting et al. (2016) can be used. In order to increase the thoroughness in assessing bias, it is suggested the research protocol being evaluated by one or more experts not belonging to the research team. In cases where more than one expert is considered, if at least one evaluation results in a “low” level of concern about bias, the process should iteratively go back to the previous LGT steps. 6.4 Review (Stage 2) After deﬁning the research Design in stage 1, the search and eligibility of primary studies to constitute the corpus of analysis are carried out in Stage 2, the Review. Besides that, the organization of the corpus, as well as its quality and reliability, is checked at this stage. As illustrated in Fig. 6.2, the Review stage consists of four steps, which include: (2.1) search and eligibility, (2.2) quality assessment, (2.3) reliability assessment, and (2.4) organization of the corpus of analysis. These steps along with their respective techniques and tools are detailed in the next subsections. 108 6 Literature Grounded Theory (LGT) 6.4.1 Search and Eligibility (Step 2.1) The role of Step 2.1, search and eligibility is to search and select the available literature in compliance with the research purposes. As depicted by Fig. 6.7,this step comprises ﬁve activities, which start by applying the search string to different selected sources to obtain the desired literature (2.1.1) (Higgins and Green 2011). Since the same study might be indexed to more than one source, in Activity 2.1.2, the obtained studies are checked for duplicates (Morandi and Camargo 2015). After removing the duplicated studies, the remaining ones have their titles and abstracts evaluated in Activity 2.1.3 (Brunton et al. 2012). Those studies with the metadata (title and abstracts) in compliance with eligibility criteria go forward, otherwise they are discarded. In cases where the content analysis is required, the studies are directed to Activity 2.1.4, wherein their full texts are captured. If the scientometric or bibliometric analysis is needed, the studies should go straight to Activity 2.1.5. The next issue (2.1.4) is to read the resulting studies in depth (Adler and Van Doren 1972). In like manner, those studies with the content (full text) following the eligibility criteria go to the snowballing search (2.1.5), and those that do not are discarded (Wohlin 2014). At the end of the process, besides the reﬁnement feedbacks, the ﬁnal product is the set of studies to compose the preliminary corpus of analysis. In cases where the review is conducted by more than one researcher, the level of agreement among them, concerning the decisions on whether include or exclude the studies, should be assessed. An issue that will be covered in Sect. 6.4.3. 6.4.2 Quality Assessment (Step 2.2) In SLR, the reliability of results is directly related to the quality of primary studies that comprise it. In this sense, to ensure that primary studies, in accordance with the eligibility criteria, have minimum conditions to provide reliable results, their quality must be assessed (Harden and Gough 2012). Nevertheless, in literature, there is no universal deﬁnition of how to assess the quality of primary studies. For Cochrane Collaboration, for example, the quality of a study can be assessed in two dimensions. The ﬁrst is the adequacy of the research question, also called external validity. The second dimension corresponds to the ability of the study to correctly respond to the research question, also called internal validity (Higgins and Green 2011). Another approach involves the use of checklists to assess the overall quality of the study, addressing different aspects of quality, such as internal validity, external validity, and reliability of results, among others (Littell et al. 2008). In LGT, the quality assessment can be performed through the checklist presented in Table 6.9. Composed of 10 questions, concerning methodological issues ranging from the deﬁnition of the research question up to the research relevance, the checklist must be applied individually for each study comprising the preliminary corpus of analysis. 6.4 Review (Stage 2) 109 Validated protocol (search string and sources) Studies in compliance with the search string (with duplicates) 1. Design 2.1.1 Literature searching Available literature in world 3 (meta-data) 2.1.2 Checking for duplicates Duplicated studies 2.1.3 Titles and abstracts screening Studies in compliance with the search string (without duplicates) Meet the eligibility criteria? Studies with meta-data not meeting the eligibility criteria No 2.1.4 Full-text reading Yes Studies with meta-data in compliance with the eligibility criteria Meet the eligibility criteria? Studies with content not meeting the eligibility criteria No Yes Studies with content in compliance with the eligibility criteria 2.1.5 Snowballing search 2.2 Quality assessment Studies to compose the preliminary corpus of analysis Validated protocol (eligibility criteria and tech. for data analysis) Search string refinements Eligibility criteria refinements Eligibility criteria refinements Search string and eligibility criteria refinements Activities of step 2.1 Information flow Feedback flow Content analysis required? Yes No Available literature in world 3 (full-text) Studies with meta-data in compliance with the eligibility criteria Fig. 6.7 Flowchart of the activities involving the search and eligibility. Source Adapted from Higgins and Green (2011) 110 6 Literature Grounded Theory (LGT) Table 6.9 Checklist for quality assessment Question Response 1. Are the research question and/or objectives clearly deﬁned? \u0002 Yes \u0002 No \u0002 Partially 2. Is there an adequate description of the context in which the research was conducted? \u0002 Yes \u0002 No \u0002 Partially 3. Is the research design appropriate to achieve the research objectives? \u0002 Yes \u0002 No \u0002 Partially 4. Is there an adequate description of the sample/case used? \u0002 Yes \u0002 No \u0002 Partially 5. Is there an adequate description of the criteria used for identifying and selecting the sample/case? \u0002 Yes \u0002 No \u0002 Partially 6. Is there an adequate description of the methods used for data collection? \u0002 Yes \u0002 No \u0002 Partially 7. Is there an adequate description of the methods used for data analysis and synthesis? \u0002 Yes \u0002 No \u0002 Partially 8. Is the synthesis using relevant results? \u0002 Yes \u0002 No \u0002 Partially 9. Does the research provide clearly stated and reliable results, with justiﬁed conclusions? \u0002 Yes \u0002 No \u0002 Partially 10. Is the research relevant for the industry and the academy alike? \u0002 Yes \u0002 No \u0002 Partially Source Created by authors based on Dybå and Dingsøyr (2008) Each question can be answered as “yes,” when the research fully meets the topic assessed; “no,” when the research does not meet or provide evidence on the topic assessed; and “partially,” in cases where the research does not fully meet the topic assessed. The questions are assumed to have the same weight, while the responses have different scores, i.e., “yes” = 1, “no” = 0, and “partially” = 0.5. The sum of responses’ score deﬁnes to which quartile the research belongs, as indicated in Table 6.10. Based on the quartiles, the decision on whether or not to include the study in the review is made. Table 6.10 Research quality scores From to Quartile State Decision 8 10 Q4 The research meets the quality criteria Include the primary study 5 7 Q3 The research meets most of the quality criteria Include the primary study, but making explicit its limitations 2 4 Q2 The research partially meets the quality criteria Perform a new evaluation and, if possible, by more than one researcher. In case of inclusion, make explicit the research limitations 0 1 Q1 The research does not meet the quality criteria Discard the primary study Source Created by authors 6.4 Review (Stage 2) 111 If the review is being conducted by a single researcher, at the end of this step, besides the reﬁnement feedbacks, the ﬁnal product will be the corpus of analysis. In cases where the review is being undertaken by more than one researcher, the level of agreement among them, for the quartiles, must be assessed. An issue that will be covered in the next subsection. 6.4.3 Reliability Assessment (Step 2.3) When the review is conducted by a single researcher, the decisions are generally evaluated when they are made, not making sense to review them post hoc. However, this procedure cannot be done when more than one person (researcher, advisor, stakeholders, etc.) is conducting or involved in the process. Moreover, there will likely be some level of disagreement regarding the decisions involving the eligibility and/or quality of the studies under evaluation (Thomé et al. 2016). Therefore, it is necessary to identify the divergences so that they can be resolved (Krippendorff 2019). In LGT, the activities of identifying and resolving divergences are undertaken in Step 2.3, the reliability assessment. Considering the identiﬁcation of divergences, there are some techniques available in the literature to assess the level of agreement among raters, such as the Fleiss’ kappa (Fleiss 1971) and Krippendorff’s alpha (Krippendorff 2019). Both techniques support two or more raters as well as can be used with binary (for eligibility) or nominal scale (for quality assessment) (Zapf et al. 2016). Fleiss’ kappa calculates the degree of agreement in classiﬁcation over that which would be expected by chance. The resulting measure is the Kappa index (k), which can be interpreted according to Table 6.11. Sharing the same purpose as Fleiss’ kappa, the Krippendorff’s alpha is considered more ﬂexible, since it can be used with a multitude of scales (binary, nominal, ordinal, interval, ratio, polar, and circular) as well as when there are missing data (Zapf et al. 2016). The resulting measure, in this case the Alpha index (α), which can be interpreted by Table 6.12. Table 6.11 Interpretation of k k Interpretation k<0 Poor agreement 0.01 < k <0.20 Slight agreement 0.21 < k <0.40 Fair agreement 0.41 < k <0.60 Moderate agreement 0.61 < k <0.80 Substantial agreement 0.81 < k <1 Almost perfect agreement Source Landis and Koch (1977) 112 6 Literature Grounded Theory (LGT) Table 6.12 Interpretation of α α Interpretation α >0.8 High level of agreement (reliable conclusions) 0.667 < α <0.8 Moderate level of agreement (preliminary conclusions only) α < 0.667 Low level of agreement Source Krippendorff (2019) Table 6.13 Tools for calculating Fleiss’ kappa and/or Krippendorff’s alpha Tool Fleiss’ kappa Krippendorff’s alpha ReCal • • Excel • • R • • Python • • MATLAB – • SPSS • – Online Kappa Calculator • – u-Alpha – • AgreeCalc • – Source Created by authors There are some available tools for calculating Fleiss’ kappa and Krippendorff’s alpha, the prominent ones are presented in Table 6.13. When divergence is found (k ≤ 0.41; α ≤ 0.667), either in the eligibility process (decision on whether or not to include a study) or in quality assessment (quartiles clas- siﬁcation) it is usually resolved through a conjoint evaluation, where the researchers decide to include or not the divergent study in the review. Although there is no rule to support this process, there are some useful guidelines: (i) if, after the conjoint eval- uation, the divergences concerning the eligibility persist, it is indicated to include the study in the review since its adherence to the research scope can still be clariﬁed during the analysis and (ii) if the divergence is about the quality of the study, and it remains after the conjoint evaluation, the study should be discarded. 6.4.4 Organization of the Corpus of Analysis (Step 2.4) The Organization of the Corpus of Analysis is a fundamental step that guarantees the traceability of decisions made during the formation of the corpus. Although it appears as the last step of the review stage, it occurs in parallel with the ﬁrst three steps, as shown in Fig. 6.2. This is because the corpus is being updated as the decisions related 6.4 Review (Stage 2) 113 to Steps 2.1, 2.2, and 2.3 are taken. Although there is no formal rule, the organization is usually materialized in the form of a “table of documents,” which in addition to allowing the reading of titles and abstracts also permits the association of eligibility and quality criteria to the studies being evaluated. Table 6.14 presents a template for organizing the corpus of analysis used in LGT. An important piece of advice is that the table is sorted in an increasing way regarding the year of publication, and this will facilitate new inclusions coming from future updates. One way to synthesize the partial results recovered from the review (Stage 2) is through the “review diagram” combined with the “table of exclusions.” The review diagram depicts the ﬂow of information through the different steps of the review. It maps out the number of records identiﬁed, included, and excluded, while the table of exclusions records the reasons for exclusions (Moher et al. 2009). Figure 6.8 presents an example of the review diagram adopted in LGT. It combines the reasoning of the PRISMA statement (www.prisma-statement.org) and the diagram presented by Gauss et al. (2021). Moreover, it considers an additional step, not explicitly found in both references, the quality assessment. Concerning the table of exclusions, LGT adopts the one proposed by Gauss et al. (2021), as shown in Table 6.15. The data used in the research diagram and the table of exclusions came from the table of documents. The outputs of the review stage are the corpus of analysis, its respective metadata, and/or full-text documents, as well as the decisions made along the process. 6.5 Literature Analysis (Stage 3) The literature analysis can be deﬁned as the process of systematically decomposing the content of a study into parts and describing how these parts are related (Hart 1998). This rationale can be broadened from a single study to the corpus of analysis, as well as from the content to the metadata. In LGT, the stage of literature analysis is subdivided into complementary steps, which involves three types of analysis: (3.1) scientometric analysis, (3.2) bibliometric analysis, and (3.3) content analysis. The following subsections highlight the objectives and the main characteristics of each of them. 6.5.1 Scientometric Analysis (Step 3.1) Scientometric analysis comprises the set of quantitative procedures used to analyze scientiﬁc development over time (Osareh 1996). It is usually employed for describing science in terms of growth, structure, interrelationships, and productivity (Hood and Wilson 2001). In this context, the prominent indicators used are (i) annual scientiﬁc 114 6 Literature Grounded Theory (LGT)Table6.14TemplatefororganizingthecorpusofanalysisIdDocumenttitleAuthorsYearSourceAbstractStatusAgreement(k)EligibilitycriteriaPhaseHighlights1AmethodologyofdevelopingproductfamilyarchitectureformasscustomizationJiaoandTseng1999JournalofIntelligentManufacturingMasscustomization,aimingatdeliveringanincreasingproductvariety…Selected0.6ProvidemethodsortechniquesaddressingmodularityintoproductfamilydesignFull-textreadingThedevelopmentofaPFAprovidesaunifyingintegrationplatform…2FundamentalsofproductfamilyarchitectureDu,Jiao,andTseng2000IntegratedManufacturingSystemsRecognizingtherationaleofaproductfamilyarchitecture(PFA)withrespectto…Discarded1.0Fundamentalissuesonproductfamilydesign(PFD)andmodularityTitleandabstractscreening–3Modularproductfamilydesign:Agent-basedPareto-optimizationandqualitylossfunction-basedpost-optimalanalysisRaiandAllada2003InternationalJournalofProductionResearchTheadventofmasscustomizationandincreasedmanufacturingcompetitionhasnecessitated…Selected0.7Providemethodsortechniquesaddressingmodularityintoproductfamilydesign–n……………Discarded0.1DisagreementamongtheresearchersconcerningthequalityReliabilityassessment–SourceCreatedbyauthors 6.5 Literature Analysis (Stage 3) 115 Web of science n = 135 Scopus n = 143 Titles and abstracts screened n = 200 Records identified through the selected sources n = 278 Excluded duplicates n = 78 Records excluded n = 63 Full-text documents assessed for eligibility n = 137 Full-text documents assessed for quality n = 72 Full-texts excluded n = 65 Search String i.e.: ((TS=( (\"Modularity\" OR \"Modular\") AND \"design\" AND ( \"Product family\" OR \"Product platform\" ) )) AND (SU=( ENGINEERING OR OPERATIONS RESEARCH MANAGEMENT SCIENCE ))) AND LANGUAGE: (English) AND DOCUMENT TYPES: (Article) AND (PY<2020) Full-texts included in the corpus of analysis n = 72 Full-texts excluded n = 0 Fig. 6.8 Review diagram. Source Adapted from PRISMA Statement (www.prisma-statement.org) and Gauss et al. (2021) production, (ii) researchers’ production, (iii) publications by country, (iv) publica- tions by source, and (v) publications by afﬁliation (Hood and Wilson 2001). Table 6.16 synthesizes the objective of each indicator. The scientometric analysis can be used explicitly or implicitly. When the objec- tive of an SLR is to evaluate scientiﬁc development over time, for example, one or more indicators presented in Table 6.16 are used explicitly in the text to support the argument. However, when the research does not share this objective, some of the indicators, like researchers’ production and publications by source, are used implic- itly to not leave out important references as well as to position the research to a qualiﬁed audience. Figure 6.9 provides examples of scientometric indicators. To operationalize the scientometric analysis, it is possible to use the R program- ming language, with the bibliometric package, developed by Aria and Cuccurullo 116 6 Literature Grounded Theory (LGT) Table 6.15 Table of exclusions No. of exclusions Percentage Excluding criteria 78 37.9 Duplicated studies 35 17.0 Absence of methods or techniques addressing modularity in Product Family Design (PFD) 18 8.7 Manufacturing and production for product families 17 8.3 Design support systems 13 6.3 Supply chain issues of product families 11 5.3 Literature review on PFD and modularity 7 3.4 Fundamental issues on PFD and modularity 6 2.9 Theoretical development on PFD and modularity 5 2.4 Very speciﬁc application not liable to generalization 4 1.9 Paper not found 3 1.5 Limited applicability to scale-based PFD 2 1.0 Customer co-design 2 1.0 Out of context 2 1.0 Civil construction 1 0.5 Aesthetics in product design 1 0.5 Service design 1 0.5 Software development 206 100.0 Total Source Adapted from Gauss et al. (2021) Table 6.16 Main indicators used in the scientometric analysis Indicators Objective Annual scientiﬁc production Analyzes the development of a theme or research ﬁeld over time. It can be used to attest to the relevance of the research topic in case the increased volume of publications is evidenced Researchers’ production Identiﬁes the most productive researchers on either a subject or a research ﬁeld, whose, therefore, must have its production incorporated into the SLR Publications by country Identiﬁes the most relevant countries on a subject or in a research ﬁeld Publications by source Identiﬁes the main journals on a subject or in a research ﬁeld. This indicator not only contributes to identifying the existing knowledge to base the research but also to share the obtained results with a qualiﬁed audience Publications by afﬁliation Identiﬁes the institutions and/or research groups that most publish on either a subject or a research ﬁeld. This indicator assists both researchers and funding agencies in identifying institutions for strategic partnerships Source Created by authors based on Aria and Cuccurullo (2017) 6.5 Literature Analysis (Stage 3) 117 (a) (b) (c) (e) (d) Fig. 6.9 Examples of Scientometric indicators: a annual scientiﬁc production; b researchers’ production; c publications by country; d publications by source; e publications by afﬁliation. Source Created by the authors based on Scopus (2020) (2017). Besides that, the Scopus and Web of Science databases provide scientometric indicators for each search performed. In all cases, the metadata (title, keywords, abstract, author, source, year, and afﬁliation) is used as input for generating the results. The next subsection presents the bibliometric analysis. 6.5.2 Bibliometric Analysis (Step 3.2) Bibliometric analysis comprehends a set of statistical procedures intended to map the state of the art or to identify research opportunities in a given ﬁeld of study (Oliveira et al. 2019). Its use involves two main streams: (i) the evaluation of research performance and (ii) the scientiﬁc mapping (Cobo et al. 2011). 118 6 Literature Grounded Theory (LGT) Table 6.17 Main research performance indicators Indicators Deﬁnition Impact factor Consists of the ratio between the total citation counts of journals belonging to the ISI database during the previous 2 or 5 years, by the total number of publications made by the journals during the same period (Bensman 2007) CiteScore Comprises the sum of the citations received in a given year to publications published in the previous 3 years divided by the sum of publications in the same previous 3 years (Deb et al. 2019) Eigenfactor Consists of the number of times articles from the journal published in the past 5 years have been cited in the Journal Citation Reports (JCR) year (Bergstrom and West 2017; Haddow 2018) SCImago Journal Rank (JCR) Comprises the ratio of the number of citations received in the given year to documents published in the 3 previous years and the number of documents published in the journal in the 3 previous years (Mering 2017) H-index Consists of the number of publications for which an author has been cited at least that same number of times (Thelwall 2008) Source Created by authors Concerning the evaluation of research performance, it aims at assessing the perfor- mance of research, researchers, and institutions (Zupic and ˇCater 2015). Moreover, it is intended to build the conceptual, social, or intellectual structure of scientiﬁc research as well as to evidence its evolution (Gutiérrez-Salcedo et al. 2017). Table 6.17 provides the prominent indicators used for measuring the research performance. Regarding scientiﬁc mapping, the objective is to build bibliometric networks by which it is possible to identify how scientiﬁc knowledge is conceptually structured (Cobo et al. 2011). Table 6.18 and Fig. 6.10 present the main network topologies used. 6.5.3 Content Analysis (Step 3.3) Unlike scientometric and bibliometric analysis that identify patterns from the meta- data of primary studies, content analysis identiﬁes patterns through the full texts (Renz et al. 2018). In LGT, the content analysis is carried out by a set of activities, as shown in Fig. 6.11. This process starts by iteratively deﬁning the codes (3.3.1), aggregating the codes into categories (3.3.2), and then assigning the codes and categories to the full texts (3.3.3). As mentioned in Chap. 4, codes are the logical units that encapsulate relevant characteristics of the content; in other words, they consist of the smallest unit of meaning (Hsieh and Shannon 2005). The codes might be of two types: “categorical” 6.5 Literature Analysis (Stage 3) 119 Table 6.18 Network topologies for scientiﬁc mapping Topology Function Purpose Unit of analysis Co-authorship Maps scientiﬁc collaboration patterns – Understand how authors, institutions, or countries cooperate in terms of scientiﬁc research – Author’s name – Country from afﬁliation – Institution from afﬁliation Co-word Maps patterns of co-occurrence between a pair of words – Deﬁnition/validation of the search terms – Identify the conceptual structure of a research ﬁeld – Identify the conceptual changes of a research ﬁeld over time – Terms extracted from title, abstract, or keywords Citation Maps the relationships among publications through its cited references – Identify the most inﬂuencing authors, documents, journals, and countries in a given subject – Author’s name – Documents – Journal’s name – Organization’s name – Country’s name Bibliographic coupling Maps the relationship between two documents that cite together a third document – Identify emerging research subjects that have not yet produced representative citation counts – Author’s oeuvres – Documents – Journal’s oeuvres Co-citation Maps the relationship between a pair of documents concurrently cited by a third document – Identify the underlying pattern of communication among researchers sharing common objectives or interests – Author’s reference – Reference – Journal reference Main-path Maps the path-dependence among publications over time – Identify the most relevant publications in different periods – Documents Source Adapted from Zupic and ˇCater (2015) and Colicchia and Strozzi (2012) and “open.” The categorical codes are deﬁned before the full-text reading, and they are usually derived from the theoretical framework established in Step 1.2. The open codes, in turn, emerge during the in-depth analysis (Strauss and Corbin 1990), which is performed in Activity 3.3.3. Regarding the categories, they consist of a group of codes sharing common char- acteristics (Bardin 1993). As well as the codes, the categories might be deﬁned before or during the exploration of the material. Those categories deﬁned before the full-text reading are called “a priori” categories, while those deﬁned during the in-depth reading are named as “a posteriori” categories (Dresch et al. 2015). In terms of the rationale used for grouping codes into categories (i.e., categorization), the 120 6 Literature Grounded Theory (LGT) Fig. 6.10 Examples of network topologies: a co-authorship; b co-word; c citation; d bibliographic coupling; e co-citation; f main path. Source Created by authors using the software VosViewer and Pajek 6.5 Literature Analysis (Stage 3) 121 Occurrence (absence) Absolute frequency Relative frequency Order Co-occurrence Confidence Lift 2. Review 3.3.1 Codes definition 3.3.5 Selection of enumeration rules Corpus of analysis (full-texts) 3.3.7 Thematic analysis 3.3.8 Structural analysis 4.1 Aggregative Synthesis 4.2 Configurative Synthesis Absolute frequency matrix Direction/intensity table Occurrence matrix A A Occurrence (absence) Absolute frequency Direction Intensity Table of comparable outcomes Activities of step 3.3 Information flow Feedback flow Codes and categories 3.3.6 Aggregative analysis CramerísV matrix Association rules Cause-effect relationships A priori categories Categorical codes Validated protocol (data analysis) A posteriori categories Validated protocol (theoretical framework) 3.3.2 Categories definition Occurrence (absence) Absolute frequency Relative frequency Absolute weighted freq. Relative weighted freq. Direction Intensity Order 3.3.4 Intercoder agreement Codes and categories 3.3.3 Encoding Open codes ≤ 0.667 Fig. 6.11 Flowchart of the activities involving the content analysis. Source Created by authors LGT adopts the thematic criterion, wherein the codes sharing the same theme are arranged together. According to Bardin (Bardin 1993), the categorization should follow ﬁve principles: (i) mutual exclusion, which states that a code cannot belong to more than one category; (ii) homogeneity, which deﬁnes that a category should be structured from a single dimension of analysis (e.g., theme); (iii) pertinence, which poses that categories should be meaningful and useful for the study being undertaken; (iv) objectivity, which asserts that a category should provide clear guid- ance for codes inclusions; and (v) productivity, which deﬁnes that a category should supply insightful outcomes. For that reason, regardless of which activity the code or category is derived from, it is fundamental to deﬁne their meanings whenever they are created. The research by Gauss et al. (2021) gives an example of that, as shown in Table 6.19. Although the codes and categories may vary from one research to another, some of them are generic, and therefore can be used by different studies. Table 6.20 gives an example of some generic codes and categories. The codes and categories are assigned to the material through the registration units, which consist of fractions of communication wherefrom it is possible to drive meaning (e.g., word or phrase). The meaning depends on the context, and therefore 122 6 Literature Grounded Theory (LGT) Table 6.19 Example of codes and categories deﬁnition Id Description Deﬁnition Type Pti Product classiﬁcation Classes of products that are used for testing the extant design methods A priori category Pt1 Consumer goods (durables) Consist of durable products that people buy for their use (OECD 2008) Categorical code Pt2 Intermediate goods Comprehend those products used in the production of other goods (OECD 2008) Categorical code Pt3 Capital goods Consist of machines and equipment used to produce products or provide services (OECD 2008) Categorical code Pt4 Military and defense goods Consist of the equipment used in defensive tactics that seek to negate the enemy’s offensive tactics (Pate et al. 2012) Open code Source Adapted from Gauss et al. (2021) every registration unit must be associated with a context unit (Bardin 1993), which in LGT might assume the format of the primary study itself. This activity of assigning codes and categories to the content, called “encoding,” is synthesized in Fig. 6.12 along with its respective elements. Activities 3.3.1, 3.3.2, and 3.3.3 might be performed by more than one researcher. When it happens, the level of agreement among them should be assessed in Activity 3.3.4, the “intercoder agreement.” The measure used for evaluating the intercoder agreement is Krippendorff’s alpha (Krippendorff 2019), and it is adopted here due to its ability to deal with missing codes and/or categories. As already indicated in Sect. 6.4.3,if α ≤ 0.667, the divergences should be addressed and resolved. It is necessary to distinguish between codes/categories—what counts—and the enumeration rules—the counting mode (Bardin 1993). The enumeration rules aim at quantifying the patterns of occurrence (absence) of codes/categories, as well as their degree of relationship. There are several enumeration rules, and each one has purposes that converge to one or more types of analysis. Table 6.21 presents the enumeration rules most frequently used in LGT. Besides the rules, the table presents their deﬁnitions, and for which type of analysis they are more suitable. After deﬁning the codes and categories, assigning them to the texts, and selecting the appropriate enumeration rules, the next issue is to identify the communica- tion patterns underlying the corpus of analysis. In LGT, this identiﬁcation can be performed by three types of analysis: (i) aggregative, (ii) thematic, and (iii) structural. 6.5 Literature Analysis (Stage 3) 123 Table 6.20 Generic codes and categories Category Deﬁnition Example of codes Context The context in which the research is undertaken, e.g., industry, the ﬁeld of study, region, etc. Automotive, mobility, and energy industries Scientiﬁc method The scientiﬁc method used to perform the research Inductive, deductive, hypothetic-deductive, and abductive Research method The research method employed to carry out the research Case study, action research, design science research, etc. Artifact’s evaluation approach The approach used to evaluate the designed artifact Observational, analytical, experimental, etc. Technique The technique used to execute a particular research step Analytical Hierarchy Process (AHP), Failure Modes and Effects Analysis (FMEA), etc. Class of problems A class that organizes the artifacts intended to solve a particular problem Product family modeling, product family conﬁguration, etc. Antecedent The events inducing the occurrence of a phenomenon Material waste, ﬁnancial loss, turnover, etc. Phenomenon The fact or situation that is observed to exist or happen Modularity, supply chain management, etc. Consequence The consequences of the occurrence of a phenomenon Lead time reduction, proﬁt increasing, etc. Outcomes The outcomes retrieved from the research Efﬁciency, throughput, efﬁcacy, immunogenicity, etc. Source Created by authors 6.5.3.1 Aggregative Analysis (Activity 3.3.6) The aggregative analysis aims at standardizing the independent outcomes retrieved from primary studies that compose the corpus of analysis. This standardization serves as a basis for aggregating and synthesizing the outcomes into an integrative knowl- edge that does not exist when only the individual studies are evaluated (Webster and Watson 2002). In LGT, the outputs of independent studies might be of ﬁve types (Higgins et al. 2020b): (i) the dichotomous or binary data, where each outcome is one of only two possible categorical responses; (ii) the continuous data, where each outcome is a measurement of a numerical quantity; (iii) the counts and rates calculated from counting the number of events occurred; (iv) time-to-event (typically survival) data that analyze the time until an event occurs, but where not all cases experienced the event (censored data); ﬁnally, (v) ordinal data (including measurement scales), where each outcome is one of several ordered categories, or generated by scoring and summing categorical responses. Each data type encompasses different effect 124 6 Literature Grounded Theory (LGT) Context unit Category 2 Category 1 A priori categories A posteriori categories Code 1.2 Code 2.1 Research Protocol Registration unit Corpus of analysis Code 1.1 Registration unit Registration unit Code 2.n Theoretical framework Categorical codes Open codes Fig. 6.12 Elements concerning the encoding activity. Source Created by authors measures. Table 6.22 presents the most commonly encountered effect measures, to which data type they belong, as well as to which synthesis technique they are more suitable. The ﬁnal product of the aggregative analysis comprises the organization of the outcomes retrieved from each primary study composing the corpus, in such a way that they can be compared and later synthesized. This organization is usually undertaken in the form of a table, in which the lines represent the primary studies, and the columns represent the codes and categories. Figure 6.13 gives two examples of tables of comparable outcomes, wherein Fig. 6.13a relates to continuous data and Fig. 6.13b refers to ordinal data. 6.5.3.2 Thematic Analysis (Activity 3.3.7) The thematic analysis tries to reveal the judgment of a theme from an examination of certain constructive elements of the discourse (Quivy 1995). It can be classiﬁed into two types: (i) categorical analysis and (ii) evaluative assertion analysis. The categorical analysis is considered the oldest and most frequently used type of analysis (Quivy 1995). It consists of calculating and comparing the frequencies of certain characteristics (codes) previously grouped into signiﬁcant categories (Bardin 1993). It is based on the rationale that the more frequently cited the more important the code/category is. The relationship between the frequencies of codes and categories follows the principle that if an itemset is frequent, then all of its subsets must also be frequent (Tan et al. 2019). For example, suppose a corpus of analysis (R), composed of six primary studies (r ), i.e., R = {r1, r2, r2, r3, r5, r6}, from which six codes (c), grouped into three categories (C), are identiﬁed after the encoding activity, i.e., C1 = 6.5 Literature Analysis (Stage 3) 125 Table 6.21 Enumeration rules Rule Deﬁnition Type of analysis Aggregative Thematic Structural Occurrence (absence) Ithastodowiththe existence, or non-existence, of a code/category • • • Absolute frequency It refers to the number of times a code/category appears • • • Relative frequency It consists of the number of times a code/category appears divided by the total amount of appearances – • • Absolute weighted frequency It refers to the number of times a code/category appears, moderated by its importance or weight – • – Relative weighted frequency It consists of the number of times a code/category appears divided by the total amount of appearances, moderated its importance or weight – • – Direction It has to do with the orientation of a code/category on a bipolar scale (e.g., negative effect, no effect, and positive effect) • • – Intensity It consists of the absolute frequency of a code/category regarding its direction • • - Order It refers to the order that a code/category appears – • • Co-occurrence It consists of the simultaneous occurrence of two or more codes/categories – – • Conﬁdence It indicates how likely one or more codes/categories appear when other codes/categories are present – – • (continued) 126 6 Literature Grounded Theory (LGT) Table 6.21 (continued) Rule Deﬁnition Type of analysis Aggregative Thematic Structural Lift It indicates how likely one or more codes/categories appear when other codes/categories are present while considering how often these other codes/categories occur – – • Source Created by authors based on Bardin (1993)andTanetal. (2019) {c1.1, c1.2}, C2 = {c2.1, c2.2}, and C3 = {c3.1, c3.2}. Considering the enumeration rule of occurrence (presence or absence of a code/category within a primary study) the absolute and relative frequencies of codes and categories, regarding the corpus of analysis, can be quantiﬁed through the occurrence matrix presented in Table 6.23. However, there are some situations where it is important to consider the number of times a code/category appears in each primary study. In these cases, the absolute and relative frequency of the corpus of analysis is usually weighted by the number of primary studies linked to the code/category (Veit et al. 2017). Table 6.24 gives an example of an absolute frequency matrix used for that purpose. Concerning the evaluative assertion analysis, it focuses on the judgment itself, having its direction and the intensity as the objects of analysis (Quivy 1995). Table 6.25 gives an example of a category with two codes (C4 = {c4.1, c4.2}) that might assume opposite directions (positive or negative judgment). 6.5.3.3 Structural Analysis (Activity 3.3.8) The structural analysis assesses how the elements of the discourse are arranged. Moreover, it tries to reveal underlying and implicit aspects of the message through the building of abstract operative models (Quivy 1995). This type of analysis assumes that the simultaneous presence (co-occurrence) of two or more codes/categories, in the same context unit, provides information about mental and ideological structures as well as latent concerns (Bardin 1993). A common form of representing the association of two nominally scaled variables is the contingency matrix, which records the absolute frequencies of codes/categories pairs, as illustrated by Table 6.26. The contingency table provides some initial indications about the strength of the association between two nominal or ordinal variables. However, the more columns and rows it has, the more difﬁcult it is to recognize and compare the association strengths. The solution is to calculate a parameter that expresses association on a scale from zero (no association) to one (perfect association). One of the most helpful measures used for this purpose is Cramer’s V (Cleff 2019). It ranges from zero to 6.5 Literature Analysis (Stage 3) 127 Table 6.22 Effect measures Data type Effect measure Deﬁnition Type of synthesis Quantitative meta-analysis Qualitative Meta-analysis Dichotomous Risk ratio The ratio of the risk of an event in the two groups • – Odds ratio The ratio of the odds of an event • – Risk difference The difference between the observed risks (proportions of individuals with the outcome of interest) in the two groups • – Continuous Mean difference The absolute difference between the mean value in the two groups • – Standardized mean difference The absolute difference between the mean value, measured in different scales, in the two groups • – Ratio of means The relative difference between the mean value in the two groups • – Counts and rates Count The number of times these events occur • – Rate The relation between counts to the amount of time during which they could have happened • – Time-to-event Hazard ratio It describes how many times more (or less) likely a participant is to suffer the event at a particular point in time if they receive the experimental rather than the comparator intervention • – (continued) 128 6 Literature Grounded Theory (LGT) Table 6.22 (continued) Data type Effect measure Deﬁnition Type of synthesis Quantitative meta-analysis Qualitative Meta-analysis Ordinal Measurement scale The intangible criteria characterized by categorical measures • • Source Created by authors based on Higgins et al. (2020b) Experiment Group (Tamiflu) Control Group (Placebo) Id. Study Name Tamiflu Mean Tamiflu Std-Dev Tamiflu Sample Size Placebo Mean Placebo Std-Dev Placebo Sample Size 1 Primary Study 1 140.600 125.200 933 165.500 156.500 473 2 Primary Study 2 129.000 114.600 240 144.500 118.000 235 3 Primary Study 3 102.400 89.900 204 125.300 98.900 200 4 Primary Study 4 154.000 166.500 17 93.600 134.400 9 5 Primary Study 5 107.600 104.600 31 171.000 177.100 27 6 Primary Study 6 193.700 152.300 199 203.900 146.300 202 7 Primary Study 7 185.000 145.600 358 192.400 145.200 375 8 Primary Study 8 138.700 138.400 226 143.700 125.400 225 Categories Codes Registration units Context units Effects of Modularization in time-to-market Id. Study Name Negative effect No effect Positive effect 1 Primary Study 1 Text quotation indicating the no effect. 2 Primary Study 2 Text quotation indicating the positive effect. 3 Primary Study 3 Text quotation indicating the positive effect. 4 Primary Study 4 Text quotation indicating the positive effect. 5 Primary Study 5 Text quotation indicating the negative effect. 6 Primary Study 6 Text quotation indicating the positive effect. Intensity 1 1 4 Categories Codes Registration units Context units Direction (a) (b) Fig. 6.13 a Effects of Tamiﬂu in the duration of ﬂu symptoms (h); b effects of modularization in time to market. Source Created by authors based on Borenstien (2021) 6.5 Literature Analysis (Stage 3) 129 Table 6.23 Occurrence matrix Codes Categories c1.1 c1.2 c2.1 c2.2 c3.1 c3.2 C1 C2 C3 Primary studies R1 1 1 R2 1 1 1 1 1 R3 1 1 1 1 R4 1 1 R5 1 1 R6 1 1 Absolute frequency 3 2 1 1 1 1 4 2 2 Relative frequency (%) 50 33.3 16.7 16.7 16.7 16.7 66.7 33.3 33.3 Source Created by authors Table 6.24 Absolute frequency matrix Codes Categories c1.1 c1.2 c2.1 c2.2 c3.1 c3.2 C1 C2 C3 Primary studies R1 5 5 R2 2 1 4 3 4 R3 1 2 1 2 R4 3 3 R5 1 1 R6 2 2 Absolute weighted frequency 4 1.3 0.3 0.7 0.2 0.3 8 2 1 Relative weighted frequency (%) 58.5 19.5 4.9 9.8 2.4 4.9 72.7 18.2 9.1 Source Created by authors Table 6.25 Direction/intensity table Codes Categories c4.1 c4.2 C4 Direction + − + − + − Primary studies R1 1 1 1 1 R2 1 1 1 1 R3 1 1 2 R4 1 1 1 1 R5 1 1 1 1 R6 1 1 1 1 Intensity 5 1 2 4 7 5 Source Created by authors 130 6 Literature Grounded Theory (LGT)Table6.26Contingencymatrixc1.1c1.2c1.3c1.4c2.1c2.2c2.3c2.4c2.5c2.6c2.7c3.1c3.2c3.3c3.4c3.5c3.6c3.7c3.8c3.9c3.10c3.11c3.12c4.1c4.2c1.19c1.2516c1.31515c1.451212c2.1243311c2.23644914c2.353227912c2.41112222c2.55433465112c2.6222414c2.721122112c3.135223436111c3.233113444136c3.311333324135c3.432111353112216c3.5312352421125c3.63123422221234c3.7221223314c3.821122111121123c3.92355342564419c3.1011111111111c3.1122221112111112c3.121112221111113c4.11223c4.212233SourceCreatedbyauthors 6.5 Literature Analysis (Stage 3) 131 one, and unlike other measures such as phi or contingency coefﬁcients, Cramer’s V is not sensitive to the matrix size. Concerning the association strength, some authors deﬁne the following ranges (Cleff 2019): • Cramer’s V ∈ [0.00; 0.10[ → no association • Cramer’s V ∈ [0.10; 0.30[ → weak association • Cramer’s V ∈ [0.30; 0.60[ → moderate association • Cramer’s V ∈ [0.60; 1.00] → strong association. In structural analysis, Cramer’s V matrices are particularly useful, since they provide an overview of the association among all the codes/categories making up the analysis. These matrices are generated from the occurrence or absolute frequency matrices, wherein only Cramer’s V coefﬁcients higher than a predeﬁned threshold (usually > 0.3), at a signiﬁcance level of α = 0.05, are considered. Table 6.27 gives an example of a Cramer’s V matrix with coefﬁcients higher than 0.3 that was generated using the R programming language. Although Cramer’s V is quite useful, it has some limitations. For instance, it does indicate the association among more than two codes/categories. Moreover, it does not indicate the direction (the higher the A, the lower the B, e.g., ↑ A ↓ B) nor the sense (from A to B, e.g., A → B) of the relationship between codes/categories. To overcome these limitations, the association analysis can be used. In this context, the uncovered relationships can be represented in the form of association rules or sets of frequent items, such as {c1, c2} → {c3} (Zhang and Zhang 2002). This rule indicates that if the codes c1 and c2 co-occur within a particular context unit, code c3 will occur as well. The left-hand side (lhs) of the rule is called antecedent, while the right-hand side (rhs) is named as consequent. There are some measures indicating the strength of an association rule, which include support, conﬁdence, and lift (Gkoulalas-Divanis and Verykios 2010). Support determines how often a rule applies to the corpus of analysis, while conﬁdence determines how frequently the consequent items appear in relationships containing the antecedent items. Lift computes the leveraging of consequent items whenever the antecedent items occur. For example, suppose a corpus of analysis composed of 36 primary studies, i.e., R = {r1, r2,..., r36}, from which 25 codes were identiﬁed (the same as presented in Table 6.27). After running an association analysis, with the support and conﬁdence thresholds set to 0.15, the following rules are found out: Lhs Rhs Support Conﬁdence Lift Count [#1] {c1.4} → {c1.3} 0.333 1.000 2.400 12 [#2] {c1.3} → {c1.4} 0.333 0.800 2.400 12 … … … … … … … … [#10] {c2.1,c2.2} →. {c2.3} 0.194 0.778 2.333 7 … … … … … … … … [#19] {c2.2} → {c1.2} 0.167 0.429 0.964 6 132 6 Literature Grounded Theory (LGT)Table6.27Cramer’sVmatrixwithcoefﬁcientshigherthan0.3(p-value>0.05)c1.1c1.2c1.3c1.4c2.1c2.2c2.3c2.4c2.5c2.6c2.7c3.1c3.2c3.3c3.4c3.5c3.6c3.7c3.8c3.9c3.10c3.11c3.12c4.1c4.2c1.11.00c1.20.381.00c1.31.00c1.41.001.00c2.11.00c2.20.491.00c2.30.460.321.00c2.41.00c2.50.301.00c2.60.481.00c2.70.411.00c3.10.380.380.301.00c3.20.341.00c3.30.600.800.691.00c3.40.540.400.480.501.00c3.50.491.00c3.60.391.00c3.70.410.671.00c3.80.360.530.330.560.421.00c3.90.310.310.490.380.320.320.320.531.00c3.100.340.370.370.550.430.360.360.580.921.00c3.111.00c3.121.00c4.10.340.311.00c4.20.340.311.001.00SourceCreatedbyauthors 6.5 Literature Analysis (Stage 3) 133 The support of rule #1 indicates that the codes c1.3 and c1.4 co-occur in 33.3% of the primary studies comprising the corpus of analysis. The conﬁdence of the same rule points out that c1.3 is present in 100% of the times c1.4 occurs. The opposite is not true, c1.4 is present in 80% of the times c1.3 occur, as the conﬁdence of rule #2 is depicted. The lift for rule # 1, in turn, indicates that c1.3 is 2.4 × more likely to occur with c1.4 than alone, or associated with other rules. Lift values equal to one indicates no leverage while values lower than one indicate repulsion. Finally, an association rule might encompass more than two codes/categories as shown by rule #10. The association analysis is usually undertaken through algorithm Apriori (Gkoulalas- Divanis and Verykios 2010; Zhang and Zhang 2002), which can be implemented, among other sources, in R programming language (https://cran.r-project.org/web/ packages/arules/arules.pdf). The problem is that correlation (or an association rule) does not always imply causation (Cleff 2019). A correlation without causation is called a spurious corre- lation, and to avoid drawing conclusions based on it, each relationship should be checked for consistency. In LGT, this check is undertaken by following some prin- ciples of causation consistency retrieved from the theory of constraints thinking process. Table 6.28 summarizes these principles and how they can be checked. It is important to highlight that these three types of analysis (aggregative, thematic, and structural) are not mutually exclusive; on the contrary, they can be used concur- rently in the same SLR. At the end of stage 3 (literature analysis), the decomposed parts of the content, as well as their relationships, serve as input ﬂows for the literature synthesis, an issue covered in the next subsection. 6.6 Literature Synthesis (Stage 4) Codes, categories, and their respective properties, when organized in an integrative fashion, are capable of providing knowledge that did not exist in independent primary studies. This is the role of literature synthesis, to generate new knowledge through the integration of decomposed parts comprising the corpus of analysis (Thomas et al. 2012). As seen in Chap. 5, there is a multitude of techniques for synthesizing the literature, and their suitability depends on the objective of the research being under- taken. Table 6.29 presents a guide for choosing the synthesis technique(s) depending on the research objective. As still seen in Chap. 5, although many of these techniques have procedures that overlap with stages 1, 2, and 3 of the LGT, they are characterized as synthesis techniques due to the ﬁnal product of the process, the synthesis of the results. In the LGT, the stage of literature synthesis is divided into two groups, which follow the classiﬁcation proposed by Thomas et al. (2012): (i) aggregative synthesis and (ii) conﬁgurative synthesis. The aggregative synthesis combines the results of multiple primary studies (homogeneous), in a comprehensive and unique result, from which it is possible to test theories or hypotheses. The conﬁgurative synthesis, in turn, integrates elements from several primary studies (heterogeneous) in a high-level 134 6 Literature Grounded Theory (LGT) Table 6.28 Principles of causation consistency Principle Illustration Guidance for checking 1. Causality existence Check for the existence of each cause-effect relationship using the “if-then” or “because” statements. For example, if [A] exists, then [B] exists; or [B] exists because of [A]. Additional questions can be used for clarifying the causality existence, they are: (i) how do I/we/you know? (ii) is this always the case? (iii) under what circumstances is this the case? (iv) under what circumstances is this not the case? 2. Causality clarity Ensure that each extant cause-effect relationship is modeled clearly and concisely. A good test is to read aloud the relationship as an “if-then” statement or as a “because” statement. An indicator that the cause-and-effect relationship is not yet clear enough is if you read it aloud to someone and feel compelled to explain further what it means 3. Sufﬁciency or insufﬁciency of cause Among the extant cause-effect relationships, check for those sharing the same effect using the “if-and-then” or “because-and” statements. The causes ﬁtting in these statements represent the ones, when occurring together, produce the effect. For example, if [A] and [B] exists, then [C] exist; or [C] exists because of [A] and [B] 4. Additional cause Among the extant cause-effect relationships, check for those sharing the same effect using the “if-or-then” or “because-or” statements. The causes ﬁtting in these statements represent the ones that produce the effect regardless of occurring together. For example, if [A] or [B] exists, then [C] exists; or [C] exists because of [B] or [A] Source Created by authors based on Cox and Schleier (2010) and Lacerda et al. (2011) abstract model, capable of describing or generating new theories and hypotheses. Next subsections highlight some of the techniques commonly adopted in LGT. 6.6.1 Aggregative Synthesis (Step 4.1) When the objective is to obtain the effect of a given intervention, based on the indepen- dent results of multiple studies using control (which did not suffer the intervention) and response groups (which suffered the intervention), quantitative meta-analysis is the most suitable technique (Littell et al. 2008). Commonly used in health science, this technique uses the output of aggregative analyses (table of comparable outcomes, e.g., Fig. 6.13a) to generate a summary quantiﬁcation of the intervention effect. The effect can be estimated through the ﬁxed or random-effect(s) models. The ﬁxed- effect model assumes that there is one true effect size underlying all the studies in 6.6 Literature Synthesis (Stage 4) 135 Table 6.29 Guide for choosing the synthesis techniques Review type Conﬁgurative Aggregative Overall objective Describe Explore Explain Speciﬁc objective(s) Broaden the comprehension of a subject Identify scientiﬁc and technological gaps Build theories or hypotheses Identify artifacts –Test theories or hypothesis –Evaluate technological effects (artifacts) Synthesis technique Narrative synthesis Integrative synthesis – Meta- ethnography – Meta-synthesis Ecological triangulation – Quantitative meta- analysis – Qualitative meta- analysis – Realistic synthesis Source Created by authors the analysis, and that all differences in observed effects are due to sampling error. By contrast, the random-effects model takes into account the heterogeneity across studies, thus assuming that the true effect size might differ from one study to another (Borenstein et al. 2009; Higgins et al. 2020a). The results of quantitative meta-analyses are usually illustrated using a forest plot, as shown in Fig. 6.14. A forest plot displays effect estimates and conﬁdence intervals Id. Study Name Difference in means p-value Difference in means and 95% confidence interval 1 Primary Study 1 -24.900 0.003 2 Primary Study 2 -15.500 0.147 3 Primary Study 3 -22.900 0.015 4 Primary Study 4 60.400 0.317 5 Primary Study 5 -63.400 0.103 6 Primary Study 6 -10.200 0.494 7 Primary Study 7 -7.400 0.491 8 Primary Study 8 -5.000 0.688 Summary result -16.759 0.000 -100.00 Context units -50.00 0.00 50.00 100.00 Favors Tamiflu Favors Placebo Weight Confidence interval Line of no effect Meta-analysis Effect measure Fig. 6.14 Impact of Tamiﬂu on ﬂu symptoms (hours to relief). Source Created by authors based on Borenstien (2021) 136 6 Literature Grounded Theory (LGT) for both individual studies and meta-analyses. Each study is represented by a block with a horizontal line, wherein the area of the block indicates the weight assigned to the study while the horizontal line depicts its conﬁdence interval (usually with a 95% level of conﬁdence) (Higgins et al. 2020a). The conﬁdence interval depicts the range of intervention effects compatible with the study’s result. If this horizontal line crosses the vertical line of no effect, the null hypothesis of difference in means being equals to zero is rejected. This can also be veriﬁed by the p-values higher than the signiﬁcance level of 5%. The size of the block draws the eye toward the studies with larger weight, which dominate the calculation of the summary result, presented as a diamond at the bottom. The effect measure illustrated in Fig. 6.14 consists of the means difference; however, the reasoning presented above also applies to the other effect measures given in Table 6.22. The results of a quantitative meta-analysis can be obtained by software comprehensive meta-analysis (https://www.meta-analysis.com/), or by R programming language (https://cran.r-project.org/web/packages/meta/meta.pdf). Although the forest plot provides a graphic representation of the qualitative meta- analysis, it should be complemented by a summary of results, as suggested by Fig. 6.15. There are situations, such as those found in operations management research, that hardly allow the use of control groups. In these cases, response groups are commonly used, in which the context is evaluated before and after the intervention. In addition to the absence of control groups, the results of this type of study tend to be heterogeneous, and for the most part presented in different types of scale. In this condition, the most appropriate technique to be used is qualitative meta-analysis. The qualitative meta-analysis combines the votes counting with the agreement analysis to estimate a summary quantiﬁcation of the intervention effect. Figure 6.16 exhibits the sequence of activities required to perform this type of synthesis. The table of comparable outcomes retrieved from the aggregative analysis serves as input ﬂow for Activities 4.1.1 and 4.1.2. This table classiﬁes the primary studies based on ordinal data, wherein the Likert or Phrase Completion scales can be used. In Activity 4.1.1, the absolute frequency of each point on the scale (codes) is calculated, giving rise to the intensity of the effect, as indicated at the bottom of Fig. 6.13b. In parallel, the level of agreement among the effects of each primary study is assessed either by Fleiss’ kappa (k) or Krippendorff’s alpha (α). Finally, in Activity 4.1.3, the effect of the intervention is accounted for. In this activity, two results are possible. The ﬁrst concerns the situation in which there is no agreement on the effect among the studies (k ≤ 0.41; α ≤ 0.667). In this condition, when using a bipolar Likert scale, as adopted in Fig. 6.13b, the result is of “no effect,” regardless of the intensity reached. The second occurs when the level of agreement calculated is k > 0.41 or α> 0.667. In this condition, it is the intensity that will determine the intervention effect. Using Fig. 6.13b as an example, the result of the intervention would be of “positive effect.” In LGT, the output of qualitative meta-analysis is usually synthesized following the CIMO logic. The reasoning behind CIMO is as follows: for this problem-in-context, it is (not) useful to conduct this intervention, which will (not) produce the outcome through these mechanisms (Denyer et al. 2008). 6.6 Literature Synthesis (Stage 4) 137 Fig. 6.15 Example of quantitative meta-analysis report. Source Borenstien (2021) 6.6.2 Conﬁgurative Synthesis (Step 4.2) When the objective is to build an abstract model, capable of explaining or exploring the underlying aspects of a set of independent and heterogeneous studies, the most suitable techniques are meta-synthesis (Walsh and Downe 2005) and meta- ethnography (Noblit and Hare 1988). As seen in Chap. 5, these techniques are quite similar, and the contribution of both to the conﬁgurative synthesis of LGT lies in their ﬁnal stages: (i) synthesizing translations (from meta-synthesis and meta-ethnography) and (ii) expressing the synthesis (from meta-ethnography). 138 6 Literature Grounded Theory (LGT) Fig. 6.16 Sequence of activities to perform the qualitative meta-analysis. Source Created by authors 3.3.6 Aggregative Analysis Activities of step 4.1 Information flow 4.1.1 Summing of the categorical responses 4.1.2 Interstudy agreement Level of agreement ( , ) Intensity 4.1.3 Intervention effect Table of comparable outcomes In the context of LGT, “synthesize translations” consists of connecting the cause- effect relationships, retrieved from the structural analysis (activity 3.3.8), into a single model through a continuous comparative evaluation of texts until a comprehensive understanding of the phenomena is realized. In terms of “expressing the synthesis,” it refers to the communication with the audience. According to Noblit and Hare (Noblit and Hare 1988), the audience inﬂuences both the form and substance of the synthesis, and therefore it is required to ensure that the translation of studies for the synthesis uses intelligible concepts to inform the ﬁnal presentation of synthesis. In practical terms, the outcomes of a conﬁgurative synthesis are represented by network-based models or frameworks, along with their summary description. Figure 6.17 provides three distinct models used for synthesis. Figure 6.17a presents a causal-loop diagram used to describe the role of equity-funded entrepreneurial start-up system in assessing technology development risk and deciding where to allocate capital (Yearworth and White 2013). Figure 6.17b depicts a functional model used to connect 72 methods to design modular product families into a meta- method (Gauss et al. 2021). Finally, Fig. 6.17c shows a conceptual framework used to explain the wishing of hastening death in patients with chronic or advanced illness (Monforte-Royo et al. 2012). Concerning the summary description of the models, it is not only required to deﬁne the constructs and variables, but also characterize their relationships (propositions or hypotheses). In this context, the references of Fig. 6.17 provide good examples of how to perform it. Besides that, as well as used for qualitative meta-analysis, the CIMO logic can also be used for this purpose. 6.6 Literature Synthesis (Stage 4) 139 Fig. 6.17 Examples models used for synthesis: a causal-loop diagram; b functional module; c conceptual framework. Source Gauss et al. (2021), Monforte-Royo et al. (2012), Yearworth and White (2013) 140 6 Literature Grounded Theory (LGT) Fig. 6.17 (continued) 6.7 Results (Stage 5) At this stage, the obtained results of SLR must be presented. The choice of which structure to follow will depend on the work being undertaken. For example, an SLR can take the form of a dissertation, thesis, or book chapter. Moreover, it can also compose a section of a scientiﬁc article, or even take the form of a complete article. There is a multitude of guidelines on how to structure a research report. For instance, the PRISMA statement requires reports containing the following sections: (i) abstract, (ii) introduction, (iii) research protocol, (iv) evaluation of the risk of bias, (v) results, and (vi) ﬁnancing (Moher et al. 2009). For the Cochrane reviews, in turn, the research report should be structured as follows: (i) context and research question, (ii) research objectives, (iii) research method, (iv) selection criteria, (v) data collection and analysis, (vi) results, and (vii) conclusions (Higgins and Green 2011). Although these structures can be used for different ﬁelds of study, they were originally conceived for health sciences, thus requiring adaptations whenever instantiated in other areas. In this sense, to be more generic in nature, the LGT adopts the structure presented in Fig. 6.2: (i) design, (ii) review, (iii) analysis, (iv) syntheses, and (v) results. 6.8 Update (Stage 6) 141 Table 6.30 Directives for updating SLR Id Directive 1 The update should occur every 2 years 2 When updating an SLR, changes in the research question might be considered 3 When no changes in the research question are required, the ﬁrst step is to update the eligibility criteria. More speciﬁcally, the time horizon, by considering the end date of the previous review as the start date of the new one 4 If there are methodological advances and the authors believe that they can improve the research results, they should be incorporated in the new SLR Source Created by authors based on Higgins and Green (2011) 6.8 Update (Stage 6) Given the rapid advance of science and technology, the updating of SLR has become essential to keep the research results up to date. To do this, Stage 6 of LGT follows the directives by Cochrane collaboration, as given in Table 6.30. It is important to note that when there are advances in the research method used to carry out the SLR, or opportunities for improvement regarding the review strategy, the new research must be undertaken from the period used by the original review. However, when the search terms are included or the original terms are changed, the update of the systematic review must cover the period covered by the original review (Higgins and Green 2011). When new research is not found during the update, this result should be recorded in the relevant sections of the review. However, if new studies are found in the updated review, they must be submitted to all the methodological steps of the research method used (Higgins and Green 2011). 6.9 Closing Remarks This chapter presented the Literature Grounded Theory (LGT), a research method for reviewing, analyzing, and synthesizing literature. By following the six LGT stages, it is possible to obtain scientiﬁc and technological knowledge from the research existing in Popper’s World 3. Different from existing methods, the LGT provides a holistic view of the SLR process, as well as overcomes the limitations of current methods in being ﬁeld dependent. Depending on the review question and objectives, it is possible to deﬁne the route to be taken and the most suitable techniques to be used, as shown in Fig. 6.18. Besides the theoretical foundations and methodological procedures provided by the chapters so far, the next chapter will approach the SLR from a perspective of computational tools to operationalize it. 142 6 Literature Grounded Theory (LGT) Open ClosedResearch question DescribeOverall objective Explore Explain Broaden the comprehension of a subject Specific objective Identify scientific and technological gaps Build theories or hypotheses Identify artifacts Test theories or hypothesis Evaluate technological effects (artifacts) Configurative AggregativeType of review Heterogeneous HomogeneousType of data Analysis Scientometrics analysis Bibliometrics analysis Content analysis Narrative synthesis Synthesis Integrative synthesis Meta-synthesis Meta-ethnography Ecological triangulation Qualitative / Quantitative meta-analysis Realistic synthesis Fig. 6.18 Framework for conducting SLR with LGT. Source Created by authors References Abbas, A., Zhang, L., Khan, S.U.: A literature review on the state-of-the-art in patent analysis. World Patent Inf. 1–11 (2014) Adler, M.J., van Doren, C.: How to Read a Book. A Touchstone Book Published by Simon & Schuster, New York (1972) Aria, M., Cuccurullo, C.: bibliometrix: an R-tool for comprehensive science mapping analysis. J. Inf. 11(4), 959–975 (2017). 1751-1577 Bacharach, S.B.: Organizational theories: some criteria for evaluation. Acad. Manage. Rev. 14(4), 496–515. 1989.03637425 Bardin, L.: L’analyse de contenu [Content Analysis], 223 p. Presses Universitaires de France Le Psychologue, Paris (1993) Barnett-Page, E., Thomas, J.: Methods for the synthesis of qualitative research: a critical review. BMC Med. Res. Methodol. 9(1), 1–11 (2009). 1471-2288 Bensman, S.J.: Garﬁeld and the impact factor. Ann. Rev. Inf. Sci. Technol. 41(1), 93–155 (2007). 1573872768 Bergstrom, C., West, J.: Eigenfactor® (2017) Bhattacherjee, A.: Social Science Research: Principles, Methods, and Practices, 3rd ed [S.l.]. Textbooks Collection (2012). 9781475146127 Booth, A. et al.: Structured methodology review identiﬁed seven (RETREAT) criteria for selecting qualitative evidence synthesis approaches. J. Clin. Epidemiol. 99, 41–52 (2018) Borenstein, M.: Impact of Tamiﬂu on ﬂu symptoms [S.l: s.n.] (2021). Disponível em: www.Meta- Analysis.com. Acesso em: 3 fev. 2021 Borenstein, M., et al.: Introduction to Meta-Analysis, 421 p. Wiley, Padstow (2009). 978-0-470- 05724-7 Brunton, G., Stansﬁeld, C., Thomas, J.: Finding relevant studies. In: An Introduction to Systematic Reviews, pp. 107–134. Sage Publications Ltd., London (2012) CGCOM: Instituto Nacional da Propriedade Industrial (2016) References 143 Chaabna, K., et al.: Gray literature in systematic reviews on population health in the Middle East and North Africa: protocol of an overview of systematic reviews and evidence mapping. Syst. Rev. 7(94), 1–6 (2018) Cleff, T.: Applied Statistics and Multivariate Data Analysis for Business and Economics [S.l.], 487 pp. Springer (2019). 9783030177669. Cobo, M.J., et al.: Science mapping software tools: review, analysis, and cooperative study among tools. J. Am. Soc. Inf. Sci. 62(7), 1382–1402 (2011) Colicchia, C., Strozzi, F.: Supply chain risk management: a new methodology for a systematic literature review. Supply Chain Manage. 17(4), 403–418 (2012). 1359-8546 Cooper, H., Hedges, L.V., Valentine, J.C.: Handbook of Research Synthesis and Meta-Analysis, 2nd edn., 610 pp. Russel Sage Foundation, New York (2009). 9780871541635 Counsell, C.: Formulating questions and locating primary studies for inclusion in systematic reviews. Ann. Int. Med. 127(5), 380–387 (1997) Cox, J.F., Schleier, J.G.: Theory of Constraints Handbook, 1175 pp. McGraw-Hill, New York (2010). 9780071665551 Deb, D., Dey, R., Balas, V.E.: Bibliometrics and research quality. In: Engineering Research Method- ology. Intelligent Systems Reference Library, vol. 153. 1st edn., pp. 95–105. Springer Nature, Singapore (2019). 978-981-13-2947-0 Denyer, D., Tranﬁeld, D., Van Aken, J.E.: Developing design propositions through research synthesis. Organizat. Stud. 29(3), 393–413 (2008). 0170-8406 Dresch, A., Lacerda, D.P., Antunes, Jr., J.A.V.: Design Science Research: A Method for Scientiﬁc and Technology Advancement, 1st edn, 161 pp. Springer (2015). 978-3-319-07373-6 Dybå, T., Dingsøyr, T.: Empirical studies of agile software development: a systematic review. Inf. Soft. Technol. 50(9–10), 833–859 (2008) Fleiss, J.L.: Measuring nominal scale agreement among many raters. Psychol. Bull. 76(5), 378–382 (1971) Garousi, V., Felderer, M., Mäntylä, M.V.: Guidelines for including grey literature and conducting multivocal literature reviews in software engineering. Inf. Soft. Technol. 1–22 (2018). 9781450336918 Gauss, L., Lacerda, D.P., Cauchick Miguel, P.A.: Module-based product family design: systematic literature review and meta-synthesis. J. Intell. Manufact. 32(1), 265–312 (2021) Gkoulalas-Divanis, A., Verykios, C.S.: Association Rule Hiding for Data Mining [S.l.], 150 pp. Springer (2010). 978-1-4419-6569-1 Gough, D., Oliver, S., Thomas, J.: An Introduction to Systematic Reviews, 1st edn., 288 pp. SAGE Publications, Los Angeles (2012). 9781849201803 Green, B.N., Johnson, C.D., Adams, A.: Writing narrative literature reviews for peer-reviewed journals: secrets of the trade. J. Chiripratic Med. 5(3), 101–117 (2006). 0024-3892 Grimshaw, J.M., et al.: Effectiveness and efﬁciency of guideline dissemination and implementation strategies. Health Technol. Assess. 8(6), 349 (2004) Gutiérrez-Salcedo, M., et al.: Some bibliometric procedures for analyzing and evaluating research ﬁelds. Appl. Intell. 48(5), 1275–1287 (2017) Haddow, G.: Bibliometric research. In: Research Methods: Information, Systems, and Contexts, 2nd edn., pp. 241–266. Chandos Publishing, Cambridge (2018). 978-0-08-102220-7 Hammerstrøm, K., et al.: Searching for studies: information retrieval methods group policy brief, November (2009) Harden, A., Gough, D.: Quality and relevance appraisal. In: An introduction to systematic reviews, 1st edn., pp. 153–178. SAGE Publications, Los Angeles (2012) Hart, C.: Doing a Literature Review: Realising the Social Science Research Imagination, 1st edn., 230 pp. SAGE Publications, London (1998) Higgins, J., Green, S.: Cochrane Handbook for Systematic Reviews of Interventions (2011) Higgins, J., Li, T., Deeks, J.J.: Analysing data and undertaking meta-analyses. In: Cochrane Hand- book for Systematic Reviews of Interventions version 6.1 [S.l: s.n.] (2020a). Disponível em: https://training.cochrane.org/handbook/current/chapter-10 144 6 Literature Grounded Theory (LGT) Higgins, J., Li, T., Deeks, J.J.: Choosing effect measures and computing estimates of effect. In: Cochrane Handbook for Systematic Reviews of Interventions Version 6.1 [S.l.]. Cochrane (2020b). Disponível em: www.training.cochrane.org/handbook Hood, W.W., Wilson, C.S.: The literature of bibliometrics, scientometrics, and informetrics. Scientometrics 52(2), 291–314 (2001) Hsieh, H.F., Shannon, S.E.: Three approaches to qualitative content analysis. Qualitat. Health Res. 15(9), 1277–1288 (2005). 1049-7323 Kitchenham, B., Charters, S.: Guidelines for performing systematic literature reviews in software engineering. Engineering 45(4ve), 1051 (2007). 1595933751 Krippendorff, K.: Content Analysis: An Introduction to Its Methodology, 4th edn., 356 pp. Sage Publications, Inc., Thousand Oaks (2019) Lacerda, D.P., Rodrigues, L.H., Da Silva, A.C.: Evaluating the synergy of business process engineering and theory of constraints thinking process. Production 21(2), 284–300 (2011) Landis, J.R., Koch, G.G.: The measurement of observer agreement for categorical data. Biometrics 33(1), 159 (1977) Littell, J.H., Corcoran, J., Pillai, V.: Systematic Review and Meta-Analysis [S.l: s.n.], 1–211 pp. (2008). 978-0-19-532654-3 Macedo, M.F.G., Muller, A.C.A., Moreira, A.C.: Patenteamento em biotecnologia: um guia prático para os elaboradores de pedidos de patente [S.l.], 200 pp. Editora Embrapa (2001) Mering, M.: Bibliometrics: Understanding author, article and journal-level metrics. J. Ser. Rev. 43(1), 41–45 (2017) Moher, D., et al.: Preferred reporting items for systematic reviews and meta-analyses: the PRISMA statement. PLoS Med. 6(7) (2009). 0031-9023 Monforte-Royo, C., et al.: What lies behind the wish to hasten death? A systematic review and meta-ethnography from the perspective of patients. PLoS ONE 7(5) (2012). 1932-6203 Morandi, M.I.W.M., Camargo, L.F.R.: Systematic Literature Review. Design In: Science Research [S.l.], p. 161. Springer (2015) Noblit, G.W., Hare, R.D.: Meta-Ethnography: Synthesizing Qualitative Studies, 1st edn. SAGE Publications, Newbury Park (1988). 9780803930230 OECD: OECD Glossary of Statistical Terms. OECD Publishing, Paris (2008) Oliveira, O.J. De., et al.: Bibliometric method for mapping the state-of-the-art and identifying research gaps and trends in literature: an essential instrument to support the development of scientiﬁc projects. IntechOpen 20 (2019) Osareh, F.: Bibliometrics, citation analysis and co-citation analysis: a review of literature I. Libri 46(1), 149–158 (1996) Pate, D.J., Patterson, M.D., German, B.J.: Optimizing families of reconﬁgurable aircraft for multiple missions. J. Aircraft title (Snowball Cit. 2nd iteration) 49(6), 1988–2000 (2012) Petticrew, M., Roberts, H.: Systematic Reviews in the Social Sciences: A Practical Guide, 1st edn., 336 pp. Blackwell Publishing, Malden, MA (2006). 1473314060098 Popper, K.: Objective knowledge, 1st edn., 394 pp. Clarendon Press, Oxford (1972) Quivy, R.: Manuel de Recherche en Sciences Sociales [Manual of Scientiﬁc Research in Social Science]. Dunod, Paris (1995). Disponível em: https://tecnologiamidiaeinteracao.ﬁles.wordpr ess.com/2018/09/quivy-manual-investigacao-novo.pdf. 9789726622758 Renz, S.M., Carrington, J.M., Badger, T.A.: Two strategies for qualitative content analysis: an intramethod approach to triangulation. Qualitat. Health Res. 28(5), 1–8 (2018) Saini, M., Shlonsky, A.: Systematic Synthesis of Qualitative Research, 1st edn., 223 pp. Oxford University Press, New York (2012). 9780195387216 Sandelowski, M. et al.: Mapping the mixed methods-mixed research synthesis terrain. J. Mixed Methods Res. 6(4), 317–331 (2011) Scopus: Scopus database (2020) Smith, V., et al.: Methodology in conducting a systematic review of systematic reviews of healthcare interventions. BMC Med. Res. Methodol. 11(15), 1–6 (2011) References 145 Snyder, H.: Literature review as a research methodology: an overview and guidelines. J. Bus. Res. 104(March), 333–339 (2019). Disponível em: https://doi.org/10.1016/j.jbusres.2019.07.039 Strauss, A., Corbin, J.: Basics of Qualitative Research: Grounded Theory Procedures and Techniques, 2nd edn., 272 pp. SAGE Publications, Newbury Park (1990). 978-1412906449 Tan, P.-N., et al.: Introduction to Data Mining, 2nd edn., 864 pp. [S.l.]. Pearson (2019) Thelwall, M.: Bibliometrics to webometrics. J. Inf. Sci. 34(4), 605–621 (2008) Thomas, J., Harden, A., Newman, M.: Synthesis: combining results systematically and appropri- ately. In: An Introduction to Systematic Reviews, 1st edn., p. 288. Sage Publications, Los Angeles (2012) Thomé, A.M.T., Scavarda, L.F., Scavarda, A.J.: Conducting systematic literature review in operations management. Product. Plann. Control 27(5), 408–420 (2016) Universidade de São Paulo: Portal da escrita cientíﬁca (2019) Veit, D.R., et al.: Towards mode 2 knowledge production. Bus. Process Manage. J. 23, 293–328 (2017) Walsh, D., Downe, S.: Meta-synthesis method for qualitative research: a literature review. J. Adv. Nurs. 50(2), 204–211 (2005). 1365-2648 Webster, J., Watson, R.T.: Analyzing the past to prepare for the future: Writing a literature review. MIS Quart. 26(2), 133–151 (2002). 0959-5309 Whiting, P., et al.: ROBIS: a new tool to assess risk of bias in systematic reviews was developed. J. Clin. Epidemiol. 69, 225–234 (2016) Whittemore, R., Knaﬂ, K.: The integrative review: updated methodology. Methodol. Issues Nurs. Res. 52(5), 546–553 (2005) Wohlin, C.: Guidelines for snowballing in systematic literature studies and a replication in software engineering. ACM Int. Conf. Proc. Ser. (2014). 9781450324762 Yearworth, M., White, L.: The uses of qualitative data in multimethodology: developing causal loop diagrams during the coding process. Eur. J. Operat. Res. 231(1), 151–161 (2013). Disponível em: https://doi.org/10.1016/j.ejor.2013.05.002 Zapf, A. et al.: Measuring inter-rater reliability for nominal data—which coefﬁcients and conﬁdence intervals are appropriate? BMC Med. Res. Methodol. 16(1), 1–10 (2016). Zhang, C., Zhang, S.: Association Rule Mining: Models and Algorithms [S.l.], 238 pp. Springer (2002). 3-540-43533-6 Zupic, I., ˇCater, T.: Bibliometric methods in management and organization. Organizat. Res. Methods 18(3), 429–472 (2015) Chapter 7 Computational Tools for Literature Review, Analysis, and Synthesis Édison Renato Silva, Liane Mahlmann Kipper, Rosiane Serrano This chapter discusses the academic workﬂow of software that can support literature review, analysis, and synthesis using the Literature Grounded Theory (LGT) method. Emphasis will be placed on functionality, not software tools themselves, as certain software tends to vary over time in response to market conditions. However, the prescribed academic workﬂow of computational tools for LGT will be illustrated using some usual computational tools. Table 7.1 describes the types of computational tools that can support the LGT Method. There are commercial and free tools. Commercial software tends to aggre- gate more than one functionality, such as reference management and data analysis, for example, while free options tend to be more speciﬁc, involving only one functionality and requiring software integration. There are several ways to set up an academic workﬂow for LGT. Speciﬁcally, for literature review, analysis and synthesis, researchers can either use all-in-one software or combine speciﬁc software to arrive at a complete solution. The combination needs to be carried out properly, to avoid rework resulting from overlapping stages or gaps in which data needs to be manipulated manually. There are different approaches to evaluating the available tools. Different considerations related to budget, previous software familiarity, language restrictions, and the speciﬁc needs of the research project must be considered for an optimal choice. Figure 7.1 provides an overview of the academic workﬂow for conducting research using LGT. For example, in the second stage of the LGT (Review), the research team will need to access databases and select metadata. Usual sources include academic databases (such as Web of Science, Scopus, and Google Scholar), editor sites (such as Springer, Elsevier, and Wiley), book libraries and vendors (Google Books and The original version of this chapter was revised: Figure 7.1 was updated. The correction to this chapter can be found at https://doi.org/10.1007/978-3-030-75722-9_10 © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_7 147 148 7 Computational Tools for Literature Review Table 7.1 LGT steps and software categories that support each step LGT steps Supporting software categories 1.1 Research question formulation Text editing 1.2 Deﬁnition of review scope and type Text editing 1.3 Deﬁnition of the research team Text editing 1.4 Deﬁnition of the search strategy Text editing 1.5 Formulation of the research protocol Text editing 1.6 Bias assessment Text editing 2.1 Search and eligibility Reference management 2.2 Quality assessment Reference management 2.3 Reliability assessment Reference management 2.4 Organization of the corpus of analysis Reference management 3.1 Scientometric analysis Scientometrics/bibliometrics 3.2 Bibliometric analysis Scientometrics/bibliometrics 3.3 Content analysis Content analysis 4.1 Aggregative synthesis Text editing 4.2 Conﬁgurative synthesis Text editing 5.1 Research report Text editing 6.1 Research update Text editing Source Created by authors Amazon, e.g.), and speciﬁc sites and social networks (Semantic Scholar, Research- Gate, Academia.Edu, etc.). Metadata, as described in Box 4.1, is “data about data,” which in the speciﬁc case of academic research refers to all kinds of informa- tion surrounding a given publication: authors, title, year of publication, publication source, publisher, the afﬁliation of the authors and so on. The importance of appro- priate, unbiased procedures to manipulate metadata grows with the ever-increasing number of publications available. The challenge is to select contributions to a given topic from a larger number of possible candidates without excluding anyone due to spurious criteria. After ﬁnding and ﬁltering metadata, researchers will search the web for the full text of selected publications, evaluate their quality and decide whether or not to include them in the literature review. A reference manager is a prime software to support dealing with metadata and full-text PDF ﬁles. Bibliometric and scientometric anal- ysis, which rely upon speciﬁc software packages, help researchers create a bird’s eye view of metadata, providing valuable context that can help understand the evolution of a speciﬁc ﬁeld. Data from selected publications will be extracted during the LGT 7 Computational Tools for Literature Review 149 Synthesis of the results Text editing Validated protocol 1 Design 2 Review 3.1 Scientometric / bibliometric 3.3 Content analysis Corpus of analysis (full-texts) Corpus of analysis (meta-data) 3 Analysis Codes, categories, and relationships Scientific development indicators 4 Synthesis Performance indicators and networks Comparable outcomes Text editing 5 Results Text editing Time interval6 UpdateStakeholders Software categories Information flow Feedback flow Reference Management 3.2 Scientometric / bibliometric Validated protocol (data analysis) Text editing Fig. 7.1 Software-based perspective of the LGT method. Source Created by authors Table 7.2 Examples of software available for each category Categories Software Text editing Word processors (MS Word, Google Docs, Apple Pages), TeX editors (TeXmaker, OverLeaf), Professional writing (Scrivener, Ulysses) Reference management Zotero, Mendeley, EndNote, Rayyan, Bookends Scientometric/bibliometric Bibexcel, CiteSpace, CoPalRed, IN-SPIRE, Network Workbench Tool, Science of Science (Sci2) Tool, SciMAT, VantagePoint, VOSViewer Content analysis NVivo, ATLAS.ti, QDA Miner, Quirkos, MAXQDA, Dedoose, webQDA, QCAmap, Iramuteq All-encompassing DistillerSR, JBI Sumari, Cochrane RevMan Source Created by authors Review stage, and then manipulated following procedures speciﬁcally developed to protect the research from possible biases. Then, a conclusion will be created and communicated as the result of the synthesis stage of the LGT method. There are numerous options commercially available for each software category. Table 7.2 shares a non-exhaustive list of some of the most popular choices. Each section in this chapter will deal with the computational tools that support each of the stages of the LGT process, starting with the elaboration of LGT protocols. 150 7 Computational Tools for Literature Review 7.1 Writing Review, Analysis, and Synthesis Protocols As explained in Chap. 6, one of the ﬁrst steps in reviewing, analyzing, and synthe- sizing the literature under the LGT is to develop the research protocol. Protocol formats vary signiﬁcantly between academic disciplines (Silva et al. 2018). Research protocols can be written using all sorts of text editors. Some options are widespread, such as Microsoft Word, Google Docs, and LibreOfﬁce. Others are less common outside speciﬁc academic domains that involve mathematics, such as TeX editors. Others are software for professional (meaning book) writers. The choice of software will depend on the research team’s decision, the researcher’s afﬁnity, accessibility, and several other factors. Section 7.6 will discuss these options in detail. To help researchers synchronize changes, work in the same version, and have a backup of their edits, a cloud-based solution (such as Google Docs or Microsoft Ofﬁce 365 with OneDrive) is recommended. Box 7.1 provides further information for this recommendation. A cloud-based version of the research protocol can also be shared with a selected number of fellow researchers outside the research team, providing them with a web-based, easy-to-use interface for suggestions and edits. Box 7.1 Factors that positively impact the use of Cloud-based text editing tools: • Their widespread use, and some free options (such as Google Docs); • The easiness to share, edit and update a single version of a protocol; • The ability to control access to the document, allowing comments, sugges- tions, and edits easily; • The ability to export the developed document to usual text formats, such as PDF, RTF, DOC. Once the protocol has been written and shared with the group of researchers selected for feedback, the research team can choose to share the protocol openly on the internet. In this case, for the health sciences ﬁeld, the Cochrane Database of Systematic Reviews (www.cochranelibrary.com) provides easy access to systematic literature review protocols. In this same ﬁeld, the need to register and disseminate systematic reviews on COVID-19 led to the creation of PROSPERO (https://www. crd.york.ac.uk/prospero/) to register reviews faster than usual. Other academic areas, such as Business and Management, Crime and Justice, Disability, Education, Inter- national Development (including nutrition), and social welfare, can beneﬁt from the Campbell Collaboration (https://campbellcollaboration.org/), which describes itself as a sister to the Cochrane Collaboration and focuses on systematic reviews of research evidence on the effectiveness of social interventions involving many disci- plines. The Campbell Collaboration publishes reviews, policy briefs, and evidence gap maps, but does not provide protocols for systematic reviews. 7.1 Writing Review, Analysis, and Synthesis Protocols 151 Fig. 7.2 Projects—research protocols at ResearchGate. Source Created by authors in ResearchGate Some researchers publish their protocols on open and freely distributed websites, such as arXiv (https://arxiv.org/), or the academic social network Research- Gate (https://www.researchgate.net/). ResearchGate, as shown in Fig. 7.2, allows researchers to publish a review, analysis, and synthesis protocol as part of a research project, making their work largely visible to the community of scholars and practitioners. Thus, depending on the ﬁeld researchers are working in, speciﬁc solutions will be needed to write and disseminate the protocols for review, analysis, and synthesis. The next section will cover the process of exporting metadata. 7.2 Accessing and Exporting Metadata and Full Texts Literature reviews, analyzes, and syntheses depend on metadata and access to the full text of publications. As deﬁned in Box 4.1, metadata is a set of data that describe and provide information about other data—in particular, data about the publication (title, year of publication, abstract, keywords, for example), the authors (names, afﬁliations, titles, for example) and the publication sources (names, type, ISSN/ISBN, etc.). 152 7 Computational Tools for Literature Review Metadata are required for bibliometric and scientometric analyzes. In particular, speciﬁc metadata must be included in the ﬁle the researchers export from academic databases, such as the number of citations and the sources that a given publication cites. Section 7.4 will explain further requirements and how to use software to conduct metadata. Full text of publications is not a requirement for scientometric and bibliometric analysis, but the content analysis is based upon them. Access to data repositories is therefore of fundamental importance. The journal publishing market is an oligopoly, with some publishers being the editors of most high-proﬁle journals (Larivière et al. 2015). Therefore, access to traditional publishers’ contents, such as Emerald, Else- vier, Routledge, Sage, Springer, Taylor and Francis, and Wiley, is indispensable for top-level research. In addition to publishers, the academic publishing market is also comprised of metadata aggregators, which are databases that provide compilations of selected subsets of academic knowledge. Each aggregator uses its criteria to select coverage areas and journals, as well as which metadata to include. They generally do not provide access to the full text, but often provide links to the full text at the publishers’ websites. The most popular metadata aggregators are Web of Science, Scopus, PubMed/MedLine, and Google Scholar. Another important role metadata aggregators play in the academic ecosystem is keeping rankings and metrics of research impact. Inclusion and ranking in metadata aggregators inﬂuence publication and citation and, therefore, the academic careers of researchers all around the world. Web of Science and Scopus have their journal clas- siﬁcation systems: Journal Citation Records (JCR) and Scimago Journal Rank (SJR), respectively. Both index some publications in journals, book series, and conference proceedings that, according to the criteria used, represent the excellence of academic research. In contrast, PubMed/MedLine and Google Scholar try to be exhaustive: PubMed aims to include all relevant medical knowledge and Google Scholar aims to include all existing academic knowledge. Access to most academic metadata and full-text repositories are subscription-only. Even though open-access journals are becoming increasingly common (allowing anyone to download full texts for free), open-access metadata aggregators are not. Google Scholar is a free metadata repository, but its use terms forbid users to export large portions of metadata, which are particularly required for bibliometrics and scientometric analysis, and systematic reviews. Therefore, although Google Scholar is a go-to database for many users, especially graduate and undergraduate students, it cannot be successfully adopted as a source for systematic literature reviews or LGT-based studies. Web of Science, Scopus, and other academic databases have unique user inter- faces, but they generally offer the same functionalities: basic, advanced, and cited reference search. Figure 7.3 shows Scopus basic search. As Chap. 6 explained, researchers should carefully develop search strings to ﬁnd appropriate and unbiased results for a given search. Testing strings in databases help with such reﬁnement. After searching at a given academic database, the researcher begins ﬁltering and exporting metadata, following the procedures deﬁned in the research protocol 7.2 Accessing and Exporting Metadata and Full Texts 153 Fig. 7.3 Basic search, Scopus database. Source Created by authors in Scopus (https://www.scopus. com/ Accessed Jan 26, 2021) (Sect. 7.1). Figure 7.4 exempliﬁes the export screen on the Web of Science database. There are different possible ﬁle extensions and various metadata available, depending on the base used. Each bibliometric, scientometric, and reference management soft- ware allows importing speciﬁc ﬁle extension formats, so researchers must ensure they are exporting to a compatible format beforehand. File extension formats “.bib” (BibTeX) and “.RIS” (RIS) are generally accepted. EndNote uses a proprietary ﬁle extension. Also, several reference management software (including Mendeley and Fig. 7.4 Exporting metadata at Web of Science. Source Created by authors in Web of Science (https://webofknowledge.com/; accessed Jan 26, 2021) 154 7 Computational Tools for Literature Review Zotero) offer semi-automatic connectors for the most popular web browsers (Firefox, Chrome, Safari, and Edge) that automate part of the export–import process. The next section will cover reference management software. 7.3 Reference Management Software The management of documents used for scientiﬁc research has invariably become necessary due to the availability of information on digital media (Yamakawa et al. 2014). Collecting, organizing, citing, and searching for references in documents requires a long time (Courraud 2014). To this end, multiple document management software are developed and used by researchers to make work efﬁcient and fast. The researcher then prioritizes reading and writing (García-Puente 2020). Reference management software help archiving and organizing new and old docu- ments saved by the researcher in personal libraries (Speare 2018) or in libraries shared with user groups (Courraud 2014). Besides, its integration with word processors allows editing citations in the document and creating automatic bibliographic refer- ence lists. Therefore, errors in the insertion of references in texts can be minimized using reference management software (Kratochvíl 2017). Reference management software offer similar features and are supported by virtual libraries that are members of the Association of Research Libraries (Speare 2018). There are several such software on the market. Table 7.3 shows the most cited and used ones (Kratochvíl 2017). As a case study, this section shows the functionalities of Mendeley Reference Manager, its integration with the Scopus database and the export of documents and quotations to Microsoft Word. To access Mendeley, the user connects to the soft- ware’s online platform (https://www.mendeley.com) and creates a proﬁle with a username and password, enabling access to the software. As one of the software’s most important functionalities is direct access on their personal equipment (desktop, tablet, or smartphone) and connection to the text editor, after creating the proﬁle, users should download, install the software on the preferred equipment and the text editor connector. Figure 7.5 outlines the interface of the Mendeley desktop on the Windows/PC operating system showing imported documents. On the left-hand side (Fig. 7.5) is My Library, which accounts for the personal database of research that can be synchronized automatically with other devices the same account is logged in. “My Library” cannot be shared with other users: Mendeley has speciﬁc databases (libraries) that can be shared with other users. Users are expected to keep their libraries organized in a logical way, particularly in shared libraries. They can create folders to subdivide and classify their documents and database, or use tags. This is essential to support the document management process and assist in literature review and future bibliometric analyses, especially in shared libraries. 7.3 Reference Management Software 155 Table 7.3 Software for reference managing Software Description Notes EndNote It is a software for bibliographic management that allows ﬁle sharing with other users and veriﬁcation of duplicate ﬁles. Synchronization of indexed ﬁles is automatic. It has compatibility with the operating systems MacOS and Windows/PC and applications for tablets and smartphones. Its communication is with the word processors Word, LibreOfﬁce, and LaTex – Commercial software; – Free access online of up to 2 GB; in the paid version, ofﬂine access without space limitation; Website: https://endnote.com/ Zotero This software allows ﬁle sharing with other users without the limit of participants. Checking for duplicate ﬁles and synchronizing indexed ﬁles are automatic. It has compatibility with the operating systems MacOS, Windows/PC, and Linux. Its communication is with the word processors Word, LibreOfﬁce, LaTex, and Google Docs – Commercial software; – Free access online and ofﬂine up to 300 MB; Website: https://www.zotero.org/ Mendeley File sharing with other users without limit of participants allows verifying duplicate ﬁles. Synchronization of indexed ﬁles is automatic. It has compatibility with the operating systems MacOS, Windows/PC, Linux, and applications for tablets and smartphones. Its communication is with the word processors Word, LibreOfﬁce, and LaTex – Commercial software; – Free access online and ofﬂine up to 2GB; Website: https://www.mendeley.com Source Created by the authors In the center of Fig. 7.5, the main tab provides a preview of the set of ﬁles (PDF/editable/video) or the input metadata inserted in the software. Users can manu- ally input document metadata without inserting the ﬁle (PDF/editable/video) or import data straight from databases (Web of Science, Scopus, among others). The right-hand side (Fig. 7.5), in turn, shows the details of the metadata: type, docu- ment name, journal publication, among other information, and the notes inserted after reading. Metadata are exported automatically to the text editor following the selected citation format (e.g., APA, Vancouver, Harvard, or a customized one) to compose in-text citations and the reference list. An advantage of using reference managers such as Mendeley is the possibility to import and export full-text PDFs or metadata ﬁles from other software. Metadata can be handled through extensions like BibTex, RIS, Zotero Library, or EndNote, and can be downloaded directly from academic databases, such as Scopus and Web of Science, using popular web browsers, such as Google Chrome, Firefox, and Safari (García-Puente 2020) using a plug-in. 156 7 Computational Tools for Literature Review Fig. 7.5 Mendeley desktop interface. Source Created by authors in software Mendeley With the option to insert the full-text or input metadata straight from search browsers or academic databases, the researcher selects the import plug-in (Web Importer), selects the location of the document in its reference manager, and person- alizes the information related to the citation. Figure 7.6 illustrates this process using the Mendeley online. The ﬁle or entry becomes available for synchronization in Mendeley Online or Mendeley Desktop after import. File synchronization is an essential factor in using reference managers since it allows the user to access documents on different platforms and provides the maintenance of the database developed by the researcher. Mendeley accepts the inclusion of documents in different formats (PDF/editable/video). However, the possibility to select part of the text and insert notes and highlights is only allowed in PDF ﬁles. Figure 7.7 shows an article, which had some quotations highlighted and commented for further reference. When a user cites a reference using Mendeley’s integration with Microsoft Word or other compatible software, citations are linked with Mendeley and stored in the text ﬁle (.docx and other ﬁles). Figure 7.8 shows the integration between Microsoft Word and Mendeley reference manager. The “insert or edit citation” and “insert bibliography” icons are responsible for inserting an in-text citation and references as the text is written, avoiding duplication, forgetfulness, and lots of formatting and rework. Users can easily choose a citation style and change it anytime. Table 7.4 exem- pliﬁes three styles of citation: the model of the American Psychological Association 7th Edition (APA), the Journal of Cleaner Production (JCP), and the Brazilian Asso- ciation of Technical Standards (ABNT/Brazil), which are installed in the Mendeley software. 7.3 Reference Management Software 157 Fig. 7.6 Importing documents in Mendeley online. Source Created by authors in software Mendeley Fig. 7.7 Text analysis in Mendeley Desktop. Source Created by authors in software Mendeley Citation styles are selected by the user from the repository included in the soft- ware or external sources, such as the Zotero Style Repository, which is shared with Mendeley (Kratochvíl 2017). Besides, styles can be created from prior knowledge in Citation Style Language. 158 7 Computational Tools for Literature Review Fig. 7.8 Mendeley interface in Microsoft Word. Source Created by authors in Microsoft Word Table 7.4 Citation styles Style References APA Serrano, R., Rodrigues, L. H., Lacerda, D. P., & Paraboni, P. B. (2018). Systems Thinking and Scenario Planning: Application in the Clothing Sector. Systemic Practice and Action Research, 31(5), 509–537. https://doi. org/10.1007/s11213-017-9438-3 JCP Serrano, R., Rodrigues, L.H., Lacerda, D.P., Paraboni, P.B., 2018. Systems Thinking and Scenario Planning: Application in the Clothing Sector. Syst. Pract. Action Res. 31, 509–537. https://doi.org/10.1007/s11213-017-9438-3 ABNT/BRASIL Serrano, R. et al. Systems Thinking and Scenario Planning: Application in the Clothing Sector. Systemic Practice and Action Research, v. 31, n. 5, p. 509–537, 11 out. 2018 Source Created by authors in Microsoft Word Finally, in addition to the basic functions offered by the reference manager, in this speciﬁc case (Mendeley Desktop) the continuous use of its online platform enables users to generate statistics related to the number of articles, geographic regions, identiﬁcation of readers by area, and researchers with interest on the subject. Furthermore, the identiﬁcation of the researcher’s reference journals, the keywords, and the authors cited facilitates future bibliometric analyses (Yamakawa et al. 2014). Another relevant functionality is sharing ﬁles between groups of Mendeley users. Authors can amplify the visibility of their work, their research, and information networks and cooperate with other researchers (García-Puente 2020) using this 7.3 Reference Management Software 159 strategy. In the Mendeley software, there is no limit for participation in groups of users. However, the inserted ﬁles occupy space in the group administrator’s cloud account, and the folder structure of each user is not shared with other researchers using the library. It should be noted that reference managers have some negative aspects. Particu- larly in Mendeley, there are some punctuation errors, incorrect formatting, problems in generating URLs, missing or incorrect dates of access to online resources, and DOI numbers (Kratochvíl 2017). Incompatibility problems in reading citations might result in disinterest and rework due to the need to manually ﬁll out or correct data (Speare 2018). There are also initial implementation barriers, especially in short-term research, due to the time spent creating the database, setting the style of citations, and mainly the need for learning (Speare 2018). In addition, the impossibility of exporting the notes inserted in the reference managers to text editors (Goldenberg 2019) is also a barrier for using this feature. However, reference managers are constantly developed and updated, seeking to improve their functionality, reduce errors, and meet the needs of various cita- tion formats/styles (Kratochvíl 2017). File management tools, therefore, need to be designed in a way that goes beyond search and language barriers (Lisbon 2018). However, it is worth emphasizing that the software does not guarantee the quality of texts or publications, therefore the researcher has the task of selecting and identi- fying the appropriate documents for insertion and use. The next section exposes the options of the software for performing scientometrics and bibliometrics analysis, in specifying the software SciMAT. 7.4 Software for Scientometric and Bibliometric Analysis With the recent worldwide growth of scientiﬁc and technological development, there has been an increase in the number of knowledge bases in electronic digital media, for technical and academic communities. Research and development activities require systematic monitoring and prospecting in the main ﬁelds of knowledge that concern their activities and correlated ones. Thus, scientometric and bibliometric tools are needed to monitor the available information. Several software have been developed for this and Table 7.5 shows examples of software that conduct scientometric and bibliometric analysis. The variety of software available requires that criteria be deﬁned for choosing the software to be used. These criteria must be deﬁned by the researcher, according to the depth of scientometric and bibliometric development needed Cobo et al. (2011). No software was capable of analyzing all of the key scientometric and bibliometric elements, which forced researchers to use various software (Box 7.2) to conduct a complete scientiﬁc mapping (Cobo et al. 2011). 160 7 Computational Tools for Literature Review Table 7.5 Main characteristics of software for scientometric and bibliometric analysis Tool Author(s) Pre-processing Normalization Scope of analysis Bibexcel Persson et al. (2009) Data and network reduction Salton’s cosine, Jaccard index, or Vladutz and Cook measures Network CiteSpace Chen (2006) Time slicing, data, and network reduction Salton’s cosine, Dice, or Jaccard Strength Explosion detection, geospatial, network, temporal CoPalRed Bailón-Moreno et al. (2006) Deduplication, time slicing, and data reduction Equivalence index Network, temporal IN-SPIRE Paciﬁc Northwest National Laboratory (2019), Wise (1999) Data reduction Conditional probability Explosion detection, network, temporal Network Workbench Tool Herr et al. (2006) Deduplication, time slicing, data, and network reduction – Explosion detection, network, temporal Science of Science (Sci2) Tool Team (2009) Deduplication, time slicing, data, and network reduction – Explosion detection, geospatial, network, temporal SciMAT Cobo et al. (2012) Deduplication, time slicing, data, and network reduction Association strength, Equivalence index, Inclusion index, Jaccard index, Salton’s cosine Network analysis (Callon density and centrality), performance and quality analysis (sum, minimum, maximum, maximum, and average quotes, and complex averages such as the h index, g index, hg index, or q2 index), and temporal analysis VantagePoint Porter and Cunningham (2004) Deduplication, time slicing, and data reduction Pearson’s r, Salton’s cosine, or the maximum proportion Explosion detection, geospatial, network, temporal VOSViewer Van Eck and Waltman (2009,2010) – Association strength Network (continued) 7.4 Software for Scientometric and Bibliometric Analysis 161 Table 7.5 (continued) Tool Author(s) Pre-processing Normalization Scope of analysis BiblioShiny Aria and Cuccurullo (2017) Conversion to R data frame Association strength, Equivalence index, Inclusion index, Jaccard index, Salton’s cosine Correspondence analysis, Multiple correspondence analysis, Multidimensional scaling Source Created by authors Box 7.2 Software analyzed by the creators of SciMAT: • Bibexcel; • CiteSpace II; • CoPalRed; • IN-SPIRE; • Leydesdorff’s Software; • Network Workbench Tool; • Sci2 Tool; • VantagePoint; • VOSViewer. With this understanding, the software SciMAT (Science Mapping Analysis Soft- ware Tool) was developed. It can be downloaded without cost and offers the following characteristics: it encompasses the complete bibliometric process; and allows the incorporation of methods, algorithms, and measures for all stages of scientometric and bibliometric analysis, from pre-processing to the visualization of results (Cobo et al. 2012; Gutiérrez-Salcedo et al. 2018; Montero-Díaz et al. 2018). Figure 7.9 shows a structure of the scientiﬁc map that can be performed using SciMAT (Cobo et al. 2012). To carry out the ﬁrst stage of scientiﬁc mapping, we recommend the use of infor- mation available in Chaps. 4 and 6. Since most researchers are less familiar with using bibliometric and scientometric software, which are much less intuitive than text editors or reference managers, this section will present a more detailed walkthrough of the use of SciMAT software. To perform scientometric or bibliometric analysis using SciMAT, it is suggested to download the software (https://sci2s.ugr.es/scimat/). The programming language used to develop SciMAT was Java, so the version of Java must be updated on your computer. 1st step—Creating a project: To import the data collected from the databases, SciMAT uses the ISI WoS format and RIS (May 2014 format) formats. SciMAT 162 7 Computational Tools for Literature Review Create a new project Period Manager •Defined by the corpus of analysis Data pre-processing •Identify and organize words and sets of word groups Construction of the strategic diagram and Thematic network •Select unit of analysis and kind of matrix. Data and Network reduction. Normalization, Clustering algorithm, Document mapper and Quality measures. Data analysis Synthesis •Present of the results 1 2 3 4 5 6 Fig. 7.9 Structure of the scientiﬁc map—SciMAT. Source Adapted from Cobo et al. (2012) works by project, that is, you must work on one project at a time. Each project can contain more than one set of data exported from the databases. To start a new project, SciMAT follows a chain of commands, which are: File > New Project > go to Browse to deﬁne the path to reach the folder with the data > Deﬁne the name of the project > Accept. After creating the project ﬁle, the researcher continues to use SciMAT by inserting the metadata in it following the format of the database where it was collected. To do so, click on File > Add Files > In ISI WoS format (for Web of Science) or In RIS (May 2014 format) (for SCOPUS) > Select the RIS ﬁle exported from the database > Select YES (import ﬁles). Figure 7.10 indicates this chain of commands. SciMAT allows you to select more than one RIS ﬁle from the database. It is worth mentioning that the RIS ﬁle is exported and not the name of the project created in the previous step. Although, after importing, there is no change to the main screen of the software, the ﬁles are inserted and data processing begins. The metadata obtained from the bases often has errors, so it is necessary to perform a pre-processing to guarantee good quality results (Cobo et al. 2012). Thus, the pre-processing step is performed, excluding duplications of authors, refer- ences, keywords, and documents. Besides, meaningless words, such as “C #,” should be deleted and those misspelled can be corrected. It is suggested that keywords be grouped when presenting the same concept. To start this pre-processing, it is recommended to follow the steps described below. 7.4 Software for Scientometric and Bibliometric Analysis 163 Fig. 7.10 Chain of command for creating a new project in SciMAT. Source Created by authors in SciMAT 2nd step—Period Manager: Access the Knowledge Base tab, which presents the following options: Authors, Documents, Periodicals, References, Periods, Publi- cation Dates, Subject Categories, and Words. At this point, select the information ﬁeld you want to check. We suggest selecting Periods and Period manager so that imported documents are organized according to the year of publication. It is worth remembering that this option is not mandatory, and the researcher can decide whether to use it or not. Figure 7.11 presents an example for an analysis of the scientiﬁc evolu- tion of the Theory of Constraints (TOC) in the period from 2010 to 2020 in SciMAT. After selecting “Periods” and “Periods manager,” the researcher follows the steps outlined in Fig. 7.11. Then the researcher selects the ADD option, in the lower left corner of the SciMAT screen and ﬁlls in the tab for the desired period according to the separation of docu- ments deﬁned by the researcher. This procedure is repeated until all the periods of interest for the research are added, so the publications will be added in the deﬁned periods. To do this, select one of the periods created, for example, “2010–2013,” and click on ADD in the lower right corner. After this procedure, a new tab will appear, with the year and the publications that were exported. Select the publications for 2010–2013, click on the arrow pointing to the right, and click on ADD. Do this for the other periods created. Figure 7.12 shows this procedure. 3rd step—Data processing: To pre-process keywords, start using the following chain of commands: “Group Set,” “Word,” “Word group manual set.” At this location is found the list of words and in the lower right corner of the screen, the total number of words is displayed, as shown in Fig. 7.13. 164 7 Computational Tools for Literature Review Fig. 7.11 Organization of documents by period. Source Created by Authors in SciMAT Fig. 7.12 Procedure for “Periods manager.” Source Created by Authors in SciMAT 7.4 Software for Scientometric and Bibliometric Analysis 165 Fig. 7.13 Pre-processing of keywords. Source Created by Authors in SciMAT Still concerning the organization of the words, two lists appear on the SciMAT screen, one on the left side of the screen called “Group name” and another in the bottom right corner, the “Words without a group.” Thus, to organize the words, use the command chain shown in Fig. 7.14. For example, the words, “CLEAN-TECH” and “CLEANTECH” (Fig. 7.15), have the same meaning, so it is recommended to join the two terms into one. The researcher can use the distance (in number) he wishes, but always trying to unite words of equal meanings. It is recommended to use increasing numbers (1, 2, 3 …). Besides, the decision to join words with the same meaning is made by the researcher. As shown Fig. 7.14 Organization of keywords. Source Created by Authors in SciMAT 166 7 Computational Tools for Literature Review Fig. 7.15 Joining words. Source Created by Authors in SciMAT in Fig. 7.15, select the word that will be kept and click on “Move” or, if you don’t want to join them, choose “Discard.” After the words with the same meaning are joined, the resulting words are re- grouped into new groups. To do so, select all the words that are in “Words without a group” and choose the option “To different group” (Fig. 7.16). Fig. 7.16 Finalization of pre-processing of words. Source Created by Authors in SciMAT 7.4 Software for Scientometric and Bibliometric Analysis 167 Fig. 7.17 Example of joining words. Source Created by Authors in SciMAT With the new list of words on the left of the SciMAT screen (Fig. 7.16)the procedure is repeated, but for groups of words or terms with different nomencla- tures, according to your search. Figure 7.17 exempliﬁes the abbreviation “TOC” and “Theory of Constraints.” To join the terms, it is necessary to select them and click on “Move to,” choose the name of the term that will be in the list, and click on “Move.” 4th step—Construction of the strategic diagram and thematic network:The strategic diagram reveals the themes identiﬁed in a given period in a two-dimensional space, characterizing them according to the measures of density and centrality (Callon et al. 1991). The thematic network or evolution map, meanwhile, monitors the evolu- tion of clusters over different periods (Cobo et al. 2012). To calculate similarity, the equivalence index can be used, which calculates the bond strength between the clus- ters (Callon et al. 1991). The equivalence index, in turn, presents values between zero and one, using a value of 1 (one) when keywords are associated and 0 (zero) when they are never associated. Equation 7.1 describes the calculation of the equivalence index. eij = c2 ij /ci c j (7.1) where cij is the number of documents in which every two keywords i and j appear and ci and cj represent the number of documents in which each one occurs. 168 7 Computational Tools for Literature Review The clustering algorithm used to detect themes can be the simple center algorithm, which demonstrates the strength of the connection between clusters (Coulter et al. 1998). To visualize the themes, SciMAT builds clusters that are plotted on two- dimensional strategic diagrams. These diagrams have four quadrants, based on values of density (y-axis) and centrality (x-axis). Density (Eq. 7.2) measures the internal link strength between keywords, while centrality (Eq. 7.3) measures the intensity of a cluster’s link with other clusters (Callon et al. 1991). d = 100\u0002\u0003 eij w \u0004 (7.2) where i and j are keywords belonging to the theme and w the number of keywords in the theme. c = 10\u0002\u0003 ekh\u0004 (7.3) where k is the keyword belonging to the theme and h is the keyword belonging to the other theme. In this context, the Callon et al. (1991) diagram is used to organize the research themes, which are classiﬁed into four groups: Motor themes, Basic and transversal themes, Emerging or declining themes, Highly developed themes, and/or isolated themes. Figure 7.18 shows an example of the aforementioned diagram, also known as a strategic diagram (Callon et al. 1991). Figure 7.18b is used to discover thematic areas, analyze the evolution of the research themes, highlighting the main areas in the research ﬁeld in a given period and the interrelationships. Figure 7.19 presents an example of the thematic evolution. Thus, the solid line (line 1 and 2) means that the clusters are connected (A 1 and A 2; Fig. 7.18 Strategic diagram (a) and thematic network structure (b). Source Sott et al. (2020) 7.4 Software for Scientometric and Bibliometric Analysis 169 Fig. 7.19 Example of thematic evolution. Source Cobo et al. (2012) B 1 and B 2) and share the main theme, while the dashed line (line 2) indicates that the clusters (B 1 and C 1) share elements that do not represent the main theme. Finally, the absence of a line indicates discontinuity (D1 and D 2), and a new cluster is formed. The thickness of the edges is proportional to the inclusion index (Eq. 7.4) and the volume of the spheres is proportional to the volume of published documents associated with each cluster (Cobo et al. 2012). inclusion index = #(U ∩ V ) (#U, #V ) (7.4) where U is each theme detected in period t (Period 1—Fig. 7.19) and V is each theme detected in period t + 1(Period2—Fig. 7.19). Another analysis that can be performed is called general overlapping and is presented in SciMAT as shown in Fig. 7.20. The circles represent the periods and the number of items in each, in this case, keywords. The horizontal arrow represents the number of keywords shared between periods 1 and 2. The stability index (iE) between them is shown in parentheses. The stability index describes the proportion of keywords from the previous period that move to the next period (for example, 170 7 Computational Tools for Literature Review Fig. 7.20 General overlapping. Source Adapted Cobo et al. (2012) 216/1299 = 0.17). The top entry arrow represents the number of new keywords in Period 2 and the top exit arrow represents those that are presented in Period 1, but not in Period 2 (Cobo et al. 2012). To exemplify the use of SciMat for the construction of the strategic diagram and the thematic network, the subsequent ﬁgures present the results obtained with the execution of the project about TOC. Figure 7.21 shows how to start data analysis for the construction of the strategic diagram and thematic network. After selecting the Make analysis option, Fig. 7.22 presents a suggested sequence of steps for the analyses. Thus, the researcher will initially select periods and transfer them to the table on the right of the SciMAT screen. After making the transfer, click Next and select “unit analysis,” marking according to the suggestion shown in Fig. 7.22, and conclude with the Next option. Figure 7.23 shows the selection of the minimum number of words that should be included in the period analyzed. In this example, the number of words 1 was used, however, it is suggested that in surveys with a larger volume of documents, 3, 5, or 7 be used. This action builds a higher quality strategic diagram and thematic network. Figure 7.24 shows the possibility of network reduction that should be used if the network is too complex. We suggest not using it in the ﬁrst creation of the strategic diagram and the thematic network. In the next steps, the normalization measures (Fig. 7.25) and clustering algorithm (Fig. 7.25) are selected. Fig. 7.21 Starting data analysis using SciMAT. Source Created by Authors in SciMAT 7.4 Software for Scientometric and Bibliometric Analysis 171 Fig. 7.22 Sequence of steps. Source Created by Authors in SciMAT Fig. 7.23 Selection of the minimum number of words per period. Source Created by Authors in SciMAT 172 7 Computational Tools for Literature Review Fig. 7.24 Select kind of matrix (a) and network reduction (b)steps. Source Created by Authors in SciMAT Fig. 7.25 Normalization and clustering algorithm. Source Created by Authors in SciMAT 7.4 Software for Scientometric and Bibliometric Analysis 173 To ﬁnalize the SciMAT process the next steps are the Document mapper, the Quality measures, and the longitudinal (selecting the measures for the longitudinal map), as shown in Fig. 7.26. For the Quality measures, we suggest that you check all those available in the software and select “Finish.” A screen will then appear to save the project according to the “Make Analysis” settings. We suggest that the project be saved under a different name than the one used in “New Project.” Figure 7.27 shows an example of analyses of overlapping Fig. 7.26 Document mapper, quality measures, and Longitudinal map. Source Created by Authors in SciMAT 174 7 Computational Tools for Literature Review Fig. 7.27 Overlapping map and evolution map. Source Created by Authors in SciMAT maps and evolution maps performed in SciMAT. Figure 7.28 shows an example of the strategic and thematic network diagram created in SciMAT. Note that a minimum number of words/period was used. To qualify this result, we need to increase the minimum number of words/period to 3. To do this, return to Step 3 (Data reduction). Steps 5 and 6 indicated in Fig. 7.9 must be performed to answer the research question(s) deﬁned in the review, analysis, and synthesis protocol created by the researchers. Box 7.3 presents articles that exemplify the use of SciMAT and the steps of the structure for scientiﬁc mapping (Fig. 7.9). 7.4 Software for Scientometric and Bibliometric Analysis 175 Fig. 7.28 Strategic and thematic network diagram. Source Created by Authors in SciMAT Box 7.3 As suggestions for practical applications of the SciMAT software (Science Mapping Analysis Software Tool) the following documents are recommended: Author Document information Cobo et al. (2012) User Guide SciMAT, available at: https://sci2s.ugr.es/scimat/sof tware/v1.01/SciMAT-v1.0-userGuide.pdf; Kipper et al. (2020) Scopus scientiﬁc mapping production in industry 4.0 (2011–2018): a bibliometric analysis. International Journal of Production Research, v. 58, n. 6, p. 1605–1627, 2020; Sott et al. (2020) Precision Techniques and Agriculture 4.0 Technologies to Promote Sustainability in the Coffee Sector: State of the Art, Challenges and Future Trends. IEEE Access, v. 8, p. 149,854–149,867, 2020 176 7 Computational Tools for Literature Review 7.5 Software for Content Analysis The best software category for content analysis of the literature (see Chap. 6, Sect. 6.5.3.) is Qualitative Data Analysis Software (QDAS). QDASs provide a common core of functions to support data encoding, theme comparison between cases (Gibbs 2014), construction of categories, semantic or node networks, and lines suggesting the interaction among data (Miles et al. 2013). The most popular QDASs available accept different ﬁle formats and types, such as textual documents, graphics, audios, and videos (Miles et al. 2013). A QDAS does not work automatically: they are a decision support system. The user needs to conﬁgure the desired analysis, review and interpret the results (Lewins and Silver 2007). The researcher must make decisions about transcription (if text is involved), data preparation (King 2010), and the methods that will be used (Paulus et al. 2017). The software helps saving time and organizing information in a mean- ingful way. Therefore, a qualitative data analysis using this software category involves efﬁcient, consistent, and systematic data management (Gibbs 2014). Analyses using QDASs can be performed in multiple sequences, but some data preparation activities can help reduce rework and task complexity (Lewins and Silver 2007). Figure 6.11 (Chap. 6) explained how content analysis should be carried out under the LGT method. Figure 7.29 proposes a sequence of steps the research must carry out to implement Content Analysis using QDAS. Selection of software Prepare and import data •Defined by the corpus of analysis Data extraction •Identify and create the categories and codes Data analysis •Treatment and interpretation of the results Synthesis •Present of the results 1 2 3 4 5 Fig. 7.29 Steps for using QDAS for content analysis. Source Created by authors 7.5 Software for Content Analysis 177 1st step—Selection of software: The selection of QDAS is derived from the familiarity of researchers involved in the project (Gibbs 2014), the complexity of the data to be analyzed, and the desired costs and functions (Miles et al. 2013). After selecting the software, the user must learn about the existing functions and check which ones are adequate and relevant to the proposed analysis. The Internet provides the user with easy access to learning materials through manuals available on ofﬁcial software websites, webinars, and access to platforms such as YouTube. The commercial software options are presented in Chap. 4, Table 4.7. Among the listed QDAS is the ATLAS.ti software for Windows/PC. ATLAS.ti will be used in the remainder of the section to exemplify the process steps of using a QDA software for data extraction, analysis, and synthesis. 2nd step—Prepare and import data: At this stage (which encompasses activity 3.3.5 in Fig. 6.11), the researcher must ﬁrst import the corpus of analysis (full- text ﬁles) into the software. Textual documents, graphics, audios, or videos can be imported and become part of the project, as shown in Fig. 7.30. From this moment on, groups of documents can be created to help make meaning of data. Documents can be grouped according to its type (text, audios, videos), source, occasion of collection or any other criteria relevant to the research being carried out. Figure 7.30 shows that the inserted documents explore the theme “Identiﬁcation of participants belonging to the fashion value ecosystem.” 3rd step—Data extraction: After importing the documents into the QDAS, the categorization and coding process begins (Fig. 7.30). The raw data of the document are transformed into elements that can be analyzed (Bardin 2011). The objective of the extraction process is to group similar data into blocks pertaining to the question, hypothesis, or theme of interest and its relations (Miles et al. 2013). The researcher Fig. 7.30 Imported documents. Source Created by authors in the ATLAS.ti 178 7 Computational Tools for Literature Review then reduces the number of units of analysis conducted (Corbin and Strauss 2015) in a meaningful way. Such categorization facilitates the data analysis process. To carry out the data extraction process (activities 3.3.1–3.3.3 in Fig. 6.11, Chap. 6), strategies such as the creation of a predetermined analytical structure—cate- gorical codes—or inductive exploration of documents—open codes (Bardin 2011; Saunders et al. 2009)—are adopted. In the ﬁrst strategy, an a priori list of categories and codes on the investigated phenomenon is structured and inserted into the QDAS. In the second strategy, when exploring the document inserted in the QDAS, the cate- gories and codes are identiﬁed and direct the desired analysis. However, regardless of the strategy adopted, the categories and codes are re-analyzed during the extrac- tion process aiming at the readjustment, exclusion, and insertion of new elements. Figure 7.31 shows the categories (Code Groups), the codes, the frequency of cita- tions linked to that code (grounded), and the density. Thus, the category “Apparel industry” has six codes associated with “Clothing.” When deﬁning the categories and codes, it is important to describe the meaning attributed to them. ATLAS.ti allows users to insert “comment/memos,” as Fig. 7.31 shows. Comments help researchers represent their interpretation of the category or code created, the concepts, questions, and directions for additional data collection (Corbin and Strauss 2015). Besides, comments are part of the analytical results and can be used to prepare the research report (Lewins and Silver 2007). Figure 7.32 highlights a created code (Fashion chain), the quotations associated with it (Model of circular), and a comment linked to the quotation (The Relooping Fashion). Fig. 7.31 Categories and codes. Source Created by authors in the ATLAS.ti 7.5 Software for Content Analysis 179 Fig. 7.32 Quotations with comments. Source Created by authors in the ATLAS.ti After data extraction, researchers can use ATLAS.ti to calculate intercoder agree- ment (activity 3.3.4 in Fig. 6.11) automatically. Similar software also have such func- tionality, which is critical to provide future readers with a measure of the data extrac- tion process quality. The most common intercoder agreement measure available in QDAS software is Krippendorff’s Alpha (Krippendorff 2004). 4th step—Data analysis: At the end of the coding and categorization process, the data are analyzed, treated, and interpreted (activities 3.3.6–3.3.8 in Fig. 6.11). In this step, the researcher reﬂects whether the results are aligned with the research question or proposed theme and which elements explored in the coding are important to answer them (Miles et al. 2013). In addition, the codes and categories identiﬁed are quantiﬁed, showing the expressed patterns and possible recombination or exclusions (Gibbs 2014) following the previously deﬁned rules of analysis (Chap. 4, Table 4.6 in this book). To perform this step, the categories and codes created are grouped, organized, and presented in summary diagrams, mathematical displays about frequency, matrices (data display), networks, word cloud, or other visual forms (Saunders et al. 2009). The most common analysis ATLAS.ti can help perform will be presented in the sequence: the Co-Occurrence table, Co-Document Table e Query tool, Network, Word Cloud, and Word List. Elements exposed in matrices derive from the crossing of rows and columns. They allow the visualization of all variables in one single place and prepare data for cross-analysis (Miles et al. 2013) as co-occurrence, when two or more elements are together simultaneously in a single context of unity. From the evidence shown in 180 7 Computational Tools for Literature Review Fig. 7.33 Frequency and co-occurrence table. Source Created by authors in the ATLAS.ti the matrix, researchers can investigate the relationship between the concepts and the categories created (Hutchison et al. 2010). Figure 7.33 shows, ﬁrst, the frequency which a given code occurs in the project. The “Production” code occurs eleven times, as the code report positioned on the left- hand side of Fig. 7.33 shows. The researcher, therefore, can assume that the more frequent a code is, the more important for the analysis it is. In the co-occurrence analysis the codes “Production” and “Distribution,” shown in central of Fig. 7.33, have a simultaneous relation, as they are identiﬁed in two places, forming an association. In the same way, the codes “Production” and “Dyeing” are dissociative because have not shown simultaneous relations. Figure 7.34, in turn, shows the analysis by crossing the codes with the groups of documents organized by theme. The “Production” code occurs nine times (frequency), and its occurrence is greater in the “Ecosystem” group. In addition, Fig. 7.34 shows quotations linked to the same code, which allows the researcher to analyze the congruence between the identiﬁed elements. The Query Tool can be used to identify the co-occurrence between codes and categories in ATLAS.ti. It shows what terms have big or small proximity and can or cannot appear together in the same citation. Figure 7.35 shows the relationship between the category “Apparel Industry” with the code “Production.” The query questioned if there was proximity between codes and categories or interrelations, and the result shows that in eleven quotations the two words co-occur. In the network presentation format, a set of points are connected by bonds, nodes, lines, or arrows that expose the relationships between the listed elements (Miles et al. 2013). Figure 7.36 shows the network for the “Production” code, the nature of its 7.5 Software for Content Analysis 181 Fig. 7.34 Data display co-document table. Source Created by authors in the ATLAS.ti Fig. 7.35 Data display query tool. Source Created by authors in the ATLAS.ti 182 7 Computational Tools for Literature Review Fig. 7.36 Network. Source Created by authors in the ATLAS.ti relationships, concepts, and causal links. Thus, the code “Nature ﬁber” belongs to the category “Fiber textile,” and its transformation causes “Production.” In addition, to indicate the relationship between the codes or key points of the data, brief descriptions or labels can be inserted in the network representation (Saunders et al. 2009). Figure 7.36 shows the commentary with the researcher’s interpretation of the code “Production”—Represent industry of clothing-, and some quotations associated with other codes. The symbols expressed by the links in the networks vary according to the deﬁned causality, in what ATLAS.ti calls an “archetype.” In the “is the cause of” archetype, the node that represents the source and the target node that verbalizes the effect are related. As a result, the networks present effective heuristics for the analysis of causal nexuses, longitudinal trends, and developing hypotheses or theories (Miles et al. 2013). A lexical analysis allows researchers to identify the terms, words, or phrases that can appear in other places and that refer to the same subject (Gibbs 2014). In ATLAS.ti the lexical coefﬁcient can be expressed by the word cloud (Fig. 7.37)or word list (Fig. 7.38). Figure 7.37 shows the word cloud. In this cloud, the most signiﬁcative words from the documents selected on the left are shown, such as the words “creative,” “business,” “industry” (central ﬁgure). In the bottom edge (Fig. 7.37) is the number 7.5 Software for Content Analysis 183 Fig. 7.37 Lexical analysis (Word Cloud). Source Created by authors in the ATLAS.ti Fig. 7.38 Lexical analysis (Word list). Source Created by authors in the ATLAS.ti of the words that appear in the cloud expressed: 65 types of words were identiﬁed, and 22.249 number of tokens. The comparison between the amount of words types and the number of tokens represents the lexical and vocabular variety of the text. The word list, in turn, provides detailed information for the lexical analysis, such as the quantiﬁed words relatively or absolutely per categories, codes, documents, or group of documents, according to researcher preference. Figure 7.38 shows the word list for the three groups of documents (left position). The word “creative” has a length coefﬁcient of 08 (08 letters), occurring 1764 times, corresponding to a total percentage of 20.54%. 184 7 Computational Tools for Literature Review 5th step—Synthesis: The last step is the translation of the results generated by the researcher in the QDAS to software used to write reports (activities 4.1 and 4.2 in Fig. 6.11). Figure 7.39 shows many options for building reports using the ATLAS.ti. The researcher can deﬁne the most relevant data result presentation options according to the research protocol, admitting that sometimes the protocol can be reviewed according to the speciﬁc necessities detected during Content Analysis. In the synthesis, researchers verbalize the assumptions adopted for the creation of cate- gories and codes and contextualize information and relationships matrices, networks, or other elements express. Therefore, the synthesis must show the adopted process Fig. 7.39 Types of reports. Source Created by authors in the ATLAS.ti 7.5 Software for Content Analysis 185 ﬂow in an organized, analytical, and careful way (Miles et al. 2013). It must also include clear and brief descriptions of what software features were used and how, making the process a transparent analysis (Paulus et al. 2017). This section showed that the systematic use of QDAS for data extraction, analysis, and synthesis results in a more rigorous and transparent Content Analysis. In addition, the adoption of a QDAS does not exclude the dynamics and ﬂuidity necessary for the coding and categorization process (Corbin and Strauss 2015); on the contrary, it ensures agility, reliability, and replicability of the research. For more information about the software ATLAS.ti we suggest consulting the company’s website (https:// atlasti.com/). The next section presents the software categories available for writing results and generating reports. 7.6 Writing the Report, Presenting Findings Presenting the results or writing the report is a simple task, although not necessarily an easy one. There are expectations—explicit standards or implicit expectations on what and how LGT results should be presented—an issue that was addressed in Chap. 6. In terms of supporting technologies, as Sect. 7.1 brieﬂy explained, three options can help writers report their ﬁndings: word processors, TeX tools, and professional writing software. Table 7.6 provides a comparison of some of the options available in the market. Text editors are one of the most popular and intuitive types of software available, considering their major role in the popularization of the personal computer as a substitute for the typewriter. Writing text, however, has evolved signiﬁcantly since the ﬁrst days of writing with computers. Today’s most useful features for researchers, in addition to basic writing and formatting options, are easy cloud sharing, support for simultaneous users and real-time changes to everyone, tracking changes, and inserting citations, especially when using reference management software in parallel. Considering such a vast number of features, easiness to use, and widespread popularity, researchers may genuinely question why they should ever consider alter- natives to traditional word processors. TeX, a typesetting system, is a popular answer to that question because it helps researchers typeset complex mathematical formulae. LaTeX is the most popular way to simplify TeX, offering “macros” that greatly facil- itates text editing. Many software run on LaTeX, including TeXMaker and Overleaf, two popular choices. LaTeX offers an advantage over traditional word processors because, in texts that require non-Latin characters, as in complex mathematical expressions and languages like Chinese, Arabic, or Devanagari, it performs the insertion easily. Unlike conven- tional “what-you-see-is-what-you-get” word processors, the ﬁnal appearance of manuscripts produced with TeX is only available after running the code developed. Many LaTeX-based software have intuitive user interfaces that compile code auto- matically and almost in real-time (such as OverLeaf), but ultimately writing using TeX requires coding. 186 7 Computational Tools for Literature Review Table 7.6 Comparison of some report writing tools Functionality Microsoft Word Google Docs TeXmaker OverLeaf Scrivener Kind Word processor Word processor Text programming Text programming Professional writing Operational systems Windows, MacOS, Android, iOS Windows, MacOS, Android, iOS Windows, MacOS, Linux Any (online) Windows, MacOS, iOS Free? No Yes Yes Yes No Spell check Yes Yes Yes Yes Yes Track changes Yes Yes No Yes Snapshots Multiple visualizations of changes (ﬁnal document, original document, detailed changes) Yes Only the ﬁnal document No Yes No Easy reorder parts of the document No No No No Yes Compare texts Difﬁcult No No No Easy Insert citations Yes Yes Yes Yes No Simultaneous users Yes (with ofﬁce 365) Yes No Yes No Accumulation of sources and ﬁles within the platform No No No No Yes Source Created by authors Professional writing tools are recommended for the creative part of texts—not doing the ﬁnal formatting, which can best be performed using LaTeX or word processors. Two of the most popular professional writing software are Scrivener and Ulysses. Figure 7.40 shows an example of using the Scrivener. Professional writing tools excel at helping researchers deal with larger volumes of text, notes, audios, videos, and sources, which is typically the case of books, thesis, or dissertations. Scrivener and Ulysses were constructed with book writers working solo in mind, so both are limited in terms of sharing and ﬁnal formatting functionalities. Their user interfaces facilitate comparing sections and versions of the text, splitting, joining, or reordering sections quickly, inserting notes and comments, track word counts of parts and the whole document, manage writing targets for each day of work, write 7.6 Writing the Report, Presenting Findings 187 Fig. 7.40 Example Scrivener in action. Source Created by authors in Scrivener on the go and synchronize seamlessly with different devices. Both tools offer a free trial but require payment. In conclusion, researchers can ﬁnd the best of both worlds by combining profes- sional writing tools with traditional word processors. Word processors are somewhere in between these two: they are useful, but not the best, for both creating writing and ﬁnal formatting. 7.7 Final Remarks This chapter presented computational tools that can assist researchers in carrying out a literature review, analysis, and synthesis using the Literature Grounded Theory (LGT) method. Since software follows changing market conditions, the chapter focused on features and categories of software, rather than providing readers with speciﬁc purchase recommendations. Thus, in addition to the various software in each category mentioned here, several other tools can help researchers carry out the entire review, analysis, and synthesis. Some of them are ﬁeld-speciﬁc, as is the case with Cochrane’s RevMan for Medicine, while others are generic, like DistillerSR and JBI SUMARI, for any ﬁeld. Such end-to-end software allow for different degrees of customization and have speciﬁc functionalities and price ranges. Although the choice of software is sometimes a matter of taste, it remains clear that conducting a review, analysis, and synthesis of the literature requires that researchers choose between alternatives and set up a workﬂow supported by software, rather than trying to conduct the entire process without computational tools. 188 7 Computational Tools for Literature Review References Aria, M., Cuccurullo, C.: bibliometrix: an R-tool for comprehensive science mapping analysis. J. Informet. 11(4), 959–975 (2017) Bailón-Moreno, R., Jurado-Alameda, E., Ruiz-Baños, R.: The scientiﬁc network of surfactants: structural analysis. J. Am. Soc. Inf. Sci. Technol. 57(7), 949–960 (2006) Bardin, L.: Análise do Conteúdo. São Paulo, Brasil: Edições 70 (2011) Callon, M., Courtial, J.P., Laville, F.: Co-word analysis as a tool for describing the network of inter- actions between basic and technological research: the case of polymer chemsitry. Scientometrics 22(1), 155–205 (1991) Chen, C.: CiteSpace II: detecting and visualizing emerging trends and transient patterns in scientiﬁc literature. J. Am. Soc. Inf. Sci. Technol. 57(3), 359–377 (2006) Cobo, M.J., et al.: Science mapping software tools: review, analysis, and cooperative study among tools. J. Am. Soc. Inf. Sci. Technol. 62(7), 1382–1402 (2011) Cobo, M.J., et al.: SciMAT: a new science mapping analysis software tool. J. Am. Soc. Inf. Sci. Technol. 63(8), 1609–1630 (2012) Corbin, J., Strauss, A.: Basics of qualitative research: techniques and procedures for developing grounded theory, 4th edn. Sage Publications Inc., Thousand Oaks, EUA (2015) Coulter, N., Monarch, I., Konda, S.: Software engineering as seen through its research literature: a study in co-word analysis. J. Am. Soc. Inf. Sci. 49(13), 1206–1223 (1998) Courraud, J.Z.: A free and open-source reference manager. Med. Writing 23(1), 46–48 (2014) García-Puente, M.: Gestores de referencias como herramientas del día a día. Zotero. Revista Pediátrica de Atención Primatria 22, 95–101 (2020) Gibbs, G.R.: Using software in qualitative analysis. In: The SAGE Handbook of Qualitative Data Analysis, pp. 277–294. SAGE Publications Ltd, 1 Oliver’s Yard, 55 City Road, London EC1Y 1SP United Kingdom (2014) Goldenberg, M.: LiteRef: a software system for managing the knowledge of research literature. Knowl. Based Syst. 174, 1–3 (2019) Gutiérrez-Salcedo, M., et al.: Some bibliometric procedures for analyzing and evaluating research ﬁelds. Appl. Intell. 48(5), 1275–1287 (2018) Herr, B.W., et al.: Designing highly ﬂexible and usable cyberinfrastructures for convergence. Ann. N. Y. Acad. Sci. 1093(1), 161–179 (2006) Hutchison, A.J., Johnston, L.H., Breckon, J.D.: Using QSR-NVivo to facilitate the development of a grounded theory project: an account of a worked example. Int. J. Soc. Res. Methodol. 13(4), 283–302 (2010) King, A.: ‘Membership matters’: applying Membership Categorisation Analysis (MCA) to quali- tative data using Computer-Assisted Qualitative Data Analysis (CAQDAS) Software. Int. J. Soc. Res. Methodol. 13(1), 1–16 (2010) Kipper, L.M., et al.: Scopus scientiﬁc mapping production in industry 4.0 (2011–2018): a bibliometric analysis. Int. J. Prod. Res. 58(6), 1605–1627 (2020) Kratochvíl, J.: Comparison of the accuracy of bibliographical references generated for medical citation styles by endnote, Mendeley, RefWorks and Zotero. J. Acad. Libr. 43(1), 57–66 (2017) Krippendorff, K.: Content Analysis: An Introduction to Its Methodology, 2nd edn. Sage Publications Inc., Thousand Oaks (2004) Larivière, V., Haustein, S., Mongeon, P.: The oligopoly of academic publishers in the digital era. PLoS ONE 10(6) (2015) Lewins, A., Silver, C.: Using Software in Qualitative Research: a step-by-step Guide. SAGE Publications Ltd., London, England (2007) Lisbon, A.H.: Multilingual scholarship: non-English sources and reference management software. J. Acad. Libr. 44(1), 60–65 (2018) Miles, M.B., Huberman, A.M., Saldana, J.: Qualitative Data Analysis: A Methods Sourcebook, 3rd edn. Sage Publications Inc., Thousand Oaks, EUA (2013) References 189 Montero-Díaz, J., et al.: A science mapping analysis of ‘Communication’ WoS subject category (1980–2013). Comunicar 26(55), 81–91 (2018) Paciﬁc Northwest National Laboratory. IN-SPIRETM visual document analysis (2019). https://in- spire.pnnl.gov/index.stm. Accessed 15 Dec 2020 Paulus, T., et al.: The discourse of QDAS: reporting practices of ATLAS.ti and NVivo users with implications for best practices. Int. J. Soc. Res. Methodol. 20(1), 35–47 (2017) Persson, O., Danell, R., Schneider, J.W.: How to use Bibexcel for various types of bibliometric analysis. In: Celebrating Scholarly Communication Studies: A Festschrift for Olle Persson at his 60th Birthday [s.l.]. International Society for Scientometrics and Informetrics, vol. 05-Sp. 09–24 (2009) Porter, A.L., Cunningham, S.W.: Tech mining. Wiley, Hoboken, NJ, USA (2004) Saunders, M., Lewis, P., Thornhill, A.: Research Methods for Business Students, 5th edn. Pearson Education Limited, Harlow, England (2009) Silva, É.R., Bartholo, R., Proença, D.: Managing the state of the art of engineering: learning from medicine. In: Fritzsche, A., Oks, S.J. (eds.) The Future of Engineering: Philosophical Foundations, Ethical Problems and Application Cases. Philosophy of Engineering and Technology, pp. 217– 227. Springer International Publishing, Cham (2018) Sott, M.K., et al.: Precision techniques and agriculture 4.0 technologies to promote sustainability in the coffee sector: state of the art, challenges and future trends. IEEE Access 8, 149854–149867 (2020) Speare, M.: Graduate student use and non-use of reference and PDF management software: an exploratory study. J. Acad. Libr. 44(6), 762–774 (2018) Team, S.: Science of science (Sci2) tool. Indiana University and SciTech Strategies (2009). https:// sci2.cns.iu.edu/user/index.php. Accessed 15 Dec 2020 Van Eck, N.J., Waltman, L.: How to normalize cooccurrence data? An analysis of some well-known similarity measures. J. Am. Soc. Inf. Sci. Technol. 60(8), 1635–1651 (2009) Van Eck, N.J., Waltman, L.: Software survey: VOSviewer, a computer program for bibliometric mapping. Scientometrics 84(2), 523–538 (2010) Wise, J.A.: The ecological approach to text visualization. J. Am. Soc. Inf. Sci. 50(13), 1224–1233 (1999) Yamakawa, E.K., et al.: Comparativo dos softwares de gerenciamento de referências bibliográﬁcas: Mendeley, EndNote e Zotero. Transinformacao 26(2), 167–176 (2014) Chapter 8 What to Consider in a Systematic Literature Review: Three Examples from Design Science Research Raymond Opdenakker, Madis Talmar This chapter focuses on introducing and commenting on examples of the Systematic Literature Review (SLR) protocol as applied within the so-called Design Science Research (DSR) approach. First, three comparable but distinctly different example articles in which SLR has been conducted will be introduced and compared. In the table (Table 8.1), we will provide a basic overview of the research approach in each paper, including key concepts, selection and coding of literature, representation of results, and contributions made by the authors to academia and practice. Second, we follow the introduction with a focused critical review of the papers along three key topics that we deem most intriguing for composing and publishing SLR. The ﬁrst of this is justiﬁcation—each of the three papers justiﬁes the use of SLR slightly differently. Building on that, in this sub-chapter, we comment upon the choice of justiﬁcations and provide ﬁrst-time authors some guidelines in legitimizing their research. The second section concerns the coding and representation of the synthe- sized knowledge from a review. We observe that each of the example papers builds on one speciﬁc generic structure for representing causal statements, although how results are conveyed is still distinctly different from paper to paper. Thirdly, we draw back on the initial purpose of the articles to emphasize how the reporting of their synthesis (i.e., a focus on the importance of context, a focus on the range of interven- tions and expected outcomes, or a focus on generative mechanisms) differs distinctly depending on the dominant purpose of each paper. As such, an intuitive typology of SLR approaches is produced, tying together the three sub-chapters of our review. We conclude the chapter by articulating three further points of attention for successfully performing systematic literature reviews within DSR. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_8 191 192 8 What to Consider in a Systematic Literature Review … Table 8.1 Overview of the three example papers Criterium Tanskanen et al. (2017) van Burg and Romme (2014) Velasco Montañez et al. (2020) Key concept External resource management Entrepreneurial opportunity Entrepreneurial university Domain(s) Marketing, operations/supply chain management, strategic management Entrepreneurship Organization studies, public policy Research questions RQ1: How does the research in strategic management, marketing, and operations/supply chain management inform evidence-based management of external resources: what is known and what is not yet known? RQ2: Do the three management disciplines effectively trade knowledge in the academic studies of external resource management (ERM)? RQ3: What are the future research opportunities for further advancing evidence-based management in the ﬁeld of ERM through research design and disciplinary integration? RQ: Which evidence-based insights can be inferred from the literature concerning how and when entrepreneurs perceive and act upon opportunities? No RQ, but a research task which is to “Produce an evidence-grounded framework of cause-effect relationships on increasing the entrepreneurial capacity of universities, as well as to qualify the strength of evidence for the relationships in the framework” Reducing the risk of author bias Protocol for performing the systematic review. Furthermore, different combinations of researchers were assigned to each journal to reduce the potential for bias arising from team composition Protocol for performing the systematic review and synthesis Protocol for performing the systematic review and synthesis (continued) 8.1 Justifying Systematic Literature Review 193 Table 8.1 (continued) Criterium Tanskanen et al. (2017) van Burg and Romme (2014) Velasco Montañez et al. (2020) Selection Journal based ﬁltering (2 journals per domain = 6intotal) Empirical studies ﬁrst, conceptual papers second. Select journals only Empirical studies only. ISI-rated journals only Number of papers reviewed 840 initially, 601 remained in the last stage 79 117 Research synthesis framework Modiﬁed CIMO-logic Modiﬁed CIMO-logic Cause-effect relationships (as a simpliﬁcation of CIMO) Analysis Qualitative content analysis, cross-citation analysis, computational content analysis Qualitative coding Qualitative coding Communication of synthesis results Tables across CIO statements (per research theme), separate explanation of mechanisms Relationship graphs across CMO statements and textual explanation per mechanism; table of action principles for practitioners Relationship graphs for cause-effect statements and textual explanations per intervention cluster Academic implications Research agenda for the future (including the popularization of the design science approach) Argue for a mechanism-based approach as a good way to avoid epistemological and paradigmatic differences in the entrepreneurship literature Evaluation of the state of research, evaluation of the quality of particular evidence, articulation of research agenda Practical implications Evidence-based decision-making in external resource management Action principles for entrepreneurs Evidence-based decision-making in university management and policy-making Source Created by authors 8.1 Justifying Systematic Literature Review While systematic literature review is a well-accepted method for academic purposes such as clarifying deﬁnitions of key concepts, categorizing earlier studies, and outlining future research within a domain, the three example studies show us that using the technique to synthesize prescriptive knowledge remains a purpose that may warrant further justiﬁcation. How then can authors provide justiﬁcation that their colleagues see legitimate for using the SLR protocol for such syntheses? 194 8 What to Consider in a Systematic Literature Review … One prominent approach that we see used in all three example studies is to asso- ciate the use of SLR with arguments for evidence-based management (Rousseau 2012; Rousseau et al. 2008). What is useful about this association is that employing the scientiﬁc knowledge-base as a source of improved practices is an argument that forms the very core of evidence-based management (Rousseau 2012). The stream explicitly calls for improved professionalism among managers and entrepreneurs (Romme 2016) with the synthesis of empirical evidence holding a special role in overcoming the conditions seen as holding managers back from improved decision- making capabilities: that (1) managers tend to be boundedly rational, that (2) prior personal experience is valued over the evidence originating from the experience of others, and that (3) managers tend to trust their intuition, while often ignoring relevant facts. In this light, we witness for instance Velasco Montañez et al. (2020) explicitly making a case that university management seems not to have taken into account research evidence on increasing the entrepreneurial capacity of universities. Assuming the reason for that being a lack of integration of previous evidence, the remaining leap to justifying the use of SLR becomes minimal. As such, evidence- based management seems to be a prominent approach to justifying research if the explicit purpose (at least partially) is to inform practice. Meanwhile, in van Burg and Romme (2014) we see the use of SLR also in the capacity of restructuring a research domain internally, without necessarily making a case for informing management (although they do). In particular, the authors observe that entrepreneurship research has separated into different ontological and epistemo- logical approaches (i.e., the positivist, the narrative, and the design research mode) which they perceive as standing in the way of further progress in the domain. SLR is vouched for as an effective approach to re-establishing conversation between the silos, as well as to integrating research results from across them. This more academically oriented justiﬁcation for SLR may beneﬁt further from adopting a mechanism-focused approach to coding and interpreting the results from previous literature (Bhaskar 1998; Bunge 2004), as that is perceived to further strengthen the theoretical value of the synthesized knowledge (van Burg and Romme 2014). Finally, a third strategy we see authors use in justifying SLR is to apply the power of the approach to produce fairer representations of (the entirety of) existing knowledge. In that, we witness both SLR methodologists (Tranﬁeld et al. 2003) and studies applying the protocol (Tanskanen et al. 2017) draw analogy with the prominent role of systematic literature review within medical science. Indeed, if research results associate directly with human wellbeing, full transparency in every step of composing a scientiﬁc argument seems relevant. It is then argued that SLR can bring such transparency also to the parts of social science papers that are often “cherry-picked” (van Burg and Romme 2014), these being the sections on previous research and hypothesis development. In this line of argumentation, SLR serves to ensure that authors have avoided a biased view on the body of reviewed knowledge (Geyskens et al. 2009). 8.2 Developing and Presenting Synthesized Knowledge 195 8.2 Developing and Presenting Synthesized Knowledge Relating to the topic of justiﬁcation, a key question to ask at the beginning of any SLR exercise is what exactly is being synthesized and for what purpose. Taking the three examples, the common point of justiﬁcation in each of them is a need for more evidence-based management (Rousseau 2012; Rousseau et al. 2008). Essential to that purpose is to learn how to manipulate some phenomenon of interest (e.g., the entrepreneurial capacity in universities) which, in hand, assumes quite an advanced understanding of the causality around that central phenomenon. Building on the three papers in focus, in this chapter, we tackle speciﬁcally the synthesis and representation of causal knowledge, which can be a basis for possibly also generating prescriptive knowledge. For example, taking the article by Tanskanen et al. (2017), we see that the authors have mapped a substantial number of causal pathways that practitioners can take advantage of in successfully managing external resources. Furthermore, the authors emphasize that the causal statements forming the synthesized pathways feature a speciﬁc structure, referred to as the CIMO-logic (Denyer et al. 2008). In this line of reasoning, while a basic causal statement could be formed by simply associating a cause to an expected effect, a more complete way to do so is to ensure that a causal argument includes all the following components: that there is a description of a context (C) within which, if a certain intervention (I) is performed, a generative mechanism (M) is triggered, producing a certain outcome (O) (Denyer et al. 2008). In CIMO statements, compared to just a two-component cause-effect description, we gain an explicit understanding of why an outcome arises from some action (i.e., the mechanism), and in what circumstances is that expected to be the case (e.g., context). As such, a synthesized causal statement relates to the generalizability of the original empirical results, as well as the (theoretical) arguments provided by authors of previous research about why the causality exists. In this sense, by adopting the CIMO-logic, a systematic literature review can gain a powerful and complete lens to code and categorize causal relationships made by previous authors in the domain. We see Tanskanen et al. (2017) take great advantage of this format, synthesizing previous research results into elaborate, but still very clear tables where all outcomes (O) observed in previous literature are categorized by their contexts (C) and performed interventions (I). Though not in the same table, the authors articulate the relevant mechanisms (M) as well, doing so in another part of the paper. Such a set of complete CIMO statements that are also grounded in nearly the entirety of the top tier scientiﬁc evidence base around some phenomenon complies with a very high standard for synthesizing knowledge on causation. Meanwhile, not always is it possible (or necessary) for a systematic literature review to produce such an elaborate set of complete CIMO statements. For example, in the paper by van Burg and Romme (2014), we see the team resorting to their synthesis work to develop CMO statements, where the interventions have become integrated into the mechanisms. The authors motivate this choice by noting that the entrepreneurial action domain’is captured by describing the boundaries of these 196 8 What to Consider in a Systematic Literature Review … actions in terms of contextual conditions, social mechanisms, and outcome patterns’ (p. 385), so it becomes valid to think of interventions as implicit to the rest of the causal statements. We conclude, thus, that the nature of the research phenomenon may inﬂuence which components are causal coding performed for. In contrast, Velasco Montañez et al. (2020) did set out to perform full CIMO-based coding of previous evidence but discovered in the process that the literature base around the entrepreneurial university phenomenon had a lack of sophistication concerning the C-s and M-s of evidence-based knowledge. Consequently, the authors resorted to a more modest coding scheme, referring to interventions found in earlier literature simply as “causes,” and any resultant outcomes as “effects.” Therefore, the maturity of a speciﬁc domain in which the phenomenon of research is embedded (van Burg and Romme 2014) can be another determinant of how detailed a synthesis exercise within that domain can become. Finally, although the structure of the causal statements differs between van Burg and Romme (2014) and Velasco Montañez et al. (2020), we see that both teams represent the synthesized knowledge by using a type of a graph where components of various causal statements are connected by arrows that indicate where earlier literature has found an (empirical) connection. In this representation, it is for the readers of the articles to piece together the many causal statements embodied in each graph. In this sense, using this graph format provides the authors with an opportunity to represent the entire landscape of causal arguments around some phenomenon (e.g., increased entrepreneurial capacity of a university) in great detail, which would be almost impossible if the same knowledge was to be conveyed only in text. Comparing Tanskanen et al. (2017) and Velasco Montañez et al. (2020), we see that the more complex the system of causal relationships is and the less clear-cut are the overall categories of these relationships (cf., the six themes in Tanskanen et al. (2017)), the more one might prefer relationship graphs over tables when it comes to representing causal statements. 8.3 Tying It Together The third aspect we wish to reﬂect upon in performing SLR is how the justiﬁcation, the research process, and the representation of the results can be geared toward the larger purpose of the paper. In this regard, perhaps the most straightforward purpose in SLR is to target the production of knowledge that is relatively directly applicable in achieving some practical end. In our pool, this relates most to Velasco Montañez et al. (2020) where the authors quite explicitly target informing decision-makers in universities. We read that to produce knowledge for that purpose, the authors ﬁrst sought to understand the various mid-range outcomes/effects associated with the overall target of the audience. Having the outcomes ﬁxed in that way allowed the team thereafter to synthesize and categorize the many interventions/causes leading to these outcomes. This approach is coherent with contributing foremost to practitioners since it enables an interested manager to seek out one or several of the mid-range 8.3 Tying It Together 197 outcomes they wish to inﬂuence most, and then simply to trace the arrows leftward to identify all the possible means of doing so. As such, focusing on the SLR foremost on the I and O components of CIMO can result in an almost toolbox-like output. If anything, the secondary purposes of that paper, including evaluating the state of the literature, and articulating the research agenda, help qualify the primary purpose of enabling evidence-based management in the domain. In contrast, van Burg and Romme (2014) specify a key purpose of their paper to be epistemological and paradigmatic bridging of the different branches of entrepreneur- ship research. Correspondingly, they focus attention on that one component of causal statements which is (arguably) most interesting theoretically—that is, mechanisms. Writing predominantly toward a scientiﬁc audience, this appears to be a fruitful choice not only to produce a coherent body of knowledge but also to bring CIMO- based synthesis closer to standard expectations in academic journals. Although, we see from their work also that a synthesis focus on mechanisms may require a subsequent second synthesis with a focus on interventions to make the developed knowledge more immediately applicable to an audience of practitioners. Finally, although not represented among the three example papers, a synthesis from SLR can also be produced with a focus on how different contexts lead particular interventions to trigger different mechanisms and thus produce different outcomes. For instance, it may be observed that implementing the same software solution in similar proﬁle ﬁrms can lead to positive reinforcement of internal processes in some, but confusion and conﬂict in other ﬁrms. In such circumstances, it is likely to be some key aspect of context that sets these two categories of ﬁrms apart, leading the software intervention to trigger a positive mechanism in one and a negative in the other. Taking the intervention as the central phenomenon (and the stable element in the synthesis) and focusing the novelty of the research toward the contextual factors to the intervention can, therefore, render highly insightful new knowledge as well. Indeed, outlining the deep importance of contextual factors in how the causality plays out may turn out to be a highly promising research future around many contemporary interventions (e.g., digitalization of ﬁrms, implementation of corporate equality policies, etc.) 8.4 Points of Further Attention in Executing SLR From previous, we see that at least three distinct focuses are possible in causality- oriented SLR, but what matters for any of them is that the research process and the resultant report are overall structured appropriately to highlight the chosen scope. The ﬁrst point of attention in performing an SLR is, therefore, to explicitly pick and justify the purpose of the exercise and have that choice drive the rest of the process. Common pitfalls here might be to assume that synthesizing previous knowledge with no particular audience or relevant purpose in mind is valuable in and of itself, or that any one synthesis beneﬁts from a diversity of different audiences and purposes. 198 8 What to Consider in a Systematic Literature Review … A second point of attention, though not unique to SLR in DSR (McInnes and Bossuyt 2015), is that the process of selecting previous works for review and synthesis takes full advantage of the ideals of SLR to be both systematic and exhaustive. In this regard, we wish the search and selection process to be not just exclusive enough (i.e., distinct to the focal phenomenon, and ﬁltering for high quality previous research), but also inclusive enough (i.e., drawing from the diversity of approaches to studying the focal phenomenon). In support of this point, we see all three example papers, on the one hand, employ the implicit quality criterion of selecting works only from certain journals, but, on the other hand, seeking to be inclusive with their choice of databases, search keywords and methodological proﬁles of previously published articles. In fact, authors probably fair best to ﬁrst create rather a larger pool of possibly useful literature, followed by more stringent exclusion criteria to help scope which exact works will be processed in full. Though not a rule, authors might ﬁnd themselves on the right track if they can measure the initial search result in the hundreds (of earlier works), but the eventual pool to review rather in the dozens. The most common pitfall in this regard is to assume that running the search and selection ﬁrst time over already renders the most optimal result. Instead, we suggest an iterative approach where the protocol is tested several times in different forms before committing to a ﬁnal version to execute in full. Finally, a third point of further attention is that claims made by authors of the synthesis are presented with just the right amount of conﬁdence dependent on their grounding in earlier literature. Here, as an alternative to (or, on top of) discriminating based on journal quality, we suggest that a natural part of processing any paper in the ﬁnal pool is also an assessment of its methodological rigor. Authors could thereafter carry this information through the rest of the synthesis process toward an honest qualiﬁcation of the eventual bit of knowledge (Velasco Montañez et al. 2020). Why this appears important is not only to convey the best of scientiﬁc understanding of the phenomenon, but also to add a layer point of control against author bias to the process of synthesis, which tends to remain the most black-boxed stage of systematic literature reviews. Common pitfalls in this regard concern equating previous evidence from higher and lower quality scientiﬁc works; considering causality claimed in only one earlier work at par with claims that have been replicated or triangulated; and frivolously integrating claims that sound similar, but are not quite identical. As an example of the latter, authors should, for instance, weigh carefully if evidence originating from different contexts but supporting some particular causality could be integrated into one causal statement, or rather be kept separate. References Bhaskar, R.: The Possibility of Naturalism: A Philosophical Critique of the Contemporary Human Sciences, 3rd edn., 208 pp. Routledge, London (1998). 0415198747 Bunge, M.: How does it work? The search for explanatory mechanisms. Philos. Soc. Sci. 34(2), 182–210 (2004) References 199 Denyer, D., Tranﬁeld, D., van Aken, J.E.: Developing design propositions through research synthesis. Organizat. Stud. 29(3), 393–413 (2008). 0170-8406 Geyskens, I., et al.: A review and evaluation of meta-analysis practices in management research. J. Manage. 35(2), 393–419 (2009) McInnes, M.D.F., Bossuyt, P.M.M.: Pitfalls of systematic reviews and meta-analyses in imaging research. Radiology 277(1), 13–21 (2015) Velasco Montañez, M., et al.: Entrepreneurial University in Practice: Synthesizing Two Decades of Evidence. Academy of Management, New York (2020) Romme, A.G.L.: The Quest for Professionalism: The Case of Management and Entrepreneurship, 1st edn., 258 pp. Oxford University Press, Oxford (2016). 978-0-19-873773-5 Rousseau, D.M.: Envisioning Evidence-Based Management, 1st edn., 432 pp. Oxford University Press, New York (2012). 9780199763986 Rousseau, D.M., Manning, J., Denyer, D.: Evidence in management and organizational science: assembling the ﬁeld’s full weight of scientiﬁc knowledge through syntheses. Acad. Manage. Ann. 2(1), 475–515 (2008) Tanskanen, K., et al.: Towards evidence-based management of external resources: developing design propositions and future research avenues through research synthesis. Res. Policy 46(6), 1087– 1105 (2017) Tranﬁeld, D., Denyer, D., Smart, P.: Towards a methodology for developing evidence-informed management knowledge by means of systematic review* introduction: the need for an evidence- informed approach. Br. J. Manage. 14, 207–222 (2003) van Burg, E., Romme, A.G.L.: Creating the future together: toward a framework for research synthesis in entrepreneurship. Entrepreneurship Theory Practice 38(2), 369–397 (2014) Chapter 9 Future Perspectives This book sought to advance the discussions about the Systematic Literature Review (SLR). As the volume of publications grows, discussions on how to generate knowl- edge through the scientiﬁc and technological literature belonging to World 3 become essential. Although the individual results of existing research in World 3 can bring important evidence about a given phenomenon, their explanatory capacity and poten- tial for generalization are ampliﬁed when evaluated together. Consequently, the ability to develop a comprehensive and systemic view of the body of research has assumed a central role in this context, a fact that has increased the search for method- ological procedures capable of delivering these capabilities. With this purpose and with applications in a wide range of knowledge areas, SLR has gained a promi- nent role in recent years. However, since each scientiﬁc community adopts speciﬁc practices, several approaches have developed independently, making it difﬁcult to compare these approaches and understand when and how they might interlink. In this context, by proposing a holistic view of the process intended to generate or test theories and hypotheses, this book broadens the traditional perspective on how to conduct an SLR. Materialized in the form of a method, entitled Literature Grounded Theory (LGT), this new standpoint enables the generation of both scientiﬁc and technological knowledge through the review, analysis, and synthesis of the literature. Applicable to several knowledge areas, and not restricted to the academic context, the LGT method allows the identiﬁcation of scientiﬁc and technological trends capable of advancing knowledge on a given situation or phenomenon, as well as supporting strategic decisions at the organizational level, particularly the ones associated to research and development (R&D). From a methodological point of view, besides connecting several approaches into a single method, this book sought to overcome the lack of knowledge and familiarity of researchers concerning synthesis procedures, a stage of fundamental importance in conducting an SLR, but not well explored so far. Still regarding the synthesis, when proposing the Qualitative Meta-Analysis, this book also transposes the limitation of current techniques in synthesizing heterogeneous and qualitative data from an aggregative perspective intended to test hypotheses and theories. © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_9 201 202 9 Future Perspectives Although this book presents methodological advances regarding the SLR, there is still much to be done in other spheres. In this sense, it is necessary to advance in the construction of speciﬁc journals that consolidate the SLR produced by different areas of knowledge, such as already done in health sciences. This development can avoid conducting overlapping or irrelevant research, while accelerating the evolu- tion of both scientiﬁc and technological knowledge. From the execution stand- point, the different stages of an SLR (design, review, analysis, synthesis, results, and update) demand the use of different software. This situation, besides increasing the complexity of the process, might result in loss of information as data is trans- ferred from one software to another. In this sense, the development of software that integrates the stages of an SLR, as well as their respective techniques, can provide greater agility and precision in the execution of research. Regarding the use of SLR outside the academic boundaries, such as in the health industry, it is necessary to reinforce its role in technological development within organizations, particularly in the formulation of technological roadmaps. Finally, we hope that Karl Popper’s ontological notion may inspire other researchers to develop concepts, artifacts, techniques, and tools that allow us to generate and test knowledge from World 3. The relationships between World 3 and the other worlds need further investigation. In this sense, the abductive scientiﬁc method, besides requiring greater appropriation by the scientiﬁc community, also needs to be better explored in the development of knowledge and new technolo- gies. Moreover, the evaluation of the artifacts retried from the abductive process also requires more attention and reﬂection concerning their rigor and pragmatic validity. We seek to contribute by presenting a research method that allows an integrated and non-bureaucratic view of SLR. Thus, we believe that this book may allow criti- cism and, consequently, an advance toward better instruments to dominate, analyze, criticize, and synthesize objective knowledge, the knowledge without a knower, the knowledge that resides in World 3. Correction to: Literature Reviews Ana Paula Cardoso Ermel , D. P. Lacerda , Maria Isabel W. M. Morandi , and Leandro Gauss Correction to: A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9 In the original version of the book, the following belated corrections have been incorporated: In chapter “Literature Analysis”, missing bullets have been updated in Figure 4.12. In chapter “Literature Synthesis”, Figure 5.1 has been moved to section 5.2.9 Grounded Theory from 5.2.10 Meta-Ethnography. In chapter “Literature Grounded Theory (LGT)”, ﬁgures are centred in Table 6.28 and the ﬂow arrows are corrected in Figures 6.2, 6.5. In chapter “Computational Tools for Literature Review, Analysis, and Synthesis”, white space has been removed in Figure 7.1. The erratum chapters have been updated with the changes. The updated versions of the chapters can be found at https://doi.org/10.1007/978-3-030-75722-9_4 https://doi.org/10.1007/978-3-030-75722-9_5 https://doi.org/10.1007/978-3-030-75722-9_6 https://doi.org/10.1007/978-3-030-75722-9_7 © The Author(s), under exclusive license to Springer Nature Switzerland AG 2021 A. P. Cardoso Ermel et al., Literature Reviews, https://doi.org/10.1007/978-3-030-75722-9_10 C1","libVersion":"0.3.2","langs":""}