{"path":"Clippings/PDF/ChatGPT y CAQDAS.pdf","text":"See discussions, st ats, and author pr ofiles for this publication at: https://www.r esearchgate.ne t/publication/367990261 ChatGPT y software CAQDAS para el análisis cualitativo de entrevistas: pasos para combinar la inteligencia artiﬁcial de OpenAI con ATLAS. ti, Nvivo y MAXQDA Technical Report · January 2023 CITATIONS 24 READS 5,213 2 author s: Carlos Lopezosa Pompeu Fabra University 85 PUBLICATIONS   790 CITATIONS    SEE PROFILE Lluís Codina Pompeu Fabra University 321 PUBLICATIONS   3,196 CITATIONS    SEE PROFILE All content following this page was uploaded by Carlos Lopezosa on 02 F ebruary 2023. The user has requested enhancement of the downloaded file. DIGIDOC REPORTS: ONLINE NEWS RESEARCH PAPERS, 2023.02 ChatGPT y programas CAQDAS para el análisis cualitativo de entrevistas: pasos para combinar la inteligencia artificial de OpenAI con ATLAS.ti, Nvivo y MAXQDA Carlos Lopezosa y Lluís Codina DigiDoc Research Group | Pompeu Fabra University (Barcelona) Roc Boronat, 138 08018 Barcelona www.upf.edu/web/digidoc/ digidoc@upf.edu Autores: Carlos Lopezosa y Lluís Codina DigiDoc Research Group - Pompeu Fabra University (Barcelona) 1 de febrero 2023. This work is distributed under this Creative Commons license Forma recomendada de citación Lopezosa, Carlos; Codina, Lluís (2023). ChatGPT y software CAQDAS para el análisis cualitativo de entrevistas: pasos para combinar la inteligencia artificial de OpenAI con ATLAS.ti, Nvivo y MAXQDA Barcelona: Departamento de Comunicación. Serie Editorial DigiDoc. PCUV04/2023 Financiación Este trabajo forma parte del desarrollo de metodologías dentro del proyecto \"Parámetros y estrategias para incrementar la relevancia de los medios y la comunicación digital en la sociedad: curación, visualización y visibilidad (CUVICOM)”. PID2021-123579OB-I00 (MICINN), Ministerio de Ciencia e Innovación (España). Actividad financiada por la Unión Europea-NextGenerationEU, Ministerio de Universidades y Plan de Recuperación, Transformación y Resiliencia, mediante convocatoria de la Universidad Pompeu Fabra (Barcelona). ChatGPT y software CAQDAS para el análisis cualitativo de entrevistas: pasos para combinar la inteligencia artificial de OpenAI con ATLAS.ti, Nvivo y MAXQDA Carlos Lopezosa (UB) y Lluís Codina (UPF) 2023 SOBRE LOS AUTORES Carlos Lopezosa es doctor en periodismo por la Universitat Pompeu Fabra e investigador visitante en la Universidad de Barcelona (Beca postdoctoral Margarita Salas). Su tesis doctoral se centró en el estudio de los factores de posicionamiento de sitios intensivos en contenidos, y en especial de medios de comunicación online, así como en la evaluación de herramientas de análisis SEO. Es especialista en posicionamiento en buscadores y en sistemas de monetización basados en estrategias de contenidos de calidad. Ha sido profesor asociado de la Universitat Pompeu Fabra, impartiendo docencia en la Facultad de Comunicación, en el Grados de Periodismo, Comunicación Audiovisual y Publicidad y Relaciones Públicas. ORCID: 0000-0001-8619-2194 Contacto: lopezosa@ub.edu | Sitio web personal: carloslopezosa.com Lluís Codina es profesor de la Facultad de Comunicación, en los grados de Periodismo y de Comunicación Audiovisual así como en el Máster Universitario en Investigación en Comunicación. Es investigador del departamento de Comunicación de la Universitat Pompeu Fabra, coordinador de la Unidad de Investigación en Periodismo y Documentación Digital (UPF) y codirector del Observatorio de Cibermedios. Es profesor también de la Barcelona School of Management – UPF. Es cofundador y miembro del equipo editorial de la Revista Académica Hipertext.net. ORCID: 0000-0001-7020-1631 Contacto: lluis.codina@upf.edu | Sitio web personal: lluiscodina.com __________________________________________ Resumen: Este informe propone orientaciones prácticas a los investigadores para analizar cualitativamente entrevistas académicas mediante el uso combinado de software inteligencia artificial (IA) y de análisis cualitativo asistido por ordenador (CAQDAS). En concreto, mostramos la manera de combinar ChatGPT y programas de análisis cualitativo como ATLAS.ti, Nvivo y MAXQDA. En primer lugar, presentamos una introducción a las entrevistas académicas y a los programas CAQDAS. En segundo lugar, se presenta una revisión de estudios académicos relacionados con el uso de ATLAS.ti, Nvivo y MAXQDA. En tercer lugar, se aborda la inteligencia artificial ChatGPT como soporte a los programas tipo CAQDAS (como los mencionados) para la codificación de entrevistas y la compilación de resultados tomando en consideración las dos condiciones generales para el uso de IA: pensamiento crítico y ética profesional. Finalmente, se ilustra con ejemplos prácticos, paso a paso, cómo combinar ChatGPT con ATLAS.ti, NVIVO y MAXQDA, respectivamente, para generar estudios cualitativos apoyados en entrevistas. Palabras clave: ChatGPT, ATLAS.ti, Nvivo, MAXQDA, inteligencia artificial, IA, CAQDAS, entrevistas, investigación cualitativa, metodologías cualitativas, análisis de datos, Software __________________________________________ __________________________________________ Abstract: This report proposes practical guidelines for researchers to qualitatively analyse academic interviews through the combined use of artificial intelligence (AI) and computer-assisted qualitative data analysis software (CAQDAS). Specifically, we show how to combine ChatGPT and qualitative analysis programs such as ATLAS.ti, Nvivo and MAXQDA. First, we present an introduction to academic interviews and CAQDAS programs. Second, a review of academic studies related to the use of ATLAS.ti, Nvivo and MAXQDA is presented. Thirdly, the ChatGPT artificial intelligence is addressed as a support for CAQDAS-type programs (such as those mentioned) for the coding of interviews and the compilation of results, considering the two general conditions for the use of AI: critical thinking and professional ethics. Finally, it is illustrated with practical examples, step by step, how to combine ChatGPT with ATLAS.ti, NVIVO and MAXQDA, respectively, to generate qualitative studies supported by interviews. Keyword: ChatGPT, ATLAS.ti, Nvivo, MAXQDA, artificial intelligence, AI, CAQDAS, interviews, qualitative research, qualitative methodologies, data analysis, Software __________________________________________ 0 Sumario Introducción ............................................................................................................................ 1 ATLAS.ti, Nvivo y MAXQDA como herramientas para la codificación y el análisis cualitativos ............................................................................................................................... 3 ChatGPT como herramienta de soporte a ATLAS.ti, Nvivo y MAXQDA ...................... 8 Combinando ChatGPT y Nvivo para el análisis cualitativo de entrevistas ................ 30 Combinando ChatGPT y MAXQDA para el análisis cualitativo de entrevistas ........ 54 Conclusiones ......................................................................................................................... 78 Bibliografía ............................................................................................................................ 79 1 Introducción Las entrevistas son un tipo de metodología ampliamente utilizada en ciencias sociales, así como en campos como la medicina. Se trata de una herramienta que se caracteriza por el desarrollo de una conversación entre el investigador (emisor) y el entrevistado (receptor) con el objetivo, entre otros, de explorar las percepciones, creencias y conocimientos de un grupo sobre un tema en particular, entender cómo perciben los miembros de un colectivo un determinado fenómeno, u obtener datos para investigaciones, como estudios de caso. También se aplican para validar objetivos y preguntas de investigación o hipótesis, y siempre se utilizan para ampliar el conocimiento sobre lo que se está investigando a través de conversaciones con diferentes tipos de personas, como pudieran ser ciudadanos, usuarios, expertos, pacientes o responsables de políticas, por poner algunos ejemplos. La forma en que se desarrolla la conversación entre el emisor y el receptor depende del tipo de entrevista que se realice. En este sentido, podemos encontrar tres tipos de entrevistas: estructuradas, semiestructuradas y no estructuradas. Cada una de este tipo de entrevista tiene sus propias características y se aplican en diferentes situaciones de investigación. En este sentido: • Entrevista estructurada: son las más rígidas y producen resultados muy sistematizados. Se basan en preguntas previamente definidas con un orden estratégico y con una serie de respuestas cerradas. Los entrevistados eligen del listado de respuestas las que consideran más adecuadas. • Entrevista semiestructurada: son más flexibles y dinámicas, ya que permiten respuestas abiertas y la interacción entre el investigador y el entrevistado. Los entrevistados pueden no solo responder a las preguntas, sino también hacer apreciaciones transversales a las preguntas realizadas. Toda la información obtenida es susceptible de ser analizada e incluida en los resultados de la investigación. • Entrevista no estructurada: son muy flexibles y permiten una amplia interpretación debido a que las preguntas son abiertas y se van formulando y construyendo a medida que avanza la entrevista. Esto permite una mayor riqueza en las valoraciones y apreciaciones de los entrevistados, ya que no están dirigidos y pueden responder libremente. Es importante tener en cuenta que cada tipo de entrevista científica tiene sus propias características y, por lo tanto, la elección de una u otra puede influir en el desarrollo y resultado de la investigación (Díaz-Bravo et al. 2003). Por ese motivo, es esencial conocer bien cada tipo de entrevista y aplicar la que más se ajuste a las necesidades del estudio en cuestión. Un aspecto esencial en las entrevistas científicas es asegurar que se extraen y aprovechan correctamente todos los datos proporcionados por los entrevistados. Para ello, muchos investigadores realizan el análisis cualitativo de las entrevistas utilizando para ello programas de análisis de contenido también conocidos como CAQDAS (por las siglas en inglés de Computer Aided Qualitative Data Analysis Software). Estos programas son capaces de codificar de forma asistida datos cualitativos de diferentes formatos, entre ellos, los datos textuales resultantes de entrevistas, lo que ayuda a los investigadores a mejorar el rigor y la eficacia de sus estudios. 2 Algunos de los programas CAQDAS más populares son ATLAS.ti (Paulus y Lester, 2015; Paulus et al. 2018; Lopezosa et al. 2022), NVivo (Lopezosa, 2020) y MAXQDA (Schultheiß y Lewandowski, 2020; 2021; Lopezosa y Codina, 2022), entre otros. Como ya se ha indicado, la manera de extraer los datos de las declaraciones de los entrevistados utilizando un CAQDAS es de forma asistida (semiautomática), por lo que hay dos aspectos sensibles que hay que tener en cuenta. Por un lado, la elección de los códigos a aplicar, y, por otro lado, la interpretación final de los informes resultantes de la codificación de las entrevistas. Los códigos, como veremos a lo largo de este informe, deben reflejar los mismos temas sobre los que hemos decidido articular las declaraciones de los entrevistados. El término código no debe hacernos pensar exclusivamente en números o en siglas. El término código es perfectamente equivalente al de tema o categoría. Por tanto, podemos pensar en los códigos como en palabras simples o compuestas, o en frases cortas, que expresan los temas principales de la investigación. La función de estos códigos o categorías es la de unir fragmentos significativos de información textual de fuentes diferentes (p.e. diferentes entrevistados) que se refieren a los mismos temas. Estos códigos pueden ser creados y seleccionados por el investigador. En el caso de las entrevistas, puede ser código de tipo deductivo, esto es, habrán sido generados antes de los análisis ya que cada una de las preguntas ha sido diseñada alrededor de cada uno de los temas. Los códigos o categorías pueden haber sido obtenidos como resultado de investigaciones o estudios previos, p.e, a partir de una revisión de la literatura o de un estudio de caso. Los códigos también pueden generarse de modo inductivo, esto es, a partir del análisis de un corpus textual de algún tipo, como el que generan las entrevistas. Por último, como es lógico, los códigos y los informes resultantes pueden ser obtenidos de un modo mixto, esto es, las preguntas o temas de las entrevistas implican una codificación deductiva a priori e inicial, pero el análisis a posteriori, bien sea de tipo intelectual, o con software de IA como el que aplicaremos aquí, permite inducir formas de codificación adicionales. En este sentido, los informes serán el resultado de la codificación aplicadas las entrevistas. Los programas CAQDAS ofrecen al investigador un informe por cada código aplicado. Estos informes son, en sí mismos, datasets en bruto que el investigador deberá leer e interpretar de modo crítico para obtener las ideas más significativas y de mayor riqueza para el estudio que esté realizando. En este sentido y, ante el auge de la inteligencia artificial, y más concretamente de ChatGPT, un lenguaje de procesamiento natural desarrollado por OpenAI (2022), este trabajo tiene como objetivo ofrecer, un método que combina ChatGPT con programas como ATLAS.ti, Nvivo y MAXQDA para mejorar la experiencia de los investigadores en el análisis cualitativo de entrevistas. A continuación, se lleva a cabo una revisión de ATLAS.ti, Nvivo y MAXQDA y su uso en la academia, seguidamente, se explica qué es ChatGPT y cómo puede ser utilizada para apoyar el proceso de codificación de entrevistas y recopilación de resultados tomando como base el pensamiento crítico y la ética profesional (Codina, 2022). Finalmente, se presentan tres ejemplos práctico detallado de cómo combinar ChatGPT con (1) ATLAS.ti, (2) Nvivo y (3) MAXQDA en estudios cualitativos basados en entrevistas. 3 ATLAS.ti, Nvivo y MAXQDA como herramientas para la codificación y el análisis cualitativos El desarrollo de las Tecnologías de la Información y la Comunicación ha permitido el surgimiento de programas CAQDAS. Programas como ATLAS.ti (Paulus y Lester, 2015; Paulus et al. 2018; Lopezosa et al.2022), NVivo (Lopezosa, 2021a; Lopezosa, 2021b) o MAXQDA (Schultheiß y Lewandowski, 2020; 2021; Lopezosa y Codina, 2022), entre otros, permiten la organización, sistematización, procesamiento y análisis de los datos que componen las investigaciones, ayudando al investigador a mejorar el rigor y la eficacia de sus estudios (Díaz et al. 2016). Entre las funciones de estos programas se encuentra la posibilidad de codificar documentos de texto, audiovisuales, fotografías e incluso importar datos de Twitter y Evernote. Además, permiten a los investigadores llevar a cabo varias funciones de análisis cualitativo, incluyendo la clasificación y filtrado de datos sin procesar, el descubrimiento y la construcción de relaciones entre los datos, la asignación y definición de temas y categorías para darle significado a los datos, la visualización de los resultados del análisis de datos y la creación de informes. En resumen, estos programas pueden ser utilizado en diversos tipos de investigaciones, como el análisis de datos de entrevistas, datos de encuestas, e incluso datos de trabajos de estudiantes. Si revisamos la literatura generada alrededor de estos programas, algunos de los estudios más destacados se resumen a continuación: • Saillard (2011) comparó dos paquetes diferentes de análisis cualitativo de datos asistidos por computadora, específicamente NVivo y MAXQDA, para el desarrollo de estudios audiovisuales. Los criterios para la evaluación comparativa de estas herramientas fueron, entre otros, la facilidad para codificar el contenido, y la interrelación entre los datos y las funcionalidades de las dos herramientas. • Schönfelder (2011) presentó un estudio comparativo entre los programas NVIVO y MAXQDA para el análisis cualitativo de datos en investigaciones, destacando los límites de sacar conclusiones a partir de los datos cualitativos desde un enfoque constructivista y analítico del discurso. • Franzosi et al. (2013) presentaron un estudio en el cual se comparó el uso de diferente software de análisis de texto para llevar a cabo un análisis narrativo cuantitativo. Se utilizaron ATLAS.ti, MAXQDA y Nvivo, y se proporcionó una guía detallada sobre los pasos involucrados en la configuración de una gramática, la entrada de datos y la consulta de datos. • Paulus, Woods, Atkins y Macklin (2015) investigaron cómo los investigadores utilizan software de análisis de datos cualitativos (QDAS) como ATLAS.ti y NVivo. Para ello realizaron un análisis del discurso de 763 artículos empíricos publicados entre 1994 y 2013 que exploraban el lenguaje utilizado por los investigadores al informar sobre el uso de QDAS. Descubrieron que la mayoría de los investigadores proporcionaron pocos detalles de su uso de QDAS más allá de nombrar el software utilizado. Los autores recomiendan que los autores que trabajen con este tipo de herramientas lleven a cabo las mejores prácticas para informar sobre su uso más allá de nombrar solo el software utilizado. 4 • Woods, Paulus, Atkins y Macklin (2015) identificaron 763 artículos en Scopus durante el periodo 1994 y 2013 que utilizaban ATLAS.ti o NVivo. Con el objetivo de conocer cómo usaban los investigadores estos dos programas de CAQDAS. Este estudio confirmó que el uso de estas dos herramientas se iba incrementando a lo largo del tiempo, que su uso era mayoritario en estudios sobre ciencias de la salud para entrevistas y focus groups y que los investigadores más prolíficos eran de Reino Unido, Estados Unidos, Países Bajos, Canadá y Australia. • Niedbalski y Ślęzak (2017) realizaron una comparación de ATLAS.ti y NVivo tomando como ejemplo el análisis cualitativo de datos en investigaciones basadas en la metodología de la teoría fundamentada (grounded theory). Analizaron los elementos técnicos y las posibilidades analíticas de ambas herramientas. En cuanto a los estudios académicos específicos sobre ATLAS.ti, es importante destacar que este software ha sido utilizado en una gran variedad de investigaciones desde hace más de 30 años. Algunos de los estudios más destacados son: • Muhr (1991) desarrolló una descripción completa sobre qué es ATLAS.ti y cuáles son sus funcionalidades, siendo uno de los trabajos fundacionales en los que se estudia esta herramienta. • Barry (1998) comparó los principales paquetes de software de análisis de datos cualitativos de la época (1998) ATLAS.ti y Nudist con la intención de ayudar a los investigadores a elegir una herramienta u otra dependiendo de sus necesidades investigativas. Para ello, mostró las fortalezas y debilidades de ambas herramientas. • Gibson, Callery, Campbell, Hall y Richards (2004) explican cómo utilizaron ATLAS.ti para analizar archivos de sonido, y describen los problemas a los que se tuvieron que enfrentar al recopilar, analizar y utilizar estos datos para la redacción de informes. El trabajo confirmó que todavía existían importantes barreras para la integración óptima de datos de audio en las investigaciones cualitativas. • Scales (2012) revisó los principios básicos del análisis cualitativo y trató de describir cómo los estudiantes utilizaban ATLAS.ti. Esta investigación no solo permitió reconocer esta herramienta esencial para evaluar datos basados en texto, sino que también ofreció una guía sobre cómo configurar un proyecto con este software. • Paulus y Bennett (2015) se centró en cómo se percibía el uso de ATLAS.ti por parte de los estudiantes de postgrado. Este trabajo confirmó, entre otras cosas, que al apoyar a los alumnos en sus primeras experiencias con ATLAS.ti, se anticipaba que podrían continuar usando esta herramienta en futuros trabajos de investigación. • Paulus y Lester (2015) explica un caso práctico de uso de ATLAS.ti aplicado al análisis cualitativo de conversaciones y discursos, con el fin de ilustrar cómo se puede aprovechar este software para completar diferentes tareas analíticas. Esta investigación confirmó que ATLAS.ti permite a los usuarios resolver importantes desafíos metodológicos, como por ejemplo trabajar con grandes conjuntos de datos y llegar a niveles de codificación que difícilmente se pueden lograr manualmente. • Hwang (2015) realizó una revisión de ATLAS.ti utilizando dos ejemplos desarrollados por el propio autor. Este estudio permitió explicar cómo utilizar este software y aplicarlo a estudios de ciencias sociales. • Menezes-Brito, et al. (2017) describieron la aplicación de ATLAS.ti tomando en cuenta sus debilidades y fortalezas como herramienta para el análisis de datos. Demostraron que es una herramienta importante para análisis cualitativo ya que es capaz de organizar, capturar y analizar datos de forma eficaz y reduce los tiempos de trabajo al optimizar el proceso de codificación del contenido de las investigaciones. 5 • Paulus, Pope, Woolf y Silver (2018) propusieron un taller de uso de ATLAS.ti y mostraron su experiencia práctica utilizando el método QDA® de cinco niveles. El estudio confirmó que para un óptimo uso del software ATLAS.ti es necesario no solo conocer bien la herramienta sino también aplicar adecuadamente estrategias analíticas. • Kalpokaite y Radivojevic (2019) en su investigación analizaron cómo el aprendizaje de ATLAS.ti afectaba a los estudiantes en entornos tanto presenciales como en línea. Los resultados de esta investigación confirmaron que el software puede ser aprendido de manera efectiva en ambos entornos. Además, el estudio incluyó recomendaciones sobre las mejores prácticas para el uso de ATLAS.ti en entornos de aprendizaje en línea. • Vila-Henninger (2019) utilizó ATLAS.ti en un estudio de entrevistas para comprender cómo los votantes estadounidenses legitiman sus posiciones políticas. Este estudio incluyó 120 entrevistas que fueron codificadas utilizando este software. • Rambaree y Nessica (2021) en su artículo, desarrollaron una discusión sobre el uso de ATLAS.ti en las ciencias sociales y en particular en estudios de trabajo social. El estudio de caso presentado en el artículo se centró en el bienestar infantil de Suecia y demostró la utilidad de ATLAS.ti como herramienta de análisis cualitativo. Asimismo, NVivo también ha sido utilizado en una variedad amplia de estudios académicos. Algunas de las investigaciones más representativas son: • Wong (2008) demuestra cómo Nvivo puede ser utilizado en el proceso de análisis de datos cualitativos, describiendo las características básicas y herramientas principales que ayudan a los investigadores cualitativos a administrar y analizar sus datos. • Hutchison et al. (2009) ilustran cómo el paquete de software QSR-NVivo puede facilitar el enfoque de la teoría fundamentada, argumentando que, si se utiliza adecuadamente, puede facilitar muchos aspectos del proceso desde el diseño y los procedimientos de muestreo temprano hasta el análisis de datos, el desarrollo teórico y la presentación de los hallazgos. • Beekhuyzen et al. (2010) se enfocan en el proceso de análisis de datos para un estudio etnográfico, analizando en detalle el uso de Nvivo en el análisis de entrevistas para la etnografía crítica y argumentando que su uso ayuda a que el proceso de análisis sea transparente. • Bergin (2011) presenta una reflexión crítica sobre el uso de NVivo 8 en la identificación de consistencia e inconsistencia durante el proceso de codificación en investigaciones cualitativas. El autor destaca la utilidad del programa para mejorar la solidez de la investigación, pero recomienda la realización de consultas a medida que se avanza en el análisis para evitar errores. • Leech y Onwuegbuzie (2011) describen siete técnicas de análisis de datos cualitativos mediante NVivo y presentan una guía paso a paso para su aplicación en investigaciones de psicología escolar. Los autores demuestran la utilidad del programa para aumentar el rigor en los procedimientos de análisis de datos. • Zapata-Sepúlveda y López-Sánchez (2011) revisaron la utilidad de Nvivo en una tesis doctoral que investigó los efectos psicológicos a largo plazo de experiencias de encarcelamiento y tortura por motivos políticos. El estudio confirmó la utilidad de Nvivo para el desarrollo de análisis de contenido temático cualitativo. 6 • Sotiriadou et al. (2014) utilizaron Nvivo y Leximancer para analizar un conjunto de datos derivados de entrevistas con expertos en gestión deportiva, con el objetivo de mostrar las diferencias en los hallazgos según el software utilizado. Los autores subrayan la importancia de considerar cuidadosamente la elección del software para el análisis de datos cualitativos, basando la decisión en aspectos como el tipo y tamaño del conjunto de datos, la competencia del investigador, las habilidades de interpretación de datos y el nivel de compromiso con el análisis. • Zamawe (2015) presenta una reflexión sobre su experiencia al interactuar con Nvivo, enfatizando en que la función principal de los programas CAQDAS no es analizar datos, sino ayudar al proceso de análisis, siendo siempre el investigador quien debe mantener el control. • Houghton et al. (2016) utilizaron Nvivo en diferentes etapas de su estudio sobre el personal sanitario que atiende a personas con demencia en situaciones agudas, confirmando la existencia de grandes beneficios en su uso como herramienta para facilitar la síntesis de hallazgos de manera sistemática y rigurosa. • Trigueros-Cervantes et al. (2016) presentan una propuesta metodológica para la organización, desarrollo y análisis de los grupos de discusión utilizando Nvivo, ilustrando cada una de las fases con un ejemplo de una investigación realizada sobre el aprendizaje de los adultos mayores en la universidad. • Muhtarom et al. (2017) presentaron un estudio en el que analizaron el proceso de pensamiento de los estudiantes al resolver problemas matemáticos. Utilizaron un método de triangulación con pruebas y entrevistas, y para la presentación y análisis de los datos utilizaron el software QSR Nvivo 11. • Wilk et al. (2017) utilizaron las herramientas NVivo y Leximancer para analizar datos masivos en línea, y discutieron las fortalezas y debilidades de ambos programas. Encontraron que, aunque ambos programas tienen fortalezas y debilidades al trabajar con datos masivos basados en texto, se complementan entre sí y proporcionan una visión más completa del análisis. • Maher et al. (2018) exploraron diferentes enfoques de análisis cualitativos, tanto tradicionales como utilizando el software Nvivo. Concluyeron que combinar la codificación del contenido utilizando Nvivo con herramientas tradicionales ofrecen un método válido de análisis. • O'Neill et al. (2018) presentaron un estudio sobre el uso de herramientas como Nvivo para el desarrollo de revisiones sistematizadas. Ofrecieron un enfoque específico paso a paso para que los investigadores puedan utilizar Nvivo en el proceso de encontrar y analizar documentos para sus estudios. • Phillips y Jing (2018) revisaron las funcionalidades, curva de aprendizaje, herramienta de colaboración, soporte técnico y costo de NVivo, concluyendo que este software agrega un valor significativo para los investigadores de análisis cualitativo. • Sepasgozar y Davis (2018) presentaron un método innovador que incluyó el uso de NVivo para explorar cómo las empresas toman decisiones de adopción de nuevas tecnologías, contribuyendo al desarrollo de un cubo metodológico para investigar el proceso de adopción de tecnología en la construcción, cubriendo conceptos como adopción, aceptación, difusión e implementación. • Bonello y Meehan (2019), en un análisis de caso de estudio cualitativo que explora el concepto de educación interprofesional en Malta, utilizaron Nvivo para producir una auditoría que recogía cómo se obtuvieron los datos, los hallazgos, las interpretaciones y las conclusiones posteriores. El trabajo concluye que Nvivo destaca por su potencial 7 para facilitar un enfoque más riguroso y transparente para el análisis de datos cualitativos. • Feng et al. (2019) describen y demuestran cómo las funciones de frecuencia de palabras, búsqueda de texto y codificación matricial de Nvivo se pueden utilizar para analizar datos cualitativos de un proyecto de evaluación longitudinal. Los autores mostraron cómo la función de codificación matricial maximiza las utilidades de Nvivo en un análisis de respuestas abiertas y resalta las diferencias entre los grupos de participantes y dentro de ellos. • Rojas-Figueroa et al. (2019) utilizaron Nvivo para analizar las redes sociales de una empresa consultora en gestión de proyectos y brindar información valiosa para satisfacer mejor a los clientes. • Almaiah y Al Mulhem (2020) emplearon el enfoque de entrevista utilizando el análisis temático a través de Nvivo para estudiar la problemática de los sistemas de e-learning. Por último, MAXQDA también es utilizado con frecuencia en estudios académicos, de hecho, así lo reportan los investigadores en sus trabajos, al mencionar este programa como parte de su metodología. En este sentido, algunos de los estudios más importantes son: • Marjaei et al. (2019) realizaron una revisión de MAXQDA centrada principalmente en el desarrollo de estudios de LIS (Library and Information Sciences). En este estudio se confirmó que los investigadores de LIS necesitan respaldar y mejorar sus estudios preparando los datos cualitativos con MAXQDA, codificando con su sistema de codificación y organizando los datos para el análisis. Asimismo, este estudio aumentó el conocimiento sobre el uso de métodos de investigación cualitativos en el campo de la Biblioteconomía y la Información (LIS) utilizando programas para el análisis cualitativo asistido por computadora. • Kuckartz (2010) señaló que MAXQDA proporciona una variedad de procedimientos y herramientas que son de gran utilidad cuando se trabajan los métodos mixtos ya que este software puede aplicarse a las diferentes etapas del análisis. En su estudio se recomienda utilizar las fortalezas de los datos cualitativos y los datos cuantitativos sobre todo en el proceso de codificación. • Rädiker (2020) presenta un método para llevar a cabo análisis cualitativos utilizando MAXQDA. El estudio incluye ejemplos prácticos y una lista de verificación para garantizar la eficacia en el uso de estas herramientas de análisis cualitativo asistido por ordenador. • Kuckartz y Rädiker (2021) proporcionan una descripción detallada de las funcionalidades y el uso adecuado de MAXQDA, con un enfoque en las metodologías mixtas. • Hatani (2015) investigó el potencial de los videos de acceso abierto en internet como fuente de datos para identificar áreas clave en salud global, registrando y analizando los diálogos en los videos mediante MAXQDA. • Consoli (2021) utilizó MAXQDA como herramienta para llevar a cabo investigaciones narrativas y para examinar su epistemología. El uso de este software ayudó a facilitar el análisis narrativo al tratar con un gran conjunto de datos de diferentes fuentes, y también permitió legitimar la metodología narrativa como un enfoque investigativo riguroso. 8 En general, como hemos podido ver de los estudios anteriormente citados, ATLAS.ti, Nvivo y MAXQDA pueden ser de gran ayuda para los investigadores que buscan organizar, sistematizar y analizar entrevistas. Cabe señalar que los programas CAQDAS cuentan con dos elementos clave sobre los que gira todo el proceso: los códigos, por un lado, y los informes que se producen como resultado de aplicar esta codificación a las entrevistas. Cuando usamos un software como ATLAS.ti, Nvivo o MAXQDA es decisión del investigador qué códigos o categorías usará para la codificación de las entrevistas. Se trata de un trabajo intelectual que surge de la reflexión crítica del investigador a medida que lee las respuestas de los entrevistados. A veces es sencillo asignar o determinar los códigos más oportunos para la codificación de las respuestas de los entrevistados, sin embargo, hay veces que requiere un esfuerzo analítico. Siempre es aconsejable que, aunque la codificación vaya a cargo de un investigador, al menos un segundo investigador la verifique, y en caso de discrepancias, estas deben resolverse por consenso. Lo mismo ocurre con los informes finales que devuelven estos programas. Estos informes finales son el resultado en bruto de la codificación de las entrevistas. En este caso, el investigador o equipo de investigadores deberá leer e interpretar los informes para obtener las ideas más significativas y de mayor riqueza para el estudio que esté realizando. De nuevo, si la interpretación crítica va a cargo de un investigador, al menos un segundo investigador deberá verificar estos resultados. Ante estos escenarios, consideramos que ChatGPT puede ser un buen punto de partida, tanto para la elección de los códigos que ayudarán a la codificación de las entrevistas, como para identificar convergencias y divergencias entre las declaraciones que se encuentran registradas en los informes finales, lo que puede ayudar mucho tanto en el proceso de diseño de los análisis como en los de verificación de los resultados. Como veremos a continuación, estos dos procesos aplicados con ChatGPT tendrán que ser validados y chequeados de forma crítica por parte del investigador o equipo de investigadores. Por tanto, siempre se deberá tener presente tanto los aspectos éticos que puedan ser de aplicación como la aplicación de un pensamiento crítico atento e inquisitivo constante. Sin esto, el resultado de la combinación de ChatGPT y un software CAQDAS podría quedar invalidado como método científico. ChatGPT como herramienta de soporte a ATLAS.ti, Nvivo y MAXQDA ChatGPT es un modelo de lenguaje desarrollado por OpenAI que utiliza técnicas de procesamiento de lenguaje natural (NLP) para generar respuestas coherentes y naturales en tiempo real. Se basa en el modelo GPT-3 y ha sido entrenado en una amplia variedad de tareas de NLP (OpenAI, 2022). Este sistema es una inteligencia artificial que está teniendo un impacto enorme en la sociedad desde mediados de diciembre de 2022, y parece que seguirá a corto y medio plazo. Ante esta circunstancia, como investigadores, debemos encontrar formas de incorporar esta IA a nuestras rutinas investigativas. 9 Sin embargo, es importante asegurarnos de que su uso durante el desarrollo de una investigación tenga un impacto positivo para la academia y para la sociedad. Es por ese motivo que, la ética y el pensamiento crítico deben ser una constante en todos los usos que se hagan con ChatGPT (Codina, 2022). Teniendo en cuenta los puntos mencionados anteriormente y la calidad sorprendente de algunas de las funcionalidades de esta IA, nuestra propuesta es utilizar ChatGPT como una herramienta para mejorar el proceso de codificación de entrevistas y la identificación de resultados de las mismas. Concretamente abordaremos las siguientes tareas: 1. Identificación de posibles códigos sin predeterminar el número de estos 2. Identificación de un número concreto de códigos 3. Identificación de códigos y subcódigos 4. Identificación de convergencias y divergencias en las respuestas de los entrevistados 5. Identificación de declaraciones positivas y negativas en las respuestas de los entrevistados 6. Identificación de las declaraciones más significativas en las respuestas de los entrevistados A continuación, en el siguiente apartado se documenta el proceso completo tanto para la selección de los códigos de partida utilizando ChatGPT que servirán después para codificar las respuestas de los entrevistados, como la consiguiente codificación con el software CAQDAS, creación de informes finales y, por último, la identificación de resultados específicos a través del análisis de los informes con ChatGPT. Este proceso se realizará paso a paso para cada uno de los programas mencionados. Comenzaremos explicando el proceso con ATLAS.ti, en segundo lugar, con Nvivo, y por último con MAXQDA. Combinando ChatGPT y ATLAS.ti para el análisis cualitativo de entrevistas A efectos de ilustrar todo el proceso, supongamos que se está realizando un estudio académico sobre la importancia de la inteligencia artificial y su relación con el periodismo y se ha conseguido entrevistar a un total de 10 profesionales en base a 5 preguntas a cada entrevistado (para nuestras explicaciones, partiremos de este número de entrevistas, sin entrar en detalles sobre el número óptimo de entrevistas que sería necesario obtener en un estudio real). Lo primero que tenemos que hacer es acceder a ChatGPT y registrarnos. Para ello podemos acceder a través del siguiente enlace: https://openai.com/blog/chatgpt/ 10 Imagen 1. Página principal de Open.Ai. A continuación, y una vez hayamos ingresado a ChatGPT tendremos acceso a la interfaz de uso de ChatGPT. En el recuadro de búsqueda, que se encuentra en la parte inferior (véase imagen 2) será donde hagamos las consultas a ChatGPT. Imagen 2. Página principal de la interfaz de uso de ChatGPT. 11 En lo que sigue empezaremos con el proceso de identificación de códigos para la codificación de las 10 entrevistas. En este caso ilustramos tres posibles funcionalidades para la identificación automática de códigos: (1) Identificación de posibles códigos, sin especificar número total de ellos; (2) identificación de un número determinados de códigos e (3) identificación de códigos y de subcódigos. Para ello, tendremos que recoger las declaraciones de la primera entrevista (véase imagen 3) y le pediremos a ChatGPT que identifique códigos. Entrevista 1: 1. ¿Qué rol cree que la inteligencia artificial desempeñará en la producción y distribución de noticias en el futuro y cómo cree que esto afectará el trabajo de los periodistas? La inteligencia artificial tiene el potencial de desempeñar un papel importante en la producción y distribución de noticias en el futuro, permitiendo una mayor automatización y eficiencia en tareas como la generación de contenido, la edición y la curación de noticias. Sin embargo, es importante tener en cuenta que esto podría tener un impacto en el trabajo de los periodistas, ya que algunas tareas podrían ser reemplazadas por tecnología. Es importante abordar esto mediante la capacitación y la adaptación para asegurar que los periodistas puedan seguir desempeñando un papel valioso en la industria de las noticias. 2. ¿Qué desafíos y oportunidades cree que presenta la inteligencia artificial para el periodismo y cómo cree que estos desafíos y oportunidades evolucionarán en el futuro? La inteligencia artificial presenta tanto desafíos como oportunidades para el periodismo. Por un lado, puede ayudar a mejorar la eficiencia y la precisión en la generación de contenido, la verificación de hechos y la curación de noticias. Por otro lado, también puede presentar desafíos en términos de privacidad, ética y confiabilidad de la información. Es importante seguir monitoreando y abordando estos desafíos a medida que la tecnología continúa evolucionando. 3. ¿Cuál es su visión sobre el uso de la inteligencia artificial en la verificación y validación de la veracidad de la información y cómo cree que esto afectará a la confianza del público en el periodismo? La inteligencia artificial puede ser una herramienta valiosa en la verificación y validación de la veracidad de la información, pero también es importante tener en cuenta que no es infalible. Es necesario un enfoque multicriterio y multidisciplinario para garantizar la precisión y la confiabilidad de la información, y asegurar que la confianza del público en el periodismo se mantenga alta. 4. ¿Qué tipo de formación y habilidades son necesarias para los periodistas para tener éxito en un mundo cada vez más basado en la inteligencia artificial y cómo cree que estas necesidades formativas evolucionarán en el futuro? Los periodistas necesitarán desarrollar habilidades en áreas como el análisis de datos, la programación y la inteligencia artificial para tener éxito en un mundo cada vez más basado en esta tecnología. Además, se requerirá un mayor énfasis en la ética y la privacidad en la formación de los periodistas. Con el tiempo, es probable que estas necesidades formativas continúen evolucionando a medida que la tecnología avance. 5. ¿Cómo cree que la inteligencia artificial afectará la diversidad y la inclusión en el periodismo y cómo podría abordarse esto? La inteligencia artificial puede tener un impacto en la diversidad y la inclusión en el periodismo si no se aborda adecuadamente. Es importante considerar cómo la tecnología está diseñada y utilizada, y asegurar que se tomen en cuenta las perspectivas de diferentes grupos de personas.” Imagen 3. Ejemplo de la entrevista que utilizaremos para identificar códigos con ChatGPT. 12 Imagen 4. Prompt con el que se le pide a ChatGPT, a partir las declaraciones de la entrevista 1, que identifique posibles temas o códigos para las entrevistas En este caso ChatGPT nos ofrece 5 códigos, al considerar que es el número óptimo que necesitamos para codificar esta entrevista. El número de códigos variará dependiendo del contenido de la entrevista. A continuación, se muestra los resultados de esta operación (véase imagen 5). 13 Imagen 5. Resultados ofrecidos por ChatGPT que muestra cinco posibles categorías o temas para codificar nuestras entrevistas. Seguidamente se ofrece una segunda propuesta para la identificación de códigos para la codificación de nuestra entrevista. En este caso se le pide a ChatGPT que identifique un número específico de códigos. Esto puede ayudar a dar una mayor profundidad a la codificación de las entrevistas. En el siguiente caso (véase imagen 6) se muestra este proceso pidiendo a la IA que identifique 10 códigos. Para ello copiamos las declaraciones de la entrevista 1 y le pedimos expresamente a ChatGPT que identifique esos diez códigos. Imagen 6. Operación que se le pide a ChatGPT sobre las declaraciones de la entrevista 1 para que la IA identifique 10 código para las entrevistas desarrolladas. El resultado de este proceso se muestra en la imagen 7. Como vemos, ChatGPT ofrece mayor cantidad de códigos que pueden ayudarnos a que cuando hagamos la codificación esta sea con un mayor grado de profundidad al incorporar más posible categorías o temas. 14 Imagen 7. Resultados ofrecidos por ChatGPT que muestra 10 posibles códigos para codificar nuestras entrevistas. La última propuesta de codificación viene motivada por el hecho de que para la codificación de entrevistas con ATLAS.ti podemos incluir además de códigos, subcódigos, es decir incorporar subtemas a los temas principales, consiguiendo así que podamos realizar una codificación con un mayor grado temático. En este sentido, el investigador debe copiar las declaraciones de la entrevista 1 y pedirle expresamente a ChatGPT que identifique códigos y subcódigos sobre las declaraciones de las entrevistas (véase imagen 8) 15 Imagen 8. Operación que se le pide a ChatGPT sobre las declaraciones de la entrevista 1 para que la IA identifique posibles códigos y subcódigos para las entrevistas desarrolladas. El resultado de esta tercera forma de identificar códigos se muestra en la imagen 9. Como vemos, ChatGPT ofrece un código principal y sus correspondientes códigos secundarios o subcódigos. 16 Imagen 9. Interfaz en donde se muestran las entrevistas incorporadas para su análisis dentro de la herramienta de ATLAS.ti. Una vez utilizando algunas de estas tres opciones para la primera entrevista se debe aplicar el mismo proceso para cada una de las demás entrevistas, ya que es posible que ChatGPT identifique nuevos códigos que puedan sernos de utilidad. Después de este proceso será esencial chequear si los códigos propuestos son adecuados para nuestras entrevistas, en definitiva, será fundamental que el investigador tenga una visión a la vez ética y crítica de los resultados. Las decisiones que seguirán, pueden llevarse a cabo mediante uno de los investigadores, pero en tal caso siempre se aconseja que al menos un segundo investigador del equipo proceda a su verificación. En el caso que nos ocupa, y tras la lectura y comprobación de la propuesta de códigos ofrecida por ChatGPT, mediante consenso con al menos un segundo investigador, supongamos que hemos decidido que los códigos que utilizaremos serán los siguientes: 1. Impacto de la inteligencia artificial en el periodismo 2. Desafíos y oportunidades de la inteligencia artificial en el periodismo 3. Uso de la inteligencia artificial frente a la desinformación 4. Formación en inteligencia artificial por parte de periodistas 5. Impacto de la IA en la diversidad e inclusión en el periodismo Una vez hecho esto, es el momento de codificar las entrevistas. El proceso de codificación, en este caso, se llevará a cabo a través de ATLAS.ti Para volcar entrevistas a ATLAS.ti, hay que registrarse en la página web (versión de pago o versión trial de 5 días), descargar la aplicación al escritorio o trabajar en la nube, y crear un nuevo proyecto. Los documentos pueden ser en formato pdf, word o bloc de notas. 17 Imagen 10. Página principal del CAQDAS ATLAS.ti una vez registrados. Para el acceso a ATLAS.ti hay que ingresar en el siguiente enlace: https://atlasti.com Para crear un nuevo proyecto en ATLAS.ti, hay que acceder a la pestaña \"Crear proyecto\" y rellena los datos en la nueva ventana que se abre. Imagen 11. Ventana del proceso de registro de un nuevo proyecto. En la figura se muestra un ejemplo de título del proyecto. En este caso le hemos llamado “Inteligencia artificial”. Es recomendable poner un título descriptivo al crear un nuevo proyecto en ATLAS.ti, ya que esto ayudará a identificar rápidamente el propósito del análisis entre varios proyectos guardados en la aplicación. 18 Imagen 12. Interfaz del nuevo proyecto “Inteligencia artificial” La imagen muestra los recursos y elementos principales disponibles en ATLAS.ti. En este caso, nos centraremos en los recursos \"Documentos\" y \"Códigos\". En \"Documentos\" subiremos cada una de las entrevistas a analizar, mientras que en \"Códigos\" crearemos temas y subtemas para asignar declaraciones específicas de las respuestas de los entrevistados. Seguidamente accedemos a la pestaña documentos (Imagen 13) y aparecerá la interfaz en donde se ubicarán los documentos de nuestras entrevistas. Para poder subirlas tendremos ingresar en el apartado “agregar documentos”. Una vez hecho esto se abrirá una ventana (Imagen 14) en donde tendremos que seleccionar los archivos de nuestro ordenador en donde estén ubicadas las entrevistas. Una vez seleccionadas, tendremos que clicar el botón “agregar condicionales”. Una vez hecho esto se incorporarán a nuestro proyecto de ATLAS.ti, los documentos (entrevistas) que hayamos seleccionado. 19 Imagen 13. Interfaz del recurso “Documentos” Imagen 14. Ventana en donde se muestra la selección de las 10 entrevistas en formato word para ser importadas al proyecto. 20 Una vez hecho esto, es el momento de recuperar los códigos finales seleccionados que fueron fruto de ChatGPT y nuestro análisis crítico de los mismos. Recordemos que, por análisis crítico y consenso de al menos dos investigadores, hemos decidido que los códigos que utilizaremos serán los siguientes: 1. Impacto de la inteligencia artificial en el periodismo 2. Desafíos y oportunidades de la inteligencia artificial en el periodismo 3. Uso de la inteligencia artificial frente a la desinformación 4. Formación en inteligencia artificial por parte de periodistas 5. Impacto de la IA en la diversidad e inclusión en el periodismo Es importante destacar que el proceso de selección y categorización temática (creación de los códigos) se debe llevar a cabo sobre todas y cada una de las entrevistas. De este modo se consigue agrupar todas las afirmaciones de los expertos entrevistados en distintos temas (códigos). En ese caso, lo primero que debemos hacer es acceder a la pestaña códigos. Una vez ingresemos en esta funcionalidad se abrirá una interfaz en blanco (Imagen 15) en donde tendremos que configurar nuestros códigos. Para ello clicaremos en “nuevo código”. Una vez hecho esto, se abrirá una ventana (Imagen 16) en donde podremos crear los diferentes códigos. Habrá que escribir el nombre de los códigos y después clicar en el botón agregar. Como ya hemos podido comprobar, la forma en que se nombran los códigos puede variar, pero es esencial que describan de manera sencilla la temática de las respuestas a codificar. Imagen 15. Interfaz en donde se muestra el recurso de códigos. En este caso está vacío ya que todavía no se han asignado códigos. 21 Imagen 16. Ventana en donde podremos crear los códigos. Esto ayudará al investigador a saber exactamente qué representa el código creado. Esto se hace sobre todo para no perder el sentido de la categorización temática si se trabaja con muchos códigos afines. En este caso mostramos el código “impacto de la inteligencia artificial en el periodismo” Imagen 17. Interfaz de la pestaña administrado de códigos en donde se muestra todos los códigos creados. Si fuera el caso, esta lista se puede ampliar desde esta misma pantalla ingresando en el símbolo “+” 22 La imagen 17 muestra los 5 códigos que podremos utilizar para marcar las afirmaciones de los 10 entrevistados. Sin embargo, esta codificación puede ser más profunda, pudiéndose crear subcódigos dentro de cada código (Imagen 9). Para crear un subcódigo seleccionaremos un código principal, haremos clic en el botón derecho del ratón, se abrirá una ventana y a continuación habrá que clicar a “añadir subcódigos”. Una vez hecho esto hay que asignarle un nombre al subcódigo y por último habrá que hacer clic en agregar. Para más información sobre cómo crear subcódigos véase el manual de Lopezosa et al. (2021). Una vez creados los códigos, se deben codificar las entrevistas. Para ello, se regresa a la pestaña \"Documentos\", se selecciona una entrevista y se abre para ver su contenido. Seleccionaremos la entrevista 1 y tomaremos como ejemplo el código \"Impacto de la Inteligencia artificial en el periodismo\". Para codificar una respuesta específica de las entrevistas con el código “Impacto de la Inteligencia artificial en el periodismo”, habrá que seleccionar del documento la afirmación que consideremos oportuna, haremos clic en el botón derecho del ratón, se abrirá una ventana y tendremos que seleccionar el elemento “Asignar códigos”. Seguidamente (imagen 18) se mostrarán los 5 códigos (que si se despliegan mostrarán los subcódigos que se crearon), seleccionaremos el código o subcódigo que consideremos, en nuestro ejemplo el código “Impacto de la Inteligencia artificial en el periodismo”. Una vez hecho esto, la afirmación que seleccionamos quedará ubicada en el código que hayamos decidido. Por lo tanto, todo el documento debe ser codificado (imagen 19), mostrándose los elementos codificados en la parte derecha de la herramienta. Este proceso se debe aplicar para cada una de las entrevistas. En este ejemplo, habría que codificar 10 entrevistas. Imagen 18. Proceso de codificación de una afirmación de la entrevista 1 bajo el código “Impacto de la Inteligencia artificial en el periodismo” 23 Imagen 19. Resultado de la codificación de todo el documento “Entrevista 1”. Una vez codificadas las 10 entrevistas utilizando los diferentes códigos, se descargan los resultados de la codificación. Esto permite obtener declaraciones unificadas por códigos o temáticas de las 10 entrevistas, lo que ayuda a obtener resultados más profundos de las entrevistas. Para ello hay que, regresar al apartado de administración de códigos (imagen 17), seguidamente seleccionar un código (o subcódigo si es el caso), hacer doble clic y aparecerán todas las afirmaciones de los 10 entrevistados que fueron marcados por el código seleccionado (en este caso seleccionaremos el código desafíos y oportunidades de la inteligencia artificial en el periodismo), después habrá que hacer clic en “exportar como reporte” y una vez hecho esto podremos descargarnos un reporte (Imagen 20) con todas las afirmaciones en donde se identificará: el código y la cita marcada con ese código para cada uno de los entrevistados. Este reporte se puede configurar para que nos dé más datos. afirmaciones de esos subcódigos y la persona que hizo dicha afirmación. Hay que descargar todos los códigos como reportes independientes. Con todo ello tendremos unos resultados sistemáticos, muy exhaustivos y de gran rigor en bruto que nos ayudarán a sacar conclusiones sobre nuestra investigación. 24 Imagen 20. Reporte de la codificación bajo el código “desafíos y oportunidades de la inteligencia artificial en el periodismo” de las 10 entrevistas. Análisis de resultados asistido por ChatGPT Normalmente estas conclusiones parten de la reflexión de los investigadores en la medida que sean capaces de interpretar e identificar relaciones entre estos datos en bruto. Sin embargo, también podemos utilizar, como ya avanzamos anteriormente, ChatGPT para que nos ayude con estos datos. A continuación mostramos tres posibles opciones: 1. Identificación de convergencias y divergencias en las respuestas de los entrevistados 2. Identificación de declaraciones positivas y negativas en las respuestas de los entrevistados 3. Identificación de las declaraciones más significativas en las respuestas de los entrevistados Para la identificación de convergencias y divergencias en las respuestas de los entrevistados tendremos que recoger las declaraciones del informe (véase imagen 20) y le pediremos a ChatGPT que identifique convergencias y divergencias sobre las declaraciones codificadas (véase imagen 21). 25 Imagen 21. Operación que se le pide a ChatGPT para que identifique de convergencias y divergencias en las respuestas de los entrevistados producto del informe generado por ATLAS.TI para el código “Desafíos y oportunidades de la inteligencia artificial en el periodismo” En este caso ChatGPT nos ofrece una afirmación en la que los diez entrevistados concuerdan, y por otro lado nos informa de que el entrevistado 2 muestra un desacuerdo rotundo frente a los otros 9 entrevistados (véase imagen 22). 26 Imagen 22. Resultados ofrecidos por ChatGPT que muestra las convergencias y divergencias de las respuestas codificadas para el código “desafíos y oportunidades de la inteligencia artificial en el periodismo”. Para la iidentificación de declaraciones positivas y negativas en las respuestas de los entrevistados tendremos que recoger las declaraciones del informe (véase imagen 20) y le pediremos a ChatGPT que identifique respuestas positivas y negativas sobre las declaraciones codificadas (véase imagen 23). Imagen 23. Operación que se le pide a ChatGPT para que identifique declaraciones positivas y negativas en las respuestas de los entrevistados producto del informe generado por ATLAS.TI para el código “Desafíos y oportunidades de la inteligencia artificial en el periodismo” 27 En este segundo supuesto, ChatGPT nos ofrece dos listados, uno con afirmaciones positivas, y el segundo con afirmaciones negativas (véase imagen 24) Imagen 24. Resultados ofrecidos por ChatGPT que muestra las declaraciones positivas y negativas de las respuestas codificadas para el código “desafíos y oportunidades de la inteligencia artificial en el periodismo”. Para la identificación de las declaraciones más significativas en las respuestas de los entrevistados tendremos que recoger las declaraciones del informe (véase imagen 20) y le pediremos a ChatGPT que identifique las respuestas más importantes que se encuentren en las declaraciones codificadas (véase imagen 25). 28 Imagen 25. Operación que se le pide a ChatGPT para que identifique las declaraciones más significativas en las respuestas de los entrevistados producto del informe generado por ATLAS.TI para el código “Desafíos y oportunidades de la inteligencia artificial en el periodismo” En este último supuesto, declaraciones directas en forma de listado en donde se indican las declaraciones más importantes según el criterio de ChatGPT (véase imagen 26) 29 Imagen 26. Resultados ofrecidos por ChatGPT que muestra las que considera que son las declaraciones más significativas de las respuestas codificadas para el código “desafíos y oportunidades de la inteligencia artificial en el periodismo”. En definitiva, como podemos observar, estas 3 opciones nos ayudarán a convertir los datos en bruto en ideas que deben servir al investigador para su propia reflexión. Es importante recordar y recalcar nuevamente que este tipo de técnicas deben utilizarse con responsabilidad, y por lo tanto, solamente pueden ser un punto de partida que necesita análisis crítico adicional, y de ningún modo un resultado final. El resultado final, en cambio, puede beneficiarse de este punto de partida, pero siempre debe ser un desarrollo genuino del esfuerzo crítico e intelectual realizado por el investigador o por el equipo de investigadores. Una vez visto el caso resultante de combinar ChatGPT con un de los tres programas de análisis cualitativo, pasamos a mostrar su uso en los otros dos programas. Para facilidad de los lectores que prefieran centrarse (o incluso separar o imprimir las páginas en uno solo de los programas), repetimos los pasos previos de registro y uso iniciales de ChatGPT. 30 Combinando ChatGPT y Nvivo para el análisis cualitativo de entrevistas Como en el caso anterior, partimos de un escenarios en el que se está realizando un estudio académico, en este caso sobre sobre el futuro en la formación en periodismo. Partimos del supuesto que se ha conseguido entrevistar a 10 profesionales. Lo primero que tenemos que hacer es acceder a ChatGPT. Seguidamente debemos acceder al sitio web mediante el siguiente enlace: https://openai.com/blog/chatgpt/ y luego registrarnos. Imagen 27. Página principal de Open.Ai. Una vez accedido a ChatGPT, tendremos acceso a la interfaz de uso. El recuadro de búsqueda, ubicado en la parte inferior de la pantalla (véase imagen 27) será desde donde le daremos indicaciones a ChatGPT. 31 Imagen 28. Página principal de la interfaz de uso de ChatGPT. A continuación, iniciaremos el proceso de identificación de códigos para la codificación de las 10 entrevistas. Para ello, ilustraremos tres funcionalidades posibles para la identificación automática de códigos: (1) identificar códigos para las entrevistas realizadas, (2) identificar un número específico de códigos para las entrevistas realizadas y (3) Identificar códigos y subcódigos para las entrevistas realizadas. Para ello, recogeremos las declaraciones de la primera entrevista (véase imagen 29) y le solicitaremos a ChatGPT que identifique los códigos correspondientes. Entrevista 1: 1. ¿Cómo se adaptarán las universidades de periodismo a los cambios tecnológicos en la industria?Es importante que las universidades de periodismo se mantengan actualizadas con los cambios tecnológicos en la industria. Esto puede lograrse mediante la incorporación de nuevas tecnologías en el currículo, la contratación de profesores con experiencia en el uso de estas tecnologías y la colaboración con profesionales de la industria para garantizar que los estudiantes estén preparados para las demandas actuales del mercado. 2. ¿Qué rol jugarán las redes sociales y las plataformas digitales en la formación de periodistas en el futuro? Las redes sociales y las plataformas digitales jugarán un papel importante en la formación de periodistas en el futuro. Los estudiantes deben aprender a utilizar estas herramientas de manera efectiva y ética para llegar a un público más amplio y para verificar la información. 3. ¿Cómo se abordará el tema de la verificación de la información en la formación de periodistas? La verificación de la información es esencial en el periodismo y debe ser abordada en la formación de los estudiantes. Se deben enseñar técnicas y herramientas para verificar la información y se 32 debe fomentar una mentalidad crítica en los estudiantes para que puedan evaluar la fiabilidad de una fuente. 4. ¿Cómo se desarrollarán las habilidades necesarias para el periodismo en datos y la visualización de datos en la formación de periodistas? Para desarrollar las habilidades necesarias para el periodismo en datos y la visualización de datos, se deben ofrecer cursos especializados y se deben proporcionar oportunidades para que los estudiantes practiquen estas habilidades. También es importante fomentar la colaboración entre estudiantes de periodismo y estudiantes de disciplinas relacionadas, como matemáticas o informática. 5. ¿Cómo se prepararán los estudiantes de periodismo para el periodismo de investigación en un mundo cada vez más complejo? El periodismo de investigación es una habilidad esencial para los periodistas y se debe incluir en la formación de los estudiantes. Se deben enseñar técnicas y herramientas para investigar temas complejos y se deben proporcionar oportunidades para que los estudiantes practiquen estas habilidades. También es importante fomentar una mentalidad curiosa y crítica.” Imagen 29. Ejemplo de la entrevista que utilizaremos para identificar códigos con ChatGPT. 33 Imagen 30. Operación en la que se le pide a ChatGPT que identifique código para la codificación de la entrevista 1 ChatGPT ofrece distintos códigos para cada respuesta. La cantidad de códigos varía de acuerdo con el contenido de la entrevista. A continuación, se presentan los resultados de esta operación (véase imagen 31). 34 Imagen 31. Resultados ofrecidos por ChatGPT que muestra diferentes códigos para codificar nuestras entrevistas. A continuación, proponemos una segunda opción para la identificación de códigos para la codificación de la entrevista. En esta ocasión, se solicita a ChatGPT que identifique un número específico de códigos. Esto puede ayudar a aumentar la profundidad de la codificación de las entrevistas. En el siguiente ejemplo (véase imagen 32), se ilustra este proceso pidiendo a la IA que identifique 10 códigos. Para ello, se copian las declaraciones de la entrevista 1 y se solicita expresamente a ChatGPT que identifique esos posibles diez códigos. 35 Imagen 32. Operación en la que se le pide a ChatGPT que identifique 10 código para las entrevista 1. El resultado de este proceso se ilustra en la imagen 33. Como se puede observar, ChatGPT ofrece una mayor cantidad de códigos que pueden ayudar a aumentar la profundidad de la codificación al incorporar más posibles categorías o temas. 36 Imagen 33. Resultados ofrecidos por ChatGPT que muestra 10 códigos para codificar nuestras entrevistas. La última propuesta para la codificación se basa en la posibilidad de utilizar subcódigos además de los códigos principales. Esto permite incorporar subtemas a los temas principales, lo que aumenta la profundidad temática de la codificación. Para ello, el investigador debe copiar las declaraciones de la entrevista 1 y solicitar expresamente a ChatGPT que identifique tanto códigos como subcódigos en relación con las declaraciones de las entrevistas (véase imagen 34). 37 Imagen 34. Operación en la que se le pide a ChatGPT que identifique códigos y subcódigo para las entrevistas desarrolladas. El resultado de esta tercera forma de identificar códigos se ilustra en la imagen 35. Como se puede observar, ChatGPT ofrece un código principal y sus correspondientes códigos secundarios o subcódigos. 38 Imagen 35. Interfaz en la que se muestran los códigos y subcódigos para codificar las entrevistas Una vez utilizadas algunas de estas tres opciones para la primera entrevista, se debe aplicar el mismo proceso para las 9 entrevistas restantes, ya que es posible que ChatGPT identifique nuevos códigos que pueden ser útiles para nuestra investigación. Luego de este proceso, es esencial revisar si los códigos propuestos por ChatGPT son adecuados para la codificación de nuestras entrevistas. En definitiva, es fundamental que el investigador tenga una visión crítica y ética de los resultados. En este caso específico, después de revisar y evaluar la propuesta de códigos ofrecida por ChatGPT, hemos decidido utilizar los siguientes códigos: 1. Nuevas tecnologías 2. Papel de las redes sociales en la formación de periodistas 3. Enseñanza para la verificación de la información 4. habilidades en periodismo en datos y visualización de datos 39 5. Enseñanza de técnicas y herramientas para investigar temas complejos Una vez hecho esto, es el momento de codificar las entrevistas. Para ello, es necesario acceder a la página web de Nvivo, registrarse (ya sea utilizando la versión de pago o la versión de prueba de 14 días) y crear un nuevo proyecto. Imagen 36. Página principal del software NVivo una vez registrados. Para el acceso a NVivo hay que ingresar en el siguiente enlace: https://www.qsrinternational.com/nvivo-qualitative-data-analysis- software/home Al acceder a la opción \"Crear un nuevo proyecto\", se abrirá una nueva ventana y se deberá completar la información correspondiente al nuevo proyecto. 40 Imagen 37. Ventana del proceso de registro de un nuevo proyecto. En la figura se muestra un ejemplo de título y descripción del proyecto. También se identifica el apartado de selección de idioma del contenido del texto, para que Nvivo lo identifique en su idioma original. 41 Imagen 38. Resultado de la pestaña importar, recurso al que hay que acceder para subir y registrar las entrevistas realizadas. Imagen 39. Ventana en donde se muestra la selección de las 10 entrevistas en formato pdf para ser importadas al proyecto. Imagen 40. Interfaz en donde se muestran las entrevistas incorporadas para su análisis dentro de la herramienta de Nvivo. 42 Imagen 41. Interfaz en donde se muestra, a la izquierda, el listado de entrevistas subidas a Nvivo y, a la derecha, el contenido de la entrevista seleccionada, en este caso, la entrevista 1. Una vez que se haya importado todo el contenido de las entrevistas, se deben recoger los códigos finales identificados del proceso desarrollado con ChatGPT y codificar las declaraciones más relevantes atendiendo a dichos códigos. Concretamente: 1. Nuevas tecnologías 2. Papel de las redes sociales en la formación de periodistas 3. Enseñanza para la verificación de la información 4. habilidades en periodismo en datos y visualización de datos 5. Enseñanza de técnicas y herramientas para investigar temas complejos Imagen 42. Pasos para la codificación de las distintas afirmaciones recogidas en las entrevistas. El primer paso es seleccionar la entrevista a codificar y el segundo paso es crear un nuevo código. 43 El proceso de selección y asignación temática (creación de un nuevo código) se aplica a todas las entrevistas. De esta manera, se agrupan todas las declaraciones de los expertos entrevistados en diferentes temas. Imagen 43. Una vez creado un código, se le da propiedades. Esto ayudará al investigador a saber exactamente qué representa el código creado. Esto se hace sobre todo para no perder el sentido de la categorización temática si se trabaja con muchos códigos afines. En este caso crearemos el código “nuevas tecnologías”. Imagen 44. Se muestra la selección de una afirmación del entrevistado 1 y su consiguiente clasificación temática. En concreto se selecciona la declaración uno, se hace accede al recurso Código (icono en forma de bombilla). 44 Imagen 45. Continuación del proceso en la selección de una afirmación del entrevistado 1 y su consiguiente clasificación temática. Tras hacer clic en códigos se despliega esta ventana en donde se muestran todos los códigos creados. En concreto, en este ejemplo, se le asigna el código “nuevas tecnologías”. A través del análisis de las entrevistas, se obtienen, como se muestra en la imagen 46, cinco códigos (que podrían haber sido más si se hubiera deseado ser más específico) que agrupan las declaraciones de los 10 entrevistados. Cada declaración deberá codificarse siguiendo el proceso anterior. Como resultado, cuando accedamos a todos los códigos podremos ver todas las declaraciones agrupadas según el código asignado. En la imagen 46, se muestran cinco códigos y específicamente las declaraciones seleccionadas para el código \"nuevas tecnologías\". 45 Imagen 46. Se muestra la selección de las declaraciones asignadas al código “nuevas tecnologías” de cada una de las entrevistas. Cada recuadro de referencia codificada es una entrevista distinta. En la imagen, por ejemplo, se trata de la afirmación de la entrevista 10 y la entrevista 11. Por último, exportaremos los resultados de estas declaraciones para obtener el informe final en bruto de cada uno de los códigos. Para ello accedemos al recurso compartir y hacemos clic a “export items” (como se muestra en la imagen 47). El resultado es un documento Word con las declaraciones del código seleccionado (como se muestra en la imagen 48). Imagen 47. Se muestra el proceso para la obtención del informe final para el código “Nuevas tecnologías” 46 Imagen 48. Resultados en bruto de las declaraciones codificadas con el código “Nuevas tecnologías” 47 Una vez obtenidos los resultados brutos, los investigadores suelen analizar los datos codificados de las entrevistas para extraer las ideas principales. Sin embargo, también es posible utilizar ChatGPT para ayudar con estos datos, tal como se mencionó anteriormente. A continuación, se presentan tres opciones posibles: 1. Analizar similitudes y diferencias en las respuestas de los participantes de la entrevista. 2. Identificar afirmaciones positivas y negativas en las respuestas de los participantes de la entrevista. 3. Seleccionar las respuestas más significativas de los participantes de la entrevista. Para analizar las similitudes y diferencias en las respuestas de los participantes de la entrevista, deberemos recopilar las declaraciones del informe (véase imagen 48) y solicitar a ChatGPT que determine las similitudes y diferencias en las declaraciones codificadas (véase imagen 49). Esto debe hacerse código por código. En este ejemplo, utilizaremos las declaraciones categorizadas con el código \"nuevas tecnologías\". 48 Imagen 49. Operación que se le pide a ChatGPT para que identifique convergencias y divergencias en las respuestas de los entrevistados producto del informe generado Nvivo para el código “nuevas tecnologías” 49 En este caso, ChatGPT nos ofrece afirmaciones con distintos grados de convergencia y divergencia respecto a temas específicos abordados por los entrevistados (véase imagen 50). Imagen 50. Resultados ofrecidos por ChatGPT que muestra las convergencias y divergencias de las respuestas codificadas para el código “nuevas tecnologías”. La segunda propuesta implicará la identificación de declaraciones positivas y negativas. Para clasificar las respuestas de los entrevistados en este sentido, se recopilarán las declaraciones del informe (véase imagen 48) y se pedirá a ChatGPT que identifique las respuestas positivas y negativas sobre las declaraciones codificadas (véase imagen 51). 50 Imagen 51. Operación que se le pide a ChatGPT para que identifique declaraciones positivas y negativas en las respuestas de los entrevistados producto del informe generado por Nvivo para el código “Nuevas tecnologías” En este segundo caso, ChatGPT ha sido capaz de identificar afirmaciones positivas y confirmar que no existen declaraciones negativas (como se muestra en la imagen 52) 51 Imagen 52. Resultados ofrecidos por ChatGPT que muestra las declaraciones positivas y negativas de las respuestas codificadas para el código “nuevas tecnologías”. Por último, para determinar las declaraciones más relevantes en las respuestas de los entrevistados, se recolectarán las declaraciones del informe (véase imagen 48) y se solicitará a ChatGPT que identifique las respuestas más significativas en las declaraciones codificadas (véase imagen 53). 52 Imagen 53. Operación que se le pide a ChatGPT para que identifique las declaraciones más significativas en las respuestas de los entrevistados producto del informe generado por Nvivo para el código “nuevas tecnologías” 53 En este último caso, se proporcionará una lista de declaraciones directas que contienen las respuestas más importantes según el criterio de ChatGPT (véase imagen 54). Imagen 54. Resultados ofrecidos por ChatGPT que muestra las que considera que son las declaraciones más significativas de las respuestas codificadas para el código “nuevas tecnologías”. En resumen, como se puede ver, estas tres opciones nos ayudarán a transformar los datos crudos en ideas que deben ser útiles para el investigador para su propia reflexión. De nuevo queremos recordar que estas técnicas se utilicen con responsabilidad, y por lo tanto solo pueden ser un punto de partida para el desarrollo final del razonamiento del 54 investigador, y en ningún caso deben formar parte del resultado final directo de la investigación realizada. Combinando ChatGPT y MAXQDA para el análisis cualitativo de entrevistas Como en los casos anteriores, partimos de un escenario concreto. Supongamos que se está realizando un estudio académico sobre sobre la desinformación y el futuro del periodismo y se ha conseguido entrevistar a 10 profesionales. Lo primero que tenemos que hacer es acceder a ChatGPT y registrarnos. Para ello podemos acceder a través del siguiente enlace: https://openai.com/blog/chatgpt/ Imagen 55. Página principal de Open.Ai. A continuación, y una vez hayamos ingresado a ChatGPT tendremos acceso a la interfaz de uso de ChatGPT. En el recuadro de búsqueda, que se encuentra en la parte inferior (véase imagen 55) será donde hagamos las consultas a ChatGPT. 55 Imagen 56. Página principal de la interfaz de uso de ChatGPT. En lo que sigue empezaremos con el proceso de identificación de códigos para la codificación de las 10 entrevistas. En este caso ilustramos tres posibles funcionalidades para la identificación automática de códigos: • Identificación de posibles códigos para las entrevistas sin determinar el número total de códigos • identificación de un número determinados de códigos • identificación de códigos y subcódigos En este sentido, tendremos que recoger las declaraciones de la primera entrevista (véase imagen 57) y le pediremos a ChatGPT que identifique códigos. Entrevista 1: 1. ¿Cómo ha evolucionado la desinformación en los últimos años y cómo afecta a la sociedad y al periodismo? La desinformación ha evolucionado significativamente en los últimos años debido al aumento de las redes sociales y a la facilidad con la que se puede compartir información en línea. Esto ha llevado a un aumento en la cantidad de noticias falsas, rumores y engaño en la sociedad. Afecta tanto a la sociedad como al periodismo, ya que puede crear confusiones y desconfianza en la información que se recibe. 2. ¿Qué medidas pueden tomar los medios de comunicación y las redes sociales para combatir la desinformación? Los medios de comunicación y las redes sociales pueden tomar medidas para combatir la desinformación mediante la promoción de la verificación de hechos y la transparencia en la publicación de información. También pueden fomentar la educación sobre cómo identificar y evitar la desinformación. Además, los medios de comunicación y las redes sociales pueden 56 colaborar para desarrollar sistemas automatizados de verificación de hechos y tomar medidas para eliminar la desinformación que se comparte. 3. ¿Cómo pueden fortalecerse los sistemas de verificación de hechos en el periodismo en el futuro? Los sistemas de verificación de hechos pueden fortalecerse en el futuro mediante la utilización de tecnologías avanzadas, como el aprendizaje automático y el procesamiento del lenguaje natural, para identificar y verificar automáticamente la información. Además, los medios de comunicación y las redes sociales pueden colaborar para desarrollar sistemas de verificación de hechos comunes y estándares. 4. ¿Cómo pueden fomentarse la ética y la responsabilidad en el periodismo en un mundo cada vez más digital? La ética y la responsabilidad en el periodismo pueden fomentarse en un mundo cada vez más digital mediante la educación y la formación continua para los periodistas, así como mediante la promoción de estándares éticos en la publicación de información. Además, los medios de comunicación y las redes sociales pueden establecer mecanismos de rendición de cuentas y sanciones para aquellos que no cumplan con estos estándares éticos. 5. ¿Cómo puede el periodismo adaptarse y evolucionar en un mundo cada vez más fragmentado y polarizado? El periodismo puede adaptarse y evolucionar en un mundo cada vez más fragmentado y polarizado mediante el uso de nuevas tecnologías y formatos para llegar a audiencias más amplias y diversas. También puede fomentar la diversidad y la inclusión en sus equipos de redacción y en sus contenidos, lo que puede permitir una representación más completa de las perspectivas y las voces de la sociedad.” Imagen 57. Ejemplo de la entrevista que utilizaremos para identificar códigos con ChatGPT. 57 Imagen 58. Operación que se le pide a ChatGPT sobre las declaraciones de la entrevista 1 para que la IA identifique código para las entrevistas desarrolladas. Cada respuesta numerada corresponde a una pregunta. En este caso ChatGPT nos ofrece diferentes códigos para cada una de las preguntas. Los códigos de la lista 1 corresponderían a posibles códigos para la respuesta a la pregunta 1, la lista 2 para la respuesta a la pregunta 2, y así sucesivamente. El número de códigos variará dependiendo del contenido de la entrevista. A continuación, se muestra los resultados de esta operación (véase imagen 59) 58 Imagen 59. Resultados ofrecidos por ChatGPT con posibles códigos a utilizar para la codificación de las entrevistas. Seguidamente se ofrece una segunda propuesta para la identificación de códigos para la codificación de nuestra entrevista. En este caso se le pide a ChatGPT que identifique un número específico de códigos. Esto puede ayudar a dar una mayor profundidad a la codificación de las entrevistas. En el siguiente caso (véase imagen 60) se muestra este proceso pidiendo a la IA que identifique 10 códigos. Para ello copiamos las declaraciones de la entrevista 1 y le pedimos expresamente a ChatGPT que identifique esos diez códigos. 59 Imagen 60. Operación que se le pide a ChatGPT sobre las declaraciones de la entrevista 1 para que la IA identifique 10 código para las entrevistas desarrolladas. El resultado de este proceso se muestra en la imagen 61. Como vemos, ChatGPT ofrece 10 cantidad códigos que pueden ayudarnos a categorizar las respuestas de los entrevistados. 60 Imagen 61. Resultados ofrecidos por ChatGPT que muestra 10 códigos para codificar nuestras entrevistas. La última propuesta de codificación viene motivada por el hecho de que para la codificación de entrevistas con MAXQDA podemos incluir además de códigos, subcódigos, es decir incorporar subtemas a los temas principales, consiguiendo así una codificación con un mayor grado temático. En este sentido, el investigador debe copiar las declaraciones de la entrevista 1 y pedirle expresamente a ChatGPT que identifique códigos y subcódigos sobre las declaraciones de las entrevistas (véase imagen 62). 61 Imagen 62. Operación que se le pide a ChatGPT sobre las declaraciones de la entrevista 1 para que la IA identifique códigos y subcódigo para las entrevistas desarrolladas. El resultado de esta tercera forma de identificar códigos se muestra en la imagen 63. Como vemos, ChatGPT ofrece un código principal y sus correspondientes códigos secundarios o subcódigos. 62 Imagen 63. Resultados ofrecidos por ChatGPT en el que se muestra posibles códigos y subcódigos a utilizar. Una vez seleccionadas algunas opciones para codificar la primera entrevista, se debe aplicar el mismo proceso a las demás entrevistas. Es posible que ChatGPT identifique nuevos códigos que puedan ser útiles. Luego de este proceso, es esencial revisar si los códigos propuestos son adecuados para las entrevistas. En última instancia, es fundamental que el investigador tenga una perspectiva ética y crítica al evaluar los resultados. 63 En este caso específico, después de revisar y evaluar los códigos sugeridos por ChatGPT, hemos decidido utilizar los siguientes códigos: 1. Evolución de la desinformación 2. Medidas frente a la Desinformación en Medios de comunicación 3. Sistemas de verificación frente a la desinformación 4. Ética y responsabilidad en el periodismo 5. Adaptación y evolución del periodismo. Una vez hecho esto, es el momento de codificar las entrevistas. Para ello, pasamos a explicar el proceso de codificación que se llevará a cabo a través de MAXQDA. Para empezar a usar este programa es necesario acceder a la página web de MAXQDA, completar los campos de registro y descargar una versión gratuita (válida por 14 días) o adquirir una licencia de pago (Estándar, Plus o Pro). Imagen 64. Página de inicio del sitio web de MAXQDA. Se puede acceder desde el siguiente enlace: https://www.maxqda.com 64 Imagen 65. Página de descarga del Software MAXQDA. Tenemos la versión para Windows y para Mac. Se puede acceder tras rellenar el formulario de “Start your free trial” que se encuentra al que se puede acceder desde el siguiente enlace: https://www.maxqda.com/trial Imagen 66. Página principal del software MAXQDA tras su instalación en el ordenador. Al seleccionar la pestaña \"Nuevo\", se abrirá una ventana en la que se deberá completar la información para crear un nuevo proyecto (véase imagen 67). 65 Imagen 67. Ventana del proceso de registro de un nuevo proyecto. En la figura se muestra un ejemplo de título y descripción del proyecto. En este caso lo hemos llamado “Desinformación y periodismo”. Es importante nombrar un nuevo proyecto de manera clara y concisa para poder identificarlo fácilmente, especialmente si se está trabajando en varios proyectos al mismo tiempo. De esta forma será más sencillo localizarlo. Una vez que se ha nombrado al proyecto, es necesario importar las entrevistas realizadas, generalmente en formato Word, PDF o Excel. Para hacerlo, se debe acceder a la herramienta \"Textos, PDF, Tabla\" que se encuentra en la esquina superior izquierda de la pantalla. Al seleccionarla, se abrirá una ventana emergente en la que se solicitará permiso a MAXQDA para acceder a los archivos de la carpeta de documentos (véase imagen 68 y 69) Imagen 68. Ventana emergente, resultado de acceder a la pestaña “importar textos, pdf o tablas” que se utiliza para subir y registrar las entrevistas realizadas. 66 Imagen 69. Ventana en donde se muestra la identificación de las 10 entrevistas en formato Word para ser importadas al proyecto. Una vez otorgado permiso a MAXQDA para acceder a los documentos, se deben seleccionar las diez entrevistas y presionar el botón azul \"abrir\". Luego de esto, las entrevistas se incluirán en el proyecto en forma de lista. El listado de entrevistas importadas aparecerá en el lado izquierdo, en la pestaña \"Sistema de documentos\" (véase imagen 70) Imagen 70. Ventana en donde se seleccionan las 10 entrevistas en formato Word para ser importadas al proyecto. Una vez se han transcrito las entrevistas, se deben seleccionar las declaraciones más relevantes o relacionadas con el tema principal y organizarlas en categorías o etiquetas 67 denominadas \"códigos\". Un código puede ser una palabra o frase que expresa un tema o concepto, y pueden ser previamente establecidos como parte de la teoría de la investigación o descubiertos a medida que se analizan las respuestas y se identifican patrones. Imagen 71. Interfaz en donde se muestran las entrevistas incorporadas para su análisis dentro de la herramienta de MAXQDA. A la izquierda se muestra el listado de entrevistas subidas a MAXQDA y, a la derecha, el contenido de la entrevista seleccionada, en este caso, la entrevista 10 (sabemos que es la entrevista 10 porque está destacada en negrita). En este caso específico, después de revisar y evaluar los códigos sugeridos por ChatGPT, hemos decidido utilizar los siguientes códigos: 1. Evolución de la desinformación 2. Medidas frente a la desinformación en medios de comunicación 3. Sistemas de verificación frente a la desinformación 4. Ética y responsabilidad en el periodismo 5. Adaptación y evolución del periodismo. Una vez hecho esto, es el momento de codificar las entrevistas. El proceso de selección y categorización temática (creación de los códigos) se llevan a cabo sobre todas y cada una de las entrevistas. De este modo se consigue organizar todas las afirmaciones de los expertos entrevistados en cada uno de los distintos temas o códigos. Para crear un código lo primero que hay que hacer es ir al sistema de códigos que se encuentra en el lateral izquierdo e ingresar en el icono verde “+”. Al acceder a dicho icono se abrirá una venta emergente (véase imagen 73) con el título “Nuevo código”. En esta ventana tendremos que asignar un nombre o etiqueta al código. Asimismo, al código creado se le puede asignar (1) un color y (2) un memo o nota descriptiva (véase: 1. Asignar un color al código permite diferenciar visualmente los distintos códigos creados, sobre todo, cuando hayamos codificado el contenido de cada una de las entrevistas. 68 2. El memo es una nota que tiene como objetivo ayudarnos a recordar las características específicas del código creado, así si olvidamos la razón por la que creamos un código específico, este memo nos ayudará a recordar la funcionalidad del código creado. Imagen 72. Pasos para la codificación de las distintas afirmaciones recogidas en las entrevistas. El primer paso es seleccionar la entrevista a codificar y el segundo paso es crear un nuevo código. En la imagen se muestra un Ejemplo de código creado. En este caso el código tiene por nombre “Evolución de la desinformación”. Por otro lado, se utiliza el memo, para ello se describe el código para recordar que este código se creó expresamente para codificar las respuestas a la pregunta 1 de nuestras entrevistas que se refiere exactamente a este mismo concepto. Imagen 73. Imagen que continúa ilustrando el proceso de codificación. En este caso se muestra el documento con nombre “entrevista 1”. Se sabe que es este documento porque en la columna izquierda está destacado este documento en negrita. En la parte central se observa el contenido completo del 69 documento “entrevista 1”. Se observa también un párrafo en azul, (respuesta a la pregunta 3) este ha sido seleccionado de forma manual (arrastrando el ratón desde la primera hasta la última palabra del párrafo). En síntesis, una vez creados todos los códigos podemos ir codificando todas las entrevistas. Para ello, primero hay que seleccionar el documento (véase la imagen 74 y 75). En este caso se selecciona la entrevista 1. Imagen 74. Imagen que muestra la entrevista 1 codificada con los cinco códigos. Imagen 75. Imagen que ilustra el proceso de codificación completo de las 10 entrevistas. Todas las afirmaciones se han categorizado atendiendo a los distintos códigos creados, en el caso de nuestro ejemplo, el contenido de todas las entrevistas se han codificado con los siguientes códigos que representan las ideas clave de nuestra investigación: (1) evolución de la desinformación, (2), medidas 70 frente a la Desinformación en Medios de comunicación, (3) sistemas de verificación frente a la desinformación, (4) ética y responsabilidad en el periodismo y (5) adaptación y evolución del periodismo. Del análisis de las entrevistas se obtienen agrupadas las afirmaciones identificadas por códigos. De este modo tenemos una visión de conjunto de las respuestas de los entrevistados con base en ideas específicas, en este caso, con base en cinco ideas (los cinco códigos creados). A continuación, se describirá el resultado de la codificación. Para ello accederemos a la pestaña informes, e ingresaremos a función resumen con segmentos codificados (véase imagen 76). Imagen 76. Se selecciona la funcionalidad “Resumen con segmentos codificados” Esta funcionalidad permitirá obtener un informe final con todas las declaraciones dispuestas por códigos (véase imagen 77 y 78). 71 Imagen 77. Proceso para la obtención de los informes finales de las declaraciones codificadas. Imagen 78. Proceso para la obtención de los informes finales de las declaraciones codificadas. Los resultados de la codificación pueden descargarse en distintos formatos como Word, Excel, etc. En el caso de este ejemplo se descargará en formato Word (véase imagen 79) 72 Imagen 79. Informe final en formato Word en donde se muestra las respuestas codificadas por los 5 códigos propuestos. Después de haber obtenido los resultados brutos, los investigadores suelen reflexionar sobre los datos codificados de las entrevistas para extraer las ideas principales, Sin embargo, podemos recurrir a ChatGPT para ayudarnos con estos datos, como ya se mencionó anteriormente. A continuación, se presentan tres opciones posibles: • Análisis de similitudes y diferencias en las respuestas de los participantes de la entrevista • Distinción de afirmaciones positivas y negativas en las respuestas de los participantes de la entrevista • Identificación de las respuestas más importantes de los participantes de la entrevista. Para analizar las similitudes y diferencias en las respuestas de los participantes de la entrevista, deberemos recopilar las afirmaciones del informe (véase imagen 79) y solicitar a ChatGPT que determine las similitudes y diferencias en las afirmaciones codificadas (véase imagen 81). Todo ello deberá hacerse código a código. En el caso de este ejemplo utilizaremos las declaraciones categorizadas con el código “Adaptación y evolución en el periodismo” 73 Imagen 80. Operación que se le pide a ChatGPT para que identifique de convergencias y divergencias en las respuestas de los entrevistados producto del informe generado por MAXQDA para el código “Adaptación y evolución en el periodismo”. En este caso ChatGPT nos ofrece diferentes declaraciones en donde hay convergencias y divergencias entre los entrevistados (véase imagen 81). 74 Imagen 81. Resultados ofrecidos por ChatGPT que muestra las convergencias y divergencias de las respuestas codificadas para el código “Adaptación y evolución en el periodismo”. Para identificar las afirmaciones positivas y negativas en las respuestas de los participantes de la entrevista, deberemos recopilar las afirmaciones del informe (véase imagen 80) y solicitar a ChatGPT que determine las respuestas positivas y negativas en las afirmaciones codificadas (véase imagen 82). 75 Imagen 82. Operación que se le pide a ChatGPT para que identifique declaraciones positivas y negativas en las respuestas de los entrevistados producto del informe generado por MAXQDA para el código “Adaptación y evolución en el periodismo” 76 En este segundo supuesto, ChatGPT nos ofrece solo un listado con afirmaciones positivas al no encontrar declaraciones negativas (véase imagen 83) Imagen 83. Resultados ofrecidos por ChatGPT que muestra las declaraciones positivas y negativas de las respuestas codificadas para el código “Adaptación y evolución en el periodismo”. Para identificar las declaraciones más significativas en las respuestas de los participantes de la entrevista, deberemos recopilar las afirmaciones del informe (véase imagen 80) y solicitar a ChatGPT que determine las respuestas más relevantes presentes en las afirmaciones codificadas (véase imagen 84). 77 Imagen 84. Operación que se le pide a ChatGPT para que identifique las declaraciones más significativas en las respuestas de los entrevistados producto del informe generado por MAXQDA para el código “Adaptación y evolución en el periodismo” En este último supuesto, se presentan las declaraciones más relevantes en un formato de listado, según la evaluación realizada por ChatGPT (véase imagen 85). 78 Imagen 85. Resultados ofrecidos por ChatGPT que muestra las que considera que son las declaraciones más significativas de las respuestas codificadas para el código “Adaptación y evolución en el periodismo”. En resumen, estas 3 opciones nos permiten transformar los datos que están en bruto en información útil para el investigador para su posterior análisis y reflexión. En definitiva, volvemos a recoger una idea que hemos estado defendiendo durante todo este trabajo, y es que resulta crucial tener en cuenta que el uso de estas técnicas debe ser responsable, y deben ser consideradas solamente como un punto de inicio para el proceso de análisis y reflexión del investigador o del equipo de investigadores. En ningún caso, deben ser consideradas como el resultado final de la investigación. Conclusiones En este informe se ha demostrado cómo se pueden utilizar herramientas tecnológicas como ChatGPT junto con ATLAS.ti, Nvivo o MAXQDA para analizar entrevistas científicas y obtener unos primeros resultados útiles para desarrollar estudios cualitativos. Se ha presentado el proceso paso a paso para trabajar de manera eficaz con estas herramientas y se ha aplicado un ejemplo práctico por cada CAQDAS para que los investigadores puedan aplicar el suyo siguiendo las pautas propuestas. Una de las principales ventajas de utilizar estas herramientas es la automatización asistida de procesos y la obtención de resultados semiautomáticos de las respuestas de los entrevistados. Además, se ha mostrado cómo podemos aprovechar las virtudes de ChatGPT para transformar las respuestas de las entrevistas en ideas para que los investigadores saquen sus propias conclusiones. Es importante destacar que el uso de ChatGPT en combinación con ATLAS.ti, Nvivo o MAXQDA debe ser siempre bajo el doble imperativo categórico de un uso que sea a la vez tan responsable como ético. La responsabilidad nos impide usar los resultados generados por 79 ChatGPT como si fueran resultados finales. En lugar de esto, son solo un punto de partida que debe ser analizado críticamente por parte de los investigadores. La ética, por su parte, es un componente siempre presente en las investigaciones de cualquier tipo, no solo las afectadas por el uso de la IA. El hecho de que en nuestro informe hemos trabajado con datos no sensibles y profesionales anónimos, cosas ambas que minimizan la mayoría de los riesgos, no debe engañarnos sobre la necesidad de aplicar todos los puntos anteriores, porque los casos reales de aplicación pueden ser, en cambio mucho más sensibles. En concreto, los resultados obtenidos del modo mostrado en este informe, pueden servir como punto de partida para el desarrollo final del argumentario del investigador fruto de su reflexión. En ningún caso pueden formar parte del resultado final de la investigación desarrollada. El uso responsable nos impone la necesidad de aplicar el pensamiento crítico. Esto significa que los resultados iniciales deben ser analizados considerando su compatibilidad con nuestros conocimientos previos, así como su verisimilitud considerando el grueso de la evidencia científica en el campo que estamos trabajando. Esto nos obliga a trabajar siempre con un background sólido respecto a la disciplina en la que nos movemos. A su vez, esto nos indica que no resulta aconsejable usar estas herramientas sin hacer al menos una revisión de la literatura del ámbito afectado, de ser posible, de tipo sistematizado. El uso ético viene determinado por cada ámbito. Los principios generales son siempre de aplicación y su incidencia dependerá de la sensibilidad del tema concreto y de la intervención de población sensible (p.e. menores edad) así como de la naturaleza de los datos obtenidos (p.e. si afectan a creencias, ideología, etc.), así como si se trata de personas identificadas o anónimas, de la necesidad de obtener permisos si los datos son sensibles, etc. Por último, exige el rechazo de resultados generados por una IA que puedan incorporar sesgos antidemocráticos, racistas, ofensivos para minorías o colectivos humanos, o de cualquier otro tipo que sean negativos para la convivencia democrática o que vayan contra los derechos humanos. En resumen, este informe presenta una práctica del uso de la IA, pero que no olvida, al contrario, la necesidad de aplicar siempre a la vez visión crítica y ética en el uso de la inteligencia artificial en el día a día del investigador. A la vez que intenta mostrar cómo se pueden utilizar programas CAQDAS para analizar entrevistas científicas de manera rigurosa, sistemática y en profundidad para obtener resultados altamente significativos en los que la validez interna y externa esté maximizada. Bibliografía • ATLAS.ti (2022). ATLAS.ti, https://atlasti.com • Almaiah, M. & Mulhem.A. (2020) Thematic Analysis for Classifying the Main Challenges and Factors Influencing the Successful Implementation of E-learning System Using NVivo, International Journal of Advanced Trends in Computer Science and Engineering, 9(1), January – February 2020, 142 – 15 • Almaiah, M. & Mulhem.A. (2020) Thematic Analysis for Classifying the Main Challenges and Factors Influencing the Successful Implementation of E-learning System Using NVivo, International Journal of Advanced Trends in Computer Science and Engineering, 9(1), January – February 2020, 142 – 15 80 • Barry, C. (1998) Choosing Qualitative Data Analysis Software: Atlas/ti and Nudist Compared, Sociological Research Online, vol. 3, no. 3, http://www.socresonline.org.uk/3/3/4.html • Beekhuyzen, J.; Nielsen, S.; & von Hellens, L. (2010) The Nvivo Looking Glass: Seeing the Data Through the Analysis. En 5th International Conference on Qualitative Research in IT & IT in Qualitative Research (QualIT2010) • Bergin M (2011) NVivo 8 and consistency in data analysis: reflecting on the use of a qualitative data analysis program. Nurse Researcher. 18, 3, 6-12. • Bonello, M., & Meehan, B. (2019). Transparency and Coherence in a Doctoral Study Case Analysis: Reflecting on the Use of NVivo within a 'Framework' Approach. The Qualitative Report, 24(3), 483-498. https://nsuworks.nova.edu/tqr/vol24/iss3/4 • Consoli, S. (2021). Uncovering the hidden face of narrative analysis: A reflexive perspective through MAXQDA. System, 102, 102611. • Dias, J.;Meireles, I.;Ribeiro, M.; Braga, T.; Catafesta, F.;Bernardino, E. (2016) Uso del software NVivo® en una investigación con Teoría Fundamentada. Index de Enermería, 25 (4) • Díaz-Bravo, L.; Torruco-García, U.; Martínez-Hernández,M.; Varela-Ruiz, M. (2003). La entrevista, recurso flexible y dinámico, Investigación en educación médica, 2 (7) • Elaldi, S., & Yerliyurt, N. S. (2017). The Efficacy of Drama in Field Experience: A Qualitative Study Using MAXQDA. Journal of Education and Learning, 6(1), 10-26. • Feng, X., & Behar-Horenstein, L. (2019). Maximizing NVivo Utilities to Analyze Open-Ended Responses. The Qualitative Report, 24(3), 563-571 https://nsuworks.nova.edu/tqr/vol24/iss3/11 • Franzosi, R; Doyle, S.; McClelland; L.; Putnam, C. & Vicari, S. (2013) Quantitative narrative analysis software options compared: PC-ACE and CAQDAS (ATLAS.ti, MAXqda, and NVivo) Qual Quant (2012) 47:3219–3247 DOI 10.1007/s11135-012-9714- 3 • Gibbs, D., Boettcher, J., Hollingsworth, J., & Slania, H. (2012). Assessing the Research Needs of Graduate Students at Georgetown University. The Journal of Academic Librarianship, 38(5), 268-276. https://doi.org/10.1016/j.acalib.2012.07.002 • Gibson, W.; Callery, P.; Campbell, M.; Hall, A.; and Richards, D. (2004) The Digital Revolution in Qualitative Research: Working with Digital Audio Data Through Atlas.Ti, Sociological Research Online, Volume 10, Issue 1, < http://www.socresonline.org.uk /10/1/gibson.html> doi:10.5153/sro.1044 • Hatani, F. (2015). Analyzing high-profile panel discussion on global health: An exploration with MAXQDA. In Forum Qualitative Sozialforschung/Forum: Qualitative Social Research (Vol. 16, No. 1). • Houghton,C.; Murphy, K.; Meehan, B.; Thomas, J.; Brooker, D.; Casey, D. (2016) From screening to synthesis: using NVIVO to enhance transparency in qualitative evidence synthesis, Journal of Clinical Nursing, 26, 873–881, doi: 10.1111/jocn.13443 • Hutchison, A.; Johnston, L. & Breckon, J. (2009) Using QSR-NVivo to facilitate the development of a grounded theory project: an account of a worked example', International Journal of Social Research Methodology, 99999:1, • Hwang, S. (2008) Utilizing Qualitative Data Analysis Software A Review of Atlas.ti, Social Science Computer Review, 26 (4), DOI: 10.1177/0894439307312485 • Kalpokaite, N.; Radivojevic, I. (2019): Teaching qualitative data analysis software online: a comparison of face-to-face and e-learning ATLAS.ti courses, International Journal of Research & Method in Education, DOI: 10.1080/1743727X.2019.1687666 • Kuckartz, U. (2010). Realizing mixed-methods approaches with MAXQDA. Philipps- Universität, Marburg. • Kuckartz, U., & Rädiker, S. (2021). Using MAXQDA for mixed methods research. In The Routledge Reviewer's Guide to Mixed Methods Analysis (pp. 305-318). Routledge. 81 • Kuckartz, A., & Sharp, M. J. (2011). Responsibility: A key category for understanding the discourse on the financial crisis—Analyzing the KWALON data set with MAXQDA 10. In Forum Qualitative Sozialforschung/Forum: Qualitative Social Research (Vol. 12, No. 1). • Leech, N.; Onwuegbuzie, A. (2011). Beyond constant comparison qualitative data analysis: Using NVivo. School Psychology Quarterly, 26 (1), 70-84 • Lopezosa, C. (2020). Entrevistas semiestructuradas con NVivo: pasos para un análisis cualitativo eficaz. En: Lopezosa, C.; Díaz-Noci, J.; Codina, L. (ed.). Anuario de Métodos de Investigación en Comunicación Social, n.1 (p.88-97). Barcelona: DigiDoc- Universitat Pompeu Fabra • Lopezosa, C., & Codina, L. (2022). MAXQDA para el análisis cualitativo de entrevistas: una guía para investigadores. • Lopezosa, C., Codina, L., & Freixa Font, P. (2022). ATLAS. ti para entrevistas semiestructuradas: guía de uso para un análisis cualitativo eficaz. • Maher, C.; Hadfield, M.; Hutchings, M. & de Eyto, A. (2018) Ensuring Rigor in Qualitative Data Analysis: A Design Research Approach to Coding Combining NVivo With Traditional Material Methods, International Journal of Qualitative Methods Volume 17: 1–13 • Marjaei, S., Yazdi, F. A., & Chandrashekara, M. (2019). MAXQDA and its Application to LIS Research. Library Philosophy and Practice, 1-9. • MAXQDA (2022). Manual Básico para MAXQDA 2022, MAXQDA. https://www.maxqda.com/download/GettingStarted-MAXQDA2022-esp.pdf • Menezes-Brito, M.J.; Silva, C.; Cozer, L.; Rezende, L.; Siqueira, H.; Souza, F. (2017) Potentialities of Atlas.ti for Data Analysis in Qualitative Research in Nursing, Computer Supported Qualitative Research, Studies in Systems, Decision and Control, 71, DOI 10.1007/978-3-319-43271-7_7 • Muhr, T. (1991) ATLAS/ti--A Prototype for the Support of Text Interpretation, Qualitative Sociology, Vol. 14, No. 4, 1991 • Muhtarom; Murtianto, Y. & Sutrisno (2017) Thinking Process of Students with High- Mathematics Ability (A Study on QSR NVivo 11-Assisted Data Analysis), International Journal of Applied Engineering Research ISSN 0973-4562 Volume 12, Number 17 (2017) pp. 6934-6940 • Niedbalski, J.; Ślęzak, I. (2017) Computer Assisted Qualitative Data Analysis Software. Using the NVivo and Atlas.ti in the Research Projects Based on the Methodology of Grounded Theory, Computer Supported Qualitative Research, Studies in Systems, Decision and Control, 71, DOI 10.1007/978-3-319-43271-7_8 • O'Neill, M. M., Booth, S. R., & Lamb, J. T. (2018). Using NVivo‚Ñ¢ for Literature Reviews: The Eight Step Pedagogy (N7+1).The Qualitative Report, 23(13), 21-39 • Paulus, T.; Woods, M.; Atkins, D. & Macklin, R.(2015): The discourse of QDAS: reporting practices of ATLAS.ti and NVivo users with implications for best practices, International Journal of Social Research Methodology, DOI: 10.1080/13645579.2015.1102454 • Paulus, T; Bennett, A. (2015): ‘I have a love–hate relationship with ATLAS.ti’™: integrating qualitative data analysis software into a graduate research methods course, International Journal of Research & Method in Education, DOI: 10.1080/1743727X.2015.1056137 • Paulus, T.; Lester, J. (2015): ATLAS.ti for conversation and discourse analysis studies, International Journal of Social Research Methodology, DOI: 10.1080/13645579.2015.1021949 • Paulus, T.; Pope, E.; Woolf, N. Silver, C. (2018): It will be very helpful once I understand ATLAS.ti: Teaching ATLAS.ti using the Five-Level QDA method, 82 International Journal of Social Research Methodology, DOI: 10.1080/13645579.2018.1510662 • Phillips, M. & Jing, L. (2018) A quick look at NVivo, Libraries Faculty and Staff Scholarship and Research. Paper 202. http://dx.doi.org/10.1080/1941126X.2018.1465535 • Phillips, M. & Zwicky, Dave (2017). Patent Information Use in Engineering Technology Design: An Analysis of Student Work,. Libraries Faculty and Staff Scholarship and Research. Paper 184. http://dx.doi.org/10.5062/f4zs2tr8 • Rädiker, S. (2020). Focused analysis of qualitative interviews with MAXQDA: Step by step. • Rambaree, K.; Nässén, N. (2021) Digitalization of Critical Reflection with ATLAS.ti Software in Social Work Supervision, Social Sciences, 10: 95. https://doi.org/10.3390/socsci10030095 • Rojas-Figueroa, A.; Londoño-Gallego, J.; Pérez-Betancur, N. & Gómez-Navarro, M. Analysis of the big data generated in the company's social networks “Sistemas Expertos SAS” using NVivo, Journal of Physics: Conference Series 1418, 012004, doi:10.1088/1742-6596/1418/1/012004 • Rossolatos, G. (2019) Negative brand meaning co‐creation in social media brand communities: A laddering approach using NVivo, Psychol Mark. 2019;36:1249–1266. • Saillard, E. K. (2011). Systematic versus interpretive analysis with two CAQDAS packages: NVivo and MAXQDA. In Forum Qualitative Sozialforschung/Forum: Qualitative Social Research (Vol. 12, No. 1). • Scales, J. (2013) Qualitative analysis of student assignments: a practical look at ATLAS.ti, Reference Services Review, Vol. 41 No. 1, 2013, pp. 134-147, DOI 10.1108/00907321311300956 • Schultheiß, S. and Lewandowski, D. (2020) Expert interviews with stakeholder groups in the context of commercial search engines within the SEO Effect project, SEO-Effekt Working Paper , 1-53 • Schönfelder, W. (2011, January). CAQDAS and qualitative syllogism logic—NVivo 8 and MAXQDA 10 compared. In Forum Qualitative Sozialforschung/Forum: Qualitative Social Research (Vol. 12, No. 1). • Schultheiß, S. and Lewandowski, D. (2021), “Outside the industry, nobody knows what we do” SEO as seen by search engine optimizers and content providers, Journal of Documentation, Vol. 77 No. 2, pp. 542-557. https://doi.org/10.1108/JD-07-2020- 0127 • Sepasgozar, S. & Davis, S. (2018) Construction Technology Adoption Cube: An Investigation on Process, Factors, Barriers, Drivers and Decision Makers Using NVivo and AHP Analysis, buildings, 8, 74; doi:10.3390/buildings8060074 • Sotiriadou, P.; Brouwers, J.; & Le, T. (2014): Choosing a qualitative data analysis tool: a comparison of NVivo and Leximancer, Annals of Leisure Research, DOI: 10.1080/11745398.2014.902292 • Trigueros-Cervantes, C.; Rivera-García, E.; Moreno-Doña, A. & Muñoz-Luna, R. (2016) Uso del software CAQDAS Nvivo en Ciencias Sociales para la investigación con grupos de discusión, index de enfermería, vol.25 no.3 • Vila-Henninger, L.A. (2019) Turning Talk into “Rationales”: Using the Extended Case Method for the Coding and Analysis of Semi-Structured Interview Data in ATLAS.ti, Bulletin de Methodologie Sociologique, Vol. 143 28–52, DOI: 10.1177/0759106319852887 83 • Wilk, V.; Soutar, G. & Harrigan, P (2017) Tackling social media data analysis Comparing and contrasting QSR NVivo and Leximancer, Qualitative Market Research: An International Journal Vol. 22 No. 2, pp. 94-113 DOI 10.1108/QMR-01- 2017-0021 • Wong L. (2008). Data analysis in qualitative research: a brief guide to using nvivo. Malaysian family physician : the official journal of the Academy of Family Physicians of Malaysia, 3(1), 14–20. • Woods,M.; Paulus,T.; Atkins, D.; Macklin, R. (2015) Advancing Qualitative Research Using Qualitative Data Analysis Software (QDAS)? Reviewing Potential Versus Practice in Published Studies using ATLAS.ti and NVivo, 1994–2013, Social Science Computer Review, 1-21, DOI: 10.1177/0894439315596311 • Zamawe, F. (2015). The Implication of Using NVivo Software in Qualitative Data Analysis: Evidence-Based Reflections. Malawi Medical Journal, 27(1) http://dx.doi.org/10.4314/mmj.v27i1.4 • Zapata-Sepúlveda, P., López-Sánchez, F. & Sánchez-Gómez, M.C. Content analysis research method with Nvivo-6 software in a PhD thesis: an approach to the long- term psychological effects on Chilean ex-prisoners survivors of experiences of torture and imprisonment. Qual Quant 46, 379–390 (2012). https://doi.org/10.1007/s11135-011-9551-9 84 Baños-Moreno, M.-J., Pastor-Sánchez, J.-A., & Martínez-Béjar, R. (2017). Interactivity features of Online Newspapers: from a facsimile model to a multimedia model one. Interactivity in online journals. Anales de Documentación, 20(2). https://doi.org/10.6018/analesdoc.20.2.282401 Choo, J. , Cheong, S. , Lee, Y. , Teh, S. (2012). 'I2Navi: An Indoor Interactive NFC Navigation System for Android Smartphones'. World Academy of Science, Engineering and Technology, Open Science Index 72, International Journal of Electronics and Communication Engineering, 6(12), 1408 - 1412. Guallar, J., Abadal, E., & Codina, L. (2012). Hemerotecas de prensa digital. Evolución y tendencias. Profesional de la Informacion, 21(6), 595-605. https://doi.org/10.3145/epi.2012.nov.06 Harvey, M., & Pointon, M. (2019). Understanding in-context interaction: An investigation into on-the-go mobile search. Information Processing and Management, 56(6). https://doi.org/10.1016/j.ipm.2019.102089 Ksiazek, T. B., Peer, L., & Lessard, K. (2016). User engagement with online news: Conceptualizing interactivity and exploring the relationship between online news videos and user comments. New Media & Society, 18(3), 502-520. https://doi.org/10.1177/1461444814545073 Kumar, R., & Saini, S. (2011). A Study on SEO Monitoring System Based on Corporate Website Development. International Journal of Computer Science, Engineering and Information Technology (IJCSEIT), 1(2). https://doi.org/10.5121/ijcseit.2011.1204 Larsson, A. O. (2012). Interactivity on Swedish newspaper websites: What kind, how much and why? Convergence, 18(2), 195-213. https://doi.org/10.1177/1354856511430184 Linares, J; Codina; L.; Freixa, P. (2015). Tendencias en Cibermedios. Análisis de la interactividad. Barcelona: Universitat Pompeu Fabra. Departament de Comunicació, 2015. 53 p. (Serie Editorial DigiDoc. Proyecto Audiencias Activas). http://hdl.handle.net/10230/24636 López Carreño, Rosana; Pastor Sánchez, J. A. (2010). Vista de Actualización del modelo de portal periodístico de prensa española. Anales de Documentación, 13, 177-184. Recuperat de https://revistas.um.es/analesdoc/article/view/107141/101811 Lopezosa, C.; Codina, L.; Freixa, P. (2018). Seo y comunicación audiovisual: análisis comparativo de portales de vídeo bajo demanda. Serie DigiDoc-EPI, n. 3. Barcelona: Universitat Pompeu Fabra, Departamento de Comunicación; Ediciones Profesionales de la Información SL. ISBN: 978 84 09 02431 5. Lopezosa C, Codina L. (2018) Análisis de posicionamiento en medios de comunicación con herramientas SEO: cobertura informativa de los premios Oscar 2017. Barcelona: Universitat Pompeu Fabra. Departament de Comunicació, 2018. 46 p. (Serie Editorial DigiDoc); (EPI; no.2) Lopezosa, C.; Codina, L.; Rovira, C. (2019a). Visibilidad web de portales de televisión y radio en España: ¿qué medios llevan a cabo un mejor posicionamiento en buscadores?. Serie 85 DigiDoc-EPI,n. 4. Barcelona: Universitat Pompeu Fabra, Departamento de Comunicación; Ediciones Profesionales de la Información SL. ISBN: 978 84 09 07716 8 Lopezosa, C., Codina, L., Pérez-Montoro, M. (2019b). SEO and Digital News Media: Visibility of Cultural Information in Spain’s Leading Newspapers. Trípodos, 44. https://doi.org/10.51698/tripodos.2019.44p41-61 Lopezosa, C., Iglesias-García, M., González-Díaz, C., & Codina, L. (2020). Experiencia de búsqueda en cibermedios: análisis comparativo de diarios nativos digitales. Revista Española de Documentación Científica, 43(1), e254-e254. Lopezosa, C., Codina, L., López-García, G., & Corbella-Cordomi, J.-M. (2020). Mapa de visibilidad y posicionamiento en buscadores de los principales grupos mediáticos españoles. Profesional De La Información, 29(2). https://doi.org/10.3145/epi.2020.mar.03 Mao, J., Liu, Y., Kando, N., Luo, C., Zhang, M., & Ma, S. (2018). Investigating result usefulness in mobile search. En Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics) (Vol. 10772 LNCS, p. 223-236). Springer Verlag. https://doi.org/10.1007/978-3-319-76941-7_17 Nielsen, J., & Molich, R. (1990). Heuristic evaluation of user interfaces. Paper presented at the Proceedings of the SIGCHI Conference on Human Factors in Computing Systems, 249- 256. Pack Sheffield, J. (2020). Search Engine Optimization and Business Communication Instruction: Interviews with Experts. Business and Professional Communication Quarterly, 2020(2), 153-183. https://doi.org/10.1177/2329490619890335 Palanisamy, R; Liu, Y. (2018). User search Satisfaction in Search Engine Optimization. Proceeding of the International Conference on Computer Networks, Big Data and IoT (ICCBI - 2018). 10.1007/978-3-030-24643-3_124. Paskin, D. (2018). News publishing across platforms: Gatekeeping for print, web, Facebook and Twitter. Newspaper Research Journal, 39(4), 376-388. https://doi.org/10.1177/0739532918806897 Pius Nedumkallel, J. (2020). Interactivity of Digital Media: Literature Review and Future Research Agenda. International Journal of Interactive Communication Systems & Technologies, 10(1). 10.4018/IJICST.2020010102 Rodríguez-Martínez, R., Codina, L., & Pedraza-Jiménez, R. (2012). Indicadores para la evaluación de la calidad en medios digitales: análisis de la interacción y de la adopción de la Web 2.0. Revista española de Documentación Científica, 35(1), 61-93. https://doi.org/10.3989/redc.2012.1.858 Pedraza-Jiménez, R; Codina, L.; Guallar, J. (2016). Calidad en sitios web: método de análisis general, e-commerce, imágenes, hemerotecas y turismo; Editorial UOC; Barcelona. Santos-Hermosa, G., Lopezosa, C., & Codina, L. (2023). Interactividad, buscabilidad y visibilidad web en periodismo digital galardonado. Cuadernos. info, (54), 269-292. 86 Santos-Hermosa, G., Lopezosa, C., & Codina, L. (2022). Analysis of interactivity in digital journalism. Freixa P, Codina L, Pérez-Montoro M, Guallar J, editors. Visualisations and narratives in digital media: methods and current trends. Barcelona: Universitat Pompeu Fabra, Ediciones Profesionales de la Información; 2022. p. 13-25. Santos-Hermosa, G., Lopezosa, C., & Codina, L. (2022). Análisis de interactividad, buscabilidad y visibilidad en el periodismo digital. In La nueva era comunicativa (pp. 537-554). Thomson Reuters Aranzadi. Tamer F. Abdelmaguid, Ashraf O. Nassef, Badawia A. Kamal & Mohamed F. Hassan (2004). A hybrid GA/heuristic approach to the simultaneous scheduling of machines and automated guided vehicles, International Journal of Production Research, 42 (2), 267- 281. DOI: 10.1080/0020754032000123579 Los INFORMES DIGIDOC, iniciados en 2016, tienen como objetivo ofrecer, de forma accesible y en abierto, los resultados de los proyectos realizados por el Grupo de Investigación en Documentación Digital y Comunicación Interactiva de la Universidad Pompeu Fabra (Barcelona). Este informe es resultado del proyecto Parámetros y estrategias para incrementar la relevancia de los medios y la comunicación digital en la sociedad: curación, visualización y visibilidad (CUVICOM) (PID2021-123579OB-I00)  Este informe propone orientaciones prácticas a los investigadores para analizar cualitativamente entrevistas académicas mediante el uso combinado de software inteligencia artificial (IA) y de análisis cualitativo asistido por ordenador (CAQDAS). En concreto, mostramos la manera de combinar ChatGPT y programas de análisis cualitativo como ATLAS.ti, Nvivo y MAXQDA. En primer lugar, presentamos una introducción a las entrevistas académicas y a los programas CAQDAS. En segundo lugar, se presenta una revisión de estudios académicos relacionados con el uso de ATLAS.ti, Nvivo y MAXQDA. En tercer lugar, se aborda la inteligencia artificial ChatGPT como soporte a los programas tipo CAQDAS (como los mencionados) para la codificación de entrevistas y la compilación de resultados tomando en consideración las dos condiciones generales para el uso de IA: pensamiento crítico y ética profesional. Finalmente, se ilustra con ejemplos prácticos, paso a paso, cómo combinar ChatGPT con ATLAS.ti, NVIVO y MAXQDA, respectivamente, para generar estudios cualitativos apoyados en entrevistas. DIGIDOC REPORTS: ONLINE NEWS RESEARCH PAPERS, 2023.02 View publication stats","libVersion":"0.3.2","langs":""}