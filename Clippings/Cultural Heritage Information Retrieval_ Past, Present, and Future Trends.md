---
title: "Cultural Heritage Information Retrieval: Past, Present, and Future Trends"
source: https://ieeexplore.ieee.org/document/10463018
author:
  - Victor de Boer
published: 
created: 2025-05-10
description: The importance of knowledge organization and information retrieval techniques has been evident throughout human history, becoming even more crucial in the digit
tags:
  - research_method/ScopingReview
  - themes/HerStory/GLAM
  - themes/HerStory/historicalMemory
---
[[Knowledge Graphs for Cultural Heritage and Digital Humanities.pdf]] #op/buscar autor

[[Cultural_Heritage_Information_Retrieval_Past_Present_and_Future_Trends.pdf]]

Cultural Heritage Information Retrieval: Past, Present, and Future Trends | IEEE Journals & Magazine | IEEE Xplore 

Conceptual framework of the cultural heritage information modeling and retrieval for end users.

## Abstract:

The importance of knowledge organization and information retrieval techniques has been evident throughout human history, becoming even more crucial in the digital age. Wh...

---

If the problem was shortage and unavailability of information in some 30 years ago, today it is information overload with the advent of digitization and more importantly, the web. With the revolution of the web, information accessibility became easier and faster. More effort was put in to digitizing information in papers and creating central databases to store the data produced and also to find and reuse them efficiently by taking advantage of the technological advancement of computers. There are three important issues here as discussed in [\[1\]](https://ieeexplore.ieee.org/document/). The first is technical interoperability, which is solved by the decentralized architecture of the web and its platform independent protocols for data sharing and exchange. The very web itself lead to the second problem, which is semantic interoperability. By connecting vast amounts of databases with unstructured data with no or little standardization, it caused a trouble that is called “the digital dark age” [\[2\]](https://ieeexplore.ieee.org/document/). Unstructured data, lacking predefined data models, poses significant challenges, including a lack of systematic organization, heterogeneity, and contextual complexity. Manual classification and labeling of such data are impractical due to its sheer volume, human subjectivity, and the scale of internet-generated content [\[3\]](https://ieeexplore.ieee.org/document/). The term “digital dark age” is introduced to highlight the potential loss of accessibility and understanding of unstructured data over time, particularly when lacking standardized semantics. Technological solutions, such as Natural Language Processing (NLP), machine learning, and artificial intelligence (AI), play a crucial role in addressing these challenges, enabling the extraction of meaningful insights from unstructured sources [\[4\]](https://ieeexplore.ieee.org/document/). Understanding what is in the data/collections is the third critical challenge. People’s perceptions of objects change throughout time. Data is not objective; rather, it is developed from a specific point of view, expressing a voice. Cultural, historical, or social conventions, or a combination of these, might shape these viewpoints. Rather than being disjointed, these various viewpoints are frequently contiguous. A polyvocal Semantic Web provides opportunities, models, and methods for identifying, representing, and showing users several points of view on an event, organization, opinion, or object [\[5\]](https://ieeexplore.ieee.org/document/).

In the current web of documents, one can only search for words and their co-occurrences [\[6\]](https://ieeexplore.ieee.org/document/). However, this is not a suitable way to search and retrieve information, since users do not always know the name of the thing they are searching for or basically their question is a semantic one. For example, artists who lived in a desired city during a special period of time. The current web cannot handle these types of queries, and it has certain limitations. There is a need for data integration and understanding to reach short-term accessibility and long-term preservation, or the data produced with great deal of effort and high cost will fade into disuse, or even worse, be unusable [\[7\]](https://ieeexplore.ieee.org/document/). In the late 20th and early 21st century, the Semantic Web was proposed to solve this problem [\[8\]](https://ieeexplore.ieee.org/document/) and since then it has been an active research field. The main aim of the Semantic Web is to transform the current web of documents into a web of data and information by making the available data machine-readable [\[9\]](https://ieeexplore.ieee.org/document/). With machines understanding the data, information retrieval can be easier, better, and faster. The Semantic Web has developed standards and technologies to structure and harmonize heterogeneous data, and its latest recommendation is design and usage of formal ontologies to achieve that goal. Of course, knowledge organization and information integration is not a new idea [\[7\]](https://ieeexplore.ieee.org/document/). This idea of formal ontology is based on the valuable past efforts and the traditional knowledge engineering methods.

The Cultural Heritage (CH) was one of the first domains to adopt Semantic Web methods, tools, and recommendations [\[10\]](https://ieeexplore.ieee.org/document/), [\[11\]](https://ieeexplore.ieee.org/document/), [\[12\]](https://ieeexplore.ieee.org/document/) for modeling collections of memory organizations, which are also known as GLAMs. This is because of its needs and the importance of its goal. The importance of cultural heritage is multifaceted and encompasses various dimensions, as evidenced by the literature. Cultural heritage plays a crucial role in fostering economic viability, contributing to the continuation of societies, and enhancing the linkages between the past, present, and future [\[13\]](https://ieeexplore.ieee.org/document/). Moreover, it serves as a significant tourism resource, supporting socio-economic development and sustainable growth in local communities [\[14\]](https://ieeexplore.ieee.org/document/). The preservation of cultural heritage is essential for maintaining cultural memory, promoting environment diversity, and generating economic benefits [\[15\]](https://ieeexplore.ieee.org/document/). Additionally, cultural heritage, as a fundamental aspect of human rights, has a profound impact on community identity, sense of place, and social cohesion, highlighting its significance in shaping individual and collective social and mental well-being [\[16\]](https://ieeexplore.ieee.org/document/).

Furthermore, the intangible cultural heritage holds substantial influence on financial results in rural tourism, emphasizing its pivotal role in driving tourism activities and experiences [\[17\]](https://ieeexplore.ieee.org/document/). The significance of safeguarding cultural heritage sites is underscored, emphasizing the essential role of local residents and the government in preserving heritage and culture [\[18\]](https://ieeexplore.ieee.org/document/). Additionally, the intangible cultural heritage is crucial for understanding cultural characteristics, inheriting traditional culture, and facilitating cultural diversity protection and tourism development [\[19\]](https://ieeexplore.ieee.org/document/). Also, cultural heritage literacy and education technologies are identified as important aspects in promoting awareness and sensitivity towards historical cultural heritage sites, contributing to the academic knowledge and cultural sensitivity of individuals [\[20\]](https://ieeexplore.ieee.org/document/), [\[21\]](https://ieeexplore.ieee.org/document/).

Establishing data models and information integration standards and knowledge management in the cultural heritage domain is of great importance, because its data has different formats and types. Also, scientists and specialists from many communities and expertise contribute to this multidisciplinary field [\[22\]](https://ieeexplore.ieee.org/document/). The data in this domain has different types of forms, such as texts, audios, videos, images, 3D models, and spatial data. This data is also related to various types of subjects, such as art, literature, archaeology, spatial science and geometry, physics, and architecture. Additionally, data acquisition and curation techniques differ from archive to archive and from country to country. Alongside these issues, lack of standards and shared understanding has had a substantial effect on data heterogeneity in the CH domain.

There are only a few review studies in the domain of cultural heritage information retrieval and knowledge management. Mostly, they focus on specific subjects, such as geospatial semantic web for CH [\[23\]](https://ieeexplore.ieee.org/document/), building heritage model (BIM) for heritage buildings [\[24\]](https://ieeexplore.ieee.org/document/), conservation and restoration [\[25\]](https://ieeexplore.ieee.org/document/), and systematic bibliography survey [\[26\]](https://ieeexplore.ieee.org/document/). However, in this paper, we seek to provide a comprehensive review of the vast topic of information retrieval and semantic web for CH domain. This work analyzes more than 25 years of research in this area by reviewing studies from late 20 <sup>th</sup> century up until 2023. The results serve as an ideal introductory manual on the evolution of semantic web, progressing from simple knowledge organization models to current ontologies and AI services, while also offering insights into potential future trends. This paper aims to fill the existing gap in the CH community, regarding the formulating the path that has been taken from the era of digitization to current knowledge management technologies, providing an overview of the gradual progress made over the years.

In this context, we introduce a novel conceptual framework that guides our investigation. The framework is structured into three key components: Cultural Heritage, Information Modeling, and Information Retrieval. Within Information Modeling, we delve into Preliminary Knowledge Organization Systems (KOSs), emphasizing early solutions such as Classification Systems, Controlled Vocabulary, Thesaurus, and Metadata Schemas. Additionally, we explore Data Integration at the Metadata Level, the significance of Formal Ontologies, and their application in the Cultural Heritage domain, exemplified through a comparative analysis of CRM vs. EDM. This paper embarks on a thorough exploration and analysis of the evolutionary trajectory of information engineering techniques within the CH domain. Against the backdrop of a shift from information scarcity to information overload, our research aims to address critical questions: How have Semantic Web technologies influenced the organization of knowledge in CH? What persistent gaps impede data interoperability, and how can these challenges be effectively addressed? By meticulously examining historical developments, tackling current challenges head-on, and probing opportunities within CH, our objective is to shed light on the current state of knowledge management. The overarching goal of this project review study is to explore and analyze the evolution of information engineering techniques in the CH domain. Our primary objective is to investigate the progress made in achieving data interoperability and knowledge organization through Semantic Web technologies. Concurrently, we will delve into specific case studies and projects that exemplify successful implementations or innovative approaches in overcoming challenges within the CH domain. Through a focus on real-world applications, we aim to extract practical insights into addressing sustainability issues, promoting data reuse, and navigating intellectual property concerns in the digital realm of cultural heritage. This paper culminates with a forward-looking discussion, highlighting potential research needs and challenges on the horizon.

Developing better information retrieval methods lies within information science and knowledge management areas of expertise. Therefore, in order to take a survey of efforts in this manner, we had to search for work about knowledge management and knowledge organization in the CH domain. With our method, we came across several famous projects, such as Europeana, CultureSampo, ARIADNE, and EEXCESS. We also found successful data models that were developed, such as CIDOC CRM, and EDM. Following these models lead to a better and more complete understanding of the progress made. The publications were received from both Google Scholar and Scopus as resources for this study. The websites and documentation of the famous projects and models were also used, which were accessible through the Google search engine. We have used various retrieval search keywords such as “cultural heritage AND information modeling”, “cultural heritage AND ontology”, “cultural heritage AND metadata”, and “cultural heritage AND taxonomy”. In addition, the names of the famous CH projects and models were used as the search keywords to retrieve the related publications. The retrieved publications were filtered after review if they did not focus on CH information modeling, management, retrieval, and visualization.

However, it seemed a little incomplete and partial just to focus on data models and techniques developed for information retrieval. After all, these models were not developed for their own sake and there were definitely some higher-level goals behind them. Especially in the CH domain with such vital information that their preservation, organization, management, manipulation, and dissemination are of great importance for the memory conservation of a society and the world. We decided to divide this paper into two main parts. The first part focuses on information modeling efforts in the CH domain with the goal of dealing with the heterogeneity of CH data and achieving interoperability, and the second on taking advantage of the interoperable information to develop an interactive, user-friendly information retrieval system. Therefore in the second part, the focus is on smart publishing systems and intelligent applications and services developed based on models and structures in the first part. Figure 1 illustrates the conceptual framework of the research with each part consisting of its subparts, which are discussed in detail in the paper. These two steps are substantial to take the CH knowledge and prepare them for presentation to users in a convenient and efficient way.

**FIGURE 1.**

Conceptual framework of the research.

### A. Preliminary Knowledge Organization Systems (KOSs): Early Solutions

From the very beginning, human beings were interested in classifying and categorizing different branches of knowledge in a hierarchical, so-called “tree-like” method [\[7\]](https://ieeexplore.ieee.org/document/). As a result, the simplest form of knowledge organization systems were classification systems. After that, there were controlled vocabularies and thesauri. These systems were created and used before the web era in libraries, museums, and archives. With the advent of computers and the web, there were computerized versions of them to search and find the information in central database systems, but after going online there were problems that were discussed in the previous section. These types of KOSs were not enough to address the heterogeneity of the data and semantic interoperability [\[27\]](https://ieeexplore.ieee.org/document/). The Semantic Web and its technologies were started to handle the previously mentioned issues. The initial recommendation of the Semantic Web was to use metadata schemas to describe the resources on the web in a machine-readable form to better structure and thus retrieve information. Although metadata schemas were a breakthrough solution, it was not yet enough and had some drawbacks, which lead to ontological data models [\[28\]](https://ieeexplore.ieee.org/document/). In this section, we discuss traditional knowledge organization systems and the steps taken toward metadata schemas. The formal ontologies and conceptual models are based on the past KOSs. Without understanding them and the challenges and issues that were faced, it would be difficult to understand what ontological data models are. The evolution mentioned is shown in Figure 2, which will be discussed in detail in the following sections.

**FIGURE 2.**

Process of knowledge organization systems evolution.

#### 1) Classification Systems

Classification systems intend to organize the knowledge for information storage and retrieval purposes mostly in libraries [\[29\]](https://ieeexplore.ieee.org/document/). With these types of systems, users are able to browse through the collection for their content of interest without prior knowledge of its existence [\[30\]](https://ieeexplore.ieee.org/document/). Later, they were converted to computer formats that created digital libraries, which provided the search and find service online. One of the first classification systems that gained widespread attention was the dewey decimal classification (DDC), Which is a system of 1000 numeric sections with decimal extensions. Later, it was combined with bibliographic classification and punctuation marks and symbols to link and relate different areas of knowledge. This system is named the universal decimal classification (UDC), Which is now used in 150000 libraries in 130 countries and is published in over 40 languages. Its web service is available on webdewey.1

The library of congress classification (LCC 2) Is another classification system that was initially developed for the library of congress in the late 19th century. it uses letters for classes and each class has a subclass that is identified by two letters.

Iconclass 3 Is a classification system designed for art and iconography. It is a well-known tool used for the description and retrieval of subjects represented in images. Ten main divisions of icon-class are coded by digits 0 to 9. The classes have subdivisions both in digits and letters.

#### 2) Controlled Vocabulary

A controlled vocabulary or term list is an ordered set of limited words and phrases, which are used to index content [\[31\]](https://ieeexplore.ieee.org/document/). Vocabulary control is used to standardize the naming and provide uniformity, which improves indexing, browsing, and retrieval of data [\[32\]](https://ieeexplore.ieee.org/document/). There are four types of controlled vocabularies, which include authority files or lists, glossaries, dictionaries, and gazetteers [\[30\]](https://ieeexplore.ieee.org/document/).

Authority files are lists of terms, names, and phrases that are used to control the variant names for an entity. This type of controlled vocabulary is used mostly in the library domain, where the bibliographic records are arranged through a procedure called authority control. Changes in a person’s name can occur due to a variety of reasons, such as artistic nicknames, and personal reasons. In these cases, the use of an authoritative controlled vocabulary maintains a consistent method of referring to the same entity with the same name within the bibliographic catalogue. It also accounts for alternatives that should refer back to the standardized designated name [\[7\]](https://ieeexplore.ieee.org/document/). Examples of such lists are the LCNAF 4 (Library of Congress Name Authority File) and the INIS’s Authority List for Journal Titles. There are many lists of this kind in different countries, which encouraged libraries to aggregate their data to form a complete reference list. The United States Library of Congress, the OCLC (Online Computer Library Center), and the German National Library began a proof of concept project to link their authority records in 1998. After four years of testing this method, this group formed the VIAF 5 (Virtual International Authority File) consortium at the 69 <sup>th</sup> IFLA (International Federation of Library Associations and Institutions) General Conference. Later, many libraries from various countries contributed to the VIAF, which became an OCLC service.

A glossary is a list of words and terms from a specific subject field or from a particular work, and it usually contains their definitions. It is used mostly within the archive domain to help with research in archives collection and records. The Glossary of Archives and Records Terminology 6 of the Society of American Archivists (SAA) and the Glossary of the Rules for Archival Description 7 are examples of these types of lists.

A gazetteer is a list of place names. traditional gazetteers were some sort of a geographic dictionary that was published as a book or in conjunction with maps or atlases. the contents of a gazetteer can include a subject’s location, the feature types (E.G. River, Town, ETC.) country, state, and other descriptive information. the gazetteer of british place names 8 and the world-historical gazetteer 9 are two examples of many of their kinds. It uses letters for classes and each class has a subclass that is identified by two letters.

#### 3) Thesaurus

A thesaurus is a type of controlled vocabulary that establishes relationships among its terms using taxonomies and a variety of semantic relations, such as hierarchy, Equivalence, and association. These relations are clearly displayed by standardized relationship indicators which are employed reciprocally [\[33\]](https://ieeexplore.ieee.org/document/). Thesauri are much more functional when it comes to retrieval of information from a system [\[34\]](https://ieeexplore.ieee.org/document/). Relationships are usually indicated by the notation BT (Broader Term), NT (Narrower Term), SY (Synonym), and rt (associative or related term). However, relations can exceed the ones mentioned above in some thesauri. These types of relationships and structures make a thesaurus resemble an ontology, but they are an exploration of terms rather than formalized conceptual entities. Furthermore, the lack of a definition of relating functions has resulted in less or no ontological commitment [\[7\]](https://ieeexplore.ieee.org/document/).

One of the top-level thesauri in the ch domain is the unesco thesaurus,10 Which covers a wide range of subject fields, such as education, culture, natural sciences, Social and human sciences, Communication, and information. It is compliant with the iso 25964 standard that includes all aspects of Developing a monolingual or multilingual thesaurus. Many thesauri have been developed based on it and it serves as a top-level thesaurus. for example, the UKAT 11 (United Kingdom Archival Thesaurus) Is a thesaurus that was developed on the basis of the unesco thesaurus for archives in the uk to help with indexing their collections and catalogs. The LCSH 12 (Library of Congress Subject Headings), Which is now in its 40 <sup>th</sup> version, Is a complete thesaurus of subject headings used for bibliographic records and is maintained by the library of congress. another thesaurus from the library of congress is the TGM (Thesaurus For Graphic Materials) Which is a tool for indexing visual materials by subject and by genre/format. The thesaurus includes more than 7,000 subject terms and 650 genre/format terms to index the types of photographs, prints, design drawings, ephemera, and other pictures. in fact, this is a merged form of the previously separated two thesauri of the tgm i (thesaurus for graphic materials I: Subject terms) and the TGM II (Thesaurus For Graphic Materials II: Genre and Physical Characteristic Terms) Since 2007. the most used thesauri in the ch domain are possibly those developed by the getty institute. the getty vocabularies 13 (AAT, TGN, ULAN, and CONA) contain structured terminology for art, architecture, decorative arts, material culture, archival materials, visual surrogates, conservation, geographic names, the names of artists, and bibliographic materials. Compliant with international standards of ISO and NISO, They provide authoritative information for catalogers, researchers, and data providers. They were and continue to be critical contributions to cultural heritage information management and documentation. The AAT (Art and Architecture Thesaurus) Is for generic concepts related to art, architecture, conservation, archaeology, and other cultural heritage. It includes work types, styles, materials, and techniques. The CONA (The Cultural Objects Name Authority) Is composed of titles, attributions, depicted subjects, and other metadata about works of art, architecture, and other cultural heritage, which are both extant and historical, physical and conceptual, linked to museum collections, special collections, archives, libraries, and other resources. The ULAN (The union list of artist names) Is a structured vocabulary, that includes names, biographies, related people, and other metadata about artists, architects, firms, studios, museums, patrons, sitters, and other people and groups involved in the creation and study of art and architecture. The tgn (the getty thesaurus of geographic names) is a structured vocabulary that includes names, and descriptions of extent and historical cities, empires, archaeological sites, and physical features important to the research of art and architecture. It uses letters for classes and each class has a subclass that is identified by two letters.

#### 4) Metadata Schemas

As previously mentioned, the Semantic Web has the goal to convert the current web of documents into a web of data by providing machine-readable formats for information. Metadata schemas are actually machine-readable data about data and according to NISO, they are intended to increase data exchange with minimal loss of content and functionality through platform-independent approaches. Metadata consists of a set of elements that are usually structured in a form of textual information [\[7\]](https://ieeexplore.ieee.org/document/), which describes, explains, locates, or otherwise makes it easier to retrieve, use, or manage an information resource [\[35\]](https://ieeexplore.ieee.org/document/). Generally, metadata schemas are classified into two categories [\[36\]](https://ieeexplore.ieee.org/document/):

1. Descriptive Metadata describes an information resource that can also be broken down into two subcategories [\[35\]](https://ieeexplore.ieee.org/document/):
	1. Content-based metadata that describes the content of a resource through tags, such as genre for movies and books or material type for an artifact.
	2. Content-independent metadata that is not about the content of the resource, but it is associated with it, such as an author of a book or the last modification of a multimedia object.
2. Administrative metadata is used for managing collections and resources, and it stores information, such as the acquisition state and the location of information.
Metadata schemas are only possible with the aforementioned technologies and basically relational databases. The Cultural Heritage domain has developed many metadata in its various fields, such as libraries, archives, and museums. One of the most prominent metadata schemas is the Dublin Core.14 It originates from libraries and now is used in many other organizations. DC contains 15 core elements that are called the Dublin Core Metadata Element Set (DCMES), which includes the title, creator, and date. These elements were later extended to 55 elements called the DCMI (Dublin Core Metadata Initiative) for a broader range of purposes and of business models. From the very start of the RDF model by W3C, DC adapted it, and it became a popular metadata for use with RDF [\[12\]](https://ieeexplore.ieee.org/document/).

Before the web era, the Library of Congress started an initiative in the 1960s to create MARC (MAchine-Readable Cataloging), which later became an international standard. In 1999, MARC21 was designed by combining the United States and Canadian MARC formats (USMARC and CAN/MARC). It was named MARC21 because it was refined for the 21 <sup>st</sup> century and to make it more accessible to the international community. Later, it adopted an XML markup language and developed MARCXML 15 in order to facilitate the sharing of and the networked access to bibliographic information. The Library of Congress’ Network Development and the MARC Standard Office developed MODS 16 (Metadata Object Description Schema) which is much easier to understand for humans compared to MARCXML, as it uses language-based tags rather than three-digit numeric tags. Moreover, it is compatible with outside metadata, such as DC and its mapping is more convenient. MADS 17 (Metadata Authority Description Schema) is an XML schema developed by the same organization to provide authority element sets and complement existing object descriptive MODS metadata.

VRA (Visual Resource Association) Core Categories 18 are developed based on DC to describe the work of visual culture as well as the images that document them. This standard is hosted by the Network Development and the MARC Standard Office of the Library of Congress in partnership with the Visual Resource Association. After a series of revisions, it is now called Core4, which is the only metadata standard devised especially for the description of images and the cultural heritage objects they represent.

The CDWA 19 (Categories for the Description of Works of Art) is a set of guidelines and also a metadata schema for the description and cataloging of works of art, architecture, groups and collections of works, and related images. The CDWA includes 532 categories and is more expressive than the VRA Core. Also, it is maintained by the Getty Institute.

In 1977, the SAA (Society of American Archivists) initiated a working group (NISTF) to develop a method for exchanging information about archival data. MARC AMC 20 (MARC for Archives and Manuscripts Control) metadata was created as a result of the efforts of the task force. Since the MARC standard only supports one level of description, it was not a substitute for the more detailed finding aids that were produced by the archivists [\[37\]](https://ieeexplore.ieee.org/document/). This problem encouraged the Berkeley Finding Aid Project to create a platform-independent, machine-readable encoding standard for archival finding aids. The EAD 21 (Encoded Archival Description) is an XML standard developed for this matter. It is based on the notion that archives are hierarchical in nature, and their descriptions are based on inheritance which enables them to provide information on different levels of detail [\[38\]](https://ieeexplore.ieee.org/document/). The EAD standard is jointly administered and maintained by the United States Library of Congress and the Society of American Archivists. Table 1 summarizes the traditional KOSs discussed in this section.

**TABLE 1** The Summary of Traditional KOSs

By leveraging established classification systems, controlled vocabularies, thesauri, and metadata schemas, experts can enhance information retrieval, ensuring semantic interoperability and effective management of CH resources. This Section offers valuable insights for authors and researchers in the Cultural Heritage field, shedding light on the historical progression of knowledge organization systems. The evolution from traditional classification systems to the emergence of controlled vocabularies, thesauri, and metadata schemas is a key aspect to acknowledge. Understanding this evolution provides a contextual foundation for grasping the ongoing challenges and advancements within the field.

### B. Data Integration at the Metadata Level

Before we discuss metadata integration approaches, it is better to discuss one last important concept related to traditional KOSs. W3C developed the SKOS (Simple Knowledge Organization System) to support the use of the traditional KOSs, such as classification systems, controlled vocabularies, thesauri, and others that are called concept schemes within the framework of the Semantic Web. These systems were developed with a lot of effort and are incorporated in many organizations and it is not possible to stop using them easily. With SKOS, they can be used in the Semantic Web space and they can be interoperable, so various organizations can exchange their data and data integration can be easier. SKOS provides specifications and standards to represent knowledge organization systems using the Resource Description Framework (RDF). Encoding this information in RDF allows it to be interchangeable between computer applications in an interoperable way. It also enables the population of elements of metadata schemas with them that adds to uniformity of description and accessibility of data over the web. SKOS has three main features to help represent a concept in a simple and understandable way [\[39\]](https://ieeexplore.ieee.org/document/):

Labeling properties are used to connect a concept to the terms that represent it in natural languages so the concept can be represented seamlessly in multilingual environments. For example, skos:altLabel is used to show alternative terms for the concept, such as synonyms and its name in other languages.

Semantic properties that are employed to represent the semantic relationships between terms in a concept such as a thesaurus. For example, skos:broader indicates generalization BT (Broader Term).

Documentation properties are used to encompass the important notes and documentation of a KOS. Notes in documentation have different roles. SKOS has notations like skos:scopeNote and skos:definition. For explanatory notes and notations, such as skos:historyNote for management notes.

So after the fact that every part of CH data providers and memory organizations developed their own specific metadata schemas describing their own data, efforts began to integrate the data from various institutions to create a virtual large-scale memory organization for seamless access to various and different aspects of the cultural heritage, such as Europeana, Netherlands E-culture, and CultureSampo in Finland. This would also make information about small-scale organizations richer, and the users could be able to find more information in an interesting area by aligning and integrating similar data from different sources. Of course, this level of integration is a step behind ontology-based information integration, which is going to be discussed in the next section. By understanding this method and its limitation, we can have a better insight into ontological data models in reaching semantic interoperability. There are many approaches for achieving metadata interoperability [\[40\]](https://ieeexplore.ieee.org/document/), but two main methods are employed for this matter in the CH domain.

- First, a single metadata schema is chosen and the contents of the databases are transformed into that metadata schema. This method is applied in the project MuseumFinland. In [\[41\]](https://ieeexplore.ieee.org/document/), the authors stated that this approach guarantees a level of consistency and interoperability, but the enforcement of data into one metadata would cause damage to the rich original data. It loses its own metadata that has specific elements describing itself, and there is no one-size-fits-all metadata for heterogeneous data in the CH domain [\[42\]](https://ieeexplore.ieee.org/document/).
- Second, the original metadata schemas and relative KOSs are kept, and a series of alignments and mapping is applied between the metadata to integrate the data and create interoperability between the different schemas and concepts. In this process, the similar and correspondent elements and also the non-correspondent ones are identified. A mapping occurs between similar elements to connect them which is called “crosswalk” [\[42\]](https://ieeexplore.ieee.org/document/). In [\[39\]](https://ieeexplore.ieee.org/document/), the authors integrated data from two Dutch CH institutions by aligning their KOSs. First, they SKOSified the two institutions’ KOSs, and then they used Falcon and SMatch tools to carry out the mapping between them. Finally, they implemented a faceted browser to provide seamless access to collections of both institutions. In [\[43\]](https://ieeexplore.ieee.org/document/), a massive amount of cultural heritage objects were chosen from six collections and a series of mapping and alignment was done since the number of metadata schemas and vocabularies used in various collections was high and a visualization system called “demonstrator” was developed at the end, which offered results for semantic queries of the users. Although compared to the first one, the second method is better, it still has some drawbacks. In this approach, some of the elements are put aside in the mapping process due to the lack of correspondent elements in other metadata, which brings about a loss of information [\[44\]](https://ieeexplore.ieee.org/document/).

At the end of the day, metadata is a useful tool for providing content and administration description of data that can help with its retrieval, though it seems not enough for the Cultural Heritage field. In the next section, limitations of pre-ontological knowledge management are discussed in detail as well as the need for another data model.

In this context, authors and researchers navigating the field of Cultural Heritage can extract multifaceted implications. Primarily, they must grasp the pivotal role of SKOS in fostering semantic interoperability among traditional KOSs within the Semantic Web. This necessitates a comprehensive understanding of SKOS features, encompassing labeling, semantic properties, and documentation, for the effective representation of concepts. When evaluating metadata integration approaches—single metadata schema versus mapping/alignment—consideration of trade-offs, such as consistency versus potential information loss, is paramount. The chosen approach should align seamlessly with the unique goals of the Cultural Heritage project at hand. A deeper exploration of practical implementations, including SKOSifying KOSs and leveraging mapping tools like Falcon and SMatch, offers valuable insights for integrating data across diverse Cultural Heritage institutions. It is imperative to acknowledge and address challenges associated with metadata integration, minimizing information loss while ensuring interoperability. Additionally, understanding how SKOS contributes to the creation of virtual large-scale memory organizations, exemplified by entities like Europeana, Netherlands E-culture, and CultureSampo, is essential. Finally, recognizing the limitations of pre-ontological knowledge management using metadata is key, prompting an anticipation of the impending discussion on the need for a more advanced data model in the subsequent section.

### C. Why Formal Ontologies? (Limitations of Traditional KOSs)

Traditional knowledge organization systems are limited in terms of semantic expressivity. Users of such systems are forced to choose from the available limited list of options to search for the information of their interest. These types of standardized frameworks may have satisfactory results in a small-scale and local organization for data entry and retrieval, but it is not a fundamental long-term solution for large scale data integration in the complicated CH domain [\[7\]](https://ieeexplore.ieee.org/document/). The reasons that indicate that such systems cannot provide interoperability at a large-scale are numerous. First of all, the linguistic limitations that are imposed by the language are a major drawback of these systems. There are two kinds of lexical ambiguity, homonymy and polysemy. “The bark of a dog versus the bark of a tree is an example of homonymy; review as a noun and as a verb is an example of polysemy [\[45\]](https://ieeexplore.ieee.org/document/).” Inability in distinguishing the meanings of the words is a classical information retrieval problem. The performance of such systems can be improved by incorporating a hierarchical structure, which allocates categories for words. This solution can be useful to disambiguate some terms but not all of them, because some terms cannot be classified in a special category [\[7\]](https://ieeexplore.ieee.org/document/). Moreover, the classical hierarchical systems cannot represent fundamental relationships, such as parts and wholes theories, for example, mereology and mereotopology. Another problem with these systems is that they are very committed to their structure and their correctness. They take it as a one-to-one correspondence to the real world, and this is evident with metadata schemas [\[7\]](https://ieeexplore.ieee.org/document/). Metadata is constructed with a human processing point of view and is not appropriate for automated tools to infer and drive new knowledge from existing information. A reason is this type of information is implicit in metadata and the relation between the entities is not considered as it is in the real world [\[1\]](https://ieeexplore.ieee.org/document/). Therefore, the right solution is one that respects every party involved in the community to reach a consensual conceptualization of the domain-independent from linguistic defects and other problems.

Ontologies are of special interest in AI (Artificial Intelligence) and its subfields, such as knowledge engineering and knowledge representation, since they allow for the exchange and reuse of knowledge in the computational form [\[46\]](https://ieeexplore.ieee.org/document/). This notion also gained widespread attention in the fields of information integration and information retrieval. This is due to what ontologies promise which is to provide a shared understanding of a domain that can facilitate communication between different parties of the community and also computers [\[46\]](https://ieeexplore.ieee.org/document/), [\[47\]](https://ieeexplore.ieee.org/document/). This method tries to deal with the information integration problem of heterogeneity with a new approach by avoiding the aforementioned issues of former knowledge organization methods such as linguistic ambiguities or commitment to a single structure that is set to model the real world perfectly. Ontologies do not intend to be in a one-to-one correspondence with the universe, and they have a functional purpose and concentrate on the particular viewpoints of domain users to provide an adequate model for their aims and are consistent with reality [\[7\]](https://ieeexplore.ieee.org/document/). There are many definitions for ontology, but the widely accepted one is given in [\[48\]](https://ieeexplore.ieee.org/document/): An ontology is a formal, explicit specification of a shared conceptualization. A ‘conceptualization’ refers to an abstract model of some phenomenon in the world by having identified the relevant concepts of that phenomenon. ‘Explicit’ means that the type of concepts used, and the constraints on their use are explicitly defined. ‘Formal’ refers to the fact that the ontology should be machine-readable, which excludes natural language. ‘Shared’ reflects the notion that an ontology captures consensual knowledge, and it is not private to a particular individual, but accepted by a group [\[46\]](https://ieeexplore.ieee.org/document/). There is an attempt to understand the concepts not “in general” but with regard to their functionality within the defined domain of use [\[49\]](https://ieeexplore.ieee.org/document/).

A formal ontology usually is comprised of a scope declaration and a series of classes and properties extracted from the discourse between the users involved. A class is “a category of items that share one or more common traits serving as criteria to identify the items belonging to the class [\[50\]](https://ieeexplore.ieee.org/document/).” which is described by a scope note that indicates the intention of that class by a text. The aim of a class is a description of that category such that a human being can read it and identify instances of it. The clarity of such descriptions is of the highest importance for the effectiveness of an ontology and research presently continues in this area [\[51\]](https://ieeexplore.ieee.org/document/). “A property serves to define a relationship of a specific kind between two classes [\[50\]](https://ieeexplore.ieee.org/document/).” Properties are generalizations of types of relations that can be possible among classes. Their formalization results from research into how users actually conduct reasoning and relate objects in the domain [\[7\]](https://ieeexplore.ieee.org/document/). There are two additional concepts that should be defined for a property to form a well-defined ontology. The first is the domain, which is the class that a property is defined for, and every property must have exactly one class as its domain. The other one is the range, which is the class that comprises all potential values of a property [\[50\]](https://ieeexplore.ieee.org/document/). The specification of these relations is the premise of the possibility of reasoning and inferring over the data at later stages [\[7\]](https://ieeexplore.ieee.org/document/). However, the primary tool to gain expressive power within the ontology is the use of an *is-a* relation over the classes and properties. Formal ontologies make use of a function of inheritance provided by the *is-a* relation in order to structure classes from more general to more specific. An ontology is left for open discussion and it never defines all possible classes. Whenever there is no class appropriate for particular data, a revision process starts between knowledge engineers who design the model and the domain community to develop a new (sub) class/ (sub) property within the model to support the new phenomenon [\[7\]](https://ieeexplore.ieee.org/document/).

As previously mentioned, formal ontologies should be encoded in a machine-readable formal language to avoid natural language pitfalls. Typical AI languages that can be used for implementing ontologies are description logics for reaching the KR (Knowledge Representing) community needs of representing declarative knowledge. Examples of such description logics include KLONE, KIF, LOOM, KRYPTON, and CYCL [\[46\]](https://ieeexplore.ieee.org/document/). It was right after the Semantic Web initiative that substantial progress occurred in this field with the development of RDF. RDF is a neutral description tool for web resources that does not define its meaning. RDFS (RDF Schema), which is an extension of RDF, provides small but useful vocabulary including simple taxonomical relationships to declare classes and properties, which makes it a basic tool for implementing ontologies. W3C identified some applications and used cases where the RDFS showed poor expressivity, and its limitations are discussed here [\[52\]](https://ieeexplore.ieee.org/document/). W3C’s Web Ontology Working Group developed OWL (Ontology Web Language), which is built upon RDF and RDFS. It is the most used ontology language and has gained widespread acceptance since it covers RDFS limitations and shortcomings. Three versions were developed for OWL (OWL full, OWL DL, and OWL lite) due to a set of different and incompatible needs, such as full RDFS compatibility, efficiency in computation, and high expressivity power with the combination of RDFS and a full logic. As we go from OWL full to OWL lite, expressivity power and RDF(S) support decrease as a trade-off for higher use convenience and computation efficiency. More details about this matter can be found in [\[52\]](https://ieeexplore.ieee.org/document/).

This Section highlights several implications for authors and researchers. It underscores the importance of recognizing the limitations of traditional KOSs, especially concerning large-scale data integration challenges, emphasizing the presence of linguistic ambiguities, structural rigidity, and implicit nature in metadata. Additionally, the significance of formal ontologies in overcoming these limitations is emphasized, with an understanding of their role in achieving semantic interoperability, establishing a shared domain understanding, and facilitating communication between communities and computers. Authors and researchers are encouraged to delve into the components of formal ontologies, including classes, properties, and the collaborative process involved in developing new entities to support evolving phenomena. Acknowledging the need for encoding formal ontologies in machine-readable languages, such as description logics, is vital, along with an understanding of the evolution of ontology languages from RDF and RDFS to OWL, considering trade-offs associated with different OWL variants.

### D. Ontologies in CH Domain

Cultural heritage that has been keeping itself up-to-date with knowledge representation techniques, embraced the ontological modeling of data, as it promised to be a useful tool for information integration and providing interoperability between various parts of the community. As stated earlier, ontologies are functional and intended to model the interactions in a domain with respect to its aims.

Perhaps the most widely known and accepted ontology in the CH domain is the CIDOC Conceptual Reference Model, which provides definitions and a formal structure for describing the implicit and explicit concepts and relationships used in cultural heritage documentation. The CIDOC CRM [\[53\]](https://ieeexplore.ieee.org/document/) is a formal ontology intended to promote a shared understanding of cultural heritage information by providing a common and extensible semantic framework that facilitates the integration, mediation, and exchange of heterogeneous cultural heritage information. It can provide the “semantic glue” necessary to mediate between different sources of CH information, such as items published by galleries, libraries, archives, and museums (also called GLAMs). The CIDOC CRM is the result of a series of work and discourse by interdisciplinary domain experts and specialists, such as computer science, archaeology, museum documentation, history, library science, physics, and philosophy over the years. The International Committee for Documentation (CIDOC) of the International Council of Museums (ICOM) initiated the work to solve knowledge engineering and representation that museums were faced with in the late 20th century. The first result of the activities was the CIDOC Relational Data Model, a relational database model with more than 400 tables, which was actually difficult to implement in a wide range [\[54\]](https://ieeexplore.ieee.org/document/). Therefore, the CIDOC Documentation Standards Working Group (DSWG) decided to change to the object-oriented method for its benefits over the relational approach, and this work resulted in the first edition of CRM. This model with 50 classes and 60 properties reduced the complexity of the relational model dramatically, and it encouraged the official creation of the CIDOC CRM Special Interest Group (SIG). This group was responsible for the development of CRM as an international standard for the museum community.

The task was achieved in 2006 since the CIDOC CRM was accepted as an official standard (ISO 21127:2006). Initially, it was released in textual form to stress its independence from specific knowledge representation formats [\[54\]](https://ieeexplore.ieee.org/document/). Later, valid formal definitions for CRM were developed in TELLOS, KIF, RDFS, and OWL. One of the trusted OWL formats of CIDOC CRM, which began from its 4.2.4 version is called Erlangen CRM [\[55\]](https://ieeexplore.ieee.org/document/). It was developed by scientists from Erlangen-Nuremberg University in Germany. Currently, CRM is the only data model that is an ISO standard in the CH domain, and it has gained much attention and acceptance. It has been used in various projects and lots of development is taking place around it. CRM is a bottom-up model based on empirical CH data, and it is open-ended, which means it can be extended for the new phenomenon observed and specialized for user needs. At the moment, CIDOC CRM is in version 6.2.3 containing 99 classes and 188 properties.

It has established an event-centric approach for modeling data, in which objects, persons, and concepts are connected via events. On its way to becoming a formal ontology for the CH domain with such wide aspects, CRM was harmonized with different top-level ontologies to become a core ontology. First, it was harmonized with ABC ontology, which is a data model for integrating multimedia information in digital libraries [\[56\]](https://ieeexplore.ieee.org/document/) during the years 2001 and 2003, and both models affected each other. For further reading on the technical issues you can refer to [\[57\]](https://ieeexplore.ieee.org/document/). Figure 3 shows the major concepts and modeling notion of this ontology. As it can be seen, temporal entities that include events are in the focus of the model, and other entities, such as objects, actors, places, and time spans are connected to it. The classes, type, and appellation, can be applied to any class in the model for deeper specializations [\[53\]](https://ieeexplore.ieee.org/document/).

**FIGURE 3.**

Major concepts of the event-centric CIDOC CRM model [\[53\]](https://ieeexplore.ieee.org/document/).

Another important mediation task that was conducted is the harmonization of FRBR (Functional Requirements for Bibliographic Records) and CIDOC CRM. FRBR is an entity-relationship model for bibliographic information in the library domain developed by IFLA to overcome difficulties in the Dublin Core metadata for the integration and retrieval of information in libraries. It is a data model similar to the object-oriented format of CRM and with this harmonization, both models benefited from each other. On one hand, CRM extended its coverage of the CH domain by adopting the library information field, and on the other hand, FRBRoo [\[58\]](https://ieeexplore.ieee.org/document/) ontology was developed for IFLA, which benefits from the event-centricity of CRM. Recently, an extension for FRBRoo is developed called PRESSoo, which handles documents published continuously and are long-lasting serials [\[59\]](https://ieeexplore.ieee.org/document/). For different purposes, several extensions are developed for CRM. CRMdig [\[60\]](https://ieeexplore.ieee.org/document/) is an extension to record the description information related to the processes and approaches of production of digital models and representations whether 2D, 3D, animations, and other types created by various technologies. This model actually documents and integrates provenance information which is an essential factor in data evaluation assessment and trustworthiness [\[61\]](https://ieeexplore.ieee.org/document/). CRMsci [\[62\]](https://ieeexplore.ieee.org/document/) is about general provenance data in various descriptive and empirical studies related to cultural objects and also scientific observations and measurements carried out. It considers relevant standards, such as INSPIRE (earth science), OBOE (life science), SEEK (ecology), Darwin Core (biodiversity), national archeological standards for excavation, digital provenance models, and others. CRMinf [\[63\]](https://ieeexplore.ieee.org/document/) is an argumentation model and extends CIDOC CRM formal ontology to integrate metadata about argumentation and inference making in empirical and descriptive sciences. It proposes classes to document states of belief made in the observation phase. This model is not yet completed, and it is under development but a validation process was done in the British Museum Discovering Sloan project. CRMarchaeo [\[64\]](https://ieeexplore.ieee.org/document/) is another extension developed in compliance with CIDOC CRM to model the metadata about the archaeological excavation process. The reason for this kind of model was to maximize the interpretation capability and evaluation of the procedure carried out since archaeological excavation activities are destructive themselves. CRMba [\[65\]](https://ieeexplore.ieee.org/document/) is an extension of CRM that was developed to model archaeological information of standing heritage buildings. It is harmonized with CRMarchaeo [\[66\]](https://ieeexplore.ieee.org/document/) because it uses archaeological information, such as stratigraphic units from that model, and attaches them to relative parts of buildings. It also uses mereology and mereotopology theories between various parts of buildings tailored to their architecture to model such information for heritage buildings. Due to its characteristics, it incorporates classes and properties from other extensions, in particular, CRMarchaeo, CRMsci, and CRMgeo which will be discussed later [\[65\]](https://ieeexplore.ieee.org/document/). Lastly, the CRMgeo extension was created to support spatio-temporal reasoning over heritage information, which will be discussed in the next section. Its major achievements were to harmonize spatial standards of the OGC (Open Geospatial Consortium) with the CIDOC CRM standard. Also, it made some changes to the core entities of the CRM, such as introducing the Space-Time Volume (SPV) concept. Details can be found in [\[67\]](https://ieeexplore.ieee.org/document/) and [\[68\]](https://ieeexplore.ieee.org/document/). A schematic view of CIDOC CRM core concepts and their extension is shown in Figure 4.

**FIGURE 4.**

Major concepts of the event-centric CIDOC CRM model [\[69\]](https://ieeexplore.ieee.org/document/).

Due to high activities and wide-spread engagements, new extensions are still under development and proposed to CRM SIG, such as extensions A and B, which proposed to harmonize MIDM (Multiple Interpretation Data Model) with CRM [\[70\]](https://ieeexplore.ieee.org/document/). CRM is implemented from large-scale projects to small-scale ones. In the ARIADNE project, CRM was used as the backbone ontology model for heterogeneous data integration. ARIADNE (Advanced Research Infrastructure for Archaeological Dataset Networking in Europe) is an e-infrastructure with the purpose of creating a place for archaeological data providers across Europe to register and connect their resources, and it is also a portal with services, such as search, and access. Some of the extensions above (CRMba, CRMarchaeo, CRMgeo, and CRMsci) were developed within this project due to the heterogeneity of data involved [\[71\]](https://ieeexplore.ieee.org/document/). The Research Space project developed an infrastructure for integrating the British Museum data and for this matter it used a simplified form of CRM [\[72\]](https://ieeexplore.ieee.org/document/). The WissKI project aims to provide a Virtual Research Environment (VRE) for managing scholarly data in memory organizations that is completely open-source and free to use. Also, it will enable researchers to work and collaborate from different places. It has developed a semi-automatic text annotator, which uses semantic web technologies, and Erlangen CRM (ECRM) was employed as its top ontology [\[73\]](https://ieeexplore.ieee.org/document/). Arches is a project supported by the Getty Conservation Institute and the World Monuments Fund. It is a WebGIS tool for management, monitoring, risk mapping, and conservation planning of built heritage. It employs OGC standards for spatial data and analysis and also uses CIDOC CRM to model its database, which eases its use for organizations already compatible with CRM [\[74\]](https://ieeexplore.ieee.org/document/).

There are data models that were developed based on CRM in some countries. CRM-EH (English Heritage) was developed by the English Heritage for the specific excavation events data of the Center for Archaeology with a series of work with CRM authorities and experts. It was designed with the intention to capture the detailed excavation/analysis procedures [\[75\]](https://ieeexplore.ieee.org/document/). In a project named STAR, a semi-automated tool was developed for extracting data from five archaeological databases and mapping them to the CRM-EH model to achieve interoperability and a better search and retrieval of the information [\[76\]](https://ieeexplore.ieee.org/document/).

In Korea, KCHDM (Korean Cultural Heritage Data Model) was developed mainly based on CIDOC CRM. It is an ontological model for integrating heterogeneous heritage data from different institutions in Korea and serves as a mediating means for collecting and connecting various database systems [\[77\]](https://ieeexplore.ieee.org/document/).

For the CultureSampo (Finnish culture on the semantic web) project, Hyvönen et al. developed a national ontology based on the thesauri of their own country in the FinnONTO [\[78\]](https://ieeexplore.ieee.org/document/) project. They just employed content independent recommendations of W3C, such as RDF, SKOS, and OWL, but they converted their national ISO abiding thesauri into light weight ontologies and created the national KOKO ontology infrastructure, which consists of one high level and mediating ontology called YSO and 14 other field-specific ontologies [\[79\]](https://ieeexplore.ieee.org/document/).

In the Europeana project which aimed to collect, enrich, and provide access to cultural heritage information of institutes all over Europe, a data model was developed that is called EDM (European Data Model). This top-level ontological model was created to replace the older flat ESE (Europeana Semantic Elements) metadata due to general shortcomings in metadata schemas. The model reuses constructs from other standards, such as Dublin Core and FOAF, to which institutions can map their data (even CIDOC CRM can be mapped to EDM) [\[80\]](https://ieeexplore.ieee.org/document/).

MONDIS (MONument Damage Information System) is an ontological framework developed to capture and reason over the built heritage documentation of damages, interventions, changes, and natural disaster occurrences, for diagnosing the current condition of the buildings that can be helpful for their conservation. The intention for this ontology was to complete the existing ontologies with the possibility to describe monument damage and its causes and consequences [\[81\]](https://ieeexplore.ieee.org/document/).

Recently, HERACLES (HEritage Resilience Against CLimate Events on Site) ontology is being developed in the course of a project with the same name. It aims for better management and monitoring of built heritage health by modeling climate change effects and different types of damage it can cause for various types of materials through specific mechanisms. It is still in the early stages, going through tests and awaiting the acceptance of experts and stakeholders [\[82\]](https://ieeexplore.ieee.org/document/).

The ontology of al-Andalusian pottery artifacts, which is a sub-domain of Islamic archaeology, is known as OntoAndalus. OntoAndalus intends to create a shared domain conceptualization, with elements denoted by terms in many languages in a future ontoterminological resource. OntoAndalus was created by interpreting a corpus of specialized publications on the topic of interest in Portuguese and Spanish, as well as English textbooks and reference materials. The ontology was developed with Protege [\[83\]](https://ieeexplore.ieee.org/document/), and the modeling language was chosen as OWL. In order to construct OntoAndalus, a top-down method was used, which included reusing a foundational ontology, dolce+dns Ultralite (DUL). DUL allows for a rich conception of the domain, covering significant archaeology subjects including artifact typology, events and methods in the pottery life cycle, and individual artifact descriptions [\[84\]](https://ieeexplore.ieee.org/document/).

Following a period of technical studies and prototype growth, which was aided by the W3C Semantic Web Activity kickoff in 2001 and the Linked Open Data movement, main national and international CH organizations and cooperation networks began to post their data utilizing Linked Data fundamentals and Semantic Web technologies. Also, another of the main prosperous application domains of Semantic Web and Linked Data technologies has published Cultural Heritage (CH) collections on the Web [\[12\]](https://ieeexplore.ieee.org/document/), [\[85\]](https://ieeexplore.ieee.org/document/). Therefore, the CH community from the very beginning embraced Semantic Web technologies, so it evolved as it did. These were some of the data models developed in the CH domain for different purposes (summarized in Table 2). By undergoing various evaluations and experiments, they were updated and modified to cover the problems reported. As a result of these types of activities, the data models became more and more mature during this time. In [\[85\]](https://ieeexplore.ieee.org/document/), an evaluation was done on three prominent data models, and its results depicted that they acted well and were appropriate for CH domain needs based on 6 main criteria that consisted overall 10 sub-criteria, especially CIDOC CRM, which is a well-established standard ontology, showing excellent performance in 6 out of 10 and ok in remaining 4.

**TABLE 2** The Ontologies Developed in the CH Domain

Reference [\[86\]](https://ieeexplore.ieee.org/document/) focuses on bringing together the knowledge needed to cross-reference multiple perspectives on cultural places into a single, graph-based resource for easy retrieval and extensibility. Neo4J was used in particular [\[87\]](https://ieeexplore.ieee.org/document/). Neo4j is an open-source graph database manager that has been used for a variety of activities relating to data representation [\[88\]](https://ieeexplore.ieee.org/document/) exploration [\[89\]](https://ieeexplore.ieee.org/document/), and visualization [\[90\]](https://ieeexplore.ieee.org/document/) since the mid-2000s. Neo4j is known for its high scalability, ease of use, and Cypher, its proprietary query language. Cypher is a declarative language that uses a SQL-inspired ASCII art syntax to highlight patterns’ structure. Reference [\[91\]](https://ieeexplore.ieee.org/document/) describe Neo4j as a key tool for enabling a more effective model of DTs, as well as managing data from various sensors. DTs are algorithms that, using a stream of data from sensors, simulate the behavior of an architectural object or item while giving real-time data access through a database.

TerminusDB is another free and open-source graph database. By scaling vertically, it seeks to store very huge graphs in the main memory. It’s made for working together to create data-intensive apps and knowledge graphs. It’s a native revision control database that’s built in the same way Git and other distributed version control systems are. TerminusDB has a RESTful API for querying graphs in Javascript or Python using the JSON-LD interchange format, and it also supports the SQL-like query language WOQL (Web Object Query Language). Branch, merge, pull, clone, push, time travel, and other git-like operations on a fully-featured graph database are all possible using TerminusDB’s delta-encoding technique [\[92\]](https://ieeexplore.ieee.org/document/).22, 23, 24

In the previous decade, commercial ontology tools have also grown and acquired widespread usage. PoolParty Semantic Suite and Ontotext are two examples of commercial services. PoolParty is a Semantic Web Thesaurus Management Tool (TMT) that aims to support the creation and maintenance of thesauri by utilizing Linked Open Data (LOD), text analysis, and simple-to-use GUIs, so thesauri can be managed and used by domain experts without requiring knowledge of the semantic web. Some components of thesaurus maintenance, such as label editing, can be done through a wiki-style interface, allowing for the lowest possible contribution barriers. PoolParty may sift through documents to find new concepts for a thesaurus. PoolParty was created to help thesauri with a variety of commercial applications. It must publish them and provide mechanisms for integrating them with diverse apps in order to achieve this [\[93\]](https://ieeexplore.ieee.org/document/). [\[94\]](https://ieeexplore.ieee.org/document/) demonstrated the PAN (Portable Antiquities of the Netherlands) specific custom web application. PAN’s main goal is to document and publish archeological discoveries in private ownership online, notably metal items discovered by metal detectorists. PAN creates information about such objects and their found locations available to a wide range of stakeholders, resulting in a significant increase in the number of archaeological artifacts available for studies and the creation of object distribution maps in the Netherlands, which are an essential study instrument for archaeologists. A REST API is used to get the PAN information. Some portions of the REST API are open to the public, while others with sensitive information (such as the specific find position) are only accessible to authorized users. PAN links were developed with three other systems: NUMIS (Dutch National Bank), PoolParty, and DANS (the Netherlands institute for permanent access to digital research resources).

Ontotext uses text processing and artificial reasoning tools to extract knowledge from texts and organize it conceptually in an ontology, based on the Semantic Web philosophy. Synaptica was able to give the user and group permissions capability on a revised structure using RDF-star, thanks to new features in the back-end graph database, Ontotext’s GraphDB. This allowed [\[95\]](https://ieeexplore.ieee.org/document/) to create and manage users and groups easier and with fewer triples than before. Their customer needed a centralized vocabulary management software platform that delivers defined concepts for finding, browsing, and discovering enterprise content across a dispersed, worldwide organization. They need the capacity to push vocabularies to consuming systems and users, as well as the ability for users to submit new ideas without having to log into the taxonomy and ontology management software. In this case, their client is a software firm that makes educational and cultural software, cartoons, and literary, cinematographic, and television works in addition to video games. Synaptica saw an opportunity to experiment with the new RDF-star specification because of their requirements. The usage of RDF-star for commercial enterprise ontology management systems is groundbreaking work as a new and developing specification in RDF graph databases.

#### 1) CRM Vs. EDM

Arguably, EDM and CRM are two of the most dominant and widely used ontologies in the CH domain [\[96\]](https://ieeexplore.ieee.org/document/), which were introduced in the previous section. In this section, we elaborate on the differences between them, and through the process the two different modeling methods are discussed. Both EDM and CRM are top-level ontologies developed to model CH data with a set of classes and properties that result in some level of abstraction and interoperability, but they have certain dissimilarities due to their specific intentions (summarized in Table 3).

**TABLE 3** Comparison of CIDOC CRM and EDM Ontologies

The outstanding distinction between the models is their structures and the way they organize descriptive information. There are two approaches for modeling information in the CH domain, which are object-centric and event-centric. In the former, the object is in the center and all other descriptions and information are connected to it. For example an object has a creator, creation date, and location. In the latter, the information related to the object is connected to the object through different events. For example, an actor’s involvement in a production event at a specific period of time and in a particular place leads to the creation of an object. CIDOC CRM uses the event-centric method to model cultural heritage data [\[53\]](https://ieeexplore.ieee.org/document/). The composition can be used to raise the granularity of event definitions. For example, significant events can result in the creation of a single artifact. Napoleon’s pistols are made up of various parts, like the barrel and grip, which are all the consequences of various manufacturing events. By decomposing an event into numerous associated events by using property consists, CIDOC-CRM caters for combining the events resulting in a creation. In practice, this can result in long paths linking an artifact to its maker: an artifact is created by a production, which contains a production performed by an actor, who is recognized by an appellation, which has the label “Jean Le Page” [\[97\]](https://ieeexplore.ieee.org/document/). In contrast, EDM employs an object-centric approach [\[96\]](https://ieeexplore.ieee.org/document/). Object-centric methods enable an artifact to be labeled and directly linked to an agent or a string concept. Both the methods have advantages and disadvantages, and it is not our intention to say one is better than the other. EDM is used in the Europeana portal, which gathers CH information from institutions in Europe. Since the object-centric approach is widely used and its constructs are already available, it is employed in EDM. A library catalog system or a collection management system is located at plenty of cultural heritage organizations. These object-centric structures keep track of which artifacts are in a collection and are frequently the data source released online. Therefore, memory institutions have stored their data mostly in an object-centric way, and its conversion to the event-centric type needs a great deal of effort which an organization must determine if the investment is worthwhile. Using an event-centric method allows for a quite normal way of sharing temporal data. Even though events add one more layer of complication, the ability to collect changes over time may be critical for several use cases. However, the event-centric method can store more detailed information for a CH object. For example, if an object has more than one contributor in its creation or has gone through changes during time with multiple acquisition events in different times and locations, the object-centric method will definitely not be able to store all the information, but in an event-centric approach different events of various type can be defined with specific spatio-temporal properties to store the abovementioned information without losing data [\[96\]](https://ieeexplore.ieee.org/document/). This leads to the second difference between the models which is a storage of changes and provenance data over time.

In EDM, this kind of information is stored in a textual format, which is difficult for machines to understand and reason over. In CRM, detailed information relating to creation, evolution, the transition of objects, and other changes to it are stored through a chain of events, which is fully machine understandable, and it is possible to query and infer from them. We can conclude that the object-centric approach stores only one state of the world, since it connects the object to one creator, one location, and one time period [\[97\]](https://ieeexplore.ieee.org/document/). One aspect of ontologies is the domain and range of the classes and properties that we discussed before in Section III-C. For every single class and property in CIDOC CRM, its range and domain are defined, but in EDM some of the classes do not have a specified domain and range. This shows that CRM has a higher ontological commitment than EDM. An unspecified domain and range would result in inconsistencies and therefore makes it difficult for inference engines to automatically deduce the types of instances used as domains and ranges of such properties in EDM [\[97\]](https://ieeexplore.ieee.org/document/) and could make it also more complex to apply in practice. Finally, there is a difference between the two models in providing different views and representations for a single object. An object can have various representations, for example, images, post cards, and 3D models. Also, it may have different views, which means different institutions provide various types of descriptions for the same object. EDM, due to its purpose, handles and supports different representations and views of an object. It provides a construct called aggregation, which connects different digital representations to its object, which allows it to represent it in various forms. It also provides different views for an object with the construct called proxy [\[65\]](https://ieeexplore.ieee.org/document/). Different descriptions for the same entity are gathered to provide multiple views for a single object. CRM does not have any special class dedicated to providing different representations and views. However, with some of its general properties, this result can be somewhat achieved [\[96\]](https://ieeexplore.ieee.org/document/).

#### 2) Ontology-Based Metadata Interoperability

Although metadata schemas have certain shortcomings discussed before in detail, they are widely used in museums and other memory institutions and cannot be disposed of that easily. Metadata interoperability approaches based on metadata are not suitable and have some downsides (fully discussed in Section III-B). However, ontologies provide an efficient approach for metadata interoperability, in which no metadata element is omitted and it keeps the original richness of data. On the other hand, ontologies act as a mediating medium and convert data between different metadata formats by defining mapping paths from metadata schemas to a core ontology and back to them. For example, in [\[96\]](https://ieeexplore.ieee.org/document/) this functionality is discussed and a mapping is developed for converting data in DC format to the CIDOC CRM ontology. Another advantage of ontology-based metadata interoperability is making implicit information in metadata become explicit. This is achieved if the ontology uses an event-centric structure since the events can bring more details and also enables them to be reasoned over by machines [\[41\]](https://ieeexplore.ieee.org/document/), [\[98\]](https://ieeexplore.ieee.org/document/).

#### 3) Ontology Technologies

Two key necessary technologies to create and use metadata schemas are XML and RDF, which are W3C recommendations. XML (eXtensible Markup Language) is a markup language that is similar to HTML, but its tags are not predefined. It can be extended to any field of interest, and it is both human-readable and machine-readable. XML is independent of platforms and languages, and it has had a fundamental role toward interoperability. However, as XML is only at the syntactic level, machines cannot clearly determine the meaning of XML tags. As a result, W3C has developed RDF with the goal of addressing the XML problems by adding semantics on top of the XML [\[38\]](https://ieeexplore.ieee.org/document/). RDF or Resource Description Framework is a data model similar to classical conceptual modeling (entity-relationship) for representing and modeling information about web resources. These descriptions are in the form of subject-predicate-object called a triple. Predicate indicates a relationship between the object and the subject that are unique web resources and have a stable web identifier called a URL (Uniform Resource Locator). This is an important issue since it helps to resolve the uniformity of an identity problem in the harmonization of different information sources. The triples of RDF are actually called statements, and the subject and a set of triples can form a linked graph with subjects and objects as nodes and predicates (or properties) as edges. As previously stated, XML and RDF deal with metadata, or the definition of information distributed on the Web. However, semantic interoperability is required if machines are to communicate with one another or share data in the proper sense of the term. A formal specification is needed to specify multiple concepts and their relationships explicitly. Ontology was created in AI to make knowledge sharing and reuse easier, and it can be created using XML and RDF [\[99\]](https://ieeexplore.ieee.org/document/).

The OntoBellini ontology, established and developed based on the paradigms of Linked Open Data and Semantic Web, is arranged to make the Belliniano Museum’s history interoperable and reusable by researchers and cultural operators, semantically in a single homogenous container. Because the vast majority of museum resources are still not fully digitized and cataloged, the idea of using a standard RDA experiment (Resource Description and Access) to develop metadata for library and cultural heritage resources was employed [\[100\]](https://ieeexplore.ieee.org/document/). The RDA standard consists of a set of data elements, standards, and instructions that can be used by various information groups around the world, such as: (A) libraries (manuscripts, books, music, and movies); (B) archives (institutional documents, personal and family papers, and business documentation); and (C) museums (works of art, costumes, artifacts, and natural objects, and photos) [\[100\]](https://ieeexplore.ieee.org/document/), [\[101\]](https://ieeexplore.ieee.org/document/). The implementation of RDA provides an opportunity to rethink those cultural heritage materials, their specific demands, and their contribution to RDA that have previously been outside or on the periphery of the general catalog and the application of globally established rules [\[102\]](https://ieeexplore.ieee.org/document/). [\[103\]](https://ieeexplore.ieee.org/document/) discusses the possibility of using the IFLA Library Reference Model (LRM) and Resource Description and Access (RDA) key entity classes to annotate cultural heritage textual documents (RunA collection). This research describes the key entities such as works, agents (people, institutions), concepts, events, timespans and places that can be used as nodes for semantic connection and networking in digital collections, including unstructured data sets such as correspondence.

The desire to share bibliographic information resulted in the creation of the Universal Bibliographic Control (UBC) program by IFLA in the early 1970s, as well as the development of standards for bibliographic descriptions (with ISBD) and access points [\[104\]](https://ieeexplore.ieee.org/document/). The Department of Musicology and Cultural Heritage, University of Pavia, Cremona, Italy, has a collection of almost 1,000 piano rolls that needed to be preserved. Therefore, cataloging according to international cataloging standards was required for a digitization project. At first, a separation between instruments and media needed to be established, and mechanical musical devices needed to be distinguished. Disks, pinned barrels, books, and rolls were the four basic types of media identified. Finally, the media’s morphological peculiarities were studied in order to determine their correct and thorough description within the International Standard for Bibliographic Description (ISBD) domains [\[105\]](https://ieeexplore.ieee.org/document/).

The EUscreen project operates as a domain aggregator for Europeana, Europe’s digital library, and represents European television archives. Its primary goal was to provide easy accessibility to a representative collection of television programs, additional sources, and articles, allowing students, scholars, and the general public to explore the history of television in a broader context. Reference [\[106\]](https://ieeexplore.ieee.org/document/) studied how the EUscreen dataset can be published as Linked Open Data. A harvesting schema based on EBU Core4, an established standard in the area of audiovisual metadata, was built to achieve semantic compatibility within the aggregation and with external repositories. The acquired metadata had to be converted to RDF using an expressive data model, and the EBU Core ontology was the best fit for this semantic transformation in this scenario. Finally, the EUscreen content was linked internally and externally, and the final repository was made accessible via a SPARQL API.

The OAIS model claims to be an open standard for archival information systems, and it has been recognized as an international standard for digital object archiving [\[107\]](https://ieeexplore.ieee.org/document/) since June 2002. OAIS serves as a reference model for how archival information can transfer from one entity (whether a place, platform, organization, media, function, or form) to another without losing any of the items that made that entity. The OAIS includes the following functional components: ingest, archival storage, data management, preservation planning, access, and administration [\[108\]](https://ieeexplore.ieee.org/document/). Reference [\[109\]](https://ieeexplore.ieee.org/document/) noticed the potential for long-term preservation of digital heritage recordings. The scientific development in cultural heritage digital processing and preservation was discussed in this study, with the most significant breakthroughs highlighted. The CEPROQHA project, which is based on a new method aimed at providing cost-effective acquisition and digital preservation (digital preservation methods rely on the OAIS) for cultural heritage artifacts in Qatar, was also presented.

Schema.org is an online activity that promotes the publication and consumption of structured data. Its major use is in web sites, such as stating that a web page explains a culinary recipe, its ingredients, and preparation process; or that it explains a film, its characters, user reviews, and so on. In addition to text and links from the HTML body, web pages constructed based on the Schema.org principles can be analyzed by search engines and other apps that employ structured data. Schema.org can be used in a wide range of domains. It could, in particular, allow CH institutions to lessen their overall data conversion effort for discovery goals [\[110\]](https://ieeexplore.ieee.org/document/). Considering the Semantic Web principles [\[8\]](https://ieeexplore.ieee.org/document/), Schema.org comes with a vocabulary that allows the description of objects of various types with subclasses, as well as properties and relationships between objects. Schema.org permits the description of visual art, books, music recordings, maps, and many other types of cultural resources in CH digital libraries.

The Schema.org vocabulary has been suggested by [\[110\]](https://ieeexplore.ieee.org/document/) as a promising solution for innovating metadata aggregation. Two case studies were undertaken in this article to analyze Schema.org information from cultural heritage institution collections. It was also investigated whether Schema.org could provide usable data sources for CH aggregators such as Europeana. As a result, Schema.org presents no impediment to data providers delivering metadata that is fully compliant with Europeana criteria and of the necessary semantic quality.

[\[111\]](https://ieeexplore.ieee.org/document/) Several case scenarios were conducted to determine the viability of implementing metadata aggregation using the International Image Interoperability Framework (IIIF) and/or Sitemaps. These investigations were carried out in collaboration with Europeana Network data providers that were actively using these two techniques in their own information systems. The combination of Sitemaps with Schema.org also appears to be a solution that would assist CH data producers, since it would improve resource findability in search engines and CH aggregation networks. IIIF is also a technology with deep roots in the CH domain and a better adoption rate there than elsewhere.

This Section not only offered a comprehensive overview of achievements and practical considerations for authors and researchers who explored the CIDOC CRM but also presented a valuable resource for those seeking a deeper understanding of the strengths and weaknesses of EDM and CRM in the CH domain. It provided insights into the CIDOC CRM’s developmental history, transitioning from a relational to an object-oriented framework, emphasizing versatility and adaptability to evolving requirements. The text highlighted harmonization strategies with other ontologies like ABC and FRBRoo, demonstrating their application in interdisciplinary projects and showcasing how ontologies could enhance coverage and utility. Descriptions of CIDOC CRM applications in real-world projects (e.g., ARIADNE, Arches) served as inspiration for practical ontology implementations across diverse contexts. Furthermore, the global impact of CIDOC CRM in countries such as England, Korea, and Finland, including its adoption in international projects like Europeana, underscored collaborative possibilities in ontology development. The mention of ongoing developments, proposed extensions (e.g., HERACLES ontology), and the introduction of evaluation criteria not only encouraged researchers to actively contribute to the evolving landscape of ontologies in the CH domain but also provided a benchmark for assessing the effectiveness of their own ontologies. This review thus contributed to a foundational understanding of ontology-based metadata interoperability and the practical application of ontologies in cultural heritage projects, making it an invaluable resource for researchers who explored ontological approaches within the context of cultural heritage data modeling and interoperability.

So far, we have discussed various aspects of CH data and the road taken from preliminary knowledge organization methods to the latest developments to structure this data for better retrieval. Now that the information is mapped to the structures created, it is time to provide services based on this structured data to search, browse, and retrieve them. These types of services could be an important achievement to replace the currently used text-based search engines. Also, there is the opportunity to develop smart and intelligent applications since the information is in a machine-understandable form. Data is in interoperable formats, which brings about the ability to develop inter-institutional systems to create a shared understanding of the issues and goals. In this section, we discuss the efforts put in this way.

### A. Publishing Structured Data for Its Use and Reuse

#### 1) Portals

The first thing to do after structuring data is to create possibilities for its use and reuse. One of the Semantic Web promises is to prevent a digital dark age and the loss of data that is generated with a lot of effort and costs. Semantic portals are great tools for aggregating heterogeneous data from various publishers and institutions. They can act as a single publishing channel for local and small institutions [\[112\]](https://ieeexplore.ieee.org/document/). As stated in [\[113\]](https://ieeexplore.ieee.org/document/), there are three types of portals: service portals accommodating a set of services e.g. Yahoo!, community portals serving as virtual meeting venues, and finally the kind of portal that we focus on in the CH case, information portals acting as hubs of data. When the content of such portals is Semantic Web content, they are called semantic information portals. These portals are based on Semantic Web technologies, and they can be useful for CH information both for the users and data publishers [\[114\]](https://ieeexplore.ieee.org/document/). End-users can enjoy a global view of the data gathered from multiple sources in a seamless homogenous repository thus reducing the time and effort needed for finding them. Users can also take advantage of semantic searching, browsing, recommendation, and other intelligent services and applications developed in the context of the portal. On the other hand, semantic portals can be beneficial for content hosts. Creating portals for distributed data provided by various memory organizations in a central manner is costly and not feasible but Semantic Web technologies are promising tools for collecting and integrating distributed heterogeneous data from various sources (semi-) automatically into a global portal. This kind of portal can be a shared, cost-effective publication channel for participating organizations with the common goal of promoting cultural knowledge among society and experts. As Semantic Web technologies like metadata and ontologies link the related information with each other, they in fact enrich the content of every organization involved for free [\[85\]](https://ieeexplore.ieee.org/document/). From 2002 to 2021, the Sampo paradigm evolved gradually as a result of lessons learned while creating the Sampo series of semantic portals and accompanying Linked Open Data (LOD) services in diverse programs.

Museum Finland [\[114\]](https://ieeexplore.ieee.org/document/) and its successor CultureSampo [\[115\]](https://ieeexplore.ieee.org/document/) are well-known examples of the first semantic information portals in the field of CH. BookSampo - Finnish Fiction Literature on the Semantic Web provides metadata for nearly all Finnish fiction literature as a knowledge graph, on which a site is built. WarSampo- Finnish World War II on the Semantic Web is a well-known Finnish service with 857000 users as of October 2021. Interest in WarSampo led to the creation of a second Sampo, WarVictim Sampo (1914– 1922), which provides statistics on the deaths and battles of the Finnish Civil War 1918 and related wars. The WarSampo infrastructure was repurposed in 2021 to launch WarMemoirSampo45, which features video interviews with WWII veterans. Another biographical system, BiographySampo and AcademySampo, is based on short biographies of all known Finnish academics educated in Finland. The Sampos Norssit Alumni, based on the student registry of a major Finnish high school and U.S. data, established the idea of distributing textual biographies as structured LOD for data exploration and analysis. Using data from the members of the United States Congress from the 1st through the 115th Congresses, Congress Prosopographer. NameSampo - is a website that exposes data about placenames and places in Finland, together with ancient maps. The Trans-Atlantic Digging into Data research program produced Mapping Manuscript Migrations (MMM). FindSampo is a system and data service that supports archaeology, particularly from the perspective of citizen scientists and metal detectorists. In addition, new Sampos are currently in the prototype stage, such as the LawSampo, ParliamentSampo, and LetterSampo framework [\[116\]](https://ieeexplore.ieee.org/document/).

#### 2) API

Portals are appropriate tools for the usage of data through various applications to provide different services but their data is static and the possibility for reuse of the data is very low. However, APIs are suitable for this matter. An API (Application Programming Interface) can lower the technical barriers and required effort and time for reusing data and services provided for developing other applications and services [\[117\]](https://ieeexplore.ieee.org/document/). The Europeana project is one of the outstanding and large-scale examples of an API-based CH data aggregator. The aim of this project as discussed before is to harvest, aggregate, and integrate heterogeneous CH data from different data providers across Europe with the help of Semantic Web technologies and standards. Europeana provides an API enabling third parties and other communities to reuse the rich data collected for their own needs [\[118\]](https://ieeexplore.ieee.org/document/). Various applications and intelligent services from portals to location-based applications can be developed by consuming the data provided by APIs. The Europeana portal is developed based on its own API created within the project.

A noteworthy point here is that some metadata schemas are created for accessing and searching information from APIs. These metadata are called harvesting and searching metadata [\[113\]](https://ieeexplore.ieee.org/document/). They were not developed for structuring data but rather for querying the APIs and harvesting information. LIDO (Light Weight Information Describing Objects) 25 is an XML schema developed collaboratively by CDWA Lite, museumdat, SPECTRUM and CIDOC CRM communities intended for delivering metadata for use in a wide range of online services. It covers a variety of descriptive information about museum objects. It is mostly based on CIDOC CRM and borrowed its event-centric concept [\[119\]](https://ieeexplore.ieee.org/document/).

There are also numerous protocols developed for federated search. Z39.50 26 is amongst the first protocols developed by the Library of Congress for searching and information retrieval from a database. It is a client-server protocol that is a NISO/ANSI standard but it dates before the web era and HTTP protocol. Z39.50 has been updated into the SRU 27 protocol (Search/Retrieval via URL), which uses the HTTP protocol and REST. SRU has a twin protocol SRW 28 (Search/Retrieve Web Service) that is based on Web Service SOAP messages. Queries in SRU and SRW are expressed using the simple Contextual Query Language (CQL), which is a standard based on Z39.50. The result set is returned as an XML document. A widely used system targeted for only harvesting metadata is the OAI-PMH (Open Archives Initiative Protocol for Metadata Harvesting).29 The OAI-PMH protocol is based on HTTP where request arguments are issued as GET or POST parameters of a URL. Data providers are repositories that expose structured metadata via service providers. Then they make OAI-PMH service requests to harvest that metadata. OAI-PMH responses are encoded in XML syntax and it supports harvesting records in any metadata format encoded in XML.

#### 3) Linked (Open) Data

As we mentioned in the early stages of the paper, recently there has been a global tendency to move from the web of documents to the web of data, in which data is machine-readable and structured and information retrieval can be improved dramatically. In 2006, Tim Berners Lee introduced the concept of Linked Data and its principles [\[120\]](https://ieeexplore.ieee.org/document/). Linked Data is concerned with data on the web and providing connections and links between them as the web of data. We can follow the links between the pages in the web of documents, and humans and machines follow links between data to find other related data [\[121\]](https://ieeexplore.ieee.org/document/). Linked Data employs two main technologies RDF and HTTP to connect structured data on the web to each other and to real-world entities such as persons, places, books, films, music, and companies, which are given unique identifiers URI. The web of data can be accessed through Linked Data browsers which navigate users between connected data by the RDF links provided. Also, its search engines can provide complex queries that were just possible in relational databases [\[122\]](https://ieeexplore.ieee.org/document/). This can turn the web into a single global database, which is sometimes referred to as the *global data space*. In [\[120\]](https://ieeexplore.ieee.org/document/), Tim Berners Lee outlines four basic rules for publishing data on the web to become a part of the Linked Data:

1. Use URIs as names for things
2. Use HTTP URIs so that people can look up those names.
3. When someone looks up a URI, provide useful information, using the standards (RDF, SPARQL)
4. Include links to other URIs, so that they can discover more things.
The web of data started with an initial project, Linking Open Data in 2007 supported by the W3C Semantic Web Education and Outreach Working Group (SWEO). The intention behind the project was to identify the data sets that were available under open licenses and republish them on the web in RDF format with links and connections between them. Through this time, the cloud of Linked Open Data grew bigger and bigger. The central parts of the cloud are DBpedia and Geonames which act as linking hubs [\[122\]](https://ieeexplore.ieee.org/document/). Most of the things we refer to are within these two. DBpedia 30 extracts Wikipedia information in RDF and includes URIs for a wide range of entities that can be referred to, while Geonames provide URIs for names of places and the spatial relationships between places in RDF format. With the growth of the Linked Open Data cloud, there was a need to create a means to validate this information. In an update of his notes in 2010, Tim Berners Lee explained a five-star system for evaluating data put on the web.
- 1 Star: Data is available on the web (whatever format), but with an open license.
- 2 Stars: Data is available as machine-readable structured data (e.g., Excel instead of a scanned image of a table).
- 3 Stars: Data is available as (2) but in a non-proprietary format (e.g., CSV instead of excel).
- 4 Stars: All the above, plus use open standards from the W3C (RDF and SPARQL) to identify things, so that people can link to them.
- 5 Stars: Data is available according to all the above, plus outgoing links to other people’s data to provide context.
LOD publishers provide different methods to access the data published. Linked Data browsers such as Tabulator,31 Disco,32 OpenLink,33 Ontology-browser 34, and Zitgist,35 make data on the web browseable based on URI dereferencing. Another way is to provide SPARQL endpoints for querying data in a standard approach to be used in mash-up applications. SPARQL endpoints enable machine and human users to make SPARQL queries to an RDF repository conveniently using HTTP. The data is also available to download in RDF dumps, which sometimes can be used for offline purposes. Lastly, there are human user interfaces that can search RDF data on the web. Examples of such application interfaces are Falcons,36 Sindice,37 Swoogle 38 and Watson.39

Linked Open Data can be a great opportunity for the CH community because its data is distributed in various formats. Adoption of LOD would have definite effects to improve the reusability and interoperability of CH information [\[123\]](https://ieeexplore.ieee.org/document/). The integration of the data with other data on the web can increase the richness of CH data and possibility of generating new knowledge. One of the early adopters of LOD is the Library of Congress publishing its authority files and thesauri. Later other organizations in the library domain joined the LOD, such as the German National Library and the British National Library publishing entities that can be referred to on the CH data network. Recently, the Getty institute published its thesauri (AAT, ULAN, CONA, IA, and TGN) as LOD under the Open Data Commons Attribution License (ODC-By) 1.0., which can be used in many applications of the CH domain. Europeana started a pilot project in 2011 to move its data to LOD [\[124\]](https://ieeexplore.ieee.org/document/). They provided a part of the data aggregated in the portal in EDM format. It is available in three ways: URI dereferencing, SPARQL endpoint, and bulk download [\[125\]](https://ieeexplore.ieee.org/document/). There are two strategies for memory organizations when it comes to publish LOD. The first is to invest in infrastructure and publishing your data as LOD, which small institutions cannot afford and is not feasible for them. This approaches requires the organization to choose or develop a domain ontology to map their data and extract it as RDF. The second is to provide their data in a special structure and format, depending on the host, to large-scale aggregators like Europeana so it gets published as LOD [\[123\]](https://ieeexplore.ieee.org/document/). In this approach, the institute does not have to map its data to a specific ontology, but it has to provide the data in a special format and structure designated by the aggregator. In the STELLAR project [\[126\]](https://ieeexplore.ieee.org/document/), the goal was to develop an automatic tool for mapping the archaeological data to CIDOC CRM. The archaeological extension they developed is called CRM-EH and they extracted them in RDF/XML with the intention of publishing it as Linked Data. Since automatic ingestion and mapping by a large-scale aggregator may cause damage to the original richness of data, authors in [\[123\]](https://ieeexplore.ieee.org/document/) proposed a methodology for small institutions to map their data to EDM on their own to keep the richness of data and link their metadata to Linked Data. The tool developed in this paper is called Amalgame which is a part of the ClioPatria semantic web toolkit. To evaluate the approach, they converted the Amsterdam Museum metadata to Linked Data, which made the museum to be the first small-scale memory organization to join the Linked Data cloud. By following the idea of this project, the Amsterdam Museum data of the Smithsonian American Art Museum (SAAM) was published as linked data with slight differences [\[127\]](https://ieeexplore.ieee.org/document/). In this project, EDM ontology was chosen and it was tailored to the SAAM data. Also, a tool named Karma was developed to do the mapping automatically and it also had the capability of visualizing the links it made so that the authorities could check the accuracy of linking to LOD sources. PerfectO [\[128\]](https://ieeexplore.ieee.org/document/) is a Knowledge Directory Services tool that concentrates on the best techniques in an ontology. As an example of how PerfectO can be used beyond the semantic web domain, it is extended to the Internet of Things (IoT) domain, improving ontologies from the Linked Open vocabularies for IoT (LOV4IoT) ontology catalog. This method is a novel approach to linking data from many domains in order to increase knowledge discovery. The idea was inspired by the Linked Data blog \[WR26\]. SEG 3.0 is an approach that uses an ontological method to implement data exchange and data access [\[129\]](https://ieeexplore.ieee.org/document/). PerfectO is a platform that supports SEG 3.0 semantic interoperability by reducing the learning curve. PerfectO picks and categorizes a subset of tools that have a basic online interface or web service. These technologies aid in the improvement of ontologies and the synthesis of a set of practices. It has a big effect because it was created to be used with the LOV4IoT ontology catalog, which includes over 20 application domains.

In this section, the focal point is the transition from conventional text-based search engines to sophisticated, intelligent applications, underscoring the paramount importance of structured, machine-understandable data. Highlighting the advancement of semantic information portals as potent instruments for consolidating and disseminating CHdata is crucial. Valuable insights gleaned from the Sampo paradigm’s evolution serve as a basis for establishing shared, cost-effective publication channels. The incorporation of APIs is proposed to augment data reuse and facilitate application development. Drawing inspiration from the Europeana project, which exemplifies large-scale aggregation and integration of CH data using API-based approaches, accentuates the practicality of this strategy. Recognizing the transformative potential of Linked Data principles is imperative. Adherence to the five-star system and active participation in initiatives such as LOD enables institutions to contribute significantly to a more interconnected and accessible global data space. Acknowledging diverse strategies for publishing LOD, be it through direct infrastructure investment or collaborative efforts with aggregators, is essential. For smaller institutions, leveraging tools like Amalgame for independent mapping is suggested to uphold the richness of their data.

### B. Automatic Information Extraction

Various applications and intelligent services from portals to location-based applications can be developed by consuming the data provided by APIs. Information Communication Technologies (ICT), for example, have assisted in the protection, curation, and reuse of human cultural heritage assets and resources. As part of the most recent advancements in ICTs, Artificial Intelligence (AI) and Big Data are predicted to have huge potential in the datafication, digitization, and reuse of such educational and cultural resources [\[130\]](https://ieeexplore.ieee.org/document/), [\[131\]](https://ieeexplore.ieee.org/document/), also using Big Data to link the knowledge structures of digital heritage with the social web [\[132\]](https://ieeexplore.ieee.org/document/). The development of tools and programs capable of warranting semantic media search, media indexing, smart segmentation, and other tasks will be ensured by the definition of controlled vocabularies, the use of ontologies concepts, and AI approaches. The impact of such tools and applications for managing Cultural Heritage that rely on ontologies and AI would open up new vistas in the field of human research as well as raising awareness of cultural identity and creativity among people and industries [\[133\]](https://ieeexplore.ieee.org/document/). In China, there are numerous intangible cultural heritage objects. To aid knowledge management and provide a public service, [\[134\]](https://ieeexplore.ieee.org/document/) proposed the intangible cultural heritage knowledge graph. Massive amounts of ICH data were acquired for this research, and domain knowledge was retrieved from the text data using NLP techniques. For Chinese intangible cultural heritage, a knowledge base according to domain ontology and instances was built, as well as a knowledge graph. The ICH knowledge graph was used to show the pattern and characteristics of intangible cultural heritage. The ICH knowledge graph could help with intangible cultural heritage knowledge organization, management, and protection. The knowledge graph is useful for intangible cultural heritage preservation and inheritance.

Machine learning is constantly showing its worth by outperforming individuals in tasks like recognition and classification. Reference [\[135\]](https://ieeexplore.ieee.org/document/) addressed visual content recognition tasks using two innovative hybrid techniques based on individual, cooperative, and synergistic operational schemata of BoVWs (Bags of Visual Words) and CNNs. Also, the Folklore Museum of Xanthi (Greece) was chosen as the case study in this work for objective evaluation. Reference [\[136\]](https://ieeexplore.ieee.org/document/) combined the two hybrid methods to create a prediction model that would aid in the preservation of cultural and national heritage. This research gathered data from IoT sensors for the repaired Woljeong Bridge in South Korea. Then, utilizing two frequently utilized recurrent units: 1- an LSTM unit and 2- a GRU, empirically tested an RNN (the joint CNN and LSTM model and the joint CNN and GRU model) [\[137\]](https://ieeexplore.ieee.org/document/). With language processing tools, deep learning algorithms were developed to classify and annotate cultural data, recover missing data, and map current data schemes and information to standardized schemes. The methods developed performed admirably and were validated on datasets of paintings acquired from a variety of museums and institutions, including the Museum of Islamic Art in Doha, Wikiart, the Rijksmuseum, and the Metropolitan Museum of New York. Reference [\[133\]](https://ieeexplore.ieee.org/document/) proposed a system equipped with artificial intelligence from computational ontologies to model photos of religious historical buildings. The ontology was built using a Convolutional Neural Network (CNN) for automated image categorization and retrieval, in addition to supporting data modeling and concept-level annotation. The entire system was put to the test on the ruins of the Santa Maria delle Grazie church in Italy, and it performed well. Reference [\[138\]](https://ieeexplore.ieee.org/document/) outlines a methodology for uncovering cultural information expressed via cultural digital images using Artificial Intelligence technologies like Computer Vision (CV) and semantic web technologies. A case study on cultural image collections from the Europeana platform is used to apply and test the proposed approach. This research starts with the preparation step, which allows us to learn about the domain and obtain the necessary materials. The second step introduces tools and strategies for analyzing and annotating information, as well as training and assessing CV models, while the third step focuses on active learning component deployment, exploration, and integration. The proposed methodology was created as part of the ChIA project (ChIA—accessing and analyzing cultural images with new technologies) [\[139\]](https://ieeexplore.ieee.org/document/), which uses AI to solve problems in the digital humanities.

Some artificial intelligence-based methods for the promotion, curation, and protection of cultural heritage were described in the current studies. The impact of digital transformation on the cultural domain was also underlined, which extended the way to a wide range of applications targeted at end-users, such as promoting collections and sharing information with wider audiences.

### C. Intelligent Applications and Services

Functions in the CH domain, as said in [\[54\]](https://ieeexplore.ieee.org/document/), are: Collection management that involves tasks such as acquisition, registration, and compiling inventories of objects and their description, hosting exhibitions, and providing insurance, rights, and protection zones. Conservation is comprised of tasks, such as the diagnosis of deterioration, establishing preventive measures, planning interventions, and applying treatments and chemical agents when needed. Research includes investigation, description, and interpretation of cultural objects and works. Presentation of retrospective knowledge is simply the most important function of all. Besides the functions mentioned above, the information in the CH domain has some special characteristics that further affect the model, and they should be developed for this domain. Information is usually discrete and lacks the consistency that exists in other disciplines, such as geology, and it also has an event-centric meaning, so people and things are connected via events. Finally, its descriptions are retrospective and about the past, which is contrary to information in fields that deal with phenomenoa in the future and involve tasks like planning and predicting. Since there is not a unified true assumption of the past, information cannot be integrated and normalized on the basis of an assumed past [\[54\]](https://ieeexplore.ieee.org/document/).

The purpose of semantic information platforms for cultural heritage is to provide smart services to the end-user for discovering the relevant information and understanding depending on her preferences and the situation in which they are using the system. In this section, some of the smart services provided to end-users in the field of CH are reviewed.

#### 1) Search and Browse

Searching and browsing are the basic services that an institution portal can offer. After all, data structuring and information management approaches are for better and more accurate retrieval of data. When the data is structured with Semantic Web technologies like ontologies and schemas ordered in hierarchies with the help of classes and properties, some services can be provided for the users to improve searching. For example, semantic auto-completion, which completes the words that a user is typing in the search box by the annotations of data that it has. This can help the user when they cannot fully remember the name of the thing they are searching for. Also, after retrieving the results, the system can order and group them based on their semantic categories, which further guides users to their interests. Moreover, semantic recommendations can be provided for users while they view a piece of information through the links and properties that connect it to other things. The CultureSampo portal [\[115\]](https://ieeexplore.ieee.org/document/) offers the abovementioned services for the end-user. The concept of faceted browsing interface is one of the most popular and widely used approaches for browsing large collections of data. This concept was used in early MuseumFinland and the CultureSampo portal and the Europeana portal. In a faceted browsing system, there are a number of facets, and each of them highlights one aspect and the dimension of the underlying data. The user can select the desired values in the facets and in this way narrow down the collection data to get to the desired information. Traditional facet browsers assume a fixed set of facets to select and navigate through relatively homogeneous data. However, data in the CH domain is heterogeneous, and this causes problems in employing facets. In [\[140\]](https://ieeexplore.ieee.org/document/), the authors developed /facet, which is a browser for Semantic Web repositories that covers the problems mentioned. It has the capability to dynamically generate facets based on the type of resources chosen by the user in the GUI developed and also incorporates a cross-type selection. /facet does not require manual prior software configuration in contrast to traditional facet browsers. It was tested on a diverse dataset gathered from three institutions with multiple varying thesauri in contrast to other projects, such as MuseumFinland, which mapped the entire data to a single schema. /facet was developed as a part of the Netherlands MultimediaN e-culture project.

Recently there’s a growing interest towards inspirational information retrieval in the CH domain. It is argued that a substantial number of users and researchers visit these data repositories to stimulate their creativity, so there should be a mechanism that balance retrieval between expected results and surprising answers yet relevant to the user’s queries [\[141\]](https://ieeexplore.ieee.org/document/). The PATHS project [\[142\]](https://ieeexplore.ieee.org/document/) is amongst few examples that have studied possibilities of a serendipitous search results in the CH domain. However, this paradigm in searching and browsing collections needs more attention.

#### 2) Inference

As discussed previously, implementing ontologies in description logics like OWL DL can increase its expressiveness, which helps computers to reason over them easily. There are several inference engines that have been developed to reason upon OWL DL such as RACER [\[143\]](https://ieeexplore.ieee.org/document/), FaCT++ [\[144\]](https://ieeexplore.ieee.org/document/), pellet [\[145\]](https://ieeexplore.ieee.org/document/), and HermiT [\[146\]](https://ieeexplore.ieee.org/document/). They can perform the following basic logical deductions [\[55\]](https://ieeexplore.ieee.org/document/):

- *Concept satisfiability* which is to check whether a newly defined concept is consistent with the knowledge base as well as satisfiability of the knowledge base as a whole.
- *Subsumption* that is to compute the proper place for a newly defined concept in the concept hierarchy.
- *Proper instantiation* that is to check whether a given individual belongs to the class it is designated to.
- *Realization* which is to compute the class a given individual belongs to and retrieve the instances of a given class.
For the first time, the authors in [\[147\]](https://ieeexplore.ieee.org/document/) developed an OWL version of CIDOC CRM (Before Erlangen CRM [\[55\]](https://ieeexplore.ieee.org/document/)) to do some reasoning on it. They developed a knowledge discovery interface based on the RACER inference engine that carried out some simple reasoning. However, OWL suffers from some limitations that lower its capability of reasoning. Although OWL provides a variety of constructors for classes, it has a limited set of constructors for properties. The concept-based modeling of OWL prevents it from performing inferences based on the properties. For example, OWL lacks composition constructors for properties that makes it unable to capture the relationship between concepts associated with a combination of properties. Also, this is, possible with OWL 2 property axioms. Individuals and literals, object properties and data properties, named classes, and datatypes are the essential syntactic building blocks of OWL 2 ontologies. These are commonly used to establish anonymous classes (i.e. sets of components without a name) from which axioms are defined, and they are applied to create more complicated expressions. Subsumption associations between classes, object properties, data types, and data properties, also statement about persons and literals, are used to build OWL 2 axioms [\[148\]](https://ieeexplore.ieee.org/document/). The typical example here is the “uncle rule” [\[149\]](https://ieeexplore.ieee.org/document/). To infer the uncle relationship, there is a need to reason over the composition of parent and brother properties, which is not possible with OWL alone. The consensus way to cope with this problem is to extend OWL with “rules languages” to increase its expressivity. Rules define specific conditions and operations to infer and extract new knowledge from a knowledge base. SWRL (Semantic Web Rule Language) [\[150\]](https://ieeexplore.ieee.org/document/) is a rule language developed based on OWL DL and OWL Lite sublanguages of OWL and Unary/Binary Datalog RuleML sublanguages of the Rule Markup Language. SWRL is a crucial step towards a standardized and interoperable inference framework in the Semantic Web infrastructure. In [\[151\]](https://ieeexplore.ieee.org/document/), for their purpose of extracting new knowledge from data with a combination of facts distributed over different sources, They used information from three art-related databases and modeled them with CIDOC CRM ontology in OWL language using Protégé 40 software. Since the CRM is event-centric and OWL is insufficiently expressive for property based ontologies, a set of rules were defined in SWRL. Using the Jess inference engine they showed the applicability of the method to derive new knowledge that was not contained in a single database.

#### 3) Data Representation and Visualization

Creative and intelligent representations and 3D visualization of thematic data can give users, whether experts or non-experts, a holistic overview in an interactive and easy-to-grasp manner. For example, in the CultureSampo portal [\[152\]](https://ieeexplore.ieee.org/document/), cultural information is represented on a map based on their locations, and they are also categorized in different types. Each of them is visualized with a specific color that gives the user the opportunity to browse a city or a place on map and find out about various cultural heritage resources there. In this portal, there is the possibility to overlay historic boundaries of cities and historic maps on the google map. There are also other intuitive ways of representing and visualizing data there, such as displaying visual items of a chosen type on a time line to realize the changes through time and visualizing the social network of famous historic figures and persons, in which user can search if there is a connecting path between two persons and how they are related. 3D visualization can be beneficial both for understanding and analyzing thematic data. In [\[153\]](https://ieeexplore.ieee.org/document/), after successfully enriching BIM model of a historic building with cultural heritage documentation by integrating IFC model with Semantic Web technologies, the authors visualized the 3D model of the building in unity game engine and the linked information to the different parts of the building. In [\[154\]](https://ieeexplore.ieee.org/document/), archaeologists and computer science researchers collaborated towards a connection between 3D spatial representation and archaeological knowledge, by integrating observable (material) and non-graphic (interpretive) data. After acquisition of 3D model of a built heritage with photogrammetry techniques, they integrated the model with geometric, topological, and temporal semantics to model Units of Stratigraphication. They visualized the integrated information on the 3D model with different colors that provided a convenient way for the user to capture information of different parts. In [\[155\]](https://ieeexplore.ieee.org/document/), the ADE developed based on CityGML for cultural heritage architecture (CHADE) was used for 3D data of a historic church. Different parts of the building in 3D model is linked to its own class and enriched with its relating information. The resulting model is rendered in a 3D GIS environment that provided different geometric measurements and visualization of thematic information. Expert users with such systems can do basic measurements and information retrieval like material of a part of the built heritage without the need to on-site experiments which are destructive. Also, they can visualize the thematic data like year of construction with colors to see the status of different parts.

However, visualization is quiet young in the CH domain. Figure 5 depicts a year-by-year analysis of publications in the topic of CH visualization. The first publication was in 2004, and from 2010 onwards, there has been a rise in interest. Since then, the number of publications has risen steadily (with fluctuations). This pattern mirrors the evolution of major CH data sources over the previous ten years [\[156\]](https://ieeexplore.ieee.org/document/). InfoVis techniques can be very helpful for presenting CH data. The amount of information stored in collections is enormous, and in some cases, like British museum it takes years for users to visit all items in the institution. InfoVis methods can provide various holistic and generous viewpoints on data and very importantly serendipitous information retrieval [\[156\]](https://ieeexplore.ieee.org/document/). Nonetheless, due to the vast amount of data and its heterogeneity, this fairly new promising field of research is still very much challenging.

**FIGURE 5.**

The evolution of the concept of CH visualization across time [\[156\]](https://ieeexplore.ieee.org/document/).

#### 4) AR/VR Applications

The CH community employed advanced multimedia technologies from an early time, as these systems could attract more audiences, especially younger people. ARCHEOGUIDE, an AR location-based user guide application in 2001 was the start in the CH domain [\[157\]](https://ieeexplore.ieee.org/document/). Visual multimedia systems are easier for people to follow therefore, their usage can help the CH community to reach wider dissemination of cultural knowledge. These methods can make the learning process in a museum more interactive than just reading labels and descriptions. Also, they have the potential to increase user engagement by enhancing the sense of place so that they could bring an added value to CH objects [\[158\]](https://ieeexplore.ieee.org/document/). However, it is argued that the use of such technologies removes the focus from CH objects and user pay more attention to the virtual graphics [\[159\]](https://ieeexplore.ieee.org/document/). For this problem, a combination of multimedia technologies with semantics seems to be a kind of solution. This way, the information used can be more organized and machine-readable so that users can select what they want to learn about the CH site or a special item, thus increasing user interaction compared to the situation where the developer of AR/VR apps choose what to see for users.

Structured and rich Linked Data can provide the possibility to create context-aware AR/VR applications that can improve retrieving personalized data, which could further contribute to increasing the CH experiences for the user. In [\[160\]](https://ieeexplore.ieee.org/document/), a mobile AR application was designed and implemented to act as a user guide. The application uses LOD published through the MultimeadiaN e-culture project and is based on the location context of the user captured via GPS sensor to harvest cultural heritage data of the user’s nearby POIs. It is based on the user view extent and heading acquired by mobile sensors data for the specific POI that the user is facing and is displayed. Also, to display the retrieved data faceted-based approach [\[140\]](https://ieeexplore.ieee.org/document/), which was developed within the same project is utilized. In [\[161\]](https://ieeexplore.ieee.org/document/), a mobile AR web-based application was developed called LOD4AR. It harvests and integrates LOD from three separate sources DBpedia, LinkedGeoData, and Data.Gov.ro which is Romanian museum data. Kim et al. [\[162\]](https://ieeexplore.ieee.org/document/) first mapped and integrated data from five Korean heritage databases to a data model that was a previously developed data model for Korean cultural heritage data KCHDM [\[63\]](https://ieeexplore.ieee.org/document/). Then they developed a mobile AR application for three POIs in a palace. The location detection is based on vision-based methods that match the camera image and the POIs image databases. The data is displayed based on the five superclasses of the KCHDM, and the user can select the category they are interested in and browse various types of information and multimedia content.

Researchers in [\[163\]](https://ieeexplore.ieee.org/document/) built and implemented the K Culture Time Machine (KCTM) program, a system for gathering cultural content with spatial and temporal information, making the semantic correlation, and visualizing it on AR and VR platforms. The program can recognize a cultural heritage site and deliver related information and materials of the heritage site using the smartphone’s inbuilt camera. At the same time, a wearable 360 video-based VR can deliver a distant experience over time and space for cultural heritage or relics. Also, historical personalities, locations, and events associated with the cultural heritage site can be searched for. In addition, visitors can see a 3D reproduction of missing cultural heritage. According to user feedback, the majority of participants showed a strong desire to visit heritage locations that were supplemented with other related material.

#### 5) Context-Aware Applications

To this end, we have discussed this matter until now and we can see that the evolution of the process in the CH domain is extraordinary and lots of effort has been put in to the work, but still, if users want to access specific information, they first should find a repository, and then they have to learn how to search within that system.

Context-aware ubiquitous computing (ubicomp) can be a solution to this problem. Mark Weiser in 1991, proposed the term ubiquitous computing and defined its features in some papers, most importantly in [\[164\]](https://ieeexplore.ieee.org/document/). He defined ubiquitous computing as invisible, non-disturbing, and calm that “weaves itself into the fabric of everyday life” [\[164\]](https://ieeexplore.ieee.org/document/). This vision of Mark Weiser means that cyberspace should be brought to the real world, so people could interact with almost every object in the environment for computing rather than a single access point to the cyberspace, which is the monitors of personal computers. In this way, users would pay less attention to the computing technologies and thus focus on their actions in the real world. Also, ubicomp is not passive like PCs, yet it is active and sometimes proactive. This means that while the user is acting with the object in their focal point of attention ubicomp technologies act around it without the user defining their needs. Ubicomp technologies provide the services that they are designed for. This way, they help the user in their everyday life without intruding on their attention. However, a prerequisite step for ubicomp to reach this level is for it to be context-aware, which means that it should capture and understand the context of the environment that the user is in. Context and its definition were first introduced by Bill Schilit [\[165\]](https://ieeexplore.ieee.org/document/). Context-aware computing tries to make assumptions about the current situation of the user. Dey also defined context as “any information that can be used to characterize the situation of an entity” [\[166\]](https://ieeexplore.ieee.org/document/). So context can be a variety of information from the location of the user, time, and to even the size of the interface of the user’s device. While context-aware applications can provide many services including location-aware user guides and recommender systems, they can increase the precision of personalized information retrieval. In the EEXCESS project [\[167\]](https://ieeexplore.ieee.org/document/), an application was developed with the purpose of providing ubiquitous access to cultural heritage information for users. After acquiring the user’s context, which is the main topics of the text of the web page that the user is reading, this application carries out a federated search on content providers using LIDO schema and aggregates the collected data based on the EDM data model complemented by W3C PROV ontology as EDM lacks provenance metadata. Then it ranks the list of data gathered based on the user’s information need and shows previews of recommended items at the bottom of the page for the user. The integrated and structured data through Semantic Web technologies can increase the efficiency of recommender systems. This is assessed and verified in the SMARTMUSEUM project [\[168\]](https://ieeexplore.ieee.org/document/). The SMARTMUSEUM application is a mobile context-aware recommender system for users interested in cultural heritage, which utilized the web of data. This application is designed for three outdoor, indoor, and web-based scenarios. In the outdoor phase, the user moves around the city, and based on their context of location acquired by the GPS sensor, the visit time of the sites, and the desired type of the information that is manually inputted by the user, cultural heritage sites are recommended to the user. In the indoor phase, the user enters a recommended place, and information about various objects is provided for the user on-site. The location context of the user is acquired by RFID sensors and based on their interested information context, personalized content is retrieved for the user. In the desktop scenario, all the context is edited by the user on the web interface. Also, users can rate the content recommended that is used by the system to refine its next recommendation in a personalized way. Authors reflect that ontology-based data structuring is effective in better matching user context and retrieved information thus increasing recommendation accuracy. Reference [\[169\]](https://ieeexplore.ieee.org/document/) suggested a data model that combines CH information with location semantics to allow an intelligent location-based user manual for tourists visiting a historical site. Users can use this to discover places they’re keen on using spatial semantics. In this study, a spatial POI-based data model for historical sites was created based on the CIDOC CRM and geosparql ontologies. To describe the cultural heritage information associated with poi and link it to geosparql throughout a mediation to integrate spatial semantics, concepts from CIDOC CRM were employed. The purpose of this research was to develop a knowledge base for historical sites that would allow the ontological data model to be deployed for the semantic location-based services (SLBS) apps like user guides and recommendation systems, as well as produce information prepared for usage in a linked data platform.

In this section, our study has yielded significant insights and practical contributions. We focused on various aspects, including search and browse functionalities, inference mechanisms, data representation and visualization, AR/VR applications, and context-aware ubiquitous computing.

Our study emphasizes the pivotal role of semantic information platforms in providing smart services for end-users in the CH domain. We showcased examples like the CultureSampo portal, highlighting how semantic technologies enhance search, browsing, and recommendation services. By implementing ontologies in OWL DL and employing inference engines like RACER, FaCT++, pellet, and HermiT, our study advances the understanding of basic logical deductions in CH. Furthermore, the introduction of SWRL as a rule language extends OWL’s expressivity, enabling the extraction of new knowledge. We explored the creative and intelligent representation of thematic data through 3D visualization, providing users with interactive and holistic overviews. Examples from projects like CultureSampo and collaborative efforts between archaeologists and computer scientists showcase the benefits of visualizing cultural information. Our study recognizes the early adoption of advanced multimedia technologies in the CH community. We highlight the potential of AR/VR applications, addressing challenges related to user engagement and the balance between virtual graphics and the focus on CH objects. The combination of multimedia technologies with semantics emerges as a solution to enhance organization and machine-readability. Context-aware ubiquitous computing emerges as a solution to access specific information in the CH domain seamlessly. Our study showcases examples like the EEXCESS and SMARTMUSEUM projects, demonstrating the efficiency of context-aware applications in providing ubiquitous access to cultural heritage information.

We presented the process that the CH community has taken to establish data interoperability through Semantic Web technologies from creating domain-specific vocabularies and metadata schemas to top-level and application-specific ontologies, also, as the various opportunities that this transfer of data and information into knowledge can provide. However, there are still challenges that need to be tackled in future studies, which we will mention in Section V-A. The spatio-temporal aspects of CH data and tourist engagement and social intelligence will be discussed in Section V-B.

### A. Remaining Challenges

This part summarizes some of the challenges from different perspectives, including sustainability, data reuse, intellectual property and Digital CH invention assessment.

#### 1) Sustainability

First, sustainability is an important issue. CH domain is one of the four primary pillars of sustainable development [\[170\]](https://ieeexplore.ieee.org/document/), therefore sustainability within the CH domain and its data are vital. The data silos and repositories mainly are project-led in the CH domain and the presumed data persistence is at stake [\[171\]](https://ieeexplore.ieee.org/document/). The challenge arising here is data stewardship and the responsibility to maintain the data [\[172\]](https://ieeexplore.ieee.org/document/). This problem first came up in the course of Archaeology Data Service (ADS) development. This archive holds the archeological data based in the UK and it has been funded and maintained from 1996 up to now in collaboration with researchers, heritage agencies, and funders [\[171\]](https://ieeexplore.ieee.org/document/), pointing out the significance of data responsibility and conservation. Other regional or large-scale portals must ensure researchers and stakeholders of its data conservation and preservation. Another issue in this regard is that small institutes and countries that lack technical and financial ability to provide their data for the integration in aggregator portals due to high standards and protocols. In this regard, during the continental-scale ARIADNE infrastructure project [\[71\]](https://ieeexplore.ieee.org/document/), for example, weaker GLAMs were given help to prepare their data according to the standards [\[171\]](https://ieeexplore.ieee.org/document/) to address the hurdles in the way of this collaborative innovation of creating a digital heritage data discovery infrastructure. In addition, these small institutes have another problem of low publicity as they attract a low number of visitors and their information is left unexplored [\[173\]](https://ieeexplore.ieee.org/document/). Semantic Web solutions can integrate data of these institutes to the Linked Open Data cloud for more visibility [\[123\]](https://ieeexplore.ieee.org/document/), thus reaching sustainability in the whole CH ecosystem.

#### 2) Data Reuse and Dissemination

Infrastructures and portals are not the ultimate goals for digital data [\[174\]](https://ieeexplore.ieee.org/document/). These digital archives are created for linking and integrating data to make its retrieval and reuse more convenient. Despite the unanimous agreement on this process of collecting, documenting, modeling, and packaging the data, the actual reuse of it is the missing part [\[174\]](https://ieeexplore.ieee.org/document/). It is not clearly shown how and to what extent these efforts have been effective in terms of reusability [\[175\]](https://ieeexplore.ieee.org/document/). Digital repositories and researchers need to save their projects’ lessons learned on the best practices of the methods applied and their impact on the dissemination and reusability of data. interoperability might have been the challenge of the last decade and it has been solved largely with various kinds of data models and metadata developed. however, todays’ challenge could be reusing the semantically linked data [\[171\]](https://ieeexplore.ieee.org/document/).

#### 3) Ontologies for Multimedia Data

Managing multimedia data within cultural heritage knowledge organizations and ontologies presents both opportunities and challenges. While traditional ontologies were primarily designed for textual information, efforts have been made to extend ontologies to accommodate multimedia content in the context of cultural heritage. Nevertheless, there are still gaps and challenges in this area that need to be addressed.

In terms of opportunities, the inclusion of multimedia data significantly enhances the richness of representing cultural artifacts. By seamlessly integrating images, audio, video, AR/VR and 3D models alongside textual descriptions, the overall comprehension of cultural heritage items is notably heightened [\[158\]](https://ieeexplore.ieee.org/document/), [\[176\]](https://ieeexplore.ieee.org/document/). This comprehensive approach ensures a more immersive user experience, fostering engagement and understanding. Furthermore, ontologies play a crucial role in facilitating cross-modal linking, allowing for connections between disparate media types. For instance, linking a painting to its associated historical documents or audio commentary contributes significantly to augmenting the user’s contextual understanding.

On the other hand, there are various challenges in the way to achieve the abovementioned benefits. Firstly, There is a semantic gap between low-level features extracted from multimedia content and the high-level concepts represented in ontologies [\[177\]](https://ieeexplore.ieee.org/document/), [\[178\]](https://ieeexplore.ieee.org/document/). Bridging this gap requires sophisticated methods for extracting meaningful information from images, audio, and video. Next, Integrating multimedia data into ontologies can be complex. Different types of media may have their own standards, metadata formats, and vocabularies [\[179\]](https://ieeexplore.ieee.org/document/). Harmonizing these diverse sources of information for seamless integration is a challenge. Another issue is that handling large volumes of multimedia data within ontologies may raise scalability and performance issues. Efficient storage, retrieval, and processing of multimedia content become critical for maintaining system performance. Additionally, designing user interfaces that effectively present and navigate multimedia content within the ontology is a challenge [\[176\]](https://ieeexplore.ieee.org/document/). There are also ethical challenges regarding multimedia data handling. This is discussed in detail later in subsection IV-A – V, “intellectual property”.

#### 4) Knowledge Maintanence Within Ontologies

In this section, we delve into the key technical challenges associated with cultural heritage knowledge acquisition, maintenance, ambiguity and information retrieval, and ontology design. Addressing these challenges is crucial for advancing the field and ensuring effective knowledge representation and retrieval. We focus on three primary challenges:

##### a: Acquiring and Maintaining Knowledge Within an Ontology

Cultural heritage knowledge is diverse and dynamic, presenting challenges in both acquiring and maintaining this knowledge within ontologies. Whether performed manually or automatically, the process requires careful consideration of heterogeneous data sources, semantic interoperability, and the evolving nature of cultural heritage information [\[180\]](https://ieeexplore.ieee.org/document/). The unsolved issues in this domain call for innovative solutions to streamline the integration of data and maintain the relevance of ontologies over time.

##### b: Ambiguity in Information Retrieval

Ambiguity is inherent in cultural heritage information retrieval due to imprecise user queries, diverse language use, and the subjective nature of cultural artifacts. this challenge requires sophisticated approaches including query expansion, relevance feedback, NLP, and contextual understanding using open data sources such as LOD [\[181\]](https://ieeexplore.ieee.org/document/), [\[182\]](https://ieeexplore.ieee.org/document/), [\[183\]](https://ieeexplore.ieee.org/document/). Effectively managing ambiguity is crucial for improving search accuracy and user satisfaction in the retrieval process.

##### c: Ontology Design

The design of ontologies for cultural heritage information retrieval involves careful consideration of formal languages, class hierarchies, relationships, and contextual factors [\[54\]](https://ieeexplore.ieee.org/document/). Achieving clarity, coherence, and simplicity while accommodating multiple perspectives is essential. despite progress in ontology engineering such as event-based modeling, there remain unsolved issues related to balancing expressiveness with complexity, which warrants ongoing exploration and refinement [\[184\]](https://ieeexplore.ieee.org/document/).

#### 5) Intellectual Property

Another issue is that the primary goals of digitization are to preserve analog information resources and their long-term storage as digital copies, as well as to enable access to these copies via digital products and networks and to gather them in digital libraries [\[31\]](https://ieeexplore.ieee.org/document/). Access to information on the global network is made possible through digitization. however, growing online prospects necessitate new forms and standards for copyright and intellectual property protection.

In this way, digitization serves as a tool for both preserving cultural history for the next generations and facilitating the availability of cultural values. Along with the benefits of digitalization, there is a risk of misappropriation of cultural values’ cultural and economic characteristics. Also, intellectual property-related concerns pose severe challenges in light of new digital capabilities in cultural heritage protection, safeguarding, and popularization. therefore, in this context, the digitalization of cultural values should be done in complete respect of any intellectual property rights that may exist [\[185\]](https://ieeexplore.ieee.org/document/).

To encourage technological reuse, it was suggested that an open software pilot be established for eu-funded projects in the digital ch area, similar to the newly launched open data pilot [\[186\]](https://ieeexplore.ieee.org/document/). Because eu and national programs are funded with public monies, the need for such an effort is also in keeping with ethical responsibility to society. the construction of an eu-wide repository for digital CH software assets, backed by suitable documentation and instructions, is a second strategy to enhance innovation technology reusability. Finally, training, such as through an online knowledge center, can assist digital ch researchers and developers in selecting the proper license for their artifacts.

#### 6) Digital CH Invention Assessment

As discussed in the article, digital innovation for the CH domain is one of the important elements that is increasing day by day. When it comes to quantifying the impact of the digital invention on cultural heritage, there appears to be a multi-dimensional approach: technical, scientific, economic, cultural, environmental, and sociological [\[187\]](https://ieeexplore.ieee.org/document/).

A digital invention can be assessed during the course of a project’s lifecycle in terms of technological adoption by its target users. Interface design and accessibility are examples of elements that can be examined in this respect. The scientific effect can also be assessed, with a focus on several disciplines ranging from ICT to the Humanities and Social Sciences. Experiments can be conducted in both controlled and uncontrolled environments to support the above. Thus, it is critical to use a holistic method for assessment throughout the life of a project, one that combines qualitative and quantitative techniques and recognizes the multi-dimensionality of cultural heritage development. It’s also vital to realize that examiners include not only those who have been officially appointed but also later generations who may have different parameters as time goes on.

In the long run, the importance of evaluating digital CH invention is based on its economic, cultural, environmental, and general societal effects. On an economic stage, crucial parameters to track involve the developed innovation’s return on investment and area competition improvement through the period. On a cultural stage, the effect of the invention can be quantified in terms of new modern forms of culture that it aids in the formation of, such as new cultural images and symbols. The level of attraction that the digital CH invention enabled a certain region or city to achieve can be quantified in terms of environmental effect. It can be determined by the increase in tourism activities, environmental awareness, and cultural and natural environment conservation that the invention accomplishes. Furthermore, and perhaps most crucially, the societal impact must be assessed in terms of social cohesiveness, community engagement, social continuity, novel education, and knowledge, feeling of place, and identity formation. It’s also important to keep in mind that determining the long-term consequences isn’t easy.

Nonetheless, society’s top priority is to establish a concrete and long-term mechanism to evaluate this [\[188\]](https://ieeexplore.ieee.org/document/).

The following are some of the open challenges that need to be addressed:

- Identifying new parts of life that digital cultural heritage can affect in order for citizens to stay up with societal needs.
- Because content can still be founded by professionals and non-experts, content evaluation is now necessary.
- Enabling large-scale cooperation and fostering circumstances conducive to the emergence of collective intelligence
- Managing a significant volume of client feedback from a variety of sources.

### B. CH Sensitivity Discovery

In this section, CH is reviewed in the field of geographical semantics, social media, and citizen participation. The discussion extends beyond geographical semantics and social media to delve into the active involvement of citizens in the CH domain. By examining the interplay between citizen participation and cultural heritage, this Section aims to shed light on the dynamic and evolving nature of CH, where the collective contributions of individuals become integral to its preservation and continued relevance.

#### 1) Spatio-Temporal Aspect of CH Data

There is a quite famous assertion among geoscientists, which claims that almost up to 80 percent of all data in the world has some spatial or geographic reference. this has been proved to some extent of reliability in [\[189\]](https://ieeexplore.ieee.org/document/) By evaluating the linked open data of the semantic web. ch data is no exception and a large proportion of cultural resources has some sort of connection to space. Therefore, they can be retrieved by search terms that refer to locations [\[190\]](https://ieeexplore.ieee.org/document/). As in many knowledge management systems ontologies and data models, heritage objects are linked to their coordinates and temporal periods, indicating that location and time are important factors in cultural events. In addition, the TGN (Thesaurus of Geographic Names) vocabulary, which was introduced, is a well-known thesaurus in the ch domain that is a structured list of place names and their previous historical names. it is used to link CH data to their location, which helps in semantically annotating and inferencing information. geospatial science deals with the phenomenon that relates to space, and it has an information system for analyzing and visualizing data called GIS (Geographic/Geospatial Information System) [\[191\]](https://ieeexplore.ieee.org/document/). With the emergence of web and web services, gis systems also went on the web for numerous reasons, intending to provide services over the web, which introduced another paradigm called WEBGIS. As a matter of fact, geospatial science also has adapted semantic web technologies [\[192\]](https://ieeexplore.ieee.org/document/), [\[193\]](https://ieeexplore.ieee.org/document/) Since spatial information is in different formats, such as vector and raster and also spatial features have various feature types, such as point, line, polygon, and etc. and also to model the different topological relations.

Giscience and geospatial semantic web can benefit the ch domain in two general aspects of 3D semantics of heritage building’s architecture and spatio-temporal reasoning. In recent years lots of research was done in the gis field for the 3D recording of cultural heritage, the important and difficult part of the work is to create structures to handle this data and integrate them while building semantic models and heritage documentation and standards. This could be helpful in making geometric measurements, managing and monitoring the health of heritage buildings, and preservation and protection planning alongside sustainable smart city visions. Work and effort in the 3d and architectural aspects of spatial science for the benefit of the ch community are more than the other aspect. For example, [\[194\]](https://ieeexplore.ieee.org/document/) recommends a method to digitally record cultural heritage buildings, enrich them with topological relations and semantics, and transfer it to a 3D GIS Environment for further analysis and management. in this approach, the authors use their previously developed HBIM (Historic Building Information Modeling) [\[195\]](https://ieeexplore.ieee.org/document/), Which is a model for capturing and modeling historic building structures from 3d models generated using BIM. after completing the 3D model with its parts that were semantically defined, it was transferred to a 3d gis environment and CITYGML was chosen for this purpose. CITYGML [\[196\]](https://ieeexplore.ieee.org/document/) is an OGC (Open Geospatial Consortium) Standard for the storage and exchange of 3D models in an interoperable way that allows the same data to be reused in different applications. The purpose of its development is to provide a standard and common definition of basic entities, at-tributes, and relations of a 3D city model. after moving to the citygml environment, different segments of the model are recognized such as rooftops, windows, and roads. then the model is ready for further analysis regarding geometry, topology, and semantics. Thematic views and analyses are also possible, but for this matter, an ade (application domain extension) is needed to be developed for CITYGML [\[194\]](https://ieeexplore.ieee.org/document/). In [\[197\]](https://ieeexplore.ieee.org/document/), an ade is proposed for citygml by extending it through xml that is capable of modeling thematic information of parts of architectural heritage buildings in multilevel views from LOD (Level of Detail) 1 to LOD 5 increasing details of parts and related information. In [\[197\]](https://ieeexplore.ieee.org/document/), another ADE is developed for CITYGML called CHADE (Cultural Heritage Application Domain Extension). In this spatial ontology, some classes are proposed for CITYGML and incorporated getty’s AAT (ART and architecture thesaurus) Vocabulary, so that the model is capable of providing geometric measurements also thematic information representation in different levels of detail. There are a lot of applications and data models developed for spatial reasoning and manipulation of 3d models for the management of cultural heritage resources. an overview of them can be found in [\[198\]](https://ieeexplore.ieee.org/document/).

There has been a great tendency to develop location-based and beyond that, location-aware applications for numerous purposes like recommendation systems for users and tourist guide systems [\[199\]](https://ieeexplore.ieee.org/document/). These applications can assist users to query surroundings spatially and finding desired locations and POIS. However, there are some problems with ch information, mentioned in [\[200\]](https://ieeexplore.ieee.org/document/), That hinder achieving the applications discussed. first, there is a problem with annotations content that have georeferenced locations with varying granularity. For example, a heritage object may refer to a country name while another refers to a city name in that country, and the missing semantic relation-ship between them would cause an error in the accuracy of information retrieval when processing a spatial query. Second, place names and extents of places have changed during time, and based on the cataloging time of objects their location name may differ, which would again cause certain problems. Finally, nearby pois are not just the ones with small distances. their accessibility and the time needed to reach the place should be analyzed. the geospatio-temporal semantic web can play an important role in solving the problems mentioned above. Although the majority of ch resources are georeferenced, the concept of place is poorly de-fined in these data. Efforts for integrating spatio-temporal reasoning into cidoc crm began in 2013, which tried to harmonize the two ogc and crm standards [\[67\]](https://ieeexplore.ieee.org/document/). The efforts resulted in crmgeo extension, which integrates geoinformation and crm ontology through conceptualizations, formal definitions, encoding standards, and topological relationships defined by ogc’s geo-sparql. Unlike other crm extensions, crmgeo brought changes to the core classes of the data model by introducing spacetime volume. It also defined some new subclasses and properties, such as phenomenal and declarative space, and integrated geospatial feature types and relationships from GEOSPARQL into CIDOC CRM ONTOLOGY [\[68\]](https://ieeexplore.ieee.org/document/). Although crmgeo provides links to spatial standard geosparql, it suffers in temporal aspect, as it lacks links to any time ontology [\[201\]](https://ieeexplore.ieee.org/document/). WIth this being said, this extension has not been used widely and overall the aspect of spatio-temporal semantics is left unexplored, which could be very helpful in spatial reasoning. This can make it possible to infer new knowledge and links that were not known before. It can reveal for example, which type of art started in which place, the influence of different kinds of art from one place to another, or types of artifacts in a special place, and so forth.

#### 2) Tourist Engagement and Social Intelligence

There is a need to engage the tourists, whether native or foreigner, more with the tangible and intangible heritage for better dissemination and education of cultural heritage. While a great number of studies agree on the capacity of the CH domain to create attachment, entertainment, and social bonding, these aspects have remained less explored [\[202\]](https://ieeexplore.ieee.org/document/). Storytelling is one of the unique features of museums and galleries [\[203\]](https://ieeexplore.ieee.org/document/). CH professionals began to provide digital storytelling tools to enable engagement and interactivity between users and heritage objects [\[204\]](https://ieeexplore.ieee.org/document/). Various technological possibilities have been applied in digital storytelling and narrative authoring tools such as multimedia presentation, VR/AR and mixed reality (MXD) interfaces [\[205\]](https://ieeexplore.ieee.org/document/), [\[206\]](https://ieeexplore.ieee.org/document/), [\[207\]](https://ieeexplore.ieee.org/document/) and indoor navigation [\[170\]](https://ieeexplore.ieee.org/document/) to connect several objects with a specific narrative. However, there are a number of suggestions that can be helpful in making digital storytelling easier and more effective. Usage of ontologies can be of great assistance in devising the plot of stories as it relates objects to each other and historical events based on their relationships and also modeling the sequence of the conceptual map of the story [\[208\]](https://ieeexplore.ieee.org/document/). Ontologies can reveal unseen connections between objects and events in the real world, which can bring up interesting stories. Museum experts can benefit from ontologies based systems that collect information from a variety of sources related to objects to build narratives [\[205\]](https://ieeexplore.ieee.org/document/).Another aspect is that heritage sites are mostly visited by groups of people rather than individually, however, most applications and services are developed for individuals [\[202\]](https://ieeexplore.ieee.org/document/). Social and shared digital experience is a necessity in the CH domain, which has not gained much attention. The CHESS [\[209\]](https://ieeexplore.ieee.org/document/) and Emotive [\[210\]](https://ieeexplore.ieee.org/document/) projects are amongst few that have focused on storytelling for groups of people, increasing collective participation and engagement. Context-awareness can also be beneficial in digital storytelling by tailoring the stories to the preferences of different users. The users of the CH domain vary from professional experts, scientists, students, and regular people and they have different ages [\[211\]](https://ieeexplore.ieee.org/document/). It can also relate the story to the day of the visit or the trending topics on social media [\[212\]](https://ieeexplore.ieee.org/document/). The CH community can benefit from social intelligence to enable the community to develop brand-new strategies for engaging and attracting more visitors. The nature of both social media and CH data are big, heterogeneous, highly unstructured, and involves a wide range of collaborators and stakeholders [\[213\]](https://ieeexplore.ieee.org/document/). Therefore, a semantic approach seems very profitable in linking the social media to the CH community and raising awareness, interest, and engagement on a wider scale.

#### 3) Citizen Participation and Contributions to CH Domain

In the context of Cultural and Historical Heritage (CHH), individuals emerge as integral participants, contributing to and benefiting from the intricate cultural narrative [\[214\]](https://ieeexplore.ieee.org/document/). Visitors to heritage sites, far from being passive spectators, actively engage in the narratives presented within exhibitions. This active participation takes on heightened significance in the realm of contemporary history, where the living memory becomes a vital repository [\[215\]](https://ieeexplore.ieee.org/document/). Individuals share personal experiences, weaving familial traditions, everyday practices, and unique perspectives on significant historical events. The integration of ICT and digital services empowers museums, transforming them into dynamic spaces that actively involve people. Moreover, the synergy of museum information services and IoT-enabled location-based features bridges the informational divide between cultural artifacts and visitors. The active participation of individuals is evidenced by the collaborative environment fostered within museum spaces, where visitors provide feedback and evaluate exhibits. This collaborative engagement enhances the interactive and intriguing nature of the museum experience. The personalized involvement appeals to a diverse audience, particularly capturing the interest of the younger generation who leverage gadgets for effective information extraction, aligning with their educational pursuits.

The dynamic involvement of individuals in the CHH domain prompts contemplation on its implications for the future of museums and heritage preservation introducing a novel concept of co-creation [\[216\]](https://ieeexplore.ieee.org/document/). Contemporary ICT trends, emphasizing personalized products, content, and experiences, are reshaping the role of museums. The challenge lies in adeptly harnessing the wealth of information contributed by individuals, transforming it into a valuable resource for preserving unofficial histories and enriching the overall visitor experience. The shift towards personalized recommendations and interactive exhibits signifies an adaptive response to the evolving expectations of a future audience accustomed to tailored services. As museums embrace this evolving landscape, it becomes imperative to explore methodologies for capturing, organizing, and effectively utilizing user-generated content. This ensures that the collective knowledge and diverse experiences of individuals not only contribute meaningfully but also shape the broader landscape of the Cultural and Historical Heritage domain.

In this paper, the evolution of information engineering techniques and Knowledge Organization Systems (KOSs) for more precise and personalized information retrieval in the Cultural Heritage realm was discussed in detail. Knowledge management is crucial in the CH domain due to obvious reasons such as dealing with rich heterogeneous data and involving different organizations and people from various fields of expertise. GLAMs (Galleries, Libraries, Archives, and Museums) are great and rich sources of CH information. This information is vitally important in memory preservation, education of new generations, tourism, and other possible areas.

As the CH community has invested significant effort and time in developing robust data models and knowledge organization methodologies, the focus should now shift towards leveraging this collective expertise. Encouraging memory organizations to not only adopt but actively contribute to LOD can catalyze advancements. This interconnected web of data serves as a foundation for the development of intelligent and personalized applications and services. The potential of the web of data can be harnessed to create sophisticated tools that enhance user interaction, engagement, and the dissemination of heritage information.

The conceptual framework developed in this study integrates Cultural Heritage, Information Modeling, and Information Retrieval, providing a structured approach to addressing challenges in the domain. Specifically, our exploration of preliminary KOSs, the role of formal ontologies, and the nuanced differences between CRM and EDM offers valuable insights. The practical implications of our research are far-reaching, providing a foundation for improved Information Retrieval methods, data integration, and user interface design in the Cultural Heritage domain.

Beyond being an insightful review, our study presents explicit formulations with practical applications for experts in the CH domain. We introduced a model for achieving semantic interoperability, providing a blueprint for memory organizations to structure their data on the LOD cloud. Further, the study offered guidelines for developing AR and VR applications in the CH domain, emphasizing the integration of multimedia technologies with semantics. The concept of context-aware ubiquitous computing was introduced to streamline information retrieval, and we advocated for its adoption in CH settings, providing a framework for developing context-aware applications.

Addressing the need for enhanced data reuse and dissemination, we recommended active documentation of project lessons learned, creating repositories that include methodologies and best practices. To navigate intellectual property concerns, we proposed an Open Software Pilot and an EU-wide repository for digital CH software assets, accompanied by training initiatives. Our multi-dimensional approach to assessing digital CH invention, encompassing technical, scientific, economic, cultural, environmental, and sociological dimensions, laid the groundwork for robust and comprehensive evaluations.

Moreover, our study underscored the importance of engaging tourists and users through digital storytelling and social intelligence. We suggested creating tools and applications catering to group experiences, leveraging ontologies for storytelling, and incorporating social intelligence to tailor experiences based on user preferences. These explicit formulations provide practical models, methods, and recommendations that memory organizations and CH experts can apply in their projects, contributing significantly to the advancement of the CH domain. The journey from data interoperability to the deployment of smart applications promises to revolutionize the CH landscape, offering enriched experiences for users and stakeholders alike. This could further help the CH industry.

### ACKNOWLEDGMENT

*(Babak Ranjgar and Abolghasem Sadeghi-Niaraki contributed equally to this work.)*