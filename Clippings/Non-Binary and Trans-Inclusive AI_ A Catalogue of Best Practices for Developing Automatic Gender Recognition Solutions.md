---
title: "Non-Binary and Trans-Inclusive AI: A Catalogue of Best Practices for Developing Automatic Gender Recognition Solutions"
source: "https://dl.acm.org/doi/10.1145/3687251.3687255"
author:
  - "[[ACM SIGAPP Applied Computing Review]]"
published:
created: 2025-03-30
description: "Artificial intelligence (AI) has significantly optimized processes across various sectors, enhancing efficiency and transforming digital interactions. However, as AI becomes more integrated into da..."
tags:
---
## Abstract

Artificial intelligence (AI) has significantly optimized processes across various sectors, enhancing efficiency and transforming digital interactions. However, as AI becomes more integrated into daily life, concerns about its social impacts and inherent biases have emerged. This study explores how AI technologies, such as facial recognition and Automatic Gender Recognition (AGR), can perpetuate and amplify societal prejudices, especially against transgender and non-binary individuals. The 2018 case of Amazon's Rekognition technology, which exhibited high false positive rates for individuals with dark skin, highlights the risks of algorithmic bias and mass surveillance. Given these challenges, this research performed performed a systematic mapping study of the literature on AI to present an analysis of problems and respective causes brought by facial recognition and AGR applications to trans and non-binary people. In a second phase, we developed and empirically assessed a catalog of 19 best practices for an ethical AI development grounded in Justice, Equity, Diversity, and Inclusion principles. We aim to establish ethical standards that promote inclusivity to trans and non-binary people, mitigating algorithmic discrimination.

## Index Terms

1. Non-Binary and Trans-Inclusive AI: A Catalogue of Best Practices for Developing Automatic Gender Recognition Solutions
	1. [Computing methodologies](https://dl.acm.org/topic/ccs2012/10010147?SeriesKey=sigapp&expand=all)
		1. [Artificial intelligence](https://dl.acm.org/topic/ccs2012/10010147.10010178?SeriesKey=sigapp&expand=all)
			1. [Computer vision](https://dl.acm.org/topic/ccs2012/10010147.10010178.10010224?SeriesKey=sigapp&expand=all)
				1. [Computer vision representations](https://dl.acm.org/topic/ccs2012/10010147.10010178.10010224.10010240?SeriesKey=sigapp&expand=all)
	2. [Social and professional topics](https://dl.acm.org/topic/ccs2012/10003456?SeriesKey=sigapp&expand=all)
		1. [User characteristics](https://dl.acm.org/topic/ccs2012/10003456.10010927?SeriesKey=sigapp&expand=all)
			1. [Gender](https://dl.acm.org/topic/ccs2012/10003456.10010927.10003613?SeriesKey=sigapp&expand=all)
	3. [Software and its engineering](https://dl.acm.org/topic/ccs2012/10011007?SeriesKey=sigapp&expand=all)
		1. [Software creation and management](https://dl.acm.org/topic/ccs2012/10011007.10011074?SeriesKey=sigapp&expand=all)
			1. [Designing software](https://dl.acm.org/topic/ccs2012/10011007.10011074.10011075?SeriesKey=sigapp&expand=all)
				1. [Requirements analysis](https://dl.acm.org/topic/ccs2012/10011007.10011074.10011075.10011076?SeriesKey=sigapp&expand=all)

#### Affiliations

[^1]: McKane Andrus and Sarah Villeneuve. 2022. Demographic-Reliant Algorithmic Fairness: Characterizing the Risks of Demographic Data Collection in the Pursuit of Fairness. In *2022 ACM Conference on Fairness, Accountability, and Transparency.*

[^2]: Francesco Del Buono, Guglielmo Faggioli, Matteo Paganelli, Andrea Baraldi, Francesco Guerra, and Nicola Ferro. 2023. A Framework to Evaluate the Quality of Integrated Datasets. *ACM SIGAPP Applied Computing Review* 22, 4 (2023), 5--23.

[^3]: Judith Butler. 1986. Sex and gender in Simone de Beauvoir's Second Sex. *Yale French Studies* 72 (1986), 35--49.

[^4]: Judith Butler. 1988. Performative Acts and Gender Constitution: An Essay in Phenomenology and Feminist Theory. *Theatre Journal* 40, 4 (1988), 519--531.

[^5]: Tsz Hin Martin Cheung, Erik Noyes, and Leonidas Deligiannidis. 2021. Face of the Team-Diversity, Equity, and Inclusion. In *2021 International Conference on Computational Science and Computational Intelligence (CSCI).* IEEE, 146--151.

[^6]: McKinsey Company. 2023. Diversity Matters Even More: The Case for Holistic Impact.

[^7]: Ramon Costa and George Valença. 2023. *Discriminação Automatizada: uma Análise dos Impactos Negativos de Tecnologias de Reconhecimento Facial para Pessoas Trans.*

[^8]: Sasha Costanza-Chock. 2020. *Design justice: Community-led practices to build the worlds we need.* The MIT Press.

[^9]: Daniela S Cruzes and Tore Dyba. 2011. Recommended steps for thematic synthesis in software engineering. In *2011 international symposium on empirical software engineering and measurement.* IEEE, 275--284.

[^10]: Paula Guedes Fernandes Da Silva. 2022. É menino! É menina! Os riscos das tecnologias de análise facial para as identidades de gênero trans e não-binárias. *Revista Direito, Estado e Sociedade* 60 (2022), 217--238.

[^11]: John-Stewart Gordon. 2021. *Ethics of Artificial Intelligence.* ResearchGate.

[^12]: Foad Hamidi, Morgan Klaus Scheuerman, and Stacy M Branham. 2018. Gender recognition or gender reductionism? The social implications of embedded gender recognition systems. In *Proceedings of the 2018 chi conference on human factors in computing systems.* ACM, 1--13.

[^13]: Raquell Holmes, Roscoe Giles, and Dorian Arnold. 2023. Diversity, Equity, and Inclusion for Computer and Information Science and Engineering Conferences: How Change Happens and Four Things You Can Do Now. *Computing in Science & Engineering* 25, 1 (2023), 57--60.

[^14]: R. B. Jora, K. K. Sodhi, P. Mittal, and P. Saxena. 2022. Role of Artificial Intelligence (AI) In meeting Diversity, Equality and Inclusion (DEI) Goals. In *2022 8th International Conference on Advanced Computing and Communication Systems (ICACCS).* 1687--1690.

[^15]: Os Keyes. 2018. The Misgendering Machines: Trans/HCI Implications of Automatic Gender Recognition. *Proceedings of the ACM on Human-Computer Interaction* 2 (2018), 1--22.

[^16]: Maria Lencastre, Daniel Silva, João Henrique C Pimentel, and Jaelson Brelaz Castro. 2024. PRIUS: Applying Gamification to User Stories Prioritization. *ACM SIGAPP Applied Computing Review* 23, 4 (2024), 27--44.

[^17]: Caitlin Lustig Jed R. Brubaker Morgan Klaus Scheuerman, Kandrea Wade. 2020. How We've Taught Algorithms to See Identity: Constructing Race and Gender in Image Databases for Facial Analysis. *Proceedings of the ACM on Human-Computer Interaction* 4 (2020), 1--35.

[^18]: Jed R. Brubaker Morgan Klaus Scheuerman, Jacob M. Paul. 2019. How Computers See Gender: An Evaluation of Gender Classification in Commercial Facial Analysis Services. *Proceedings of the ACM on Human-Computer Interaction* 3 (2019), 1--33.

[^19]: C. Nutall. 2005. *MBT Teaching Reading Skills.* Macmillan ELT, Oxford.

[^20]: C. O'neil. 2016. *Weapons of Math Destruction: How Big Data Increases Inequality and Threatens Democracy.* Crown Publishing Group, New York.

[^21]: Kai Petersen, Robert Feldt, Shahid Mujtaba, and Michael Mattsson. 2008. Systematic mapping studies in software engineering. In *12th International Conference on Evaluation and Assessment in Software Engineering (EASE) 12.* 1--10.

[^22]: Hina Saeeda, Muhammad Ovais Ahmad, and Tomas Gustavsson. 2023. Identifying and Categorizing Challenges in Large-Scale Agile Software Development Projects: Insights from Two Swedish Companies. *ACM SIGAPP Applied Computing Review* 23, 2 (2023), 23--43.

[^23]: Jacob Snow. 2018. Amazon's Face Recognition Falsely Matched 28 Members of Congress With Mugshots. (2018). https://www.aclu.org/blog/privacy-technology/surveillance-technologies/amazons-face-recognition-falsely-matched-28 Retrieved August 24, 2017.

[^24]: Krzysztof Wach, Cong Doanh Duong, Joanna Ejdys, Rūta Kazlauskaitė, Pawel Korzynski, Grzegorz Mazurek, Joanna Paliszkiewicz, and Ewa Ziemba. 2023. The dark side of generative artificial intelligence: A critical analysis of controversies and risks of ChatGPT. *Entrepreneurial Business and Economics Review* 11, 2 (2023), 7--24.

[^25]: Katherine Wyers. 2022. Leaving No-One Behind? A Research Agenda for Queer Issues in ICT4D. In *ICT4D 2022: Freedom and Social Inclusion in a Connected World.* Catholic Relief Services, 533--552.

[^26]: Didar Zowghi and Muneera Bano. 2024. AI for all: Diversity and Inclusion in AI. *AI and Ethics* (may 2024), 1--4. ABOUT THE AUTHORS: Michel Perilo holds a degree in Computer Science from the Federal Rural University of Pernambuco. He currently works as a software development consultant at Thoughtworks. He has a keen interest in studying topics related to responsible technology and design. George Valença is associate professor and innovation supervisor at the Department of Computing at UFRPE/Brazil. He has served as chief scientist of the Pernambuco Court of Accounts innovation initiative since 2020 via a technical cooperation involving more than 20 researchers. His research investigates the socio-technical challenges brought by Big Techs' platforms and ecosystems. In recent years, he has dedicated special attention to protect the rights of specific social groups in the digital environment, such as children and the LGTBQIAPN+ community. As a postdoctoral fellow, he investigates manipulative design patterns in the postgraduate course in Intelligence Technologies and Digital Design at PUC-SP. Aldenir Telles is a computer science undergraduate student at UFRPE and a final year undergraduate student in system analysis at SENAC college. Currently, they hold a developer internship position at Framework Digital. They possess a keen interest in studying subjects pertaining to inclusion and diversity within the field of Information Technology.